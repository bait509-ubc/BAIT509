{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAIT 509 Assignment 2\n",
    "\n",
    "__Evaluates__: Class meetings 04 and 05 (not 06, which is specific to your final project).\n",
    "\n",
    "__Due__: Monday, March 19 at 10:00am (i.e., the start of Class Meeting 07).\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "You must use proper spelling and grammar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifiers\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# other sklearn stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "# numpy and friends\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "In all of the below, when commenting on accuracy, be clear about the distinction between training accuracy and validation accuracy. Comment on both of these separately when appropriate.\n",
    "\n",
    "#### 1(a) \n",
    "\n",
    "You are tasked with classifying the handwritten digits (from lab 1). Explore the use of boosting with low depth decision trees for this task. Comment on the performance, both in an absolute sense and compared to your results from lab 1. Make a plot of classification error vs. `n_estimators` in the `AdaBoostClassifier` and interpret your results in the context of bias/variance. Make sure to clearly document your code and your results. We suggest using depth-3 decision trees as your base classifier. You're welcome to fiddle with hyperparameters such as the `learning_rate` in the `AdaBoostClassifier` (I found that lowering the learning rate made a prettier picture). \n",
    "\n",
    "Some starter code is below.\n",
    "\n",
    "(FYI: another popular approach, not covered in DSCI 571 but worth being aware of, is gradient boosting. See for example [GradientBoostingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html).)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree training error: 0.533055\n",
      "Tree test error: 0.502778\n",
      "Boost training error: 0.195546\n",
      "Boost test error: 0.275000\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "X = digits['data']   # these are the features (pixel intensities). split this into X_train and X_validation\n",
    "y = digits['target'] # these are the labels (0-9). split this into y_train and y_validation.\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "baseclass = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "baseclass.fit(X_train, y_train)\n",
    "print(\"Tree training error: %f\" % (1.0-baseclass.score(X_train,y_train)))\n",
    "print(\"Tree test error: %f\" % (1.0-baseclass.score(X_validation,y_validation)))\n",
    "\n",
    "boost = AdaBoostClassifier(baseclass)\n",
    "boost.fit(X_train, y_train)\n",
    "print(\"Boost training error: %f\" % (1.0-boost.score(X_train,y_train)))\n",
    "print(\"Boost test error: %f\" % (1.0-boost.score(X_validation,y_validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1(b)\n",
    "\n",
    "Try using decision trees with [bagging](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html). How well can you get it to work? Is `max_depth=3` still a good choice for the base classifier? Briefly discuss.\n",
    "\n",
    "#### (optional) 1(c)\n",
    "Implement bagging yourself (still using sklearn's DecisionTreeClassifier) and compare with the sklearn implementation.\n",
    "\n",
    "#### 1(d)\n",
    "\n",
    "Let's try model averaging. Take your 2 systems above, and 2 kNN classifiers with different $k$-values (of your choice). Have each of your systems \"vote\" on the digit class. Comment on the performance compared to each individual classifier. You can break ties in an arbitrary fashion of your choice. You can use [VotingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 4: decision trees with binary features\n",
    "\n",
    "The file `newsgroups.pkl` is a Pickle file containing the following objects:\n",
    "* `groupnames`: The names of four newsgroups.\n",
    "* `wordlist`: A list of words that occur in posts to these newsgroups.\n",
    "*  `X`: A binary matrix as a scipy sparse matrix ([documentation](http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.spmatrix.html#scipy.sparse.spmatrix); [more info](http://www.scipy-lectures.org/advanced/scipy_sparse/index.html)). Each row corresponds to a post, and each column corresponds to a word from the word list. A value of $1$ means that the word occured in the post. Note: if you want to convert a sparse matrix to a regular dense numpy array, do `X.toarray()`.\n",
    "* `y`: A vector with values $0$ through $3$, with the value corresponding to the newsgroup that the post came from (comp.*, rec.*, sci.*, talk.*).\n",
    "* `Xtest` and `ytest`: the word lists and newsgroup labels for additional newsgroup posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4(a) Implementing a decision tree\n",
    "\n",
    "rubric={reasoning:5}\n",
    "\n",
    "The documentation for the scikit-learn implementation of the decision tree classifier is at http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "Using sklearn's decision tree classifier, report the training and test accuracy when using a decision tree of depth $10$. Draw a decision tree corresponding to the one you train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4(c) Entropy Criterion (Optional)\n",
    "\n",
    "rubric={reasoning:2}\n",
    "\n",
    "Modify your code by creating an option to use information gain (entropy reduction) as a split criterion, rather than minimizing error. Compare the training and testing error in each case, with a tree of depth 10. Briefly discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Decision tree regression \n",
    "\n",
    "\n",
    "Decision trees can also be used for regression; see [here](http://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html) and [here](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) for implementations with `scikit-learn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3. Random Forests for classification\n",
    "rubric={reasoning:5}\n",
    "\n",
    "#### 3(a)\n",
    "\n",
    "Use [random forest classification](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) on the digits dataset. Compare the training and validation accuracy to your results from Exercise 1.\n",
    "\n",
    "#### 3(b)\n",
    "\n",
    "Pick 2 choices of the random forest hyperparameters (any 2 hyperparameter sets of your choosing, aside from the default) and report the training/validation error in each case. In each case, discuss whether you think there's any underfitting or overfitting.\n",
    " \n",
    "#### 3(c)\n",
    "\n",
    "What's one advantage and one disadvantage of random forests compared to classification models that we learned previously (kNN, decision trees)?\n",
    "\n",
    "#### 3(d)\n",
    "\n",
    "How much randomness is there really in **random** forests? Do the results change drastically if you re-fit a forest using the same data and same hyperparameters (try it)? If it does, is that worrying?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(e) random Forests for regression\n",
    "\n",
    "Try [random forest regression](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) on a regression problem of your choice. What are the pros and cons of this approach vs. linear regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "rubric={reasoning:2}\n",
    "\n",
    "Under what circumstances is boosting useful? Under what circumstances is model averaging useful? Discuss in the context of the bias/variance tradeoff. Maximum 3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Contemplating decision trees; Training error vs. test error, overfitting\n",
    "\n",
    "\n",
    "Recall the two parts of the fundamental bias-variance trade-off in machine learning:\n",
    "\n",
    "1. How small we can make the training error.\n",
    "2. How well the training error approximates the test error.\n",
    "\n",
    "In a decision tree classifier, how do the different parameters affect each of the two parts of the trade-off, if at all?\n",
    "\n",
    "Expanding on this by focusing in on the tree depth parameter, make a plot with the depth of the decision tree on the $x$-axis (varying it from $1$ through $15$) and the error on the training data $\\{X,y\\}$ on the $y$-axis. Then, make the analogous plot with test error instead of training error. Briefly explain your results. \n",
    "\n",
    "You can use sklearn's decision tree classifier for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-----------------\n",
    "__Attribution__: Much of this material is from Mark Schmidt via CPSC 340."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
