
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Lecture 4 - SVM with RBF Kernel and Feature Preprocessing &#8212; BAIT 509 - Business Applications of Machine Learning</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.37f24b989f4638ff9c27c22dc7559d4f.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="canonical" href="https://bait509-ubc.github.io/BAIT509/intro.html/lectures/lecture4.html" />
    <link rel="shortcut icon" href="../_static/bait_logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Lecture 5 - Preprocessing Categorical Features and Column Transformer" href="lecture5.html" />
    <link rel="prev" title="Lecture 3 - Baseline, k-Nearest Neighbours" href="lecture3.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://bait509-ubc.github.io/BAIT509/intro.html/lectures/lecture4.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Lecture 4 - SVM with RBF Kernel and Feature Preprocessing" />
<meta property="og:description" content="Lecture 4 - SVM with RBF Kernel and Feature Preprocessing  Hayley Boyce, Wednesday, April 28th 2021  &lt;h1&gt;Table of Contents&lt;span class=&#34;tocSkip&#34;&gt;&lt;/span&gt;&lt;/h1&gt; &lt;di" />
<meta property="og:image"       content="https://bait509-ubc.github.io/BAIT509/intro.html/_static/bait_logo.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/bait_logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">BAIT 509 - Business Applications of Machine Learning</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Things You Should Know
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/who.html">
   Who: Hayley Boyce
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/how.html">
   How: The Course Structure
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/what.html">
   What: Learning Outcomes
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="lecture1.html">
   Lecture 1 - Introduction to Machine Learning &amp; The Decision Tree Algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture2.html">
   Lecture 2 - Splitting and Cross-validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture3.html">
   Lecture 3 - Baseline, k-Nearest Neighbours
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Lecture 4 - SVM with RBF Kernel and Feature Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture5.html">
   Lecture 5 - Preprocessing Categorical Features and Column Transformer
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/attribution.html">
   Attribution
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/lectures/lecture4.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/bait509-ubc/BAIT509"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/bait509-ubc/BAIT509/issues/new?title=Issue%20on%20page%20%2Flectures/lecture4.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/bait509-ubc/BAIT509/edit/master/lectures/lecture4.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/bait509-ubc/BAIT509/master?urlpath=tree/lectures/lecture4.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#house-keeping">
   House Keeping
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lecture-learning-objectives">
   Lecture Learning Objectives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#five-minute-recap-lightning-questions">
   Five Minute Recap/ Lightning Questions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-lingering-questions">
     Some lingering questions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-with-k-nn">
   Regression with
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -NN
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pros-and-cons-of-k-nearest-neighbours">
   Pros and Cons of ùëò -Nearest Neighbours
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pros">
     Pros:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cons">
     Cons:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice">
   Let‚Äôs Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#support-vector-machines-svms-with-rbf-kernel">
   Support Vector Machines (SVMs) with RBF Kernel
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperparameters-of-svm">
     Hyperparameters of SVM
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gamma-and-the-fundamental-trade-off">
       <code class="docutils literal notranslate">
        <span class="pre">
         gamma
        </span>
       </code>
       and the fundamental trade-off
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#c-and-the-fundamental-trade-off">
       <code class="docutils literal notranslate">
        <span class="pre">
         C
        </span>
       </code>
       and the fundamental trade-off
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Let‚Äôs Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing">
   Preprocessing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-importance-of-preprocessing-an-example-of-why">
     The importance of Preprocessing - An Example of Why
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#basketball-dataset">
       Basketball dataset
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sklearn-s-predict-vs-transform">
     Sklearn‚Äôs
     <em>
      predict
     </em>
     vs
     <em>
      transform
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#common-preprocessing-techniques">
     Common preprocessing techniques
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   Let‚Äôs Practice!
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#california-housing-data-a-case-study">
   California housing data (A case study)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#when-is-it-ok-to-do-things-before-splitting">
     When is it OK to do things before splitting?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing-imputation">
   Preprocessing: Imputation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-we-don-t-drop-the-rows">
     Why we don‚Äôt drop the rows
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-we-don-t-drop-the-column">
     Why we don‚Äôt drop the column
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-we-use-imputation">
     Why we use imputation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing-scaling">
   Preprocessing: Scaling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   Let‚Äôs Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-transformations-and-the-golden-rule">
   Feature transformations and the golden rule
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bad-methodology-1-scaling-the-data-separately">
     Bad methodology 1: Scaling the data separately
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bad-methodology-2-scaling-the-data-together">
     Bad methodology 2: Scaling the data together
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pipelines">
   Pipelines
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   Let‚Äôs Practice
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#practice-coding-problem">
     Practice Coding Problem
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-we-ve-learned-today-a-id-9-a">
   What We‚Äôve Learned Today
   <a id="9">
   </a>
  </a>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="lecture-4-svm-with-rbf-kernel-and-feature-preprocessing">
<h1>Lecture 4 - SVM with RBF Kernel and Feature Preprocessing<a class="headerlink" href="#lecture-4-svm-with-rbf-kernel-and-feature-preprocessing" title="Permalink to this headline">¬∂</a></h1>
<p><em>Hayley Boyce, Wednesday, April 28th 2021</em></p>
<h1>Table of Contents<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#House-Keeping" data-toc-modified-id="House-Keeping-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>House Keeping</a></span></li><li><span><a href="#Lecture-Learning-Objectives" data-toc-modified-id="Lecture-Learning-Objectives-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Lecture Learning Objectives</a></span></li><li><span><a href="#Five-Minute-Recap/-Lightning-Questions" data-toc-modified-id="Five-Minute-Recap/-Lightning-Questions-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Five Minute Recap/ Lightning Questions</a></span><ul class="toc-item"><li><span><a href="#Some-lingering-questions" data-toc-modified-id="Some-lingering-questions-3.1"><span class="toc-item-num">3.1&nbsp;&nbsp;</span>Some lingering questions</a></span></li></ul></li><li><span><a href="#Regression-with-$k$-NN" data-toc-modified-id="Regression-with-$k$-NN-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>Regression with $k$-NN</a></span></li><li><span><a href="#Pros-and-Cons-of-ùëò--Nearest-Neighbours" data-toc-modified-id="Pros-and-Cons-of-ùëò--Nearest-Neighbours-5"><span class="toc-item-num">5&nbsp;&nbsp;</span>Pros and Cons of ùëò -Nearest Neighbours</a></span><ul class="toc-item"><li><span><a href="#Pros:" data-toc-modified-id="Pros:-5.1"><span class="toc-item-num">5.1&nbsp;&nbsp;</span>Pros:</a></span></li><li><span><a href="#Cons:" data-toc-modified-id="Cons:-5.2"><span class="toc-item-num">5.2&nbsp;&nbsp;</span>Cons:</a></span></li></ul></li><li><span><a href="#Let's-Practice" data-toc-modified-id="Let's-Practice-6"><span class="toc-item-num">6&nbsp;&nbsp;</span>Let's Practice</a></span></li><li><span><a href="#Support-Vector-Machines-(SVMs)-with-RBF-Kernel" data-toc-modified-id="Support-Vector-Machines-(SVMs)-with-RBF-Kernel-7"><span class="toc-item-num">7&nbsp;&nbsp;</span>Support Vector Machines (SVMs) with RBF Kernel</a></span><ul class="toc-item"><li><span><a href="#Hyperparameters-of-SVM" data-toc-modified-id="Hyperparameters-of-SVM-7.1"><span class="toc-item-num">7.1&nbsp;&nbsp;</span>Hyperparameters of SVM</a></span><ul class="toc-item"><li><span><a href="#gamma-and-the-fundamental-trade-off" data-toc-modified-id="gamma-and-the-fundamental-trade-off-7.1.1"><span class="toc-item-num">7.1.1&nbsp;&nbsp;</span><code>gamma</code> and the fundamental trade-off</a></span></li><li><span><a href="#C-and-the-fundamental-trade-off" data-toc-modified-id="C-and-the-fundamental-trade-off-7.1.2"><span class="toc-item-num">7.1.2&nbsp;&nbsp;</span><code>C</code> and the fundamental trade-off</a></span></li></ul></li></ul></li><li><span><a href="#Let's-Practice" data-toc-modified-id="Let's-Practice-8"><span class="toc-item-num">8&nbsp;&nbsp;</span>Let's Practice</a></span></li><li><span><a href="#Preprocessing" data-toc-modified-id="Preprocessing-9"><span class="toc-item-num">9&nbsp;&nbsp;</span>Preprocessing</a></span><ul class="toc-item"><li><span><a href="#The-importance-of-Preprocessing---An-Example-of-Why" data-toc-modified-id="The-importance-of-Preprocessing---An-Example-of-Why-9.1"><span class="toc-item-num">9.1&nbsp;&nbsp;</span>The importance of Preprocessing - An Example of Why</a></span><ul class="toc-item"><li><span><a href="#Basketball-dataset" data-toc-modified-id="Basketball-dataset-9.1.1"><span class="toc-item-num">9.1.1&nbsp;&nbsp;</span>Basketball dataset</a></span></li></ul></li><li><span><a href="#Sklearn's-predict-vs-transform" data-toc-modified-id="Sklearn's-predict-vs-transform-9.2"><span class="toc-item-num">9.2&nbsp;&nbsp;</span>Sklearn's <em>predict</em> vs <em>transform</em></a></span></li><li><span><a href="#Common-preprocessing-techniques" data-toc-modified-id="Common-preprocessing-techniques-9.3"><span class="toc-item-num">9.3&nbsp;&nbsp;</span>Common preprocessing techniques</a></span></li></ul></li><li><span><a href="#Let's-Practice!" data-toc-modified-id="Let's-Practice!-10"><span class="toc-item-num">10&nbsp;&nbsp;</span>Let's Practice!</a></span></li><li><span><a href="#California-housing-data-(A-case-study)" data-toc-modified-id="California-housing-data-(A-case-study)-11"><span class="toc-item-num">11&nbsp;&nbsp;</span>California housing data (A case study)</a></span><ul class="toc-item"><li><span><a href="#When-is-it-OK-to-do-things-before-splitting?" data-toc-modified-id="When-is-it-OK-to-do-things-before-splitting?-11.1"><span class="toc-item-num">11.1&nbsp;&nbsp;</span>When is it OK to do things before splitting?</a></span></li></ul></li><li><span><a href="#Preprocessing:-Imputation" data-toc-modified-id="Preprocessing:-Imputation-12"><span class="toc-item-num">12&nbsp;&nbsp;</span>Preprocessing: Imputation</a></span><ul class="toc-item"><li><span><a href="#Why-we-don't-drop-the-rows" data-toc-modified-id="Why-we-don't-drop-the-rows-12.1"><span class="toc-item-num">12.1&nbsp;&nbsp;</span>Why we don't drop the rows</a></span></li><li><span><a href="#Why-we-don't-drop-the-column" data-toc-modified-id="Why-we-don't-drop-the-column-12.2"><span class="toc-item-num">12.2&nbsp;&nbsp;</span>Why we don't drop the column</a></span></li><li><span><a href="#Why-we-use-imputation" data-toc-modified-id="Why-we-use-imputation-12.3"><span class="toc-item-num">12.3&nbsp;&nbsp;</span>Why we use imputation</a></span></li></ul></li><li><span><a href="#Preprocessing:-Scaling" data-toc-modified-id="Preprocessing:-Scaling-13"><span class="toc-item-num">13&nbsp;&nbsp;</span>Preprocessing: Scaling</a></span></li><li><span><a href="#Let's-Practice" data-toc-modified-id="Let's-Practice-14"><span class="toc-item-num">14&nbsp;&nbsp;</span>Let's Practice</a></span></li><li><span><a href="#Feature-transformations-and-the-golden-rule" data-toc-modified-id="Feature-transformations-and-the-golden-rule-15"><span class="toc-item-num">15&nbsp;&nbsp;</span>Feature transformations and the golden rule</a></span><ul class="toc-item"><li><span><a href="#Bad-methodology-1:-Scaling-the-data-separately" data-toc-modified-id="Bad-methodology-1:-Scaling-the-data-separately-15.1"><span class="toc-item-num">15.1&nbsp;&nbsp;</span>Bad methodology 1: Scaling the data separately</a></span></li><li><span><a href="#Bad-methodology-2:-Scaling-the-data-together" data-toc-modified-id="Bad-methodology-2:-Scaling-the-data-together-15.2"><span class="toc-item-num">15.2&nbsp;&nbsp;</span>Bad methodology 2: Scaling the data together</a></span></li></ul></li><li><span><a href="#Pipelines" data-toc-modified-id="Pipelines-16"><span class="toc-item-num">16&nbsp;&nbsp;</span>Pipelines</a></span></li><li><span><a href="#Let's-Practice" data-toc-modified-id="Let's-Practice-17"><span class="toc-item-num">17&nbsp;&nbsp;</span>Let's Practice</a></span><ul class="toc-item"><li><span><a href="#Practice-Coding-Problem" data-toc-modified-id="Practice-Coding-Problem-17.1"><span class="toc-item-num">17.1&nbsp;&nbsp;</span>Practice Coding Problem</a></span></li></ul></li><li><span><a href="#What-We've-Learned-Today" data-toc-modified-id="What-We've-Learned-Today-18"><span class="toc-item-num">18&nbsp;&nbsp;</span>What We've Learned Today<a id="9"></a></a></span></li></ul></div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importing our libraries</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">altair</span> <span class="k">as</span> <span class="nn">alt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span><span class="p">,</span> <span class="n">DummyRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span><span class="p">,</span> <span class="n">train_test_split</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;code/&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">display_tree</span> <span class="kn">import</span> <span class="n">display_tree</span>
<span class="kn">from</span> <span class="nn">plot_classifier</span> <span class="kn">import</span> <span class="n">plot_classifier</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Preprocessing and pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">euclidean_distances</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">OrdinalEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="house-keeping">
<h2>House Keeping<a class="headerlink" href="#house-keeping" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p>Assignment due today at 11:59pm!</p></li>
<li><p>Course feedback!</p></li>
<li><p>Assignment - things I should know?</p></li>
<li><p>Assignment2 - before or after the weekend?</p></li>
<li><p>Polls coming Monday!</p></li>
<li><p>I hear you don‚Äôt like breakout rooms, let‚Äôs try this lecture without them!</p></li>
<li><p>Per the announcement Monday, download the data for this lecture <a class="reference external" href="https://www.kaggle.com/harrywang/housing">here</a> and include it in your <code class="docutils literal notranslate"><span class="pre">data</span></code> folder that resides in <code class="docutils literal notranslate"><span class="pre">lectures</span></code>.</p></li>
</ul>
</div>
<div class="section" id="lecture-learning-objectives">
<h2>Lecture Learning Objectives<a class="headerlink" href="#lecture-learning-objectives" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p>Identify when to implement feature transformations such as imputation and scaling.</p></li>
<li><p>Describe the difference between normalizing and standardizing and be able to use scikit-learn‚Äôs <code class="docutils literal notranslate"><span class="pre">MinMaxScaler()</span></code> and <code class="docutils literal notranslate"><span class="pre">StandardScaler()</span></code> to pre-process numeric features.</p></li>
<li><p>Apply <code class="docutils literal notranslate"><span class="pre">sklearn.pipeline.Pipeline</span></code> to build a machine learning pipeline.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> for applying numerical feature transformations to the data.</p></li>
<li><p>Discuss the golden rule in the context of feature transformations.</p></li>
</ul>
</div>
<div class="section" id="five-minute-recap-lightning-questions">
<h2>Five Minute Recap/ Lightning Questions<a class="headerlink" href="#five-minute-recap-lightning-questions" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p>When using a Dummy Regressor what value does the model predict for unseen data?</p></li>
<li><p>When using a Dummy Classifier (the one we examined in lecture) what class does the model predict for unseen data?</p></li>
<li><p>What is the name of the distance metric used in the <span class="math notranslate nohighlight">\(k\)</span>-nn model we looked at?</p></li>
<li><p>If a dataset has 14 features and 1 target column, how many dimensions will the feature vector be?</p></li>
<li><p>What is the hyperparameter name of the <span class="math notranslate nohighlight">\(k\)</span>-nn classifier we looked at last lecture?</p></li>
</ul>
<div class="section" id="some-lingering-questions">
<h3>Some lingering questions<a class="headerlink" href="#some-lingering-questions" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p>How does a <span class="math notranslate nohighlight">\(k\)</span>-nn Regressor work?</p></li>
<li><p>Are we ready to do machine learning on real-world datasets?</p></li>
<li><p>We‚Äôve looked at data with numeric features but what do we do if we have features with categories or string values?</p></li>
<li><p>What happens if we are missing data in our features?</p></li>
<li><p>Is there a cleaner way to do all the steps we need to do?</p></li>
</ul>
</div>
</div>
<div class="section" id="regression-with-k-nn">
<h2>Regression with <span class="math notranslate nohighlight">\(k\)</span>-NN<a class="headerlink" href="#regression-with-k-nn" title="Permalink to this headline">¬∂</a></h2>
<p>In <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbour regression, we take the average of <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbours instead of the majority vote.</p>
<p>Let‚Äôs look at an example.</p>
<p>Here we are creating some synthetic data with fifty examples and only one feature.</p>
<p>We only have one feature of <code class="docutils literal notranslate"><span class="pre">length</span></code> and our goal is to predict <code class="docutils literal notranslate"><span class="pre">weight</span></code>.</p>
<p>Regression plots more naturally in 1D, classification in 2D, but of course we can do either for any <span class="math notranslate nohighlight">\(d\)</span></p>
<p>Right now, do not worry about the code and only focus on data and our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">X_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">n</span><span class="p">)</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_1</span><span class="p">[:,</span><span class="kc">None</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;length&#39;</span><span class="p">])</span>
<span class="n">X</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.017641</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.044818</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.091420</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.144858</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.181941</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="mi">2</span> <span class="o">+</span> <span class="n">X_1</span><span class="p">[:,</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="mi">5</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">])</span>
<span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>weight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.879136</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.997894</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.478710</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.085554</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.966069</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">snake_X_train</span><span class="p">,</span> <span class="n">snake_X_test</span><span class="p">,</span> <span class="n">snake_y_train</span><span class="p">,</span> <span class="n">snake_y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let‚Äôs visualize our training data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">source</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">snake_X_train</span><span class="p">,</span> <span class="n">snake_y_train</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">scatter</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span><span class="o">.</span><span class="n">mark_point</span><span class="p">(</span><span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
    <span class="n">alt</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="s1">&#39;length:Q&#39;</span><span class="p">),</span>
    <span class="n">alt</span><span class="o">.</span><span class="n">Y</span><span class="p">(</span><span class="s1">&#39;weight:Q&#39;</span><span class="p">))</span>

<span class="n">scatter</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<div id="altair-viz-78994d4703604e68b45e5cd47c487ae6"></div>
<script type="text/javascript">
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== "altair-viz-78994d4703604e68b45e5cd47c487ae6") {
      outputDiv = document.getElementById("altair-viz-78994d4703604e68b45e5cd47c487ae6");
    }
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm//vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm//vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm//vega-embed@6?noext",
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () => resolve(paths[lib]);
        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName("head")[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === "function") {
      displayChart(vegaEmbed);
    } else {
      loadScript("vega")
        .then(() => loadScript("vega-lite"))
        .then(() => loadScript("vega-embed"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 400, "continuousHeight": 300}}, "data": {"name": "data-b6b36d9253ffa44549ee85a5d64b6eb6"}, "mark": {"type": "point", "color": "green", "filled": true}, "encoding": {"x": {"type": "quantitative", "field": "length"}, "y": {"type": "quantitative", "field": "weight"}}, "height": 300, "width": 500, "$schema": "https://vega.github.io/schema/vega-lite/v4.8.1.json", "datasets": {"data-b6b36d9253ffa44549ee85a5d64b6eb6": [{"length": 0.8636790430972607, "weight": 4.576361037001124}, {"length": 1.9261422504970944, "weight": 13.202452240297143}, {"length": 0.4635223269063644, "weight": 3.036717957612905}, {"length": 1.659269208383312, "weight": 10.741236182681416}, {"length": 0.19430885385429708, "weight": 1.8282080103323208}, {"length": 0.04481789861428447, "weight": 0.9978944887899464}, {"length": 0.25439884335892937, "weight": 1.4050286615609828}, {"length": 1.1001689778262722, "weight": 6.658544218660192}, {"length": 1.9978725971978604, "weight": 10.793341712878705}, {"length": 1.00228938297457, "weight": 5.816130197227949}, {"length": 1.269087747645001, "weight": 8.14709171213338}, {"length": 0.6155816412329262, "weight": 3.8814700785811547}, {"length": 1.430134918262468, "weight": 10.942452943373507}, {"length": 1.0616820749689326, "weight": 7.050004673208427}, {"length": 0.2842007136313087, "weight": 2.0259473636361065}, {"length": 0.790796632453904, "weight": 5.412164286624593}, {"length": 1.9430446949938083, "weight": 9.969047660376281}, {"length": 0.1448579115838513, "weight": 3.0855539261640805}, {"length": 0.9313538600000172, "weight": 7.126420940707391}, {"length": 1.790821845529422, "weight": 9.666842021995915}, {"length": 0.18194088602394864, "weight": 0.9660688867970529}, {"length": 0.6680020152213719, "weight": 6.6004067700389495}, {"length": 1.481690661909318, "weight": 9.76601245186589}, {"length": 0.5758672037560256, "weight": 3.2341883032876337}, {"length": 1.7746097947686443, "weight": 10.826327046810647}, {"length": 1.0058645065193186, "weight": 6.3989427144772195}, {"length": 1.5222278801204971, "weight": 7.970989072227188}, {"length": 1.5888137071881239, "weight": 10.052971989802893}, {"length": 0.3714529237948939, "weight": 2.5827469509487457}, {"length": 1.2972445915032906, "weight": 7.4175478369773735}, {"length": 1.3271308108279647, "weight": 9.708141426694272}, {"length": 0.9066035456620644, "weight": 6.811819097396922}, {"length": 1.697223012379464, "weight": 8.902665018051042}, {"length": 0.7669692466886153, "weight": 3.9387370250353544}, {"length": 0.6918259683827501, "weight": 4.384694352965299}, {"length": 1.5471471399891856, "weight": 9.877240942967013}, {"length": 1.3842759805475549, "weight": 9.897884290328975}, {"length": 1.1581849350007274, "weight": 6.414029739258383}, {"length": 0.09142003290228187, "weight": 1.4787104396491553}, {"length": 1.832353950861439, "weight": 10.574916090691092}]}}, {"mode": "vega-lite"});
</script></div></div>
</div>
<p>Now let‚Äôs try the <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbours regressor on this data.</p>
<p>Then we create our <code class="docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code> object with <code class="docutils literal notranslate"><span class="pre">n_neighbors=1</span></code> so we are only considering 1 neighbour and with <code class="docutils literal notranslate"><span class="pre">uniform</span></code> weights.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>

<span class="n">knnr_1</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;uniform&quot;</span><span class="p">)</span>
<span class="n">knnr_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">,</span><span class="n">snake_y_train</span><span class="p">);</span>

<span class="n">predicted</span> <span class="o">=</span> <span class="n">knnr_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">)</span>
<span class="n">predicted</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 4.57636104],
       [13.20245224],
       [ 3.03671796],
       [10.74123618],
       [ 1.82820801],
       [ 0.99789449],
       [ 1.40502866],
       [ 6.65854422],
       [10.79334171],
       [ 5.8161302 ],
       [ 8.14709171],
       [ 3.88147008],
       [10.94245294],
       [ 7.05000467],
       [ 2.02594736],
       [ 5.41216429],
       [ 9.96904766],
       [ 3.08555393],
       [ 7.12642094],
       [ 9.66684202],
       [ 0.96606889],
       [ 6.60040677],
       [ 9.76601245],
       [ 3.2341883 ],
       [10.82632705],
       [ 6.39894271],
       [ 7.97098907],
       [10.05297199],
       [ 2.58274695],
       [ 7.41754784],
       [ 9.70814143],
       [ 6.8118191 ],
       [ 8.90266502],
       [ 3.93873703],
       [ 4.38469435],
       [ 9.87724094],
       [ 9.89788429],
       [ 6.41402974],
       [ 1.47871044],
       [10.57491609]])
</pre></div>
</div>
</div>
</div>
<p>If we scored over regressors we get this perfect score of one since we have <code class="docutils literal notranslate"><span class="pre">n_neighbors=1</span></code> we are likely to overfit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knnr_1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">,</span> <span class="n">snake_y_train</span><span class="p">)</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
<p>Plotting this we can see our model is trying to get every example correct since n_neighbors=1. (the mean of 1 point is just going to be the point value)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">),</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">knnr_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">grid</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">,</span> <span class="n">snake_y_train</span><span class="p">,</span> <span class="s2">&quot;.r&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;length&quot;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture4_18_0.png" src="../_images/lecture4_18_0.png" />
</div>
</div>
<p>What happens when we use <code class="docutils literal notranslate"><span class="pre">n_neighbors=10</span></code>?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knnr_10</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;uniform&quot;</span><span class="p">)</span>
<span class="n">knnr_10</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">,</span> <span class="n">snake_y_train</span><span class="p">)</span>
<span class="n">knnr_10</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">,</span> <span class="n">snake_y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9254540554756747
</pre></div>
</div>
</div>
</div>
<p>Now we can see we are getting a lower score over the training set. Our score decreased from 1.0 when to had <code class="docutils literal notranslate"><span class="pre">n_neighbors=1</span></code> to now having a score of 0.925.</p>
<p>When we plot our model, we can see that it no longer is trying to get every example correct.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">knnr_10</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">grid</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">,</span> <span class="n">snake_y_train</span><span class="p">,</span> <span class="s2">&quot;.r&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">16</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">16</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;length&quot;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">16</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture4_22_0.png" src="../_images/lecture4_22_0.png" />
</div>
</div>
</div>
<div class="section" id="pros-and-cons-of-k-nearest-neighbours">
<h2>Pros and Cons of ùëò -Nearest Neighbours<a class="headerlink" href="#pros-and-cons-of-k-nearest-neighbours" title="Permalink to this headline">¬∂</a></h2>
<div class="section" id="pros">
<h3>Pros:<a class="headerlink" href="#pros" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p>Easy to understand, interpret.</p></li>
<li><p>Simply hyperparameter <span class="math notranslate nohighlight">\(k\)</span> (<code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code>) controlling the fundamental tradeoff.</p></li>
<li><p>Can learn very complex functions given enough data.</p></li>
<li><p>Lazy learning: Takes no time to <code class="docutils literal notranslate"><span class="pre">fit</span></code></p></li>
</ul>
<br>
</div>
<div class="section" id="cons">
<h3>Cons:<a class="headerlink" href="#cons" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p>Can potentially be VERY slow during prediction time.</p></li>
<li><p>Often not that great test accuracy compared to the modern approaches.</p></li>
<li><p>Need to scale your features. We‚Äôll be looking into this in an upcoming lecture (lecture 4 I think?).</p></li>
</ul>
</div>
</div>
<div class="section" id="let-s-practice">
<h2>Let‚Äôs Practice<a class="headerlink" href="#let-s-practice" title="Permalink to this headline">¬∂</a></h2>
<div class="math notranslate nohighlight">
\[\begin{split} X = \begin{bmatrix}5 &amp; 2\\4 &amp; 3\\  2 &amp; 2\\ 10 &amp; 10\\ 9 &amp; -1\\ 9&amp; 9\end{bmatrix}, \quad y = \begin{bmatrix}0\\0\\1\\1\\1\\2\end{bmatrix}.\end{split}\]</div>
<p>If <span class="math notranslate nohighlight">\(k=3\)</span>, what would you predict for <span class="math notranslate nohighlight">\(x=\begin{bmatrix} 0\\0\end{bmatrix}\)</span> if we were doing regression rather than classification?</p>
</div>
<div class="section" id="support-vector-machines-svms-with-rbf-kernel">
<h2>Support Vector Machines (SVMs) with RBF Kernel<a class="headerlink" href="#support-vector-machines-svms-with-rbf-kernel" title="Permalink to this headline">¬∂</a></h2>
<p>Another popular similarity-based algorithm is Support Vector Machines (SVM).</p>
<p>SVMs use a different similarity metric which is called a ‚Äúkernel‚Äù in ‚ÄúSVM land‚Äù.</p>
<p>We are going to concentrate on the specific kernel called Radial Basis Functions (RBFs).</p>
<p>Back to the good ol‚Äô Canadian and USA cities data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cities_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/canada_usa_cities.csv&quot;</span><span class="p">)</span>
<span class="n">cities_train_df</span><span class="p">,</span> <span class="n">cities_test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cities_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">cities_train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>160</th>
      <td>-76.4813</td>
      <td>44.2307</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>127</th>
      <td>-81.2496</td>
      <td>42.9837</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>169</th>
      <td>-66.0580</td>
      <td>45.2788</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>188</th>
      <td>-73.2533</td>
      <td>45.3057</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>187</th>
      <td>-67.9245</td>
      <td>47.1652</td>
      <td>Canada</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cities_X_train</span> <span class="o">=</span> <span class="n">cities_train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">])</span>
<span class="n">cities_y_train</span> <span class="o">=</span> <span class="n">cities_train_df</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">]</span>
<span class="n">cities_X_test</span> <span class="o">=</span> <span class="n">cities_test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">])</span>
<span class="n">cities_y_test</span> <span class="o">=</span> <span class="n">cities_test_df</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">]</span>

<span class="n">cities_X_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>160</th>
      <td>-76.4813</td>
      <td>44.2307</td>
    </tr>
    <tr>
      <th>127</th>
      <td>-81.2496</td>
      <td>42.9837</td>
    </tr>
    <tr>
      <th>169</th>
      <td>-66.0580</td>
      <td>45.2788</td>
    </tr>
    <tr>
      <th>188</th>
      <td>-73.2533</td>
      <td>45.3057</td>
    </tr>
    <tr>
      <th>187</th>
      <td>-67.9245</td>
      <td>47.1652</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cities_y_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>160    Canada
127    Canada
169    Canada
188    Canada
187    Canada
Name: country, dtype: object
</pre></div>
</div>
</div>
</div>
<p>Unlike with <span class="math notranslate nohighlight">\(k\)</span>-nn, we are  not going into detail about how support vector machine classifiers or regressor works but more so on how to use it with <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>.</p>
<p>We can use our training feature table (<span class="math notranslate nohighlight">\(X\)</span>) and target (<span class="math notranslate nohighlight">\(y\)</span>) values by using this new SVM model with (RBF) but with the old set up with <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> and <code class="docutils literal notranslate"><span class="pre">.score()</span></code> that we have seen time and time again.</p>
<p>We import the <code class="docutils literal notranslate"><span class="pre">SVC</span></code> tool from the <code class="docutils literal notranslate"><span class="pre">sklearn.svm</span></code> library (The ‚ÄúC‚Äù in SVC represents  <em>Classifier</em>.</p>
<p>To import the regressor we import <code class="docutils literal notranslate"><span class="pre">SVR</span></code> - R for <em>Regressor</em>)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
</pre></div>
</div>
</div>
</div>
<p>We can cross-validate and score exactly how we saw before.</p>
<p>(For now, ignore <code class="docutils literal notranslate"><span class="pre">gamma=0.01</span></code> we are addressing it coming up)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">cities_X_train</span><span class="p">,</span> <span class="n">cities_y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.002341</td>
      <td>0.001332</td>
      <td>0.823529</td>
      <td>0.842105</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.002276</td>
      <td>0.001902</td>
      <td>0.823529</td>
      <td>0.842105</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.002765</td>
      <td>0.001634</td>
      <td>0.727273</td>
      <td>0.858209</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.001918</td>
      <td>0.001321</td>
      <td>0.787879</td>
      <td>0.843284</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.002797</td>
      <td>0.001794</td>
      <td>0.939394</td>
      <td>0.805970</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm_cv_score</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">svm_cv_score</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8203208556149733
</pre></div>
</div>
</div>
</div>
<p>The biggest thing to know about support vector machines is that superficially, support vector machines are very similar to ùëò-Nearest Neighbours.</p>
<p>You can think of SVM with RBF kernel as a ‚Äúsmoothed‚Äù version of the <span class="math notranslate nohighlight">\(k\)</span>-Nearest Neighbours.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cities_X_train</span><span class="p">,</span> <span class="n">cities_y_train</span><span class="p">);</span>

<span class="n">kn5_model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">kn5_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cities_X_train</span><span class="p">,</span> <span class="n">cities_y_train</span><span class="p">);</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;SVC&quot;</span><span class="p">)</span>
<span class="n">plot_classifier</span><span class="p">(</span><span class="n">cities_X_train</span><span class="p">,</span> <span class="n">cities_y_train</span><span class="p">,</span> <span class="n">svm</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;KNN with k = 5&quot;</span><span class="p">)</span>
<span class="n">plot_classifier</span><span class="p">(</span><span class="n">cities_X_train</span><span class="p">,</span> <span class="n">cities_y_train</span><span class="p">,</span> <span class="n">kn5_model</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">());</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture4_37_0.png" src="../_images/lecture4_37_0.png" />
</div>
</div>
<p>An observation is classified as a positive class if on average it looks more like positive examples. An observation is classified as a negative class if on average it looks more like negative examples.</p>
<p>The primary difference between ùëò-NNs and SVMs is that:</p>
<ul class="simple">
<li><p>Unlike <span class="math notranslate nohighlight">\(k\)</span>-NNs, SVMs only remember the key examples (Those examples are called <strong>support vectors</strong>).</p></li>
<li><p>When it comes to predicting a query point, we only consider the key examples from the data and only calculate the distance to these key examples. This makes it more efficient than ùëò-NN.</p></li>
</ul>
<div class="section" id="hyperparameters-of-svm">
<h3>Hyperparameters of SVM<a class="headerlink" href="#hyperparameters-of-svm" title="Permalink to this headline">¬∂</a></h3>
<p>There are  2 main hyperparameters for support vector machines with an RBF kernel;</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">gamma</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">C</span></code></p></li>
</ul>
<p>(told you we were coming back to it!)</p>
<p>We are not equipped to understand the meaning of these parameters at this point but you are expected to describe their relationship to the fundamental tradeoff.</p>
<p>(In short, <code class="docutils literal notranslate"><span class="pre">C</span></code> is the penalty the model accepts for wrongly classified examples, and <code class="docutils literal notranslate"><span class="pre">gamma</span></code> is the curvature (see <a class="reference external" href="https://towardsdatascience.com/hyperparameter-tuning-for-support-vector-machines-c-and-gamma-parameters-6a5097416167">here</a> for more)</p>
<p>See <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html"><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>‚Äôs explanation of RBF SVM parameters</a></p>
<div class="section" id="gamma-and-the-fundamental-trade-off">
<h4><code class="docutils literal notranslate"><span class="pre">gamma</span></code> and the fundamental trade-off<a class="headerlink" href="#gamma-and-the-fundamental-trade-off" title="Permalink to this headline">¬∂</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">gamma</span></code> controls the complexity of a model, just like other hyperparameters we‚Äôve seen.</p>
<ul class="simple">
<li><p>higher gamma, higher the complexity.</p></li>
<li><p>lower gamma, lower the complexity.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">10.0</span> <span class="o">**</span> <span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">rbf_svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">)</span>
    <span class="n">rbf_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cities_X_train</span><span class="p">,</span> <span class="n">cities_y_train</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;gamma = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">gamma</span><span class="p">);</span>
    <span class="n">plot_classifier</span><span class="p">(</span><span class="n">cities_X_train</span><span class="p">,</span> <span class="n">cities_y_train</span><span class="p">,</span> <span class="n">rbf_svm</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">(),</span> <span class="n">show_data</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture4_41_0.png" src="../_images/lecture4_41_0.png" />
</div>
</div>
</div>
<div class="section" id="c-and-the-fundamental-trade-off">
<h4><code class="docutils literal notranslate"><span class="pre">C</span></code> and the fundamental trade-off<a class="headerlink" href="#c-and-the-fundamental-trade-off" title="Permalink to this headline">¬∂</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">C</span></code> also controls the complexity of a model and in turn the fundamental tradeoff.</p>
<ul class="simple">
<li><p>higher <code class="docutils literal notranslate"><span class="pre">C</span></code> values, higher the complexity.</p></li>
<li><p>lower <code class="docutils literal notranslate"><span class="pre">C</span></code> values, lower the complexity.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <span class="mf">10.0</span> <span class="o">**</span> <span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">rbf_svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">rbf_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cities_X_train</span><span class="p">,</span> <span class="n">cities_y_train</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;C = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">C</span><span class="p">);</span>
    <span class="n">plot_classifier</span><span class="p">(</span><span class="n">cities_X_train</span><span class="p">,</span> <span class="n">cities_y_train</span><span class="p">,</span> <span class="n">rbf_svm</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">(),</span> <span class="n">show_data</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture4_43_0.png" src="../_images/lecture4_43_0.png" />
</div>
</div>
<p>Obtaining optimal validation scores requires a hyperparameter search between both <code class="docutils literal notranslate"><span class="pre">gamma</span></code> and <code class="docutils literal notranslate"><span class="pre">C</span></code> to balance the fundamental trade-off.
We will learn how to search over multiple hyperparameters at a time in lecture 5.</p>
</div>
</div>
</div>
<div class="section" id="id1">
<h2>Let‚Äôs Practice<a class="headerlink" href="#id1" title="Permalink to this headline">¬∂</a></h2>
<p><strong>True or False</strong></p>
<p>1.In Scikit Learn‚Äôs SVC classifier, large values of gamma tend to result in higher training scores but probably lower validation scores.<br />
2.If we increase both <code class="docutils literal notranslate"><span class="pre">gamma</span></code> and <code class="docutils literal notranslate"><span class="pre">C</span></code>, we can‚Äôt be certain if the model becomes more complex or less complex.</p>
<p><strong>Coding practice</strong></p>
<p>Below is some starter code that creates your feature table and target column from the data from the <code class="docutils literal notranslate"><span class="pre">bball.csv</span></code> dataset (in the data folder).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bball_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/bball.csv&#39;</span><span class="p">)</span>
<span class="n">bball_df</span> <span class="o">=</span> <span class="n">bball_df</span><span class="p">[(</span><span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;G&#39;</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;F&#39;</span><span class="p">)]</span>

<span class="c1"># Define X and y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">bball_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="s1">&#39;salary&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<ol class="simple">
<li><p>Split the dataset into 4 objects: <code class="docutils literal notranslate"><span class="pre">X_train</span></code>, <code class="docutils literal notranslate"><span class="pre">X_test</span></code>, <code class="docutils literal notranslate"><span class="pre">y_train</span></code>, <code class="docutils literal notranslate"><span class="pre">y_test</span></code>. Make the test set 0.2 (or the train set 0.8) and make sure to use <code class="docutils literal notranslate"><span class="pre">random_state=7</span></code>.</p></li>
<li><p>Create an <code class="docutils literal notranslate"><span class="pre">SVM</span></code> model with <code class="docutils literal notranslate"><span class="pre">gamma</span></code> equal to 0.1 and <code class="docutils literal notranslate"><span class="pre">C</span></code> equal to 10.</p></li>
<li><p>Cross-validate using cross_validate() on the objects X_train and y_train specifying the model and making sure to use 5 fold cross-validation and <code class="docutils literal notranslate"><span class="pre">return_train_score=True</span></code>.</p></li>
<li><p>Calculate the mean training and cross-validation scores.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Split the dataset</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 3. Cross-validate</span>
<span class="n">scores_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.002690</td>
      <td>0.001404</td>
      <td>0.571429</td>
      <td>0.994898</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.002484</td>
      <td>0.001452</td>
      <td>0.571429</td>
      <td>0.994898</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.002435</td>
      <td>0.001478</td>
      <td>0.551020</td>
      <td>0.994898</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.002569</td>
      <td>0.001265</td>
      <td>0.530612</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.002366</td>
      <td>0.001280</td>
      <td>0.571429</td>
      <td>0.994898</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores_df</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.002509
score_time     0.001376
test_score     0.559184
train_score    0.995918
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores_df</span><span class="o">.</span><span class="n">mean</span><span class="p">()[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5591836734693878
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores_df</span><span class="o">.</span><span class="n">mean</span><span class="p">()[</span><span class="s1">&#39;train_score&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9959183673469388
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="preprocessing">
<h2>Preprocessing<a class="headerlink" href="#preprocessing" title="Permalink to this headline">¬∂</a></h2>
<div class="section" id="the-importance-of-preprocessing-an-example-of-why">
<h3>The importance of Preprocessing - An Example of Why<a class="headerlink" href="#the-importance-of-preprocessing-an-example-of-why" title="Permalink to this headline">¬∂</a></h3>
<p>So far we have seen:</p>
<ul class="simple">
<li><p>Models: Decision trees, ùëò-NNs, SVMs with RBF kernel.</p></li>
<li><p>Fundamentals: Train-validation-test split, cross-validation, the fundamental tradeoff, the golden rule.</p></li>
</ul>
<p>Now ‚Ä¶</p>
<p><strong>Preprocessing</strong>: Transforming input data into a format a machine learning model can use and understand.</p>
<div class="section" id="basketball-dataset">
<h4>Basketball dataset<a class="headerlink" href="#basketball-dataset" title="Permalink to this headline">¬∂</a></h4>
<p>Let‚Äôs take a look at the <code class="docutils literal notranslate"><span class="pre">bball.csv</span></code> dataset we just used in practice.</p>
<ul class="simple">
<li><p>Let‚Äôs look at the  3 feature columns <code class="docutils literal notranslate"><span class="pre">height</span></code>, <code class="docutils literal notranslate"><span class="pre">weight</span></code> and <code class="docutils literal notranslate"><span class="pre">salary</span></code>.</p></li>
<li><p>Let‚Äôs see if these features can help predict the <code class="docutils literal notranslate"><span class="pre">position</span></code> basketball players is.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bball_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/bball.csv&#39;</span><span class="p">)</span>
<span class="n">bball_df</span> <span class="o">=</span> <span class="n">bball_df</span><span class="p">[(</span><span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;G&#39;</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;F&#39;</span><span class="p">)]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">bball_df</span><span class="p">[[</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;salary&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span><span class="n">bball_df</span><span class="p">[</span><span class="s2">&quot;position&quot;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>weight</th>
      <th>height</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>152</th>
      <td>79.4</td>
      <td>1.88</td>
      <td>1588231.0</td>
    </tr>
    <tr>
      <th>337</th>
      <td>82.1</td>
      <td>1.91</td>
      <td>2149560.0</td>
    </tr>
    <tr>
      <th>130</th>
      <td>106.6</td>
      <td>2.03</td>
      <td>6500000.0</td>
    </tr>
    <tr>
      <th>340</th>
      <td>106.1</td>
      <td>2.08</td>
      <td>2961120.0</td>
    </tr>
    <tr>
      <th>50</th>
      <td>96.2</td>
      <td>1.93</td>
      <td>4861207.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>152    G
337    G
130    F
340    F
50     G
Name: position, dtype: object
</pre></div>
</div>
</div>
</div>
<p>First, let‚Äôs see what validations scores we get if we simply predict the most occurring target value in the dataset using the dummy classifier model we saw in the last lecture.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dummy</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;most_frequent&quot;</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">dummy</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean training score&#39;</span><span class="p">,</span> <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean validation score&#39;</span><span class="p">,</span> <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean training score 0.57
Mean validation score 0.57
</pre></div>
</div>
</div>
</div>
<p>Here we get a mean validation score for our 5 fold cross_validation (5 is the default) of 57%. Let‚Äôs now see how much better a <span class="math notranslate nohighlight">\(k\)</span>-nn model does on the data. We saw that it doesn‚Äôt do to well on SVM, let‚Äôs see if there is a difference with <span class="math notranslate nohighlight">\(k\)</span>-nn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean training score&#39;</span><span class="p">,</span> <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean validation score&#39;</span><span class="p">,</span> <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean training score 0.7
Mean validation score 0.5
</pre></div>
</div>
</div>
</div>
<p>Ok, not the score we were hoping for.</p>
<p>We are getting a worse score than the dummy classifier. This can‚Äôt be right‚Ä¶.. and it isn‚Äôt and we are going to explain why!</p>
<p>Let‚Äôs have a look at just 2 players.</p>
<p>We can see the values in each column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">two_players</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">two_players</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>weight</th>
      <th>height</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>285</th>
      <td>91.2</td>
      <td>1.98</td>
      <td>1882867.0</td>
    </tr>
    <tr>
      <th>236</th>
      <td>112.0</td>
      <td>2.08</td>
      <td>2000000.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>The values in the <code class="docutils literal notranslate"><span class="pre">weight</span></code> column are around 100.</p></li>
<li><p>The values in the <code class="docutils literal notranslate"><span class="pre">height</span></code> column are around 2.</p></li>
<li><p>The values in the <code class="docutils literal notranslate"><span class="pre">salary</span></code> column are much higher at around 2 million.</p></li>
</ul>
<p>Let‚Äôs now calculate the distance between the two players.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">euclidean_distances</span><span class="p">(</span><span class="n">two_players</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[     0.        , 117133.00184683],
       [117133.00184683,      0.        ]])
</pre></div>
</div>
</div>
</div>
<p>So the distance between the players is 117133.0018.</p>
<p>What happens if we only consider the salary column?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">euclidean_distances</span><span class="p">(</span><span class="n">two_players</span><span class="p">[[</span><span class="s2">&quot;salary&quot;</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[     0., 117133.],
       [117133.,      0.]])
</pre></div>
</div>
</div>
</div>
<p>It looks like it‚Äôs almost the same distance!</p>
<p>The distance is completely dominated by the <code class="docutils literal notranslate"><span class="pre">salary</span></code> column, the feature with the largest values and the <code class="docutils literal notranslate"><span class="pre">weight</span></code> and <code class="docutils literal notranslate"><span class="pre">height</span></code> columns are being ignored in the distance calculation.</p>
<p><strong>Does it matter?</strong></p>
<p>Yes! The scale is based on how data was collected.</p>
<p>Features on a smaller scale can be highly informative and there is no good reason to ignore them.
We want our model to be robust and not sensitive to the scale.</p>
<p><strong>What about for decision trees? Did scale matter then?</strong></p>
<p>No. In decision trees we ask questions on one feature at a time and so the nodes are created independently without considering others.</p>
<p>We have to scale our columns before we use our <span class="math notranslate nohighlight">\(k\)</span>-nn algorithm (and many others) so they are all using a similar range of values!</p>
<p>And you guessed it - Sklearn has tools called transformers for this.</p>
<p>We‚Äôll be using <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>‚Äôs <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"><code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code></a> for this example.
We will talk about this type of preprocessing in more detail in a hot minute but for now, concentrate on the syntax.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>                    <span class="c1"># Create feature transformer object, can accept hyperparameters like models can! </span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>                          <span class="c1"># Fitting the transformer on the train split</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>   <span class="c1"># Transforming the train split</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>     <span class="c1"># Transforming the test split</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">sklearn</span></code> uses <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">transform</span></code> paradigms for feature transformations. (In model building it was <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">predict</span></code> or <code class="docutils literal notranslate"><span class="pre">score</span></code>)</p>
<p>We <code class="docutils literal notranslate"><span class="pre">fit</span></code> the transformer on the train split and then <code class="docutils literal notranslate"><span class="pre">transform</span></code> the train split as well as the test split.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>weight</th>
      <th>height</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.552775</td>
      <td>-1.236056</td>
      <td>-0.728809</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.257147</td>
      <td>-0.800950</td>
      <td>-0.670086</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.425407</td>
      <td>0.939473</td>
      <td>-0.214967</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.370661</td>
      <td>1.664650</td>
      <td>-0.585185</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.286690</td>
      <td>-0.510879</td>
      <td>-0.386408</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now if we look at our features they are all within the same scales as opposed to what it was before:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>weight</th>
      <th>height</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>152</th>
      <td>79.4</td>
      <td>1.88</td>
      <td>1588231.0</td>
    </tr>
    <tr>
      <th>337</th>
      <td>82.1</td>
      <td>1.91</td>
      <td>2149560.0</td>
    </tr>
    <tr>
      <th>130</th>
      <td>106.6</td>
      <td>2.03</td>
      <td>6500000.0</td>
    </tr>
    <tr>
      <th>340</th>
      <td>106.1</td>
      <td>2.08</td>
      <td>2961120.0</td>
    </tr>
    <tr>
      <th>50</th>
      <td>96.2</td>
      <td>1.93</td>
      <td>4861207.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
</div>
<div class="section" id="sklearn-s-predict-vs-transform">
<h3>Sklearn‚Äôs <em>predict</em> vs <em>transform</em><a class="headerlink" href="#sklearn-s-predict-vs-transform" title="Permalink to this headline">¬∂</a></h3>
<p>When we make models, we <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">predict</span></code>(<code class="docutils literal notranslate"><span class="pre">score</span></code>) with the syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">X_train_predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
<p>With preprocessing, we replace the <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> step with a <code class="docutils literal notranslate"><span class="pre">.transform()</span></code> step. We can pass <code class="docutils literal notranslate"><span class="pre">y_train</span></code> in <code class="docutils literal notranslate"><span class="pre">fit</span></code> but it‚Äôs usually ignored. It allows us to pass it just to be consistent with the usual usage of <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>‚Äôs <code class="docutils literal notranslate"><span class="pre">fit</span></code> method.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">transformer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="p">[</span><span class="n">y_train</span><span class="p">])</span>
<span class="n">X_train_transformed</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
<p>We can also carry out fitting and transforming in one call using <code class="docutils literal notranslate"><span class="pre">.fit_transform()</span></code>, but we must be mindful to use it only on the train split and <strong>NOT</strong> on the test split.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_transformed</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
<p>Let‚Äôs scale our features for this basketball dataset and then compare the results with our original score without scaling.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn_unscaled</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">knn_unscaled</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train score: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">knn_unscaled</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test score: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">knn_unscaled</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train score:  0.71
Test score:  0.45
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn_scaled</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">knn_scaled</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train score: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">knn_scaled</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test score: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">knn_scaled</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train score:  0.94
Test score:  0.89
</pre></div>
</div>
</div>
</div>
<p>The scores with scaled data are now much better compared to the unscaled data in the case of ùëò-NNs.</p>
<p>We can see now that ùëò-NN is doing better than the Dummy Classifier when we scaled our features.</p>
<p>We are not carrying out cross-validation here for a reason that we‚Äôll look into soon.</p>
<p>We are being a bit sloppy here by using the test set several times for teaching purposes.</p>
<p>But when we build any ML models, we should only assess the test set once.</p>
</div>
<div class="section" id="common-preprocessing-techniques">
<h3>Common preprocessing techniques<a class="headerlink" href="#common-preprocessing-techniques" title="Permalink to this headline">¬∂</a></h3>
<p>Here are some commonly performed feature transformation techniques we will focus on in this lesson.</p>
<ul class="simple">
<li><p>Imputation</p>
<ul>
<li><p>Tackling missing values</p></li>
</ul>
</li>
<li><p>Scaling</p>
<ul>
<li><p>Scaling of numeric features</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="id2">
<h2>Let‚Äôs Practice!<a class="headerlink" href="#id2" title="Permalink to this headline">¬∂</a></h2>
<ol class="simple">
<li><p>Name a model that will still produce meaningful predictions with different scaled column values.</p></li>
<li><p>Complete the following statement: Preprocessing is done ____.</p></li>
</ol>
<ul class="simple">
<li><p>To the model but before training</p></li>
<li><p>To the data before training the model</p></li>
<li><p>To the model after training</p></li>
<li><p>To the data after training the model</p></li>
</ul>
<ol class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> is a type of what?</p></li>
<li><p>What data splits does <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> alter (Training, Testing, Validation, None, All)?</p></li>
</ol>
<p><strong>True or False</strong><br />
5. Columns with lower magnitudes compared to columns with higher magnitudes are less important when making predictions.<br />
6. A model less sensitive to the scale of the data makes it more robust.</p>
</div>
<div class="section" id="california-housing-data-a-case-study">
<h2>California housing data (A case study)<a class="headerlink" href="#california-housing-data-a-case-study" title="Permalink to this headline">¬∂</a></h2>
<p>For the next few examples of preprocessing,  we are going to be using a dataset exploring the prices of homes in California to demonstrate feature transformation techniques.  The data can be downloaded from this site <a class="reference external" href="https://www.kaggle.com/harrywang/housing">here</a>. Please make sure that you include it in your <code class="docutils literal notranslate"><span class="pre">data</span></code> folder that resides in <code class="docutils literal notranslate"><span class="pre">lectures</span></code>.</p>
<p>This dataset is a modified version of the California Housing dataset available from <a class="reference external" href="https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html">Lu√≠s Torgo‚Äôs University of Porto website</a></p>
<p>The task is to predict median house values in California districts, given several features from these districts.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">housing_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/housing.csv&quot;</span><span class="p">)</span>
<span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">housing_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

<span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6051</th>
      <td>-117.75</td>
      <td>34.04</td>
      <td>22.0</td>
      <td>2948.0</td>
      <td>636.0</td>
      <td>2600.0</td>
      <td>602.0</td>
      <td>3.1250</td>
      <td>113600.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>20113</th>
      <td>-119.57</td>
      <td>37.94</td>
      <td>17.0</td>
      <td>346.0</td>
      <td>130.0</td>
      <td>51.0</td>
      <td>20.0</td>
      <td>3.4861</td>
      <td>137500.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>14289</th>
      <td>-117.13</td>
      <td>32.74</td>
      <td>46.0</td>
      <td>3355.0</td>
      <td>768.0</td>
      <td>1457.0</td>
      <td>708.0</td>
      <td>2.6604</td>
      <td>170100.0</td>
      <td>NEAR OCEAN</td>
    </tr>
    <tr>
      <th>13665</th>
      <td>-117.31</td>
      <td>34.02</td>
      <td>18.0</td>
      <td>1634.0</td>
      <td>274.0</td>
      <td>899.0</td>
      <td>285.0</td>
      <td>5.2139</td>
      <td>129300.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>14471</th>
      <td>-117.23</td>
      <td>32.88</td>
      <td>18.0</td>
      <td>5566.0</td>
      <td>1465.0</td>
      <td>6303.0</td>
      <td>1458.0</td>
      <td>1.8580</td>
      <td>205000.0</td>
      <td>NEAR OCEAN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Some column values are mean/median but some are not.</p>
<p>Before we use this data we need to do some <strong>feature engineering</strong>.</p>
<p>That means we are going to transform our data into features that may be more meaningful for our prediction.</p>
<p>Let‚Äôs add some new features to the dataset which could help predict the target: <code class="docutils literal notranslate"><span class="pre">median_house_value</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">rooms_per_household</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;total_rooms&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">],</span>
                           <span class="n">bedrooms_per_household</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;total_bedrooms&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">],</span>
                           <span class="n">population_per_household</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;population&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">])</span>

<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">rooms_per_household</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;total_rooms&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">],</span>
                         <span class="n">bedrooms_per_household</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;total_bedrooms&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">],</span>
                         <span class="n">population_per_household</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;population&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">])</span>

<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;total_rooms&#39;</span><span class="p">,</span> <span class="s1">&#39;total_bedrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;population&#39;</span><span class="p">])</span>  
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;total_rooms&#39;</span><span class="p">,</span> <span class="s1">&#39;total_bedrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;population&#39;</span><span class="p">])</span> 

<span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6051</th>
      <td>-117.75</td>
      <td>34.04</td>
      <td>22.0</td>
      <td>602.0</td>
      <td>3.1250</td>
      <td>113600.0</td>
      <td>INLAND</td>
      <td>4.897010</td>
      <td>1.056478</td>
      <td>4.318937</td>
    </tr>
    <tr>
      <th>20113</th>
      <td>-119.57</td>
      <td>37.94</td>
      <td>17.0</td>
      <td>20.0</td>
      <td>3.4861</td>
      <td>137500.0</td>
      <td>INLAND</td>
      <td>17.300000</td>
      <td>6.500000</td>
      <td>2.550000</td>
    </tr>
    <tr>
      <th>14289</th>
      <td>-117.13</td>
      <td>32.74</td>
      <td>46.0</td>
      <td>708.0</td>
      <td>2.6604</td>
      <td>170100.0</td>
      <td>NEAR OCEAN</td>
      <td>4.738701</td>
      <td>1.084746</td>
      <td>2.057910</td>
    </tr>
    <tr>
      <th>13665</th>
      <td>-117.31</td>
      <td>34.02</td>
      <td>18.0</td>
      <td>285.0</td>
      <td>5.2139</td>
      <td>129300.0</td>
      <td>INLAND</td>
      <td>5.733333</td>
      <td>0.961404</td>
      <td>3.154386</td>
    </tr>
    <tr>
      <th>14471</th>
      <td>-117.23</td>
      <td>32.88</td>
      <td>18.0</td>
      <td>1458.0</td>
      <td>1.8580</td>
      <td>205000.0</td>
      <td>NEAR OCEAN</td>
      <td>3.817558</td>
      <td>1.004801</td>
      <td>4.323045</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="section" id="when-is-it-ok-to-do-things-before-splitting">
<h3>When is it OK to do things before splitting?<a class="headerlink" href="#when-is-it-ok-to-do-things-before-splitting" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p>Here it would have been OK to add new features before splitting because we are not using any global information in the data but only looking at one row at a time.</p></li>
<li><p>But just to be safe and to avoid accidentally breaking the golden rule, it‚Äôs better to do it after splitting.</p></li>
</ul>
</div>
</div>
<div class="section" id="preprocessing-imputation">
<h2>Preprocessing: Imputation<a class="headerlink" href="#preprocessing-imputation" title="Permalink to this headline">¬∂</a></h2>
<p>Imputation is handling missing values in our data so let‚Äôs explore this a little.</p>
<p>We can <code class="docutils literal notranslate"><span class="pre">.info()</span></code> we can we all the different column dtypes and also all the number of null values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Int64Index: 18576 entries, 6051 to 19966
Data columns (total 10 columns):
 #   Column                    Non-Null Count  Dtype  
---  ------                    --------------  -----  
 0   longitude                 18576 non-null  float64
 1   latitude                  18576 non-null  float64
 2   housing_median_age        18576 non-null  float64
 3   households                18576 non-null  float64
 4   median_income             18576 non-null  float64
 5   median_house_value        18576 non-null  float64
 6   ocean_proximity           18576 non-null  object 
 7   rooms_per_household       18576 non-null  float64
 8   bedrooms_per_household    18391 non-null  float64
 9   population_per_household  18576 non-null  float64
dtypes: float64(9), object(1)
memory usage: 1.6+ MB
</pre></div>
</div>
</div>
</div>
<p>We see that we have all columns with dtype <code class="docutils literal notranslate"><span class="pre">float64</span></code> except for <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code> which appears categorical.</p>
<p>We also notice that the <code class="docutils literal notranslate"><span class="pre">bedrooms_per_household</span></code> column appears to have some <code class="docutils literal notranslate"><span class="pre">Non-Null</span></code> rows.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;bedrooms_per_household&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>185
</pre></div>
</div>
</div>
</div>
<p>Knowing this information let‚Äôs build a model.</p>
<p>When we create our feature table and target objects, we are going to drop the categorical variable <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code>.  Currently, we don‚Äôt know how to build models with categorical data, but we will shortly. We will return to this column soon.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">,</span> <span class="s2">&quot;ocean_proximity&quot;</span><span class="p">])</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">]</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">,</span> <span class="s2">&quot;ocean_proximity&quot;</span><span class="p">])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">]</span>

<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>What happens when we try to fit our model with this data?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ValueError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">48</span><span class="o">-</span><span class="mi">144</span><span class="n">fd69ce732</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nn">/usr/local/lib/python3.8/site-packages/sklearn/neighbors/_base.py</span> in <span class="ni">fit</span><span class="nt">(self, X, y)</span>
<span class="g g-Whitespace">   </span><span class="mi">1105</span>         <span class="s2">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">1106</span><span class="s2">         if not isinstance(X, (KDTree, BallTree)):</span>
<span class="ne">-&gt; </span><span class="mi">1107</span><span class="s2">             X, y = self._validate_data(X, y, accept_sparse=&quot;csr&quot;,</span>
<span class="g g-Whitespace">   </span><span class="mi">1108</span><span class="s2">                                        multi_output=True)</span>
<span class="g g-Whitespace">   </span><span class="mi">1109</span><span class="s2">         self._y = y</span>

<span class="nn">/usr/local/lib/python3.8/site-packages/sklearn/base.py</span> in <span class="ni">_validate_data</span><span class="nt">(self, X, y, reset, validate_separately, **check_params)</span>
<span class="g g-Whitespace">    </span><span class="mi">430</span><span class="s2">                 y = check_array(y, **check_y_params)</span>
<span class="g g-Whitespace">    </span><span class="mi">431</span><span class="s2">             else:</span>
<span class="ne">--&gt; </span><span class="mi">432</span><span class="s2">                 X, y = check_X_y(X, y, **check_params)</span>
<span class="g g-Whitespace">    </span><span class="mi">433</span><span class="s2">             out = X, y</span>
<span class="g g-Whitespace">    </span><span class="mi">434</span><span class="s2"> </span>

<span class="nn">/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py</span> in <span class="ni">inner_f</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">70</span><span class="s2">                           FutureWarning)</span>
<span class="nn">     71         kwargs.update({k: arg for k, arg</span> in <span class="ni">zip</span><span class="nt">(sig.parameters, args)})</span>
<span class="ne">---&gt; </span><span class="mi">72</span><span class="s2">         return f(**kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">73</span><span class="s2">     return inner_f</span>
<span class="g g-Whitespace">     </span><span class="mi">74</span><span class="s2"> </span>

<span class="nn">/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py</span> in <span class="ni">check_X_y</span><span class="nt">(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)</span>
<span class="g g-Whitespace">    </span><span class="mi">793</span><span class="s2">         raise ValueError(&quot;y cannot be None&quot;)</span>
<span class="g g-Whitespace">    </span><span class="mi">794</span><span class="s2"> </span>
<span class="ne">--&gt; </span><span class="mi">795</span><span class="s2">     X = check_array(X, accept_sparse=accept_sparse,</span>
<span class="g g-Whitespace">    </span><span class="mi">796</span><span class="s2">                     accept_large_sparse=accept_large_sparse,</span>
<span class="g g-Whitespace">    </span><span class="mi">797</span><span class="s2">                     dtype=dtype, order=order, copy=copy,</span>

<span class="nn">/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py</span> in <span class="ni">inner_f</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">70</span><span class="s2">                           FutureWarning)</span>
<span class="nn">     71         kwargs.update({k: arg for k, arg</span> in <span class="ni">zip</span><span class="nt">(sig.parameters, args)})</span>
<span class="ne">---&gt; </span><span class="mi">72</span><span class="s2">         return f(**kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">73</span><span class="s2">     return inner_f</span>
<span class="g g-Whitespace">     </span><span class="mi">74</span><span class="s2"> </span>

<span class="nn">/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py</span> in <span class="ni">check_array</span><span class="nt">(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)</span>
<span class="g g-Whitespace">    </span><span class="mi">642</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">643</span><span class="s2">         if force_all_finite:</span>
<span class="ne">--&gt; </span><span class="mi">644</span><span class="s2">             _assert_all_finite(array,</span>
<span class="g g-Whitespace">    </span><span class="mi">645</span><span class="s2">                                allow_nan=force_all_finite == &#39;allow-nan&#39;)</span>
<span class="g g-Whitespace">    </span><span class="mi">646</span><span class="s2"> </span>

<span class="nn">/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py</span> in <span class="ni">_assert_all_finite</span><span class="nt">(X, allow_nan, msg_dtype)</span>
<span class="g g-Whitespace">     </span><span class="mi">94</span><span class="s2">                 not allow_nan and not np.isfinite(X).all()):</span>
<span class="g g-Whitespace">     </span><span class="mi">95</span><span class="s2">             type_err = &#39;infinity&#39; if allow_nan else &#39;NaN, infinity&#39;</span>
<span class="ne">---&gt; </span><span class="mi">96</span><span class="s2">             raise ValueError(</span>
<span class="g g-Whitespace">     </span><span class="mi">97</span><span class="s2">                     msg_err.format</span>
<span class="g g-Whitespace">     </span><span class="mi">98</span><span class="s2">                     (type_err,</span>

<span class="ne">ValueError</span>: Input contains NaN, infinity or a value too large for dtype(&#39;float64&#39;).
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">Input</span> <span class="pre">contains</span> <span class="pre">NaN,</span> <span class="pre">infinity</span> <span class="pre">or</span> <span class="pre">a</span> <span class="pre">value</span> <span class="pre">too</span> <span class="pre">large</span> <span class="pre">for</span> <span class="pre">dtype('float64').</span></code></p>
</div></blockquote>
<p>The classifier can‚Äôt deal with missing values (NaNs).</p>
<p>How can we deal with this problem?</p>
<div class="section" id="why-we-don-t-drop-the-rows">
<h3>Why we don‚Äôt drop the rows<a class="headerlink" href="#why-we-don-t-drop-the-rows" title="Permalink to this headline">¬∂</a></h3>
<p>We could drop any rows that are missing information but that‚Äôs problematic too.</p>
<p>Then we would need to do the same in our test set.</p>
<p>And what happens if we get missing values in our deployment data? what then?</p>
<p>Furthermore, what if the missing values don‚Äôt occur at random and we‚Äôre systematically dropping certain data?
Perhaps a certain type of house contributes to more missing values.</p>
<p>Dropping the rows is not a great solution, especially if there‚Äôs a lot of missing values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(18576, 8)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_no_nan</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">y_train_no_nan</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

<span class="n">X_train_no_nan</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(18391, 8)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="why-we-don-t-drop-the-column">
<h3>Why we don‚Äôt drop the column<a class="headerlink" href="#why-we-don-t-drop-the-column" title="Permalink to this headline">¬∂</a></h3>
<p>If we drop the column instead of the rows, we are throwing away, in this case, 18391 values just because we don‚Äôt have 185 missing values out of a total of 18567.</p>
<p>We are throwing away 99% of the column‚Äôs data because we are missing 1%.</p>
<p>But perhaps if we were missing 99.9% of the column values, for example, it would make more sense to drop the column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(18576, 8)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_no_col</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X_train_no_col</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(18576, 7)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="why-we-use-imputation">
<h3>Why we use imputation<a class="headerlink" href="#why-we-use-imputation" title="Permalink to this headline">¬∂</a></h3>
<p>With <strong>Imputation</strong>, we invent values for the missing data.</p>
<p>Using <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>‚Äôs <strong>transformer</strong> <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code>, we can impute the <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values in the data with some value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
</pre></div>
</div>
</div>
</div>
<p>We can impute missing values in:</p>
<ul class="simple">
<li><p><strong>Categorical columns</strong>:</p>
<ul>
<li><p>with the most frequent value</p></li>
<li><p>with a constant of our choosing.</p></li>
</ul>
</li>
<li><p><strong>Numeric columns</strong>:</p>
<ul>
<li><p>with the mean  of the column</p></li>
<li><p>with the median of the column</p></li>
<li><p>or a constant of our choosing.</p></li>
</ul>
</li>
</ul>
<p>If I sort the values by <code class="docutils literal notranslate"><span class="pre">bedrooms_per_household</span></code> and look at the end of the dataframe, we can see our missing values in the <code class="docutils literal notranslate"><span class="pre">bedrooms_per_household</span></code> column.</p>
<p>Pay close attention to index 7763 since we are going to look at this row after imputation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;bedrooms_per_household&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>households</th>
      <th>median_income</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>18786</th>
      <td>-122.42</td>
      <td>40.44</td>
      <td>16.0</td>
      <td>181.0</td>
      <td>2.1875</td>
      <td>5.491713</td>
      <td>NaN</td>
      <td>2.734807</td>
    </tr>
    <tr>
      <th>17923</th>
      <td>-121.97</td>
      <td>37.35</td>
      <td>30.0</td>
      <td>386.0</td>
      <td>4.6328</td>
      <td>5.064767</td>
      <td>NaN</td>
      <td>2.588083</td>
    </tr>
    <tr>
      <th>16880</th>
      <td>-122.39</td>
      <td>37.59</td>
      <td>32.0</td>
      <td>715.0</td>
      <td>6.1323</td>
      <td>6.289510</td>
      <td>NaN</td>
      <td>2.581818</td>
    </tr>
    <tr>
      <th>4309</th>
      <td>-118.32</td>
      <td>34.09</td>
      <td>44.0</td>
      <td>726.0</td>
      <td>1.6760</td>
      <td>3.672176</td>
      <td>NaN</td>
      <td>3.163912</td>
    </tr>
    <tr>
      <th>538</th>
      <td>-122.28</td>
      <td>37.78</td>
      <td>29.0</td>
      <td>1273.0</td>
      <td>2.5762</td>
      <td>4.048704</td>
      <td>NaN</td>
      <td>2.938727</td>
    </tr>
    <tr>
      <th>4591</th>
      <td>-118.28</td>
      <td>34.06</td>
      <td>42.0</td>
      <td>1179.0</td>
      <td>1.2254</td>
      <td>2.096692</td>
      <td>NaN</td>
      <td>3.218830</td>
    </tr>
    <tr>
      <th>19485</th>
      <td>-120.98</td>
      <td>37.66</td>
      <td>10.0</td>
      <td>255.0</td>
      <td>0.9336</td>
      <td>3.662745</td>
      <td>NaN</td>
      <td>1.572549</td>
    </tr>
    <tr>
      <th>6962</th>
      <td>-118.05</td>
      <td>33.99</td>
      <td>38.0</td>
      <td>357.0</td>
      <td>3.7328</td>
      <td>4.535014</td>
      <td>NaN</td>
      <td>2.481793</td>
    </tr>
    <tr>
      <th>14970</th>
      <td>-117.01</td>
      <td>32.74</td>
      <td>31.0</td>
      <td>677.0</td>
      <td>2.6973</td>
      <td>5.129985</td>
      <td>NaN</td>
      <td>3.098966</td>
    </tr>
    <tr>
      <th>7763</th>
      <td>-118.10</td>
      <td>33.91</td>
      <td>36.0</td>
      <td>130.0</td>
      <td>3.6389</td>
      <td>5.584615</td>
      <td>NaN</td>
      <td>3.769231</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Using the same <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">transform</span></code> syntax we saw earlier for transformers, we can impute the <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values.</p>
<p>Here we specify <code class="docutils literal notranslate"><span class="pre">strategy=&quot;median&quot;</span></code> which replaces all the missing values with the column median.</p>
<p>We fit on the training data and transform it on the train and test splits.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)</span>
<span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">);</span>
<span class="n">X_train_imp</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_imp</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_imp</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-117.75      ,   34.04      ,   22.        , ...,    4.89700997,
           1.05647841,    4.31893688],
       [-119.57      ,   37.94      ,   17.        , ...,   17.3       ,
           6.5       ,    2.55      ],
       [-117.13      ,   32.74      ,   46.        , ...,    4.73870056,
           1.08474576,    2.0579096 ],
       ...,
       [-121.76      ,   37.33      ,    5.        , ...,    5.95839311,
           1.03156385,    3.49354376],
       [-122.44      ,   37.78      ,   44.        , ...,    4.7392638 ,
           1.02453988,    1.7208589 ],
       [-119.08      ,   36.21      ,   20.        , ...,    5.49137931,
           1.11781609,    3.56609195]])
</pre></div>
</div>
</div>
</div>
<p>Ok, the output of this isn‚Äôt a dataframe but a NumPy array!</p>
<p>I can do a bit of wrangling here to take a look at this new array with our previous column labels and as a dataframe.</p>
<p>If I search for our index 7763 which previously contained a <code class="docutils literal notranslate"><span class="pre">NaN</span></code> value, we can see that now I have the median value for the <code class="docutils literal notranslate"><span class="pre">bedrooms_per_household</span></code> column from the <code class="docutils literal notranslate"><span class="pre">X_train</span></code> dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_imp_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">X_train_imp_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="mi">7763</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>households</th>
      <th>median_income</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7763</th>
      <td>-118.1</td>
      <td>33.91</td>
      <td>36.0</td>
      <td>130.0</td>
      <td>3.6389</td>
      <td>5.584615</td>
      <td>1.04886</td>
      <td>3.769231</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;bedrooms_per_household&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0488599348534202
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="mi">7763</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>households</th>
      <th>median_income</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7763</th>
      <td>-118.1</td>
      <td>33.91</td>
      <td>36.0</td>
      <td>130.0</td>
      <td>3.6389</td>
      <td>5.584615</td>
      <td>NaN</td>
      <td>3.769231</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now when we try and fit our model using <code class="docutils literal notranslate"><span class="pre">X_train_imp</span></code>, it works!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">();</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5609808539232339
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="preprocessing-scaling">
<h2>Preprocessing: Scaling<a class="headerlink" href="#preprocessing-scaling" title="Permalink to this headline">¬∂</a></h2>
<p>So we‚Äôve seen why scaling is important earlier but let‚Äôs take a little bit of a closer look here.
There are many ways to scale your data but we are going to look at 2 of them.</p>
<p><img alt="" src="https://amueller.github.io/COMS4995-s19/slides/aml-05-preprocessing/images/scaler_comparison_scatter.png" /></p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Approach</p></th>
<th class="head"><p>What it does</p></th>
<th class="head"><p>How to update <span class="math notranslate nohighlight">\(X\)</span> (but see below!)</p></th>
<th class="head"><p>sklearn implementation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>normalization</p></td>
<td><p>sets range to <span class="math notranslate nohighlight">\([0,1]\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">-=</span> <span class="pre">np.min(X,axis=0)</span></code><br><code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">/=</span> <span class="pre">np.max(X,axis=0)</span></code></p></td>
<td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"><code class="docutils literal notranslate"><span class="pre">MinMaxScaler()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p>standardization</p></td>
<td><p>sets sample mean to <span class="math notranslate nohighlight">\(0\)</span>, s.d. to <span class="math notranslate nohighlight">\(1\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">-=</span> <span class="pre">np.mean(X,axis=0)</span></code><br><code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">/=</span>&#160; <span class="pre">np.std(X,axis=0)</span></code></p></td>
<td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler"><code class="docutils literal notranslate"><span class="pre">StandardScaler()</span></code></a></p></td>
</tr>
</tbody>
</table>
<p>For more resources and articles on this, see <a class="reference external" href="http://www.dataminingblog.com/standardization-vs-normalization/">here</a> and <a class="reference external" href="https://medium.com/&#64;rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc">here</a>.</p>
<p>Let‚Äôs see what happens when we use each of them.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">StandardScaler</span>
</pre></div>
</div>
</div>
</div>
<p>First, let‚Äôs see how standardization is done first.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled_std</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">)</span>
<span class="n">X_test_scaled_std</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_imp</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_scaled_std</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>households</th>
      <th>median_income</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6051</th>
      <td>0.908140</td>
      <td>-0.743917</td>
      <td>-0.526078</td>
      <td>0.266135</td>
      <td>-0.389736</td>
      <td>-0.210591</td>
      <td>-0.083813</td>
      <td>0.126398</td>
    </tr>
    <tr>
      <th>20113</th>
      <td>-0.002057</td>
      <td>1.083123</td>
      <td>-0.923283</td>
      <td>-1.253312</td>
      <td>-0.198924</td>
      <td>4.726412</td>
      <td>11.166631</td>
      <td>-0.050132</td>
    </tr>
    <tr>
      <th>14289</th>
      <td>1.218207</td>
      <td>-1.352930</td>
      <td>1.380504</td>
      <td>0.542873</td>
      <td>-0.635239</td>
      <td>-0.273606</td>
      <td>-0.025391</td>
      <td>-0.099240</td>
    </tr>
    <tr>
      <th>13665</th>
      <td>1.128188</td>
      <td>-0.753286</td>
      <td>-0.843842</td>
      <td>-0.561467</td>
      <td>0.714077</td>
      <td>0.122307</td>
      <td>-0.280310</td>
      <td>0.010183</td>
    </tr>
    <tr>
      <th>14471</th>
      <td>1.168196</td>
      <td>-1.287344</td>
      <td>-0.843842</td>
      <td>2.500924</td>
      <td>-1.059242</td>
      <td>-0.640266</td>
      <td>-0.190617</td>
      <td>0.126808</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Here, any negative values represent values that are lower than the calculated feature mean and anything positive and greater than 0 are values greater than the original column mean.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Unscaled training score :&#39;</span><span class="p">,</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Unscaled training score : 0.561
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled_std</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Scaled training score :&#39;</span><span class="p">,</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled_std</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Scaled training score : 0.7978563117812038
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X_train_scaled_norm</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">)</span>
<span class="n">X_test_scaled_norm</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_imp</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_scaled_norm</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>households</th>
      <th>median_income</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6051</th>
      <td>0.657371</td>
      <td>0.159405</td>
      <td>0.411765</td>
      <td>0.098832</td>
      <td>0.181039</td>
      <td>0.028717</td>
      <td>0.021437</td>
      <td>0.002918</td>
    </tr>
    <tr>
      <th>20113</th>
      <td>0.476096</td>
      <td>0.573858</td>
      <td>0.313725</td>
      <td>0.003124</td>
      <td>0.205942</td>
      <td>0.116642</td>
      <td>0.182806</td>
      <td>0.001495</td>
    </tr>
    <tr>
      <th>14289</th>
      <td>0.719124</td>
      <td>0.021254</td>
      <td>0.882353</td>
      <td>0.116264</td>
      <td>0.148998</td>
      <td>0.027594</td>
      <td>0.022275</td>
      <td>0.001099</td>
    </tr>
    <tr>
      <th>13665</th>
      <td>0.701195</td>
      <td>0.157279</td>
      <td>0.333333</td>
      <td>0.046703</td>
      <td>0.325099</td>
      <td>0.034645</td>
      <td>0.018619</td>
      <td>0.001981</td>
    </tr>
    <tr>
      <th>14471</th>
      <td>0.709163</td>
      <td>0.036132</td>
      <td>0.333333</td>
      <td>0.239599</td>
      <td>0.093661</td>
      <td>0.021064</td>
      <td>0.019905</td>
      <td>0.002922</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Looking at the data after normalizing it, we see this time there are no negative values and they all are between 0 and 1.</p>
<p>And the score now?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled_norm</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Scaled training score :&#39;</span><span class="p">,</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled_norm</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Scaled training score : 0.8006485189373813
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Big difference in the KNN training performance after scaling the data.</p></li>
<li><p>But we saw last week that the training score doesn‚Äôt tell us much. We should look at the cross-validation score.</p></li>
</ul>
<p>So let‚Äôs see how we can do this but first‚Ä¶. let‚Äôs practice!</p>
</div>
<div class="section" id="id3">
<h2>Let‚Äôs Practice<a class="headerlink" href="#id3" title="Permalink to this headline">¬∂</a></h2>
<ol class="simple">
<li><p>When/Why do we need to impute our data?</p></li>
<li><p>If we have <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values in our data, can we simply drop the column missing the data?</p></li>
<li><p>Which scaling method will never produce negative values?</p></li>
<li><p>Which scaling method will never produce values greater than 1?</p></li>
<li><p>Which scaling method will produce values where the range depends on the values in the data?</p></li>
</ol>
<p><strong>True or False</strong><br />
6. <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> is a type of transformer.<br />
7. Scaling is a form of transformation.<br />
8. We can use <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> to impute values that are missing from numerical and categorical columns.</p>
</div>
<div class="section" id="feature-transformations-and-the-golden-rule">
<h2>Feature transformations and the golden rule<a class="headerlink" href="#feature-transformations-and-the-golden-rule" title="Permalink to this headline">¬∂</a></h2>
<p>How to carry out cross-validation?</p>
<ul class="simple">
<li><p>Last week we saw that cross-validation is a better way to get a realistic assessment of the model.</p></li>
<li><p>Let‚Äôs try cross-validation with transformed data.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">X_train_scaled_std</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.012620</td>
      <td>0.250975</td>
      <td>0.696373</td>
      <td>0.794236</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.009453</td>
      <td>0.215144</td>
      <td>0.684447</td>
      <td>0.791467</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.007875</td>
      <td>0.242024</td>
      <td>0.695532</td>
      <td>0.789436</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.007983</td>
      <td>0.231915</td>
      <td>0.679478</td>
      <td>0.793243</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.007914</td>
      <td>0.132963</td>
      <td>0.680657</td>
      <td>0.794820</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>Do you see any problem here?</p></li>
</ul>
<p>We are using our <code class="docutils literal notranslate"><span class="pre">X_train_scaled</span></code> in our <code class="docutils literal notranslate"><span class="pre">cross_validate()</span></code> function which already has all our preprocessing done.</p>
<a class="reference internal image-reference" href="../_images/cross-validation.png"><img alt="../_images/cross-validation.png" src="../_images/cross-validation.png" style="width: 80%;" /></a>
<p>That means that our validation set information is being used to calculate the mean and standard deviation (or min and max values for <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code>) for our training split!</p>
<p>We are allowing information from the validation set to <strong>leak</strong> into the training step.</p>
<p>What was our golden rule of machine learning again? Oh yeah -&gt; <em><strong>Our test data should not influence our training data</strong></em>.</p>
<p>This applies also to our validation data and that it also should not influence our training data.</p>
<p>With imputation and scaling, we are scaling and imputing values based on all the information in the data meaning the training data AND the validation data and so we are not adhering to the golden rule anymore.</p>
<p>Every row in our <code class="docutils literal notranslate"><span class="pre">x_train_scaled</span></code> has now been influenced in a minor way by every other row in <code class="docutils literal notranslate"><span class="pre">x_train_scaled</span></code>.</p>
<p>With scaling every row has been transformed based on all the data before splitting between training and validation.</p>
<p>We need to take care that we are keeping our validation data truly as unseen data.</p>
<p>Before we look at the right approach to this, let‚Äôs look at the <strong>WRONG</strong> approaches.</p>
<div class="section" id="bad-methodology-1-scaling-the-data-separately">
<h3>Bad methodology 1: Scaling the data separately<a class="headerlink" href="#bad-methodology-1-scaling-the-data-separately" title="Permalink to this headline">¬∂</a></h3>
<p>We make our transformer, we fit it on the training data and then transform the training data.</p>
<p>Then, we make a second transformer, fit it on the test data and then transform our test data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">();</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">);</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">)</span>


<span class="c1"># Creating a separate object for scaling test data - Not a good idea.</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">();</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_test_imp</span><span class="p">);</span> <span class="c1"># Calling fit on the test data - Yikes! </span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_imp</span><span class="p">)</span> <span class="c1"># Transforming the test data using the scaler fit on test data ... Bad! </span>


<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training score: &quot;</span><span class="p">,</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test score: &quot;</span><span class="p">,</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training score:  0.8
Test score:  0.7
</pre></div>
</div>
</div>
</div>
<p>This is bad because we are using two different StandardScaler objects but we want to apply the same transformation on the training and test splits.</p>
<p>The test data will have different values than the training data producing a different transformation than the training data.</p>
<p>We should never fit on test data, whether it‚Äôs to build a model or with a transforming, test data should never be exposed to the fit function.</p>
</div>
<div class="section" id="bad-methodology-2-scaling-the-data-together">
<h3>Bad methodology 2: Scaling the data together<a class="headerlink" href="#bad-methodology-2-scaling-the-data-together" title="Permalink to this headline">¬∂</a></h3>
<p>The next mistake is when we scale the data together. So instead of splitting our data, we are combining our training and testing and scaling it together.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_imp</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test_imp</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((18576, 8), (2064, 8))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># join the train and test sets back together</span>
<span class="n">XX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">X_train_imp</span><span class="p">,</span> <span class="n">X_test_imp</span><span class="p">))</span><span class="c1">## Don&#39;t do it! </span>
<span class="n">XX</span><span class="o">.</span><span class="n">shape</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(20640, 8)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XX</span><span class="p">)</span>
<span class="n">XX_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">XX</span><span class="p">)</span> 
<span class="n">XX_train</span> <span class="o">=</span> <span class="n">XX_scaled</span><span class="p">[:</span><span class="mi">18576</span><span class="p">]</span>
<span class="n">XX_test</span> <span class="o">=</span> <span class="n">XX_scaled</span><span class="p">[</span><span class="mi">18576</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XX_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train score: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">XX_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span> <span class="c1"># Misleading score</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test score: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">XX_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span> <span class="c1"># Misleading score</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train score:  0.8
Test score:  0.71
</pre></div>
</div>
</div>
</div>
<p>Here we are scaling the train and test splits together.</p>
<p>The golden rule says that the test data shouldn‚Äôt influence the training in any way.</p>
<p>Information from the test split is now affecting the mean for standardization!</p>
<p>This is a clear violation of the golden rule.</p>
<p>So what do we do? Enter ‚Ä¶.</p>
</div>
</div>
<div class="section" id="pipelines">
<h2>Pipelines<a class="headerlink" href="#pipelines" title="Permalink to this headline">¬∂</a></h2>
<p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html">Scikit-learn Pipeline</a> is here to save the day!</p>
<p>A <strong>pipeline</strong> is a sklearn function that contains a sequence of steps.</p>
<p>Essentially we give it all the actions we want to do with our data such as transformers and models and the pipeline will execute them in steps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs combine the preprocessing and model with pipeline.</p>
<p>we will instruct the pipeline to:</p>
<ol class="simple">
<li><p>Do imputation using <code class="docutils literal notranslate"><span class="pre">SimpleImputer()</span></code> using a strategy of ‚Äúmedian‚Äù</p></li>
<li><p>Scale our data using <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code></p></li>
<li><p>Build a <code class="docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code>.</p></li>
</ol>
<p>(The last step should be a model and earlier steps should be transformers)</p>
<p>Note: The input for <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> is a list containing tuples (one for each step).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
        <span class="p">(</span><span class="s2">&quot;reg&quot;</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">())</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;imputer&#39;, SimpleImputer(strategy=&#39;median&#39;)),
                (&#39;scaler&#39;, StandardScaler()), (&#39;reg&#39;, KNeighborsRegressor())])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Note that we are passing <code class="docutils literal notranslate"><span class="pre">X_train</span></code> and <strong>NOT</strong> the imputed or scaled data here.</p></li>
</ul>
<p>When we call <code class="docutils literal notranslate"><span class="pre">fit</span></code>  the pipeline is carrying out the following steps:</p>
<ul class="simple">
<li><p>Fit <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> on <code class="docutils literal notranslate"><span class="pre">X_train</span></code>.</p></li>
<li><p>Transform <code class="docutils literal notranslate"><span class="pre">X_train</span></code> using the fit <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> to create <code class="docutils literal notranslate"><span class="pre">X_train_imp</span></code>.</p></li>
<li><p>Fit <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> on <code class="docutils literal notranslate"><span class="pre">X_train_imp</span></code>.</p></li>
<li><p>Transform <code class="docutils literal notranslate"><span class="pre">X_train_imp</span></code> using the fit <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> to create <code class="docutils literal notranslate"><span class="pre">X_train_imp_scaled</span></code>.</p></li>
<li><p>Fit the model (<code class="docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code> in our case) on <code class="docutils literal notranslate"><span class="pre">X_train_imp_scaled</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([126500., 117380., 187700., ..., 259500., 308120.,  60860.])
</pre></div>
</div>
</div>
</div>
<p>When we call <code class="docutils literal notranslate"><span class="pre">predict</span></code> on our data, the following steps are carrying out:</p>
<ul class="simple">
<li><p>Transform <code class="docutils literal notranslate"><span class="pre">X_train</span></code> using the fit <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> to create <code class="docutils literal notranslate"><span class="pre">X_train_imp</span></code>.</p></li>
<li><p>Transform <code class="docutils literal notranslate"><span class="pre">X_train_imp</span></code> using the fit <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> to create <code class="docutils literal notranslate"><span class="pre">X_train_imp_scaled</span></code>.</p></li>
<li><p>Predict using the fit model (<code class="docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code> in our case) on <code class="docutils literal notranslate"><span class="pre">X_train_imp_scaled</span></code>.</p></li>
</ul>
<p>It is not fitting any of the data this time.</p>
<a class="reference internal image-reference" href="https://amueller.github.io/COMS4995-s20/slides/aml-04-preprocessing/images/pipeline.png"><img alt="https://amueller.github.io/COMS4995-s20/slides/aml-04-preprocessing/images/pipeline.png" src="https://amueller.github.io/COMS4995-s20/slides/aml-04-preprocessing/images/pipeline.png" style="width: 50%;" /></a>
<p><a class="reference external" href="https://amueller.github.io/COMS4995-s20/slides/aml-04-preprocessing/#18">Source</a></p>
<p>We can‚Äôt accidentally re-fit the preprocessor on the test data as we did before.</p>
<p>It automatically makes sure the same transformations are applied to train and test.</p>
<p>Now when we do cross-validation on the pipeline the transformers and the model are refit on each fold.</p>
<p>The pipeline applies the <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> on the train portion of the data and only <code class="docutils literal notranslate"><span class="pre">transform</span></code> on the validation portion in <strong>each fold</strong>.</p>
<p>This is how to avoid the Golden Rule violation!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores_processed</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores_processed</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.030792</td>
      <td>0.246158</td>
      <td>0.693883</td>
      <td>0.792395</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.026444</td>
      <td>0.225536</td>
      <td>0.685017</td>
      <td>0.789108</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.023450</td>
      <td>0.227923</td>
      <td>0.694409</td>
      <td>0.787796</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.024536</td>
      <td>0.214518</td>
      <td>0.677055</td>
      <td>0.792444</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.023502</td>
      <td>0.170633</td>
      <td>0.714494</td>
      <td>0.823421</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores_processed</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.025745
score_time     0.216953
test_score     0.692972
train_score    0.797033
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dummy</span> <span class="o">=</span> <span class="n">DummyRegressor</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">dummy</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.002139
score_time     0.000518
test_score    -0.055115
train_score   -0.054611
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>We can trust here now that the scores are not influenced but the training data and all our steps were done efficiently and easily too.</p>
</div>
<div class="section" id="id4">
<h2>Let‚Äôs Practice<a class="headerlink" href="#id4" title="Permalink to this headline">¬∂</a></h2>
<ol class="simple">
<li><p>Which of the following steps cannot be used in a pipeline?</p>
<ul class="simple">
<li><p>Scaling</p></li>
<li><p>Model building</p></li>
<li><p>Imputation</p></li>
<li><p>Data Splitting</p></li>
</ul>
</li>
<li><p>Why can‚Äôt we fit and transform the training and test data together?</p></li>
</ol>
<p><strong>True or False</strong><br />
3. We have to be careful of the order we put each transformation and model in a pipeline.<br />
4. Pipelines will fit and transform on both the training and validation folds during cross-validation.</p>
<div class="section" id="practice-coding-problem">
<h3>Practice Coding Problem<a class="headerlink" href="#practice-coding-problem" title="Permalink to this headline">¬∂</a></h3>
<p>Let‚Äôs bring in the basketball dataset again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Loading in the data</span>
<span class="n">bball_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/bball.csv&#39;</span><span class="p">)</span>
<span class="n">bball_df</span> <span class="o">=</span> <span class="n">bball_df</span><span class="p">[(</span><span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;G&#39;</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;F&#39;</span><span class="p">)]</span>

<span class="c1"># Define X and y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">bball_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="s1">&#39;salary&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span>

<span class="c1"># Split the dataset</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Build a pipeline named <code class="docutils literal notranslate"><span class="pre">bb_pipe</span></code> that:</p>
<ol class="simple">
<li><p>Imputes using ‚Äúmedian‚Äù as a strategy,</p></li>
<li><p>scale using <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code></p></li>
<li><p>builds a <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code>.</p></li>
</ol>
<p>Next, do 5 fold cross-validation on the pipeline using <code class="docutils literal notranslate"><span class="pre">X_train</span></code> and <code class="docutils literal notranslate"><span class="pre">y_train</span></code> and save the results in a dataframe.
Take the mean of each column and assess your model.</p>
</div>
</div>
<div class="section" id="what-we-ve-learned-today-a-id-9-a">
<h2>What We‚Äôve Learned Today<a id="9"></a><a class="headerlink" href="#what-we-ve-learned-today-a-id-9-a" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p>How the <span class="math notranslate nohighlight">\(k\)</span>NN algorithm works for regression.</p></li>
<li><p>How to build an SVM with RBF kernel model.</p></li>
<li><p>How changing <code class="docutils literal notranslate"><span class="pre">gamma</span></code> and <code class="docutils literal notranslate"><span class="pre">C</span></code> hyperparameters affects the fundamental tradeoff.</p></li>
<li><p>How to imputer values when we are missing data.</p></li>
<li><p>Why it‚Äôs important to scale our features.</p></li>
<li><p>How to scales our features.</p></li>
<li><p>How to build a pipeline that executes a number of steps without breaking the golden rule of ML.</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "bait509-ubc/BAIT509",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="lecture3.html" title="previous page">Lecture 3 - Baseline, k-Nearest Neighbours</a>
    <a class='right-next' id="next-link" href="lecture5.html" title="next page">Lecture 5 - Preprocessing Categorical Features and Column Transformer</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Hayley Boyce<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>