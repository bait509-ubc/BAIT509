
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>6. Naive Bayes and Hyperparameter Optimization &#8212; BAIT 509 - Business Applications of Machine Learning</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://bait509-ubc.github.io/BAIT509/intro.html/lectures/lecture6.html" />
    <link rel="shortcut icon" href="../_static/bait_logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7. Linear Models" href="lecture7.html" />
    <link rel="prev" title="5. Preprocessing Categorical Features and Column Transformer" href="lecture5.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/bait_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">BAIT 509 - Business Applications of Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p class="caption" role="heading">
 <span class="caption-text">
  Things You Should Know
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/who.html">
   Who: Hayley Boyce
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/how.html">
   How: The Course Structure
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/what.html">
   What: Learning Outcomes
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="lecture1.html">
   1. Intro to ML &amp;  Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture2.html">
   2. Splitting and Cross-validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture3.html">
   3. Baseline, k-Nearest Neighbours
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture4.html">
   4. SVM with RBF Kernel and Feature Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture5.html">
   5. Preprocessing Categorical Features and Column Transformer
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   6. Naive Bayes and Hyperparameter Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture7.html">
   7. Linear Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture8.html">
   8. Business Objectives/Statistical Questions and Feature Selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture9.html">
   9. Classification and Regression Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture10.html">
   10. Multi-Class, Pandas Profiling, Finale
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/attribution.html">
   Attribution
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/lectures/lecture6.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/bait509-ubc/BAIT509"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/bait509-ubc/BAIT509/issues/new?title=Issue%20on%20page%20%2Flectures/lecture6.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/bait509-ubc/BAIT509/edit/master/lectures/lecture6.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/bait509-ubc/BAIT509/master?urlpath=tree/lectures/lecture6.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#house-keeping">
   6.1. House Keeping
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lecture-learning-objectives">
   6.2. Lecture Learning Objectives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#five-minute-recap-lightning-questions">
   6.3. Five Minute Recap/ Lightning Questions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-lingering-questions">
     6.3.1. Some lingering questions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#naive-bayes-introduction-spam-non-spam">
   6.4. Naive Bayes introduction -  spam/non spam
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#naive-bayes-from-scratch">
   6.5. Naive Bayes from scratch
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#naive-bayes-approximation">
     6.5.1. Naive Bayes’ approximation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#estimating-p-text-spam-mid-text-message-the-left-side-of-our-equation">
     6.5.2. Estimating
     <span class="math notranslate nohighlight">
      \(P(\text{spam} \mid \text{message})\)
     </span>
     (The left side of our equation)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#estimating-p-text-non-spam-mid-text-message-the-right-side-of-our-equation">
     6.5.3. Estimating
     <span class="math notranslate nohighlight">
      \(P(\text{non spam} \mid \text{message})\)
     </span>
     (The right side of our equation)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#naive-bayes-classifier">
   6.6. Naive Bayes classifier
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-simple-solution-laplace-smoothing">
     6.6.1. A simple solution: Laplace smoothing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alpha-hyperparameter-and-the-fundamental-tradeoff">
     6.6.2.
     <code class="docutils literal notranslate">
      <span class="pre">
       alpha
      </span>
     </code>
     hyperparameter and the fundamental tradeoff
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#naive-bayes-on-real-data">
   6.7. Naive Bayes on Real Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice">
   6.8. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#automated-hyperparameter-optimization">
   6.9. Automated Hyperparameter Optimization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-problem-with-hyperparameters">
     6.9.1. The problem with hyperparameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-pick-hyperparameters">
     6.9.2. How to pick hyperparameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     6.9.3. Automated hyperparameter optimization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#let-s-apply-it">
     6.9.4. Let’s Apply it
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exhaustive-grid-search-trying-all-the-options">
   6.10. Exhaustive grid search - Trying ALL the options
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#implement-with-pipelines">
     6.10.1. Implement with Pipelines
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-a-grid">
     6.10.2. Why a grid?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#now-what">
     6.10.3. Now what?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#notice-any-problems">
     6.10.4. Notice any problems?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#randomized-hyperparameter-optimization">
     6.10.5. Randomized hyperparameter optimization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#continuous-values-for-hyperparameter-tuning-optional">
     6.10.6. Continuous values for hyperparameter tuning - optional
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-problem-with-hyperparameter-tuning-overfitting-the-validation-set">
   6.11. The problem with hyperparameter tuning - overfitting the validation set
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-overfitting-the-validation-set">
     6.11.1. Example: overfitting the validation set
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   6.12. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice-coding">
   6.13. Let’s Practice - Coding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-we-ve-learned-today-a-id-9-a">
   6.14. What We’ve Learned Today
   <a id="9">
   </a>
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="naive-bayes-and-hyperparameter-optimization">
<h1><span class="section-number">6. </span>Naive Bayes and Hyperparameter Optimization<a class="headerlink" href="#naive-bayes-and-hyperparameter-optimization" title="Permalink to this headline">¶</a></h1>
<p><em>Hayley Boyce, May 5th, 2021</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importing our libraries</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">altair</span> <span class="k">as</span> <span class="nn">alt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span><span class="p">,</span> <span class="n">DummyRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span><span class="p">,</span> <span class="n">SVC</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;code/&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">display_tree</span> <span class="kn">import</span> <span class="n">display_tree</span>
<span class="kn">from</span> <span class="nn">plot_classifier</span> <span class="kn">import</span> <span class="n">plot_classifier</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Preprocessing and pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">euclidean_distances</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">OrdinalEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="house-keeping">
<h2><span class="section-number">6.1. </span>House Keeping<a class="headerlink" href="#house-keeping" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Quiz Today!</p></li>
<li><p>Result of Polls</p></li>
<li><p>Assignment due Monday</p></li>
<li><p>Project groups this week</p></li>
<li><p>Project instructions next week</p></li>
<li><p>Heavy class today, more learning, less practice (sorry!)</p></li>
</ul>
</div>
<div class="section" id="lecture-learning-objectives">
<h2><span class="section-number">6.2. </span>Lecture Learning Objectives<a class="headerlink" href="#lecture-learning-objectives" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Explain the naive assumption of naive Bayes.</p></li>
<li><p>Predict targets by hands-on toy examples using naive Bayes.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>’s <code class="docutils literal notranslate"><span class="pre">MultiNomialNB</span></code>.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> and explain its usefulness.</p></li>
<li><p>Explain the need for smoothing in naive Bayes.</p></li>
<li><p>Explain how <code class="docutils literal notranslate"><span class="pre">alpha</span></code> controls the fundamental tradeoff.</p></li>
<li><p>Explain the need for hyperparameter optimization</p></li>
<li><p>Carry out hyperparameter optimization using <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>’s <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> and <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code>.</p></li>
</ul>
</div>
<div class="section" id="five-minute-recap-lightning-questions">
<h2><span class="section-number">6.3. </span>Five Minute Recap/ Lightning Questions<a class="headerlink" href="#five-minute-recap-lightning-questions" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>What kind of preprocessing must I do if I have a feature with categories that have an order to them?</p></li>
<li><p>How many columns do I need for a binary feature?</p></li>
<li><p>What tool do we use to preprocess all our pipelines and build a model without breaking the golden rule?</p></li>
<li><p>Between <code class="docutils literal notranslate"><span class="pre">Pipeline()</span></code> and <code class="docutils literal notranslate"><span class="pre">make_pipeline()</span></code>, which one assigns names to the steps on our behalf?</p></li>
<li><p>In text data, what are our features made up of?</p></li>
</ul>
<div class="section" id="some-lingering-questions">
<h3><span class="section-number">6.3.1. </span>Some lingering questions<a class="headerlink" href="#some-lingering-questions" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>How do I tune multiple hyperparameters at once?</p></li>
<li><p>What algorithm works well with our <code class="docutils literal notranslate"><span class="pre">spam</span></code>, <code class="docutils literal notranslate"><span class="pre">non</span> <span class="pre">spam</span></code> problem?</p></li>
</ul>
</div>
</div>
<div class="section" id="naive-bayes-introduction-spam-non-spam">
<h2><span class="section-number">6.4. </span>Naive Bayes introduction -  spam/non spam<a class="headerlink" href="#naive-bayes-introduction-spam-non-spam" title="Permalink to this headline">¶</a></h2>
<p>Last lecture we saw this spam classification problem where we used <code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code> to vectorize the text into features and used an <code class="docutils literal notranslate"><span class="pre">SVC</span></code> to classify each text message into either a class of <code class="docutils literal notranslate"><span class="pre">spam</span></code> or <code class="docutils literal notranslate"><span class="pre">non</span> <span class="pre">spam</span></code>.</p>
<p><span class="math notranslate nohighlight">\(X = \begin{bmatrix}\text{&quot;URGENT!! You have been selected to receive a £900 prize reward!&quot;,}\\ \text{&quot;Lol your always so convincing.&quot;}\\ \text{&quot;Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now!&quot;}\\ \end{bmatrix}\)</span> and <span class="math notranslate nohighlight">\(y = \begin{bmatrix}\text{spam} \\ \text{non spam} \\ \text{spam} \end{bmatrix}\)</span></p>
</div>
<div class="section" id="naive-bayes-from-scratch">
<h2><span class="section-number">6.5. </span>Naive Bayes from scratch<a class="headerlink" href="#naive-bayes-from-scratch" title="Permalink to this headline">¶</a></h2>
<p>Let’s do some naive Bayes calculations <strong>by hand</strong>🖐 🤚 .</p>
<p>Yes, there is going to be some math here but it’s going to be really helpful in understanding how this algorithm works!</p>
<p>Below we have a few texts and they are classed as either being  <strong>spam</strong> or <strong>non spam</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="p">[</span>
                        <span class="s2">&quot;URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Lol you are always so convincing.&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Sauder has interesting courses.&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Sauder has been interesting so far.&quot;</span> <span class="p">],</span>
                   <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;spam&quot;</span><span class="p">,</span> <span class="s2">&quot;non spam&quot;</span><span class="p">,</span> <span class="s2">&quot;non spam&quot;</span><span class="p">,</span> <span class="s2">&quot;spam&quot;</span><span class="p">,</span> <span class="s2">&quot;spam&quot;</span><span class="p">,</span> <span class="s2">&quot;non spam&quot;</span><span class="p">]})</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>URGENT!! As a valued network customer you have...</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Lol you are always so convincing.</td>
      <td>non spam</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Sauder has interesting courses.</td>
      <td>non spam</td>
    </tr>
    <tr>
      <th>3</th>
      <td>URGENT! You have won a 1 week FREE membership ...</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Had your mobile 11 months or more? U R entitle...</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Sauder has been interesting so far.</td>
      <td>non spam</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We know that we need to encode categorical data and transform it to numeric data to use it with machine learning since categoric columns throw an error when we try to fit our model.</p>
<p>This sounds like a job for <code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code> since we have words that need to be converted into features!</p>
<p>Here we are going to set <code class="docutils literal notranslate"><span class="pre">max_features=4</span></code> to make our calculations a little easier and <code class="docutils literal notranslate"><span class="pre">stop_words='english'</span></code> so we are getting meaningful words as features and not stop words.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>


<span class="n">count_vect</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">max_features</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">count_vect</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">])</span>
<span class="n">train_bow_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="nb">sorted</span><span class="p">(</span><span class="n">count_vect</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">])</span>

<span class="n">train_bow_df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">train_bow_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>free</th>
      <th>prize</th>
      <th>sauder</th>
      <th>urgent</th>
      <th>target</th>
    </tr>
    <tr>
      <th>X</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Lol you are always so convincing.</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
    <tr>
      <th>Sauder has interesting courses.</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
    <tr>
      <th>URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Sauder has been interesting so far.</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Suppose we are given 2 text messages in and we want to find the targets for these examples, how do we do it using naive Bayes?</p>
<p>First, let’s get a numeric representation of our text messages.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_texts</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;URGENT! Free!!&quot;</span><span class="p">,</span> <span class="s2">&quot;I like Sauder&quot;</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">count_vect</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_texts</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">test_bow_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">count_vect</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">test_texts</span><span class="p">)</span>
<span class="n">test_bow_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>urgent</th>
      <th>prize</th>
      <th>sauder</th>
      <th>free</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>URGENT! Free!!</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>I like Sauder</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s look at the text: “<strong>URGENT! Free!!</strong>”</p>
<blockquote>
<div><p>Is this <strong>spam</strong> or <strong>non spam</strong>?</p>
</div></blockquote>
<p>So what we want to know is:</p>
<div class="math notranslate nohighlight">
\[P(\textrm{spam}|\textrm{&quot;URGENT! Free!!&quot;})\]</div>
<div class="math notranslate nohighlight">
\[ \text{and} \]</div>
<div class="math notranslate nohighlight">
\[P(\textrm{non spam}|\textrm{&quot;URGENT! Free!!&quot;})\]</div>
<p>We really only care which one of these is bigger and whichever probability is larger is how we can classify our sentence as <strong>spam</strong> or <strong>non spam</strong>.</p>
<div class="math notranslate nohighlight">
\[P(\textrm{spam}|\textrm{&quot;URGENT! Free!!&quot;}) &gt; P(\textrm{non spam}|\textrm{&quot;URGENT! Free!!&quot;})\]</div>
<p>Remember our Bayes’ Theorem is the following:</p>
<div class="math notranslate nohighlight">
\[\text{P}(Y|X) = \frac{\text{P}(X | Y) \text{P}(Y)}{\text{P}(X)}\]</div>
<p>In this case:</p>
<p><span class="math notranslate nohighlight">\(X\)</span> is the representation of the words in our text ie; <span class="math notranslate nohighlight">\(\text{free} = 1, \text{prize} = 0, \text{sauder} = 0,  \text{urgent} = 1\)</span></p>
<p><span class="math notranslate nohighlight">\(y\)</span> is our target either spam or non spam</p>
<p>Substituting into Bayes rule we get:</p>
<div class="math notranslate nohighlight">
\[\frac{P(\text{free} = 1, \text{prize} = 0,\text{sauder} = 0,  \text{urgent} = 1 |\textrm{spam})*P(\textrm{spam})}{P(\text{free} = 1, \text{prize} = 0,\text{sauder} = 0, \text{urgent} = 1 )}&gt;\frac{P(\text{free} = 1, \text{prize} = 0, \text{sauder} = 0, \text{urgent} = 1 |\textrm{non spam})*P(\textrm{non spam})}{P(\text{free} = 1, \text{prize} = 0,\text{sauder} = 0, \text{urgent} = 1 )}\]</div>
<p>Now, there are two reasons naive Bayes is so easy:</p>
<ol class="simple">
<li><p>We can cancel out the denominator which leads us to this:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[P(\text{free} = 1, \text{prize} = 0,\text{sauder} = 0, \text{urgent} = 1|\textrm{spam})*P(\textrm{spam}) &gt; P(\text{free} = 1, \text{prize} = 0,\text{sauder} = 0, \text{urgent} = 1|\textrm{non spam})*P(\textrm{non spam})\]</div>
<ol class="simple">
<li><p>We can simplify the numerator</p></li>
</ol>
<div class="section" id="naive-bayes-approximation">
<h3><span class="section-number">6.5.1. </span>Naive Bayes’ approximation<a class="headerlink" href="#naive-bayes-approximation" title="Permalink to this headline">¶</a></h3>
<p>We assume each feature (word) is conditionally independent. (Assume that all features in <span class="math notranslate nohighlight">\(X\)</span> are mutually independent, conditional on the target class.)</p>
<ul class="simple">
<li><p>In general,
$<span class="math notranslate nohighlight">\(P(\text{message} \mid \text{spam}) = P(w_1, w_2, . . . , w_d \mid \text{spam}) \approx \prod_{i=1}^{d}P(w_i \mid \text{spam})\)</span>$</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(\text{message} \mid \text{non spam}) = P(w_1, w_2, . . . , w_d \mid \text{non spam}) \approx \prod_{i=1}^{d}P(w_i \mid \text{non spam})\]</div>
<p>That means simply:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation}
\begin{split}
&amp; P(\text{free} = 1, \text{prize} = 0,\text{sauder} = 0, \text{urgent} = 1 \mid \text{spam}) \\
&amp;\approx  P(\text{free} = 1 \mid \text{spam}) \times P(\text{prize} = 0 \mid \text{spam}) \times P(\text{sauder} = 0 \mid \text{spam}) \times  P(\text{urgent} = 1 \mid \text{spam})
\end{split}
\end{equation}\end{split}\]</div>
<p>And for the other class <strong>non spam</strong>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation}
\begin{split}
&amp; P(\text{free} = 1, \text{prize} = 0,\text{sauder} = 0, \text{urgent} = 1 \mid \text{non spam}) \\
&amp;\approx P(\text{free} = 1 \mid \text{non spam}) \times P(\text{prize} = 0 \mid \text{non spam}) \times P(\text{sauder} = 0 \mid \text{non spam}) \times P(\text{urgent} = 1 \mid \text{non spam})
\end{split}
\end{equation}\end{split}\]</div>
<p>So our equation has boiled down to is:</p>
<div class="math notranslate nohighlight">
\[ P(\text{free} = 1 \mid \text{spam}) \times P(\text{prize} = 0 \mid \text{spam}) \times P(\text{sauder} = 0 \mid \text{spam}) \times P(\text{urgent} = 1 \mid \text{spam})*P(\textrm{spam}) &gt;\]</div>
<div class="math notranslate nohighlight">
\[ P(\text{free} = 1 \mid \text{non spam}) \times P(\text{prize} = 0 \mid \text{non spam}) \times P(\text{sauder} = 0 \mid \text{non spam}) \times P(\text{urgent} = 1 \mid \text{non spam}) *P(\textrm{non spam})\]</div>
<ul class="simple">
<li><p>Now we just need to calculate each of those probabilities which is easy!</p></li>
</ul>
</div>
<div class="section" id="estimating-p-text-spam-mid-text-message-the-left-side-of-our-equation">
<h3><span class="section-number">6.5.2. </span>Estimating <span class="math notranslate nohighlight">\(P(\text{spam} \mid \text{message})\)</span> (The left side of our equation)<a class="headerlink" href="#estimating-p-text-spam-mid-text-message-the-left-side-of-our-equation" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[P(\text{free} = 1 \mid \text{spam}) \times P(\text{prize} = 0 \mid \text{spam})  \times P(\text{sauder} = 0 \mid \text{spam}) \times P(\text{urgent} = 1 \mid \text{spam})*P(\textrm{spam}) \]</div>
<p>We need the following:</p>
<ol class="simple">
<li><p>Prior probability:
<span class="math notranslate nohighlight">\(P(\text{spam})\)</span></p></li>
<li><p>Conditional probabilities:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(P(\text{free} = 1 \mid \text{spam})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{prize} = 0 \mid \text{spam})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{sauder} = 0 \mid \text{spam})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{urgent} = 1 \mid \text{spam})\)</span></p></li>
</ol>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_bow_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>free</th>
      <th>prize</th>
      <th>sauder</th>
      <th>urgent</th>
      <th>target</th>
    </tr>
    <tr>
      <th>X</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Lol you are always so convincing.</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
    <tr>
      <th>Sauder has interesting courses.</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
    <tr>
      <th>URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Sauder has been interesting so far.</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>Prior probability</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(P(\text{spam}) = 3/6\)</span></p></li>
</ul>
</li>
<li><p>Conditional probabilities</p>
<ul>
<li><p>What is  <span class="math notranslate nohighlight">\(P(\text{free} = 1 \mid \text{spam})\)</span> ??</p>
<ul>
<li><p>Given target is spam, how often “free”= 1? <span class="math notranslate nohighlight">\(= 2/3\)</span></p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(P(\text{prize} = 0 \mid \text{spam}) = 1/3\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{sauder} = 0 \mid \text{spam}) = 3/3\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{urgent} = 1 \mid \text{spam}) = 2/3\)</span></p></li>
</ul>
</li>
</ul>
<p>Now we have everything we need to do our calculations!</p>
<div class="math notranslate nohighlight">
\[P(\textrm{spam}|\text{free} = 1, \text{prize} = 0, \text{sauder} = 0,  \text{urgent} = 1) = P(\text{free} = 1|\textrm{spam})*P(\text{prize} = 0|\textrm{spam})*P(\textrm{sauder = 0}|\textrm{spam})*P(\text{urgent} = 1|\textrm{spam})*P(\textrm{spam})\]</div>
<div class="math notranslate nohighlight">
\[=  \frac{2}{3} * \frac{1}{3}* \frac{3}{3} * \frac{2}{3} *\frac{3}{6} \]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spam_prior</span> <span class="o">=</span> <span class="mi">3</span><span class="o">/</span><span class="mi">6</span>
<span class="n">sauder0_spam</span> <span class="o">=</span> <span class="mi">3</span><span class="o">/</span><span class="mi">3</span>
<span class="n">free1_spam</span> <span class="o">=</span> <span class="mi">2</span><span class="o">/</span><span class="mi">3</span>
<span class="n">prize0_spam</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span>
<span class="n">urgent1_spam</span> <span class="o">=</span> <span class="mi">2</span><span class="o">/</span><span class="mi">3</span>
<span class="n">spam_prob</span> <span class="o">=</span> <span class="n">spam_prior</span> <span class="o">*</span> <span class="n">sauder0_spam</span> <span class="o">*</span> <span class="n">free1_spam</span> <span class="o">*</span> <span class="n">prize0_spam</span> <span class="o">*</span> <span class="n">urgent1_spam</span>
<span class="n">spam_prob</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.07407407407407407
</pre></div>
</div>
</div>
</div>
<p>Ok, So we’ve done our left side! Now we have to do the right!</p>
</div>
<div class="section" id="estimating-p-text-non-spam-mid-text-message-the-right-side-of-our-equation">
<h3><span class="section-number">6.5.3. </span>Estimating <span class="math notranslate nohighlight">\(P(\text{non spam} \mid \text{message})\)</span>  (The right side of our equation)<a class="headerlink" href="#estimating-p-text-non-spam-mid-text-message-the-right-side-of-our-equation" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[P(\text{free} = 1 \mid \text{ non spam}) \times P(\text{prize} = 0 \mid \text{non spam})  \times P(\text{sauder} = 0 \mid \text{non spam}) \times P(\text{urgent} = 1 \mid \text{non spam})*P(\textrm{non spam}) \]</div>
<p>Now we need the following:</p>
<ol class="simple">
<li><p>Prior probability: <span class="math notranslate nohighlight">\(P(\text{non spam})\)</span></p></li>
<li><p>Conditional probabilities:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(P(\text{free} = 1 \mid \text{non spam})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{prize} = 0 \mid \text{non spam})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{sauder} = 0 \mid \text{non spam})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{urgent} = 1 \mid \text{non spam})\)</span></p></li>
</ol>
</li>
</ol>
<p>Again we use the data to calculate these probabilities.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_bow_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>free</th>
      <th>prize</th>
      <th>sauder</th>
      <th>urgent</th>
      <th>target</th>
    </tr>
    <tr>
      <th>X</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Lol you are always so convincing.</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
    <tr>
      <th>Sauder has interesting courses.</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
    <tr>
      <th>URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Sauder has been interesting so far.</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>Prior probability</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(P(\text{non spam}) = 3/6\)</span></p></li>
</ul>
</li>
<li><p>Conditional probabilities</p>
<ul>
<li><p>What is <span class="math notranslate nohighlight">\(P(\text{free} = 1 \mid \text{non spam})\)</span> ?</p>
<ul>
<li><p>Given the target is non spam, how ofter “free”=1? <span class="math notranslate nohighlight">\(0/3\)</span></p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(P(\text{prize} = 0 \mid \text{non spam}) = 3/3\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{sauder} = 0 \mid \text{non spam}) =1/3\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{urgent} = 1 \mid \text{non spam}) = 0/3\)</span></p></li>
</ul>
</li>
</ul>
<p>Time for our calculation:</p>
<div class="math notranslate nohighlight">
\[P(\textrm{non spam}|\text{free} = 1, \text{prize} = 0,\text{sauder} = 0,  \text{urgent} = 1) = P(\text{free} = 1|\textrm{non spam})*P( \text{prize} = 0|\textrm{non spam})*P(\textrm{sauder = 0}|\textrm{non spam})*P(\text{urgent} = 1|\textrm{non spam})*P(\textrm{non spam})\]</div>
<div class="math notranslate nohighlight">
\[= \frac{1}{3} * \frac{0}{3} * \frac{3}{3}* \frac{0}{3} *\frac{3}{6} \]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">non_spam_prior</span> <span class="o">=</span> <span class="mi">3</span><span class="o">/</span><span class="mi">6</span>
<span class="n">sauder0_non_spam</span> <span class="o">=</span> <span class="mi">0</span><span class="o">/</span><span class="mi">3</span>
<span class="n">free1_non_spam</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span>
<span class="n">prize0_non_spam</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span>
<span class="n">urgent1_non_spam</span> <span class="o">=</span> <span class="mi">2</span><span class="o">/</span><span class="mi">3</span>
<span class="n">non_spam_prob</span> <span class="o">=</span> <span class="n">non_spam_prior</span> <span class="o">*</span> <span class="n">sauder0_non_spam</span> <span class="o">*</span> <span class="n">free1_non_spam</span> <span class="o">*</span> <span class="n">prize0_non_spam</span> <span class="o">*</span> <span class="n">urgent1_non_spam</span>
<span class="n">non_spam_prob</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0
</pre></div>
</div>
</div>
</div>
<p>so our equation:</p>
<div class="math notranslate nohighlight">
\[ P(\text{free} = 1 \mid \text{spam}) \times P(\text{prize} = 0 \mid \text{spam}) \times P(\text{sauder} = 0 \mid \text{spam}) \times P(\text{urgent} = 1 \mid \text{spam})*P(\textrm{spam}) &gt;\]</div>
<div class="math notranslate nohighlight">
\[ P(\text{free} = 1 \mid \text{non spam}) \times P(\text{prize} = 0 \mid \text{non spam}) \times P(\text{sauder} = 0 \mid \text{non spam}) \times P(\text{urgent} = 1 \mid \text{non spam}) *P(\textrm{non spam})\]</div>
<p>has been calculated to</p>
<p>0.07407407407407407 &gt; 0.0</p>
<p>Since our left side is greater than the right side, our text is classified as <strong>spam</strong>!</p>
<p>We could normalize this result and say 100% spam and 0% non spam so that the probabilities add up to 100%.</p>
<p>Now let’s verify our result using sklearn.</p>
</div>
</div>
<div class="section" id="naive-bayes-classifier">
<h2><span class="section-number">6.6. </span>Naive Bayes classifier<a class="headerlink" href="#naive-bayes-classifier" title="Permalink to this headline">¶</a></h2>
<p>The main Naive Bayes classifier in sklearn is called <code class="docutils literal notranslate"><span class="pre">MultinomialNB</span></code> and exists in the <code class="docutils literal notranslate"><span class="pre">naive_bayes</span></code> module.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_bow_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>free</th>
      <th>prize</th>
      <th>sauder</th>
      <th>urgent</th>
      <th>target</th>
    </tr>
    <tr>
      <th>X</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Lol you are always so convincing.</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
    <tr>
      <th>Sauder has interesting courses.</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
    <tr>
      <th>URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Sauder has been interesting so far.</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s split up our data into our features and targets:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">train_bow_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_bow_df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Here I am selecting the first row of our test set which was the <strong>URGENT! Free!!</strong> text.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_bow_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">0</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>urgent</th>
      <th>prize</th>
      <th>sauder</th>
      <th>free</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>URGENT! Free!!</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Here we get a prediction of spam:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nb</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_bow_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.8/site-packages/sklearn/naive_bayes.py:511: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10
  warnings.warn(&#39;alpha too small will result in numeric errors, &#39;
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;spam&#39;], dtype=&#39;&lt;U8&#39;)
</pre></div>
</div>
</div>
</div>
<p>Instead of using <code class="docutils literal notranslate"><span class="pre">predict</span></code>,  we can use something called <code class="docutils literal notranslate"><span class="pre">predict_proba()</span></code>  with Naive Bayes classifier which gives us the <em><strong>proba</strong></em>bilities of each class happening.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">predict</span></code> returns the class with the highest probability.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> gives us the actual probability scores.</p></li>
<li><p>Looking at the probabilities can help us understand the model.</p></li>
</ul>
<p>We will look more into this in Lecture 7.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prediction</span> <span class="o">=</span>  <span class="n">nb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_bow_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span><span class="n">prediction</span><span class="p">,</span><span class="n">columns</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>non spam</th>
      <th>spam</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.250000e-20</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We get the same probabilities as we did it by hand.</p>
<p>(Ok 2.250000e-20 is essentially 0 but due to computing and storage, python specifies this 0 as an extremely small number.)</p>
<p>What about this warning we see?</p>
<blockquote>
<div><p>‘alpha too small will result in numeric errors’</p>
</div></blockquote>
<p>Well, let’s look at our conditional probabilities again from the right side of our equation.</p>
<ul class="simple">
<li><p>Conditional probabilities</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(P(\text{free} = 1 \mid \text{non spam}) = 0/3\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{prize} = 0 \mid \text{non spam}) = 3/3\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{sauder} = 0 \mid \text{non spam}) =  1/3\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{urgent} = 1 \mid \text{non spam}) = 0/3\)</span></p></li>
</ul>
</li>
</ul>
<p>Is it wise to say that given a text that is non spam the probability of free occurring is 0?</p>
<p>Not really. We only are using 6 examples here and setting this to 0 (and <span class="math notranslate nohighlight">\(P(\text{urgent} = 1 \mid \text{non spam}) = 0\)</span>)   is making the whole right side of the equation equal to 0.</p>
<p>Naive Bayes naively multiplies all the feature likelihoods together, and if any of the terms is zero, it’s going to void all other evidence and the probability of the class is going to be zero.</p>
<p>This is somewhat problematic.</p>
<p>We have limited data and if we do not see a feature occurring with a class, it doesn’t mean it would never occur with that class.</p>
<p>How can we fix this?</p>
<div class="section" id="a-simple-solution-laplace-smoothing">
<h3><span class="section-number">6.6.1. </span>A simple solution: Laplace smoothing<a class="headerlink" href="#a-simple-solution-laplace-smoothing" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>The simplest way to avoid zero probabilities is to add a value(<span class="math notranslate nohighlight">\(\alpha\)</span>) to all the counts. This is called <strong>Laplace smoothing</strong></p></li>
</ul>
<p>Generally, we set alpha (<span class="math notranslate nohighlight">\(\alpha\)</span>) equal to 1 and in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> we control it using hyperparameter <code class="docutils literal notranslate"><span class="pre">alpha</span></code>.</p>
<p>This means that we give an instance of every word appearing once with a target of spam, as well as a target of non spam.</p>
<p>By default <code class="docutils literal notranslate"><span class="pre">alpha=1.0</span></code> in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>.</p>
<p>Let’s see what our probabilities are now using alpha=1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nb</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_bow_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">0</span><span class="p">]]),</span>
             <span class="n">columns</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>non spam</th>
      <th>spam</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.235849</td>
      <td>0.764151</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>A bit smoother now, wouldn’t you say?</p>
</div>
<div class="section" id="alpha-hyperparameter-and-the-fundamental-tradeoff">
<h3><span class="section-number">6.6.2. </span><code class="docutils literal notranslate"><span class="pre">alpha</span></code> hyperparameter and the fundamental tradeoff<a class="headerlink" href="#alpha-hyperparameter-and-the-fundamental-tradeoff" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>High alpha <span class="math notranslate nohighlight">\(\rightarrow\)</span> underfitting</p>
<ul>
<li><p>means we are adding large counts to everything and so we are diluting the data</p></li>
</ul>
</li>
<li><p>Low alpha <span class="math notranslate nohighlight">\(\rightarrow\)</span> overfitting</p></li>
</ul>
</div>
</div>
<div class="section" id="naive-bayes-on-real-data">
<h2><span class="section-number">6.7. </span>Naive Bayes on Real Data<a class="headerlink" href="#naive-bayes-on-real-data" title="Permalink to this headline">¶</a></h2>
<p>let’s try <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>’s implementation of Naive Bayes on a modified version of Kaggle’s <a class="reference external" href="https://www.kaggle.com/vstepanenko/disaster-tweets">Disaster Tweets</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tweets_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/tweets_mod.csv&quot;</span><span class="p">)</span>
<span class="n">tweets_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>YOU THERE, PACHIRISU PUNK, PREPARE TO BE DESTR...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Face absolutely flattened against the glass of...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Bruhhhh I screamed when she said that 😭 MY HEA...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Granting warrants to "authorise police to ente...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Ang lala hahaha I woke up to a deluge of death...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>3995</th>
      <td>As it seems to be fairly contagious, I'm think...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3996</th>
      <td>#BoundBrookFire Firefighters from several diff...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3997</th>
      <td>It is turning out to be a very violent storm a...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3998</th>
      <td>A raging fire in Bound Brook, New Jersey, on S...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3999</th>
      <td>Hazardous eruption a possibility after Philipp...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>4000 rows × 2 columns</p>
</div></div></div>
</div>
<p>Let’s split it into our training and test sets as well as our features and target objects.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">tweets_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>
<span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1420</th>
      <td>How low have you sunk Alice, just clickbait fo...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1638</th>
      <td>Watching this tonight as I was working yesterd...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>616</th>
      <td>January 14, 2020 at about 08:30 am, personnel ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>184</th>
      <td>Next oil spill you drone strike the CEO's neig...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2075</th>
      <td>Another 6.0 aftershock has hit Puerto Rico aft...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Next, we make a pipeline and cross-validate!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_nb</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">CountVectorizer</span><span class="p">(),</span> <span class="n">MultinomialNB</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe_nb</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.091117</td>
      <td>0.017300</td>
      <td>0.796875</td>
      <td>0.948438</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.076795</td>
      <td>0.015993</td>
      <td>0.801562</td>
      <td>0.948438</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.071020</td>
      <td>0.015681</td>
      <td>0.801562</td>
      <td>0.946875</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.070094</td>
      <td>0.013736</td>
      <td>0.837500</td>
      <td>0.945703</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.076934</td>
      <td>0.014068</td>
      <td>0.814063</td>
      <td>0.944531</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.077192
score_time     0.015356
test_score     0.810312
train_score    0.946797
dtype: float64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="let-s-practice">
<h2><span class="section-number">6.8. </span>Let’s Practice<a class="headerlink" href="#let-s-practice" title="Permalink to this headline">¶</a></h2>
<p>Using naive Bayes by hand, what class would naive Bayes predict for the second example “I like Sauder”.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_bow_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>free</th>
      <th>prize</th>
      <th>sauder</th>
      <th>urgent</th>
      <th>target</th>
    </tr>
    <tr>
      <th>X</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Lol you are always so convincing.</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
    <tr>
      <th>Sauder has interesting courses.</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
    <tr>
      <th>URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Sauder has been interesting so far.</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>non spam</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_bow_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">1</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>urgent</th>
      <th>prize</th>
      <th>sauder</th>
      <th>free</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>I like Sauder</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s do some of the steps here:</p>
<p><strong>spam side</strong></p>
<p>1. Prior probability:<br />
<span class="math notranslate nohighlight">\(P(\text{spam}) = \)</span></p>
<p>2. Conditional probabilities:</p>
<p>2.1 <span class="math notranslate nohighlight">\(P(\text{free} = 0 \mid \text{spam}) = \)</span><br />
2.2 <span class="math notranslate nohighlight">\(P(\text{prize} = 0 \mid \text{spam}) = \)</span>
2.3 <span class="math notranslate nohighlight">\(P(\text{sauder} = 1 \mid \text{spam}) = \)</span>
2.4 <span class="math notranslate nohighlight">\(P(\text{urgent} = 0 \mid \text{spam}) = \)</span></p>
<br>
<p>3. <span class="math notranslate nohighlight">\(P(\textrm{spam}|\text{free} = 0, \text{prize} = 0, \text{sauder} = 1,  \text{urgent} = 0) = \)</span></p>
<p><strong>non spam side</strong></p>
<p>4. Prior probability:<br />
<span class="math notranslate nohighlight">\(P(\text{non spam}) = \)</span></p>
<p>5. Conditional probabilities:<br />
5.1 <span class="math notranslate nohighlight">\(P(\text{free} = 0 \mid \text{non spam}) = \)</span><br />
5.2 <span class="math notranslate nohighlight">\(P(\text{prize} = 0 \mid \text{non spam}) = \)</span><br />
5.3 <span class="math notranslate nohighlight">\(P(\text{sauder} = 1 \mid \text{non spam}) = \)</span><br />
5.4 <span class="math notranslate nohighlight">\(P(\text{urgent} = 0 \mid \text{non spam}) = \)</span></p>
<p>6. <span class="math notranslate nohighlight">\(P(\textrm{non spam}|\text{free} = 0, \text{prize} = 0, \text{sauder} = 1,  \text{urgent} = 0) =\)</span></p>
<p><strong>Final Class</strong></p>
<p>7. CLASS AS:</p>
<div class="dropdown admonition">
<p class="admonition-title">Solutions!</p>
<p>1/. <span class="math notranslate nohighlight">\(3/6\)</span><br />
2.1 <span class="math notranslate nohighlight">\(1/3\)</span><br />
2.2 <span class="math notranslate nohighlight">\(1/3\)</span><br />
2.3 <span class="math notranslate nohighlight">\(0/3\)</span><br />
2.4 <span class="math notranslate nohighlight">\(1/3\)</span><br />
3. <span class="math notranslate nohighlight">\(\frac{1}{3} * \frac{1}{3}* \frac{0}{3} * \frac{1}{3} *\frac{3}{6} = 0\)</span></p>
<p>4. <span class="math notranslate nohighlight">\(3/6\)</span><br />
5.1 <span class="math notranslate nohighlight">\(3/3\)</span><br />
5.2 <span class="math notranslate nohighlight">\(3/3\)</span><br />
5.3 <span class="math notranslate nohighlight">\(2/3\)</span><br />
5.4 <span class="math notranslate nohighlight">\(3/3\)</span></p>
<p>6. <span class="math notranslate nohighlight">\(\frac{3}{3} * \frac{3}{3}* \frac{2}{3} * \frac{3}{3} *\frac{3}{6} = 1/3\)</span><br />
7. Non spam</p>
</div>
</div>
<div class="section" id="automated-hyperparameter-optimization">
<h2><span class="section-number">6.9. </span>Automated Hyperparameter Optimization<a class="headerlink" href="#automated-hyperparameter-optimization" title="Permalink to this headline">¶</a></h2>
<p>We’ve seen quite a few different hyperparameters for different models.</p>
<p>We’ve seen <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> and <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> for decision trees.</p>
<p>We’ve seen <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code> and <code class="docutils literal notranslate"><span class="pre">weights</span></code> for K-Nearest Neighbours and we’ve seen <code class="docutils literal notranslate"><span class="pre">gamma</span></code> and <code class="docutils literal notranslate"><span class="pre">C</span></code> for SVMs with RBF.</p>
<p>We’ve even seen hyperparameters for our transformations like <code class="docutils literal notranslate"><span class="pre">strategy</span></code> for our <code class="docutils literal notranslate"><span class="pre">SimpleImputer()</span></code>.</p>
<p>They are important and we’ve seen they can really help optimize your model, but we’ve also seen how difficult it can be to figure out how to set them.</p>
<div class="section" id="the-problem-with-hyperparameters">
<h3><span class="section-number">6.9.1. </span>The problem with hyperparameters<a class="headerlink" href="#the-problem-with-hyperparameters" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>We may have a lot of them. (deep learning!)</p></li>
<li><p>Picking reasonable hyperparameters is important -&gt; it helps avoid underfit or overfit models.</p></li>
<li><p>Nobody knows exactly how to choose them.</p></li>
<li><p>May interact with each other in unexpected ways.</p></li>
<li><p>The best settings depend on the specific data/problem.</p></li>
<li><p>Can take a long time to execute.</p></li>
</ul>
</div>
<div class="section" id="how-to-pick-hyperparameters">
<h3><span class="section-number">6.9.2. </span>How to pick hyperparameters<a class="headerlink" href="#how-to-pick-hyperparameters" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Manual hyperparameter optimization (What we’ve done so far)</p>
<ul>
<li><p>We may have some intuition about what might work.</p></li>
<li><p>It takes a lot of work.</p></li>
</ul>
</li>
</ul>
<p><strong>OR…</strong></p>
<ul class="simple">
<li><p><strong>Automated hyperparameter optimization</strong> (hyperparameter tuning)</p>
<ul>
<li><p>Reduce human effort.</p></li>
<li><p>Less prone to error.</p></li>
<li><p>Data-driven approaches may be effective.</p></li>
<li><p>It may be hard to incorporate intuition.</p></li>
<li><p>Overfitting on the validation set.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id1">
<h3><span class="section-number">6.9.3. </span>Automated hyperparameter optimization<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Exhaustive grid search: <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"><code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.GridSearchCV</span></code></a></p></li>
<li><p>Randomized hyperparameter optimization: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html" target="_blank"><code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.RandomizedSearchCV</span></code></a></p></li>
</ul>
</div>
<div class="section" id="let-s-apply-it">
<h3><span class="section-number">6.9.4. </span>Let’s Apply it<a class="headerlink" href="#let-s-apply-it" title="Permalink to this headline">¶</a></h3>
<p>Let’s bring back the cities dataset we worked with in previous lectures.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cities_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/canada_usa_cities.csv&quot;</span><span class="p">)</span>
<span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cities_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">]),</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">]),</span> <span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>160</th>
      <td>-76.4813</td>
      <td>44.2307</td>
    </tr>
    <tr>
      <th>127</th>
      <td>-81.2496</td>
      <td>42.9837</td>
    </tr>
    <tr>
      <th>169</th>
      <td>-66.0580</td>
      <td>45.2788</td>
    </tr>
    <tr>
      <th>188</th>
      <td>-73.2533</td>
      <td>45.3057</td>
    </tr>
    <tr>
      <th>187</th>
      <td>-67.9245</td>
      <td>47.1652</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
</div>
<div class="section" id="exhaustive-grid-search-trying-all-the-options">
<h2><span class="section-number">6.10. </span>Exhaustive grid search - Trying ALL the options<a class="headerlink" href="#exhaustive-grid-search-trying-all-the-options" title="Permalink to this headline">¶</a></h2>
<p>We import <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn.model_selection</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
</pre></div>
</div>
</div>
</div>
<p>We need to first decide on our model and which hyperparameters we want to tune.</p>
<p>We are going to use an SVC classifier.</p>
<p>After that, we built a dictionary called <code class="docutils literal notranslate"><span class="pre">param_grid</span></code> and we specify the values we wish to look over for the hyperparameter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]}</span>
</pre></div>
</div>
</div>
</div>
<p>Then we initiate our model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Assigning <code class="docutils literal notranslate"><span class="pre">verbose</span></code> tells <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> to print some output while it’s running.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 4 candidates, totalling 20 fits
[CV] gamma=0.1 .......................................................
[CV] ........................................ gamma=0.1, total=   0.0s
[CV] gamma=0.1 .......................................................
[CV] ........................................ gamma=0.1, total=   0.0s
[CV] gamma=0.1 .......................................................
[CV] ........................................ gamma=0.1, total=   0.0s
[CV] gamma=0.1 .......................................................
[CV] ........................................ gamma=0.1, total=   0.0s
[CV] gamma=0.1 .......................................................
[CV] ........................................ gamma=0.1, total=   0.0s
[CV] gamma=1.0 .......................................................
[CV] ........................................ gamma=1.0, total=   0.0s
[CV] gamma=1.0 .......................................................
[CV] ........................................ gamma=1.0, total=   0.0s
[CV] gamma=1.0 .......................................................
[CV] ........................................ gamma=1.0, total=   0.0s
[CV] gamma=1.0 .......................................................
[CV] ........................................ gamma=1.0, total=   0.0s
[CV] gamma=1.0 .......................................................
[CV] ........................................ gamma=1.0, total=   0.0s
[CV] gamma=10 ........................................................
[CV] ......................................... gamma=10, total=   0.0s
[CV] gamma=10 ........................................................
[CV] ......................................... gamma=10, total=   0.0s
[CV] gamma=10 ........................................................
[CV] ......................................... gamma=10, total=   0.0s
[CV] gamma=10 ........................................................
[CV] ......................................... gamma=10, total=   0.0s
[CV] gamma=10 ........................................................
[CV] ......................................... gamma=10, total=   0.0s
[CV] gamma=100 .......................................................
[CV] ........................................ gamma=100, total=   0.0s
[CV] gamma=100 .......................................................
[CV] ........................................ gamma=100, total=   0.0s
[CV] gamma=100 .......................................................
[CV] ........................................ gamma=100, total=   0.0s
[CV] gamma=100 .......................................................
[CV] ........................................ gamma=100, total=   0.0s
[CV] gamma=100 .......................................................
[CV] ........................................ gamma=100, total=   0.0s
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.1s finished
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GridSearchCV(estimator=SVC(), param_grid={&#39;gamma&#39;: [0.1, 1.0, 10, 100]},
             verbose=2)
</pre></div>
</div>
</div>
</div>
<p>The nice thing about this is we can do this for multiple hyperparameters simultaneously as well.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
    <span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 16 candidates, totalling 80 fits
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.
[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.4s
[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    2.6s finished
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,
             param_grid={&#39;C&#39;: [0.1, 1.0, 10, 100],
                         &#39;gamma&#39;: [0.1, 1.0, 10, 100]},
             verbose=2)
</pre></div>
</div>
</div>
</div>
<p>The grid in <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> stands for the way that it’s checking the hyperparameters.</p>
<p>Since there 4 options for each, grid search is checking every value in each hyperparameter to one another.</p>
<p>That means it’s checking 4 x 4 = 16 different combinations of hyperparameter values for the model.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> we can specify the number of folds of cross-validation with the argument <code class="docutils literal notranslate"><span class="pre">cv</span></code>.</p>
<p>Since we are specifying <code class="docutils literal notranslate"><span class="pre">cv=5</span></code> that means that fit is called a total of 80 times (16 different combinations x 5 cross-validation folds).</p>
<p>Something new we’ve added here is <code class="docutils literal notranslate"><span class="pre">n_jobs=-1</span></code>.</p>
<p>This is a little more complex.</p>
<p>Setting this to -1 helps make this process faster by running hyperparameter optimization in parallel instead of in a sequence.</p>
<div class="section" id="implement-with-pipelines">
<h3><span class="section-number">6.10.1. </span>Implement with Pipelines<a class="headerlink" href="#implement-with-pipelines" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">steps</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
        <span class="p">(</span><span class="s2">&quot;clf&quot;</span><span class="p">,</span> <span class="n">SVC</span><span class="p">())])</span>
</pre></div>
</div>
</div>
</div>
<p>After specifying the steps in a pipeline, a user must specify a set of values for each hyperparameter in <code class="docutils literal notranslate"><span class="pre">param_grid</span></code> as we did before but this time we specify the name of the step followed by two underscores <code class="docutils literal notranslate"><span class="pre">__</span></code> and the name of the hyperparameter.</p>
<p>This is because the pipeline would not know which hyperparameter goes with each step. Does <code class="docutils literal notranslate"><span class="pre">gamma</span></code> correspond to the hyperparameter in <code class="docutils literal notranslate"><span class="pre">SimpleImputer()</span></code> or <code class="docutils literal notranslate"><span class="pre">StandardScaler()</span></code>?</p>
<p>This now gives the pipeline clear instructions on which hyperparameters correspond with which step.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;clf__gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
    <span class="s2">&quot;clf__C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Notice that we named our steps in the pipeline, so <code class="docutils literal notranslate"><span class="pre">clf</span></code> corresponds to the model initialization of the SVM classifier.</p>
<p>If we used <code class="docutils literal notranslate"><span class="pre">make_pipeline()</span></code> remember that the function names the steps by default the lower case name of each transformation or model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">),</span>
                    <span class="n">StandardScaler</span><span class="p">(),</span>
                    <span class="n">SVC</span><span class="p">())</span>
<span class="n">pipe</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;simpleimputer&#39;, SimpleImputer(strategy=&#39;median&#39;)),
                (&#39;standardscaler&#39;, StandardScaler()), (&#39;svc&#39;, SVC())])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;svc__gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
    <span class="s2">&quot;svc__C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Now when we initiate <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>, we set the first argument to the pipeline name instead of the model name this time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 16 candidates, totalling 80 fits
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.
[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.2s
[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    2.6s finished
</pre></div>
</div>
</div>
</div>
<p>Looking a bit closer these are the steps being performed with <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">C</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
            <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="n">folds</span><span class="p">:</span>
                <span class="n">fit</span> <span class="ow">in</span> <span class="n">training</span> <span class="n">portion</span> <span class="k">with</span> <span class="n">the</span> <span class="n">given</span> <span class="n">C</span> <span class="ow">and</span> <span class="n">gamma</span>
                <span class="n">score</span> <span class="n">on</span> <span class="n">validation</span> <span class="n">portion</span>
            <span class="n">compute</span> <span class="n">average</span> <span class="n">score</span>
    <span class="n">pick</span> <span class="n">hyperparameters</span> <span class="k">with</span> <span class="n">the</span> <span class="n">best</span> <span class="n">score</span>
</pre></div>
</div>
<p>In this case, we can see from the output that 80 executions are done, just like we calculated (4 x 4 x 5 = 80).</p>
</div>
<div class="section" id="why-a-grid">
<h3><span class="section-number">6.10.2. </span>Why a grid?<a class="headerlink" href="#why-a-grid" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="../_images/cross.gif"><img alt="404 image" src="../_images/cross.gif" style="width: 60%;" /></a>
<p>If we fix <code class="docutils literal notranslate"><span class="pre">C</span></code> with a value of 1 and loop over the values of 1, 10 and 100 for <code class="docutils literal notranslate"><span class="pre">gamma</span></code>.</p>
<p>This results in <code class="docutils literal notranslate"><span class="pre">100</span></code> having the best score with 0.82.</p>
<p>Next, we fix <code class="docutils literal notranslate"><span class="pre">gamma</span></code> at <code class="docutils literal notranslate"><span class="pre">100</span></code> since that was what we found was the most optimal when <code class="docutils literal notranslate"><span class="pre">C</span></code> was equal to 1.</p>
<p>When we loop over the values of 1, 10 and 100 for <code class="docutils literal notranslate"><span class="pre">C</span></code> we get the most optimal value to be 10.</p>
<p>So naturally, we would pick the values <code class="docutils literal notranslate"><span class="pre">100</span></code> for <code class="docutils literal notranslate"><span class="pre">gamma</span></code> and <code class="docutils literal notranslate"><span class="pre">10</span></code> for <code class="docutils literal notranslate"><span class="pre">C</span></code>.</p>
<p>HOWEVER - if we had performed every possible combination, we would have seen that the optimal values would have actually been <code class="docutils literal notranslate"><span class="pre">10</span></code> for both <code class="docutils literal notranslate"><span class="pre">gamma</span></code> and <code class="docutils literal notranslate"><span class="pre">C</span></code>.</p>
<p>The same thing is shown if we did it the other way around, first fixing <code class="docutils literal notranslate"><span class="pre">gamma</span></code> at a value of 1 and then looping over all possible values of <code class="docutils literal notranslate"><span class="pre">C</span></code>.</p>
<p>This time the most optimal combination is <code class="docutils literal notranslate"><span class="pre">gamma</span></code> equal to 1 and <code class="docutils literal notranslate"><span class="pre">C</span></code> equal to 100 which is again not the optimal value of 10 for each.</p>
<p>This is why it is so important not to fix either of the hyperparameters since it won’t necessarily help you find the most optimal values.</p>
</div>
<div class="section" id="now-what">
<h3><span class="section-number">6.10.3. </span>Now what?<a class="headerlink" href="#now-what" title="Permalink to this headline">¶</a></h3>
<p>How do we know what the best hyperparameter values are after fitting?</p>
<p>We can extract the best hyperparameter values with <code class="docutils literal notranslate"><span class="pre">.best_params_</span></code> and their corresponding score with <code class="docutils literal notranslate"><span class="pre">.best_score_</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;svc__C&#39;: 10, &#39;svc__gamma&#39;: 1.0}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8208556149732621
</pre></div>
</div>
</div>
</div>
<p>We can extract the optimal classifier inside with <code class="docutils literal notranslate"><span class="pre">.best_estimator_</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_model</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
</pre></div>
</div>
</div>
</div>
<p>This has already been fully fitted on with all the data and not just a portion from cross-validation so all we need to do is score!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8502994011976048
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8333333333333334
</pre></div>
</div>
</div>
</div>
<p>We can either save it as a new model and fit and score on this new one <em>or</em> we can use the <code class="docutils literal notranslate"><span class="pre">grid_search</span></code> object directly and it will by default score using the optimal model.
These both give the same results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8502994011976048
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8333333333333334
</pre></div>
</div>
</div>
</div>
<p>The same can be done for <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> as well, either using the saved model or using the <code class="docutils literal notranslate"><span class="pre">grid_search</span></code> object directly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;,
       &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;USA&#39;, &#39;USA&#39;, &#39;Canada&#39;, &#39;Canada&#39;,
       &#39;Canada&#39;, &#39;Canada&#39;, &#39;USA&#39;, &#39;Canada&#39;, &#39;USA&#39;, &#39;Canada&#39;, &#39;Canada&#39;,
       &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;,
       &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;USA&#39;, &#39;Canada&#39;,
       &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;USA&#39;, &#39;USA&#39;, &#39;Canada&#39;,
       &#39;Canada&#39;, &#39;Canada&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;,
       &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;USA&#39;, &#39;USA&#39;, &#39;Canada&#39;, &#39;Canada&#39;,
       &#39;Canada&#39;, &#39;Canada&#39;, &#39;USA&#39;, &#39;Canada&#39;, &#39;USA&#39;, &#39;Canada&#39;, &#39;Canada&#39;,
       &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;,
       &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;USA&#39;, &#39;Canada&#39;,
       &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;Canada&#39;, &#39;USA&#39;, &#39;USA&#39;, &#39;Canada&#39;,
       &#39;Canada&#39;, &#39;Canada&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="notice-any-problems">
<h3><span class="section-number">6.10.4. </span>Notice any problems?<a class="headerlink" href="#notice-any-problems" title="Permalink to this headline">¶</a></h3>
<p>This seems pretty nice and obeys the golden rule however the new problem is the execution time.</p>
<p>Think about how much time it would take if we had 5 hyperparameters each with 10 different values.</p>
<p>That would mean we would be needing to call <code class="docutils literal notranslate"><span class="pre">cross_validate()</span></code> 100,000 times!</p>
<p>Exhaustive search may become infeasible fairly quickly.</p>
<p><strong>Enter randomized hyperparameter search!</strong></p>
</div>
<div class="section" id="randomized-hyperparameter-optimization">
<h3><span class="section-number">6.10.5. </span>Randomized hyperparameter optimization<a class="headerlink" href="#randomized-hyperparameter-optimization" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;svc__gamma&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
    <span class="s2">&quot;svc__C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">random_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 10 candidates, totalling 50 fits
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.
[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.3s finished
</pre></div>
</div>
</div>
</div>
<p>Notice that we use the same arguments in <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV()</span></code> as in <code class="docutils literal notranslate"><span class="pre">GridSearchCV()</span></code> however with 1 new addition - <code class="docutils literal notranslate"><span class="pre">n_iter</span></code>.</p>
<p>This argument gives us more control and lets us restrict how many candidates are searched over.</p>
<p><code class="docutils literal notranslate"><span class="pre">GridSearchCV()</span></code> conducts <code class="docutils literal notranslate"><span class="pre">cross_validate()</span></code> on every single possible combination of the hyperparameters specified in <code class="docutils literal notranslate"><span class="pre">param_grid</span></code>.</p>
<p>Now we can change that and control that using <code class="docutils literal notranslate"><span class="pre">n_iter</span></code> which will pick a random subset containing the specified number of combinations.</p>
<p>The last time when we used exhaustive grid search, we had 80 fits (4 x 4 x 5).</p>
<p>This time we see only 50 fits (10 combinations instead of 16 and 5 folds)!</p>
</div>
<div class="section" id="continuous-values-for-hyperparameter-tuning-optional">
<h3><span class="section-number">6.10.6. </span>Continuous values for hyperparameter tuning - optional<a class="headerlink" href="#continuous-values-for-hyperparameter-tuning-optional" title="Permalink to this headline">¶</a></h3>
<p>For randomized grid search we can search over a range of continuous values instead of discrete values like in <code class="docutils literal notranslate"><span class="pre">GridSearchCV()</span></code>.</p>
<p>We can specify a range of values instead of a list of values for each hyperparameter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;svc__C&quot;</span><span class="p">:</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
    <span class="s2">&quot;svc__gamma&quot;</span><span class="p">:</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_gs</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">random_gs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_gs</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;svc__C&#39;: 30.962086187979253, &#39;svc__gamma&#39;: 17.526459755968204}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_gs</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7452205882352942
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_gs</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7142857142857143
</pre></div>
</div>
</div>
</div>
<p><strong>How differently does exhaustive and random search score?</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8333333333333334
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_search</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8333333333333334
</pre></div>
</div>
</div>
</div>
<p>Here, (and often) they produce similar scores.</p>
</div>
</div>
<div class="section" id="the-problem-with-hyperparameter-tuning-overfitting-the-validation-set">
<h2><span class="section-number">6.11. </span>The problem with hyperparameter tuning - overfitting the validation set<a class="headerlink" href="#the-problem-with-hyperparameter-tuning-overfitting-the-validation-set" title="Permalink to this headline">¶</a></h2>
<p>Since we are repeating cross-validation over and over again, it’s not necessarily unseen data anymore.</p>
<p>This may produce overly optimistic results.</p>
<p>If our dataset is small and if our validation set is hit too many times, we suffer from <strong>optimization bias</strong> or <strong>overfitting the validation set</strong>.</p>
<div class="section" id="example-overfitting-the-validation-set">
<h3><span class="section-number">6.11.1. </span>Example: overfitting the validation set<a class="headerlink" href="#example-overfitting-the-validation-set" title="Permalink to this headline">¶</a></h3>
<p>Attribution: <a class="reference external" href="https://www.cs.ubc.ca/~schmidtm/">Mark Scmidt</a></p>
<p>This exercise helps explain the concept of overfitting on the validation set.</p>
<p>Consider a multiple-choice (a,b,c,d) “test” with 10 questions:</p>
<ul class="simple">
<li><p>If you choose answers randomly, the expected grade is 25% (no bias).</p></li>
<li><p>If you fill out two tests randomly and pick the best, the expected grade is 33%.</p>
<ul>
<li><p>overfitting ~8%.</p></li>
</ul>
</li>
<li><p>If you take the best among 10 random tests, the expected grade is ~47%.</p></li>
<li><p>If you take the best among 100, the expected grade is ~62%.</p></li>
<li><p>If you take the best among 1000, the expected grade is ~73%.</p>
<ul>
<li><p>You have so many “chances” that you expect to do well.</p></li>
</ul>
</li>
</ul>
<p><strong>But on new questions, the “random choice” accuracy is still 25%.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Code attributed to Rodolfo Lourenzutti </span>

<span class="n">number_tests</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]</span>
<span class="k">for</span> <span class="n">ntests</span> <span class="ow">in</span> <span class="n">number_tests</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
        <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="n">ntests</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;The expected grade among the best of </span><span class="si">%d</span><span class="s2"> tests is : </span><span class="si">%0.2f</span><span class="s2">&quot;</span>
        <span class="o">%</span> <span class="p">(</span><span class="n">ntests</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="mf">10.0</span><span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The expected grade among the best of 1 tests is : 0.25
The expected grade among the best of 2 tests is : 0.33
The expected grade among the best of 10 tests is : 0.47
The expected grade among the best of 100 tests is : 0.62
The expected grade among the best of 1000 tests is : 0.74
</pre></div>
</div>
</div>
</div>
<p>If we instead used a 100-question test then:</p>
<ul class="simple">
<li><p>Expected grade from best over 1 randomly-filled tests is 25%.</p></li>
<li><p>Expected grade from best over 2 randomly-filled tests is ~27%.</p></li>
<li><p>Expected grade from best over 10 randomly-filled tests is ~32%.</p></li>
<li><p>Expected grade from best over 100 randomly-filled tests is ~36%.</p></li>
<li><p>Expected grade from best over 1000 randomly-filled tests is ~40%.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Code attributed to Rodolfo Lourenzutti </span>

<span class="n">number_tests</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]</span>
<span class="k">for</span> <span class="n">ntests</span> <span class="ow">in</span> <span class="n">number_tests</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
        <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mf">100.0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="n">ntests</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="s2">&quot;The expected grade among the best of </span><span class="si">%d</span><span class="s2"> tests is : </span><span class="si">%0.2f</span><span class="s2">&quot;</span>
        <span class="o">%</span> <span class="p">(</span><span class="n">ntests</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="mf">100.0</span><span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The expected grade among the best of 1 tests is : 0.25
The expected grade among the best of 2 tests is : 0.27
The expected grade among the best of 10 tests is : 0.32
The expected grade among the best of 100 tests is : 0.36
The expected grade among the best of 1000 tests is : 0.40
</pre></div>
</div>
</div>
</div>
<p>The optimization bias <strong>grows with the number of things we try</strong>.<br />
But, optimization bias <strong>shrinks quickly with the number of examples</strong>.<br />
But it’s still non-zero and growing if you over-use your validation set!</p>
<p>Essentially our odds of doing well on a multiple-choice exam (if we are guessing) increases the more times we can repeat and randomly take the exam again.</p>
<p>Because we have so many chances you’ll eventually do well and perhaps this is not representative of your knowledge (remember you are randomly guessing)</p>
<p>The same occurs with selecting hyperparameters.</p>
<p>The more hyperparameters values and combinations we try, the more likely we will randomly get a better scoring model by chance and not because the model represents the data well.</p>
<p>This overfitting can be decreased somewhat by increasing the number of questions or in our case, the number of examples we have.</p>
<p>TLDR: If your test score is lower than your validation score, it may be because did so much hyperparameter optimization that you got lucky and the bigger data set that you have, the better.</p>
</div>
</div>
<div class="section" id="id2">
<h2><span class="section-number">6.12. </span>Let’s Practice<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>1. Which method will attempt to find the optimal hyperparameter for the data by searching every combination possible of hyperparameter values given?<br />
2. Which method gives you fine-grained control over the amount of time spent searching?<br />
3. If I want to search for the most optimal hyperparameter values among 3 different hyperparameters each with 3 different values how many trials of cross-validation would be needed?</p>
<p><span class="math notranslate nohighlight">\(x= [1,2,3]\)</span><br />
<span class="math notranslate nohighlight">\(y= [4,5,6]\)</span><br />
<span class="math notranslate nohighlight">\(z= [7,8,9]\)</span></p>
<p><strong>True or False</strong></p>
<p>4. A Larger <code class="docutils literal notranslate"><span class="pre">n_iter</span></code> will take longer but will search over more hyperparameter values.<br />
5. Automated hyperparameter optimization can only be used for multiple hyperparameters.</p>
<div class="dropdown admonition">
<p class="admonition-title">Solutions!</p>
<ol class="simple">
<li><p>Exhaustive Grid Search (<code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>)</p></li>
<li><p>Randomized Grid Search (<code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code>)</p></li>
<li><p><span class="math notranslate nohighlight">\(3 * 3 * 3 = 27\)</span></p></li>
<li><p>True</p></li>
<li><p>False</p></li>
</ol>
</div>
</div>
<div class="section" id="let-s-practice-coding">
<h2><span class="section-number">6.13. </span>Let’s Practice - Coding<a class="headerlink" href="#let-s-practice-coding" title="Permalink to this headline">¶</a></h2>
<p>We are going to practice grid search using our basketball dataset that we have seen before.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Loading in the data</span>
<span class="n">bball_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/bball.csv&#39;</span><span class="p">)</span>
<span class="n">bball_df</span> <span class="o">=</span> <span class="n">bball_df</span><span class="p">[(</span><span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;G&#39;</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;F&#39;</span><span class="p">)]</span>

<span class="c1"># Define X and y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">bball_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="s1">&#39;salary&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span>

<span class="c1"># Split the dataset</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

<span class="n">bb_pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
            <span class="n">steps</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)),</span>
                   <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
                   <span class="p">(</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">())])</span>
</pre></div>
</div>
</div>
</div>
<ol class="simple">
<li><p>Using the pipeline <code class="docutils literal notranslate"><span class="pre">bb_pipe</span></code> provided, create a grid of parameters to search over <code class="docutils literal notranslate"><span class="pre">param_grid</span></code>. Search over the values 1, 5, 10, 20, 30, 40, and 50 for the hyperparameter <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code> and ‘uniform’ and ‘distance’ for the hyperparameter <code class="docutils literal notranslate"><span class="pre">weights</span></code> (make sure to call them appropriately).</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> to hyperparameter tune using cross-validate equal to 10 folds. Make sure to specify the arguments <code class="docutils literal notranslate"><span class="pre">verbose=2</span></code> and <code class="docutils literal notranslate"><span class="pre">n_jobs=-1</span></code>.</p></li>
<li><p>Train your  pipeline with grid search.</p></li>
<li><p>Find the best hyperparameter values. Make sure to print these results.</p></li>
<li><p>Lastly, score your model on the test set.</p></li>
</ol>
</div>
<div class="section" id="what-we-ve-learned-today-a-id-9-a">
<h2><span class="section-number">6.14. </span>What We’ve Learned Today<a id="9"></a><a class="headerlink" href="#what-we-ve-learned-today-a-id-9-a" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>How to predict by using naive Bayes.</p></li>
<li><p>How to use <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>’s <code class="docutils literal notranslate"><span class="pre">MultiNomialNB</span></code>.</p></li>
<li><p>What <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> is.</p></li>
<li><p>Why we need smoothing in  naive Bayes.</p></li>
<li><p>How to carry out hyperparameter optimization using <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>’s <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> and <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code>.</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "bait509-ubc/BAIT509",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="lecture5.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title"><span class="section-number">5. </span>Preprocessing Categorical Features and Column Transformer</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="lecture7.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title"><span class="section-number">7. </span>Linear Models</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Hayley Boyce<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>