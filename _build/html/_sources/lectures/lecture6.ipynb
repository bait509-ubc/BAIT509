{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes and Hyperparameter Optimization\n",
    "\n",
    "*Hayley Boyce, May 5th, 2021*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our libraries\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.svm import SVR, SVC\n",
    "\n",
    "import sys\n",
    "sys.path.append('code/')\n",
    "from display_tree import display_tree\n",
    "from plot_classifier import plot_classifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing and pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Keeping \n",
    "- Quiz Today!\n",
    "- Result of Polls\n",
    "- Assignment due Monday\n",
    "- Project groups this week\n",
    "- Project instructions next week\n",
    "- Heavy class today, more learning, less practice (sorry!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture Learning Objectives \n",
    "\n",
    "- Explain the naive assumption of naive Bayes. \n",
    "- Predict targets by hands-on toy examples using naive Bayes.\n",
    "- Use `scikit-learn`'s `MultiNomialNB`.\n",
    "- Use `predict_proba` and explain its usefulness. \n",
    "- Explain the need for smoothing in naive Bayes.\n",
    "- Explain how `alpha` controls the fundamental tradeoff. \n",
    "- Explain the need for hyperparameter optimization  \n",
    "- Carry out hyperparameter optimization using `sklearn`'s `GridSearchCV` and `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five Minute Recap/ Lightning Questions \n",
    "\n",
    "- What kind of preprocessing must I do if I have a feature with categories that have an order to them?\n",
    "- How many columns do I need for a binary feature?\n",
    "- What tool do we use to preprocess all our pipelines and build a model without breaking the golden rule? \n",
    "- Between `Pipeline()` and `make_pipeline()`, which one assigns names to the steps on our behalf? \n",
    "- In text data, what are our features made up of?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some lingering questions\n",
    "\n",
    "- How do I tune multiple hyperparameters at once?\n",
    "- What algorithm works well with our `spam`, `non spam` problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes introduction -  spam/non spam\n",
    "Last lecture we saw this spam classification problem where we used `CountVectorizer()` to vectorize the text into features and used an `SVC` to classify each text message into either a class of `spam` or `non spam`.   \n",
    "\n",
    "$X = \\begin{bmatrix}\\text{\"URGENT!! You have been selected to receive a ¬£900 prize reward!\",}\\\\ \\text{\"Lol your always so convincing.\"}\\\\ \\text{\"Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now!\"}\\\\ \\end{bmatrix}$ and $y = \\begin{bmatrix}\\text{spam} \\\\ \\text{non spam} \\\\ \\text{spam} \\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For years, the best spam filtering methods used naive Bayes.\n",
    "\n",
    "Naive Bayes is based on Bayes' Theorem: \n",
    "\n",
    "<img src='imgs/bayes.png' width=\"50%\"> \n",
    "\n",
    "\n",
    "- This is our first probabilistic classifier where we think of learning as a problem of statistical inference.\n",
    "\n",
    "- Other applications of Naive Bayes:\n",
    "    - Folder ordering, document clustering, etc.\n",
    "    - Sentiment analysis (e.g., movies, restaurants, etc.)\n",
    "    - Classifying products into groups based on descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some naive Bayes calculations **by hand**üñê ü§ö . \n",
    "\n",
    "Yes, there is going to be some math here but it's going to be really helpful in understanding how this algorithm works! \n",
    "\n",
    "Below we have a few texts and they are classed as either being  **spam** or **non spam**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URGENT!! As a valued network customer you have...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lol you are always so convincing.</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sauder has interesting courses.</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sauder has been interesting so far.</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   X         y\n",
       "0  URGENT!! As a valued network customer you have...      spam\n",
       "1                  Lol you are always so convincing.  non spam\n",
       "2                    Sauder has interesting courses.  non spam\n",
       "3  URGENT! You have won a 1 week FREE membership ...      spam\n",
       "4  Had your mobile 11 months or more? U R entitle...      spam\n",
       "5                Sauder has been interesting so far.  non spam"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'X': [\n",
    "                        \"URGENT!! As a valued network customer you have been selected to receive a ¬£900 prize reward!\",\n",
    "                        \"Lol you are always so convincing.\",\n",
    "                        \"Sauder has interesting courses.\",\n",
    "                        \"URGENT! You have won a 1 week FREE membership in our ¬£100000 prize Jackpot!\",\n",
    "                        \"Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!\",\n",
    "                        \"Sauder has been interesting so far.\" ],\n",
    "                   'y': [\"spam\", \"non spam\", \"non spam\", \"spam\", \"spam\", \"non spam\"]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that we need to encode categorical data and transform it to numeric data to use it with machine learning since categoric columns throw an error when we try to fit our model.\n",
    "\n",
    "This sounds like a job for `CountVectorizer()` since we have words that need to be converted into features! \n",
    "\n",
    "Here we are going to set `max_features=4` to make our calculations a little easier and `stop_words='english'` so we are getting meaningful words as features and not stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>sauder</th>\n",
       "      <th>urgent</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT!! As a valued network customer you have been selected to receive a ¬£900 prize reward!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lol you are always so convincing.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sauder has interesting courses.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URGENT! You have won a 1 week FREE membership in our ¬£100000 prize Jackpot!</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sauder has been interesting so far.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    free  prize  sauder  \\\n",
       "X                                                                         \n",
       "URGENT!! As a valued network customer you have ...     0      1       0   \n",
       "Lol you are always so convincing.                      0      0       0   \n",
       "Sauder has interesting courses.                        0      0       1   \n",
       "URGENT! You have won a 1 week FREE membership i...     1      1       0   \n",
       "Had your mobile 11 months or more? U R entitled...     1      0       0   \n",
       "Sauder has been interesting so far.                    0      0       1   \n",
       "\n",
       "                                                    urgent    target  \n",
       "X                                                                     \n",
       "URGENT!! As a valued network customer you have ...       1      spam  \n",
       "Lol you are always so convincing.                        0  non spam  \n",
       "Sauder has interesting courses.                          0  non spam  \n",
       "URGENT! You have won a 1 week FREE membership i...       1      spam  \n",
       "Had your mobile 11 months or more? U R entitled...       0      spam  \n",
       "Sauder has been interesting so far.                      0  non spam  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "count_vect = CountVectorizer(max_features = 4, stop_words='english')\n",
    "data = count_vect.fit_transform(df['X'])\n",
    "train_bow_df = pd.DataFrame(data.toarray(), columns=sorted(count_vect.vocabulary_), index=df['X'])\n",
    "\n",
    "train_bow_df['target'] = df['y'].tolist()\n",
    "train_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are given 2 text messages in and we want to find the targets for these examples, how do we do it using naive Bayes?\n",
    "\n",
    "First, let's get a numeric representation of our text messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urgent</th>\n",
       "      <th>prize</th>\n",
       "      <th>sauder</th>\n",
       "      <th>free</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT! Free!!</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like Sauder</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                urgent  prize  sauder  free\n",
       "URGENT! Free!!       1      0       0     1\n",
       "I like Sauder        0      0       1     0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts = [\"URGENT! Free!!\", \"I like Sauder\"]\n",
    "data = count_vect.transform(test_texts).toarray()\n",
    "test_bow_df = pd.DataFrame(data, columns=count_vect.vocabulary_, index=test_texts)\n",
    "test_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the text: \"**URGENT! Free!!**\"\n",
    "\n",
    "> Is this **spam** or **non spam**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we want to know is: \n",
    "\n",
    "$$P(\\textrm{spam}|\\textrm{\"URGENT! Free!!\"})$$\n",
    "\n",
    "$$ \\text{and} $$\n",
    "\n",
    "$$P(\\textrm{non spam}|\\textrm{\"URGENT! Free!!\"})$$\n",
    "\n",
    "\n",
    "We really only care which one of these is bigger and whichever probability is larger is how we can classify our sentence as **spam** or **non spam**.\n",
    "\n",
    "\n",
    "$$P(\\textrm{spam}|\\textrm{\"URGENT! Free!!\"}) > P(\\textrm{non spam}|\\textrm{\"URGENT! Free!!\"})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember our Bayes' Theorem is the following:\n",
    "\n",
    "$$\\text{P}(Y|X) = \\frac{\\text{P}(X | Y) \\text{P}(Y)}{\\text{P}(X)}$$\n",
    "In this case:\n",
    "\n",
    "$X$ is the representation of the words in our text ie; $\\text{free} = 1, \\text{prize} = 0, \\text{sauder} = 0,  \\text{urgent} = 1$  \n",
    "\n",
    "$y$ is our target either spam or non spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substituting into Bayes rule we get:\n",
    "\n",
    "$$\\frac{P(\\text{free} = 1, \\text{prize} = 0,\\text{sauder} = 0,  \\text{urgent} = 1 |\\textrm{spam})*P(\\textrm{spam})}{P(\\text{free} = 1, \\text{prize} = 0,\\text{sauder} = 0, \\text{urgent} = 1 )}>\\frac{P(\\text{free} = 1, \\text{prize} = 0, \\text{sauder} = 0, \\text{urgent} = 1 |\\textrm{non spam})*P(\\textrm{non spam})}{P(\\text{free} = 1, \\text{prize} = 0,\\text{sauder} = 0, \\text{urgent} = 1 )}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there are two reasons naive Bayes is so easy:\n",
    "1. We can cancel out the denominator which leads us to this: \n",
    "\n",
    "\n",
    "$$P(\\text{free} = 1, \\text{prize} = 0,\\text{sauder} = 0, \\text{urgent} = 1|\\textrm{spam})*P(\\textrm{spam}) > P(\\text{free} = 1, \\text{prize} = 0,\\text{sauder} = 0, \\text{urgent} = 1|\\textrm{non spam})*P(\\textrm{non spam})$$\n",
    "\n",
    "2. We can simplify the numerator\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes' approximation\n",
    "\n",
    "We assume each feature (word) is conditionally independent. (Assume that all features in $X$ are mutually independent, conditional on the target class.)\n",
    "\n",
    "- In general, \n",
    "$$P(\\text{message} \\mid \\text{spam}) = P(w_1, w_2, . . . , w_d \\mid \\text{spam}) \\approx \\prod_{i=1}^{d}P(w_i \\mid \\text{spam})$$\n",
    "\n",
    "$$P(\\text{message} \\mid \\text{non spam}) = P(w_1, w_2, . . . , w_d \\mid \\text{non spam}) \\approx \\prod_{i=1}^{d}P(w_i \\mid \\text{non spam})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means simply:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\begin{split}\n",
    "& P(\\text{free} = 1, \\text{prize} = 0,\\text{sauder} = 0, \\text{urgent} = 1 \\mid \\text{spam}) \\\\\n",
    "&\\approx  P(\\text{free} = 1 \\mid \\text{spam}) \\times P(\\text{prize} = 0 \\mid \\text{spam}) \\times P(\\text{sauder} = 0 \\mid \\text{spam}) \\times  P(\\text{urgent} = 1 \\mid \\text{spam})\n",
    "\\end{split}\n",
    "\\end{equation}$$\n",
    "\n",
    "And for the other class **non spam**:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\begin{split}\n",
    "& P(\\text{free} = 1, \\text{prize} = 0,\\text{sauder} = 0, \\text{urgent} = 1 \\mid \\text{non spam}) \\\\\n",
    "&\\approx P(\\text{free} = 1 \\mid \\text{non spam}) \\times P(\\text{prize} = 0 \\mid \\text{non spam}) \\times P(\\text{sauder} = 0 \\mid \\text{non spam}) \\times P(\\text{urgent} = 1 \\mid \\text{non spam})\n",
    "\\end{split}\n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our equation has boiled down to is:\n",
    "\n",
    "$$ P(\\text{free} = 1 \\mid \\text{spam}) \\times P(\\text{prize} = 0 \\mid \\text{spam}) \\times P(\\text{sauder} = 0 \\mid \\text{spam}) \\times P(\\text{urgent} = 1 \\mid \\text{spam})*P(\\textrm{spam}) >$$ \n",
    "$$ P(\\text{free} = 1 \\mid \\text{non spam}) \\times P(\\text{prize} = 0 \\mid \\text{non spam}) \\times P(\\text{sauder} = 0 \\mid \\text{non spam}) \\times P(\\text{urgent} = 1 \\mid \\text{non spam}) *P(\\textrm{non spam})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we just need to calculate each of those probabilities which is easy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating $P(\\text{spam} \\mid \\text{message})$ (The left side of our equation)\n",
    "\n",
    "$$P(\\text{free} = 1 \\mid \\text{spam}) \\times P(\\text{prize} = 0 \\mid \\text{spam})  \\times P(\\text{sauder} = 0 \\mid \\text{spam}) \\times P(\\text{urgent} = 1 \\mid \\text{spam})*P(\\textrm{spam}) $$ \n",
    "\n",
    "We need the following:  \n",
    "1. Prior probability: \n",
    "    $P(\\text{spam})$ \n",
    "\n",
    "2. Conditional probabilities: \n",
    "    1. $P(\\text{free} = 1 \\mid \\text{spam})$\n",
    "    2. $P(\\text{prize} = 0 \\mid \\text{spam})$\n",
    "    3. $P(\\text{sauder} = 0 \\mid \\text{spam})$\n",
    "    4. $P(\\text{urgent} = 1 \\mid \\text{spam})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>sauder</th>\n",
       "      <th>urgent</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT!! As a valued network customer you have been selected to receive a ¬£900 prize reward!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lol you are always so convincing.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sauder has interesting courses.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URGENT! You have won a 1 week FREE membership in our ¬£100000 prize Jackpot!</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sauder has been interesting so far.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    free  prize  sauder  \\\n",
       "X                                                                         \n",
       "URGENT!! As a valued network customer you have ...     0      1       0   \n",
       "Lol you are always so convincing.                      0      0       0   \n",
       "Sauder has interesting courses.                        0      0       1   \n",
       "URGENT! You have won a 1 week FREE membership i...     1      1       0   \n",
       "Had your mobile 11 months or more? U R entitled...     1      0       0   \n",
       "Sauder has been interesting so far.                    0      0       1   \n",
       "\n",
       "                                                    urgent    target  \n",
       "X                                                                     \n",
       "URGENT!! As a valued network customer you have ...       1      spam  \n",
       "Lol you are always so convincing.                        0  non spam  \n",
       "Sauder has interesting courses.                          0  non spam  \n",
       "URGENT! You have won a 1 week FREE membership i...       1      spam  \n",
       "Had your mobile 11 months or more? U R entitled...       0      spam  \n",
       "Sauder has been interesting so far.                      0  non spam  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prior probability\n",
    "    - $P(\\text{spam}) = 3/6$\n",
    "    \n",
    "- Conditional probabilities\n",
    "    -  What is  $P(\\text{free} = 1 \\mid \\text{spam})$ ??\n",
    "       - Given target is spam, how often \"free\"= 1? $= 2/3$ \n",
    "    - $P(\\text{prize} = 0 \\mid \\text{spam}) = 1/3$  \n",
    "    - $P(\\text{sauder} = 0 \\mid \\text{spam}) = 3/3$   \n",
    "    - $P(\\text{urgent} = 1 \\mid \\text{spam}) = 2/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything we need to do our calculations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\textrm{spam}|\\text{free} = 1, \\text{prize} = 0, \\text{sauder} = 0,  \\text{urgent} = 1) = P(\\text{free} = 1|\\textrm{spam})*P(\\text{prize} = 0|\\textrm{spam})*P(\\textrm{sauder = 0}|\\textrm{spam})*P(\\text{urgent} = 1|\\textrm{spam})*P(\\textrm{spam})$$\n",
    "$$=  \\frac{2}{3} * \\frac{1}{3}* \\frac{3}{3} * \\frac{2}{3} *\\frac{3}{6} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07407407407407407"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_prior = 3/6\n",
    "sauder0_spam = 3/3\n",
    "free1_spam = 2/3\n",
    "prize0_spam = 1/3\n",
    "urgent1_spam = 2/3\n",
    "spam_prob = spam_prior * sauder0_spam * free1_spam * prize0_spam * urgent1_spam\n",
    "spam_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, So we've done our left side! Now we have to do the right!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating $P(\\text{non spam} \\mid \\text{message})$  (The right side of our equation)\n",
    "\n",
    "$$P(\\text{free} = 1 \\mid \\text{ non spam}) \\times P(\\text{prize} = 0 \\mid \\text{non spam})  \\times P(\\text{sauder} = 0 \\mid \\text{non spam}) \\times P(\\text{urgent} = 1 \\mid \\text{non spam})*P(\\textrm{non spam}) $$ \n",
    "\n",
    "Now we need the following:\n",
    "\n",
    "1. Prior probability: $P(\\text{non spam})$ \n",
    "2. Conditional probabilities: \n",
    "    1. $P(\\text{free} = 1 \\mid \\text{non spam})$\n",
    "    2. $P(\\text{prize} = 0 \\mid \\text{non spam})$\n",
    "    3. $P(\\text{sauder} = 0 \\mid \\text{non spam})$\n",
    "    4. $P(\\text{urgent} = 1 \\mid \\text{non spam})$\n",
    "\n",
    "Again we use the data to calculate these probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>sauder</th>\n",
       "      <th>urgent</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT!! As a valued network customer you have been selected to receive a ¬£900 prize reward!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lol you are always so convincing.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sauder has interesting courses.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URGENT! You have won a 1 week FREE membership in our ¬£100000 prize Jackpot!</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sauder has been interesting so far.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    free  prize  sauder  \\\n",
       "X                                                                         \n",
       "URGENT!! As a valued network customer you have ...     0      1       0   \n",
       "Lol you are always so convincing.                      0      0       0   \n",
       "Sauder has interesting courses.                        0      0       1   \n",
       "URGENT! You have won a 1 week FREE membership i...     1      1       0   \n",
       "Had your mobile 11 months or more? U R entitled...     1      0       0   \n",
       "Sauder has been interesting so far.                    0      0       1   \n",
       "\n",
       "                                                    urgent    target  \n",
       "X                                                                     \n",
       "URGENT!! As a valued network customer you have ...       1      spam  \n",
       "Lol you are always so convincing.                        0  non spam  \n",
       "Sauder has interesting courses.                          0  non spam  \n",
       "URGENT! You have won a 1 week FREE membership i...       1      spam  \n",
       "Had your mobile 11 months or more? U R entitled...       0      spam  \n",
       "Sauder has been interesting so far.                      0  non spam  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prior probability \n",
    "    - $P(\\text{non spam}) = 3/6$\n",
    "\n",
    "- Conditional probabilities \n",
    "    - What is $P(\\text{free} = 1 \\mid \\text{non spam})$ ?\n",
    "        - Given the target is non spam, how ofter \"free\"=1? $0/3$\n",
    "    - $P(\\text{prize} = 0 \\mid \\text{non spam}) = 3/3$\n",
    "    - $P(\\text{sauder} = 0 \\mid \\text{non spam}) =1/3$\n",
    "    - $P(\\text{urgent} = 1 \\mid \\text{non spam}) = 0/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for our calculation:\n",
    "\n",
    "$$P(\\textrm{non spam}|\\text{free} = 1, \\text{prize} = 0,\\text{sauder} = 0,  \\text{urgent} = 1) = P(\\text{free} = 1|\\textrm{non spam})*P( \\text{prize} = 0|\\textrm{non spam})*P(\\textrm{sauder = 0}|\\textrm{non spam})*P(\\text{urgent} = 1|\\textrm{non spam})*P(\\textrm{non spam})$$\n",
    "$$= \\frac{1}{3} * \\frac{0}{3} * \\frac{3}{3}* \\frac{0}{3} *\\frac{3}{6} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_spam_prior = 3/6\n",
    "sauder0_non_spam = 0/3\n",
    "free1_non_spam = 1/3\n",
    "prize0_non_spam = 1/3\n",
    "urgent1_non_spam = 2/3\n",
    "non_spam_prob = non_spam_prior * sauder0_non_spam * free1_non_spam * prize0_non_spam * urgent1_non_spam\n",
    "non_spam_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so our equation: \n",
    "\n",
    "$$ P(\\text{free} = 1 \\mid \\text{spam}) \\times P(\\text{prize} = 0 \\mid \\text{spam}) \\times P(\\text{sauder} = 0 \\mid \\text{spam}) \\times P(\\text{urgent} = 1 \\mid \\text{spam})*P(\\textrm{spam}) >$$ \n",
    "$$ P(\\text{free} = 1 \\mid \\text{non spam}) \\times P(\\text{prize} = 0 \\mid \\text{non spam}) \\times P(\\text{sauder} = 0 \\mid \\text{non spam}) \\times P(\\text{urgent} = 1 \\mid \\text{non spam}) *P(\\textrm{non spam})$$\n",
    "\n",
    "has been calculated to \n",
    "\n",
    "0.07407407407407407 > 0.0\n",
    "\n",
    "Since our left side is greater than the right side, our text is classified as **spam**!\n",
    "\n",
    "We could normalize this result and say 100% spam and 0% non spam so that the probabilities add up to 100%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's verify our result using sklearn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier\n",
    "\n",
    "The main Naive Bayes classifier in sklearn is called `MultinomialNB` and exists in the `naive_bayes` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>sauder</th>\n",
       "      <th>urgent</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT!! As a valued network customer you have been selected to receive a ¬£900 prize reward!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lol you are always so convincing.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sauder has interesting courses.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URGENT! You have won a 1 week FREE membership in our ¬£100000 prize Jackpot!</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sauder has been interesting so far.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    free  prize  sauder  \\\n",
       "X                                                                         \n",
       "URGENT!! As a valued network customer you have ...     0      1       0   \n",
       "Lol you are always so convincing.                      0      0       0   \n",
       "Sauder has interesting courses.                        0      0       1   \n",
       "URGENT! You have won a 1 week FREE membership i...     1      1       0   \n",
       "Had your mobile 11 months or more? U R entitled...     1      0       0   \n",
       "Sauder has been interesting so far.                    0      0       1   \n",
       "\n",
       "                                                    urgent    target  \n",
       "X                                                                     \n",
       "URGENT!! As a valued network customer you have ...       1      spam  \n",
       "Lol you are always so convincing.                        0  non spam  \n",
       "Sauder has interesting courses.                          0  non spam  \n",
       "URGENT! You have won a 1 week FREE membership i...       1      spam  \n",
       "Had your mobile 11 months or more? U R entitled...       0      spam  \n",
       "Sauder has been interesting so far.                      0  non spam  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split up our data into our features and targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_bow_df.drop(columns='target')\n",
    "y_train = train_bow_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am selecting the first row of our test set which was the **URGENT! Free!!** text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urgent</th>\n",
       "      <th>prize</th>\n",
       "      <th>sauder</th>\n",
       "      <th>free</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT! Free!!</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                urgent  prize  sauder  free\n",
       "URGENT! Free!!       1      0       0     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bow_df.iloc[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get a prediction of spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/naive_bayes.py:511: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype='<U8')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha=0)\n",
    "nb.fit(X_train, y_train)\n",
    "nb.predict(test_bow_df.iloc[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using `predict`,  we can use something called `predict_proba()`  with Naive Bayes classifier which gives us the ***proba***bilities of each class happening. \n",
    "\n",
    "- `predict` returns the class with the highest probability.\n",
    "- `predict_proba` gives us the actual probability scores. \n",
    "- Looking at the probabilities can help us understand the model.\n",
    "\n",
    "We will look more into this in Lecture 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non spam</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.250000e-20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       non spam  spam\n",
       "0  2.250000e-20   1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction =  nb.predict_proba(test_bow_df.iloc[[0]])\n",
    "pd.DataFrame(data =prediction,columns = nb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the same probabilities as we did it by hand. \n",
    "\n",
    "(Ok 2.250000e-20 is essentially 0 but due to computing and storage, python specifies this 0 as an extremely small number.)\n",
    "\n",
    "What about this warning we see? \n",
    "\n",
    "> 'alpha too small will result in numeric errors'\n",
    "\n",
    "Well, let's look at our conditional probabilities again from the right side of our equation. \n",
    "\n",
    "\n",
    "- Conditional probabilities \n",
    "    - $P(\\text{free} = 1 \\mid \\text{non spam}) = 0/3$ \n",
    "    - $P(\\text{prize} = 0 \\mid \\text{non spam}) = 3/3$\n",
    "    - $P(\\text{sauder} = 0 \\mid \\text{non spam}) =  1/3$\n",
    "    - $P(\\text{urgent} = 1 \\mid \\text{non spam}) = 0/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it wise to say that given a text that is non spam the probability of free occurring is 0? \n",
    "\n",
    "Not really. We only are using 6 examples here and setting this to 0 (and $P(\\text{urgent} = 1 \\mid \\text{non spam}) = 0$)   is making the whole right side of the equation equal to 0. \n",
    "\n",
    "Naive Bayes naively multiplies all the feature likelihoods together, and if any of the terms is zero, it's going to void all other evidence and the probability of the class is going to be zero. \n",
    "\n",
    "This is somewhat problematic. \n",
    "\n",
    "We have limited data and if we do not see a feature occurring with a class, it doesn't mean it would never occur with that class. \n",
    "\n",
    "How can we fix this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple solution: Laplace smoothing\n",
    "\n",
    "- The simplest way to avoid zero probabilities is to add a value($\\alpha$) to all the counts. This is called **Laplace smoothing**\n",
    "\n",
    "Generally, we set alpha ($\\alpha$) equal to 1 and in `scikit-learn` we control it using hyperparameter `alpha`.\n",
    "\n",
    "This means that we give an instance of every word appearing once with a target of spam, as well as a target of non spam. \n",
    "\n",
    "By default `alpha=1.0` in `scikit-learn`.\n",
    "\n",
    "Let's see what our probabilities are now using alpha=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non spam</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.235849</td>\n",
       "      <td>0.764151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   non spam      spam\n",
       "0  0.235849  0.764151"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha=1)\n",
    "nb.fit(X_train, y_train)\n",
    "pd.DataFrame(data = nb.predict_proba(test_bow_df.iloc[[0]]),\n",
    "             columns = nb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit smoother now, wouldn't you say?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `alpha` hyperparameter and the fundamental tradeoff \n",
    "\n",
    "- High alpha $\\rightarrow$ underfitting\n",
    "    - means we are adding large counts to everything and so we are diluting the data\n",
    "- Low alpha $\\rightarrow$ overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Real Data\n",
    "\n",
    "let's try `scikit-learn`'s implementation of Naive Bayes on a modified version of Kaggle's [Disaster Tweets](https://www.kaggle.com/vstepanenko/disaster-tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YOU THERE, PACHIRISU PUNK, PREPARE TO BE DESTR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Face absolutely flattened against the glass of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bruhhhh I screamed when she said that üò≠ MY HEA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Granting warrants to \"authorise police to ente...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ang lala hahaha I woke up to a deluge of death...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>As it seems to be fairly contagious, I'm think...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>#BoundBrookFire Firefighters from several diff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>It is turning out to be a very violent storm a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>A raging fire in Bound Brook, New Jersey, on S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>Hazardous eruption a possibility after Philipp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0     YOU THERE, PACHIRISU PUNK, PREPARE TO BE DESTR...       0\n",
       "1     Face absolutely flattened against the glass of...       0\n",
       "2     Bruhhhh I screamed when she said that üò≠ MY HEA...       0\n",
       "3     Granting warrants to \"authorise police to ente...       0\n",
       "4     Ang lala hahaha I woke up to a deluge of death...       0\n",
       "...                                                 ...     ...\n",
       "3995  As it seems to be fairly contagious, I'm think...       1\n",
       "3996  #BoundBrookFire Firefighters from several diff...       1\n",
       "3997  It is turning out to be a very violent storm a...       1\n",
       "3998  A raging fire in Bound Brook, New Jersey, on S...       1\n",
       "3999  Hazardous eruption a possibility after Philipp...       1\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv(\"data/tweets_mod.csv\")\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split it into our training and test sets as well as our features and target objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>How low have you sunk Alice, just clickbait fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>Watching this tonight as I was working yesterd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>January 14, 2020 at about 08:30 am, personnel ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Next oil spill you drone strike the CEO's neig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>Another 6.0 aftershock has hit Puerto Rico aft...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "1420  How low have you sunk Alice, just clickbait fo...       0\n",
       "1638  Watching this tonight as I was working yesterd...       0\n",
       "616   January 14, 2020 at about 08:30 am, personnel ...       0\n",
       "184   Next oil spill you drone strike the CEO's neig...       0\n",
       "2075  Another 6.0 aftershock has hit Puerto Rico aft...       1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(tweets_df, test_size=0.2, random_state=123)\n",
    "X_train, y_train = train_df[\"text\"], train_df[\"target\"]\n",
    "X_test, y_test = test_df[\"text\"], test_df[\"target\"]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we make a pipeline and cross-validate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.091117</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.948438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076795</td>\n",
       "      <td>0.015993</td>\n",
       "      <td>0.801562</td>\n",
       "      <td>0.948438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071020</td>\n",
       "      <td>0.015681</td>\n",
       "      <td>0.801562</td>\n",
       "      <td>0.946875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.070094</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.945703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076934</td>\n",
       "      <td>0.014068</td>\n",
       "      <td>0.814063</td>\n",
       "      <td>0.944531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.091117    0.017300    0.796875     0.948438\n",
       "1  0.076795    0.015993    0.801562     0.948438\n",
       "2  0.071020    0.015681    0.801562     0.946875\n",
       "3  0.070094    0.013736    0.837500     0.945703\n",
       "4  0.076934    0.014068    0.814063     0.944531"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_nb = make_pipeline(CountVectorizer(), MultinomialNB(alpha=1))\n",
    "scores = cross_validate(pipe_nb, X_train, y_train, return_train_score=True)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.077192\n",
       "score_time     0.015356\n",
       "test_score     0.810312\n",
       "train_score    0.946797\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice\n",
    "\n",
    "Using naive Bayes by hand, what class would naive Bayes predict for the second example \"I like Sauder\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>sauder</th>\n",
       "      <th>urgent</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT!! As a valued network customer you have been selected to receive a ¬£900 prize reward!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lol you are always so convincing.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sauder has interesting courses.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URGENT! You have won a 1 week FREE membership in our ¬£100000 prize Jackpot!</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sauder has been interesting so far.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    free  prize  sauder  \\\n",
       "X                                                                         \n",
       "URGENT!! As a valued network customer you have ...     0      1       0   \n",
       "Lol you are always so convincing.                      0      0       0   \n",
       "Sauder has interesting courses.                        0      0       1   \n",
       "URGENT! You have won a 1 week FREE membership i...     1      1       0   \n",
       "Had your mobile 11 months or more? U R entitled...     1      0       0   \n",
       "Sauder has been interesting so far.                    0      0       1   \n",
       "\n",
       "                                                    urgent    target  \n",
       "X                                                                     \n",
       "URGENT!! As a valued network customer you have ...       1      spam  \n",
       "Lol you are always so convincing.                        0  non spam  \n",
       "Sauder has interesting courses.                          0  non spam  \n",
       "URGENT! You have won a 1 week FREE membership i...       1      spam  \n",
       "Had your mobile 11 months or more? U R entitled...       0      spam  \n",
       "Sauder has been interesting so far.                      0  non spam  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urgent</th>\n",
       "      <th>prize</th>\n",
       "      <th>sauder</th>\n",
       "      <th>free</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I like Sauder</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               urgent  prize  sauder  free\n",
       "I like Sauder       0      0       1     0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bow_df.iloc[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some of the steps here: \n",
    "\n",
    "**spam side**\n",
    "\n",
    "1\\. Prior probability:     \n",
    "$P(\\text{spam}) = $ \n",
    "\n",
    "2\\. Conditional probabilities: \n",
    "\n",
    "2.1 $P(\\text{free} = 0 \\mid \\text{spam}) = $     \n",
    "2.2 $P(\\text{prize} = 0 \\mid \\text{spam}) = $\n",
    "2.3 $P(\\text{sauder} = 1 \\mid \\text{spam}) = $\n",
    "2.4 $P(\\text{urgent} = 0 \\mid \\text{spam}) = $\n",
    "    \n",
    "<br>\n",
    "\n",
    "3\\. $P(\\textrm{spam}|\\text{free} = 0, \\text{prize} = 0, \\text{sauder} = 1,  \\text{urgent} = 0) = $\n",
    "\n",
    "\n",
    "**non spam side**   \n",
    "\n",
    "4\\. Prior probability:       \n",
    "$P(\\text{non spam}) = $ \n",
    "\n",
    "5\\. Conditional probabilities:     \n",
    "5.1 $P(\\text{free} = 0 \\mid \\text{non spam}) = $    \n",
    "5.2 $P(\\text{prize} = 0 \\mid \\text{non spam}) = $   \n",
    "5.3 $P(\\text{sauder} = 1 \\mid \\text{non spam}) = $     \n",
    "5.4 $P(\\text{urgent} = 0 \\mid \\text{non spam}) = $    \n",
    "    \n",
    "6\\. $P(\\textrm{non spam}|\\text{free} = 0, \\text{prize} = 0, \\text{sauder} = 1,  \\text{urgent} = 0) =$    \n",
    "\n",
    "\n",
    "**Final Class**      \n",
    "\n",
    "7\\. CLASS AS:     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Solutions!\n",
    ":class: dropdown\n",
    "\n",
    "1/. $3/6$       \n",
    "2.1 $1/3$    \n",
    "2.2 $1/3$     \n",
    "2.3 $0/3$     \n",
    "2.4 $1/3$      \n",
    "3\\. $\\frac{1}{3} * \\frac{1}{3}* \\frac{0}{3} * \\frac{1}{3} *\\frac{3}{6} = 0$         \n",
    "\n",
    "4\\. $3/6$    \n",
    "5.1 $3/3$        \n",
    "5.2 $3/3$   \n",
    "5.3 $2/3$    \n",
    "5.4 $3/3$    \n",
    "\n",
    "6\\. $\\frac{3}{3} * \\frac{3}{3}* \\frac{2}{3} * \\frac{3}{3} *\\frac{3}{6} = 1/3$    \n",
    "7\\. Non spam     \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Hyperparameter Optimization\n",
    "\n",
    "We‚Äôve seen quite a few different hyperparameters for different models. \n",
    "\n",
    "We‚Äôve seen `max_depth` and `min_samples_split` for decision trees. \n",
    "\n",
    "We‚Äôve seen `n_neighbors` and `weights` for K-Nearest Neighbours and we‚Äôve seen `gamma` and `C` for SVMs with RBF.\n",
    "\n",
    "We‚Äôve even seen hyperparameters for our transformations like `strategy` for our `SimpleImputer()`. \n",
    "\n",
    "They are important and we‚Äôve seen they can really help optimize your model, but we‚Äôve also seen how difficult it can be to figure out how to set them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem with hyperparameters\n",
    "\n",
    "- We may have a lot of them. (deep learning!)\n",
    "- Picking reasonable hyperparameters is important -> it helps avoid underfit or overfit models. \n",
    "- Nobody knows exactly how to choose them.\n",
    "- May interact with each other in unexpected ways.\n",
    "- The best settings depend on the specific data/problem.\n",
    "- Can take a long time to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to pick hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Manual hyperparameter optimization (What we've done so far)\n",
    "    - We may have some intuition about what might work.    \n",
    "    - It takes a lot of work.    \n",
    "    \n",
    "**OR...**\n",
    "\n",
    "- **Automated hyperparameter optimization** (hyperparameter tuning)\n",
    "    - Reduce human effort.  \n",
    "    - Less prone to error.   \n",
    "    - Data-driven approaches may be effective. \n",
    "    - It may be hard to incorporate intuition.     \n",
    "    - Overfitting on the validation set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated hyperparameter optimization\n",
    "\n",
    "- Exhaustive grid search: [`sklearn.model_selection.GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "- Randomized hyperparameter optimization: <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\" target=\"_blank\">`sklearn.model_selection.RandomizedSearchCV`</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Apply it\n",
    "\n",
    "Let's bring back the cities dataset we worked with in previous lectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-76.4813</td>\n",
       "      <td>44.2307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-81.2496</td>\n",
       "      <td>42.9837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-66.0580</td>\n",
       "      <td>45.2788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-73.2533</td>\n",
       "      <td>45.3057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-67.9245</td>\n",
       "      <td>47.1652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     longitude  latitude\n",
       "160   -76.4813   44.2307\n",
       "127   -81.2496   42.9837\n",
       "169   -66.0580   45.2788\n",
       "188   -73.2533   45.3057\n",
       "187   -67.9245   47.1652"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df = pd.read_csv(\"data/canada_usa_cities.csv\")\n",
    "train_df, test_df = train_test_split(cities_df, test_size=0.2, random_state=123)\n",
    "X_train, y_train = train_df.drop(columns=['country']), train_df['country']\n",
    "X_test, y_test = test_df.drop(columns=['country']), test_df['country']\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exhaustive grid search - Trying ALL the options\n",
    "\n",
    "We import `GridSearchCV` from `sklearn.model_selection` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to first decide on our model and which hyperparameters we want to tune. \n",
    "\n",
    "We are going to use an SVC classifier. \n",
    "\n",
    "After that, we built a dictionary called `param_grid` and we specify the values we wish to look over for the hyperparameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"gamma\": [0.1, 1.0, 10, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we initiate our model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(svc, param_grid, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning `verbose` tells `GridSearchCV` to print some output while it's running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] ........................................ gamma=0.1, total=   0.0s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] ........................................ gamma=0.1, total=   0.0s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] ........................................ gamma=0.1, total=   0.0s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] ........................................ gamma=0.1, total=   0.0s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] ........................................ gamma=0.1, total=   0.0s\n",
      "[CV] gamma=1.0 .......................................................\n",
      "[CV] ........................................ gamma=1.0, total=   0.0s\n",
      "[CV] gamma=1.0 .......................................................\n",
      "[CV] ........................................ gamma=1.0, total=   0.0s\n",
      "[CV] gamma=1.0 .......................................................\n",
      "[CV] ........................................ gamma=1.0, total=   0.0s\n",
      "[CV] gamma=1.0 .......................................................\n",
      "[CV] ........................................ gamma=1.0, total=   0.0s\n",
      "[CV] gamma=1.0 .......................................................\n",
      "[CV] ........................................ gamma=1.0, total=   0.0s\n",
      "[CV] gamma=10 ........................................................\n",
      "[CV] ......................................... gamma=10, total=   0.0s\n",
      "[CV] gamma=10 ........................................................\n",
      "[CV] ......................................... gamma=10, total=   0.0s\n",
      "[CV] gamma=10 ........................................................\n",
      "[CV] ......................................... gamma=10, total=   0.0s\n",
      "[CV] gamma=10 ........................................................\n",
      "[CV] ......................................... gamma=10, total=   0.0s\n",
      "[CV] gamma=10 ........................................................\n",
      "[CV] ......................................... gamma=10, total=   0.0s\n",
      "[CV] gamma=100 .......................................................\n",
      "[CV] ........................................ gamma=100, total=   0.0s\n",
      "[CV] gamma=100 .......................................................\n",
      "[CV] ........................................ gamma=100, total=   0.0s\n",
      "[CV] gamma=100 .......................................................\n",
      "[CV] ........................................ gamma=100, total=   0.0s\n",
      "[CV] gamma=100 .......................................................\n",
      "[CV] ........................................ gamma=100, total=   0.0s\n",
      "[CV] gamma=100 .......................................................\n",
      "[CV] ........................................ gamma=100, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(), param_grid={'gamma': [0.1, 1.0, 10, 100]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice thing about this is we can do this for multiple hyperparameters simultaneously as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"gamma\": [0.1, 1.0, 10, 100],\n",
    "    \"C\": [0.1, 1.0, 10, 100]\n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "grid_search = GridSearchCV(svc, param_grid, cv= 5, verbose=2, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1.0, 10, 100],\n",
       "                         'gamma': [0.1, 1.0, 10, 100]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid in `GridSearchCV` stands for the way that it‚Äôs checking the hyperparameters. \n",
    "\n",
    "Since there 4 options for each, grid search is checking every value in each hyperparameter to one another. \n",
    "\n",
    "That means it‚Äôs checking 4 x 4 = 16 different combinations of hyperparameter values for the model. \n",
    "\n",
    "In `GridSearchCV` we can specify the number of folds of cross-validation with the argument `cv`. \n",
    "\n",
    "Since we are specifying `cv=5` that means that fit is called a total of 80 times (16 different combinations x 5 cross-validation folds)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something new we've added here is `n_jobs=-1`. \n",
    "\n",
    "This is a little more complex.  \n",
    "\n",
    "Setting this to -1 helps make this process faster by running hyperparameter optimization in parallel instead of in a sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement with Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After specifying the steps in a pipeline, a user must specify a set of values for each hyperparameter in `param_grid` as we did before but this time we specify the name of the step followed by two underscores `__` and the name of the hyperparameter.\n",
    "\n",
    "\n",
    "This is because the pipeline would not know which hyperparameter goes with each step. Does `gamma` correspond to the hyperparameter in `SimpleImputer()` or `StandardScaler()`?\n",
    "\n",
    "This now gives the pipeline clear instructions on which hyperparameters correspond with which step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"clf__gamma\": [0.1, 1.0, 10, 100],\n",
    "    \"clf__C\": [0.1, 1.0, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we named our steps in the pipeline, so `clf` corresponds to the model initialization of the SVM classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we used `make_pipeline()` remember that the function names the steps by default the lower case name of each transformation or model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n",
       "                ('standardscaler', StandardScaler()), ('svc', SVC())])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(SimpleImputer(strategy=\"median\"),\n",
    "                    StandardScaler(),\n",
    "                    SVC())\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"svc__gamma\": [0.1, 1.0, 10, 100],\n",
    "    \"svc__C\": [0.1, 1.0, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we initiate `GridSearchCV`, we set the first argument to the pipeline name instead of the model name this time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    2.6s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, return_train_score=True, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking a bit closer these are the steps being performed with `GridSearchCV`. \n",
    "\n",
    "\n",
    "```\n",
    "for gamma in [0.1, 1.0, 10, 100]:\n",
    "        for C in [0.1, 1.0, 10, 100]:\n",
    "            for fold in folds:\n",
    "                fit in training portion with the given C and gamma\n",
    "                score on validation portion\n",
    "            compute average score\n",
    "    pick hyperparameters with the best score\n",
    "```\n",
    "\n",
    "In this case, we can see from the output that 80 executions are done, just like we calculated (4 x 4 x 5 = 80). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why a grid? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/cross.gif\"  width = \"60%\" alt=\"404 image\" />\n",
    "\n",
    "If we fix `C` with a value of 1 and loop over the values of 1, 10 and 100 for `gamma`.\n",
    "\n",
    "This results in `100` having the best score with 0.82. \n",
    "\n",
    "Next, we fix `gamma` at `100` since that was what we found was the most optimal when `C` was equal to 1. \n",
    "\n",
    "When we loop over the values of 1, 10 and 100 for `C` we get the most optimal value to be 10. \n",
    "\n",
    "\n",
    "So naturally, we would pick the values `100` for `gamma` and `10` for `C`. \n",
    "\n",
    "HOWEVER - if we had performed every possible combination, we would have seen that the optimal values would have actually been `10` for both `gamma` and `C`. \n",
    "\n",
    "The same thing is shown if we did it the other way around, first fixing `gamma` at a value of 1 and then looping over all possible values of `C`. \n",
    "\n",
    "This time the most optimal combination is `gamma` equal to 1 and `C` equal to 100 which is again not the optimal value of 10 for each. \n",
    "\n",
    "This is why it is so important not to fix either of the hyperparameters since it won‚Äôt necessarily help you find the most optimal values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now what?\n",
    "\n",
    "How do we know what the best hyperparameter values are after fitting?\n",
    "\n",
    "We can extract the best hyperparameter values with `.best_params_` and their corresponding score with `.best_score_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 10, 'svc__gamma': 1.0}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8208556149732621"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the optimal classifier inside with `.best_estimator_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has already been fully fitted on with all the data and not just a portion from cross-validation so all we need to do is score! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8502994011976048"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either save it as a new model and fit and score on this new one *or* we can use the `grid_search` object directly and it will by default score using the optimal model. \n",
    "These both give the same results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8502994011976048"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same can be done for `.predict()` as well, either using the saved model or using the `grid_search` object directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada',\n",
       "       'Canada', 'Canada', 'Canada', 'USA', 'USA', 'Canada', 'Canada',\n",
       "       'Canada', 'Canada', 'USA', 'Canada', 'USA', 'Canada', 'Canada',\n",
       "       'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada',\n",
       "       'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'USA', 'Canada',\n",
       "       'Canada', 'Canada', 'Canada', 'Canada', 'USA', 'USA', 'Canada',\n",
       "       'Canada', 'Canada'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada',\n",
       "       'Canada', 'Canada', 'Canada', 'USA', 'USA', 'Canada', 'Canada',\n",
       "       'Canada', 'Canada', 'USA', 'Canada', 'USA', 'Canada', 'Canada',\n",
       "       'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada',\n",
       "       'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'USA', 'Canada',\n",
       "       'Canada', 'Canada', 'Canada', 'Canada', 'USA', 'USA', 'Canada',\n",
       "       'Canada', 'Canada'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice any problems? \n",
    "\n",
    "This seems pretty nice and obeys the golden rule however the new problem is the execution time. \n",
    "\n",
    "Think about how much time it would take if we had 5 hyperparameters each with 10 different values.\n",
    "\n",
    "That would mean we would be needing to call `cross_validate()` 100,000 times!\n",
    "\n",
    "Exhaustive search may become infeasible fairly quickly.\n",
    "\n",
    "**Enter randomized hyperparameter search!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"svc__gamma\": [0.1, 1.0, 10, 100],\n",
    "    \"svc__C\": [0.1, 1.0, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(pipe, param_grid, cv=5, verbose=2, n_jobs=-1, n_iter=10)\n",
    "random_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we use the same arguments in `RandomizedSearchCV()` as in `GridSearchCV()` however with 1 new addition - `n_iter`. \n",
    "\n",
    "This argument gives us more control and lets us restrict how many candidates are searched over. \n",
    "\n",
    "`GridSearchCV()` conducts `cross_validate()` on every single possible combination of the hyperparameters specified in `param_grid`. \n",
    "\n",
    "Now we can change that and control that using `n_iter` which will pick a random subset containing the specified number of combinations.\n",
    "\n",
    "The last time when we used exhaustive grid search, we had 80 fits (4 x 4 x 5). \n",
    "\n",
    "This time we see only 50 fits (10 combinations instead of 16 and 5 folds)!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous values for hyperparameter tuning - optional\n",
    "\n",
    "For randomized grid search we can search over a range of continuous values instead of discrete values like in `GridSearchCV()`. \n",
    "\n",
    "We can specify a range of values instead of a list of values for each hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"svc__C\": scipy.stats.uniform(0, 100),\n",
    "    \"svc__gamma\": scipy.stats.uniform(0, 100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_gs = RandomizedSearchCV(pipe, param_grid, n_jobs=-1, cv=10, return_train_score=True, n_iter=10)\n",
    "random_gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 30.962086187979253, 'svc__gamma': 17.526459755968204}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7452205882352942"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How differently does exhaustive and random search score?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, (and often) they produce similar scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem with hyperparameter tuning - overfitting the validation set\n",
    "\n",
    "Since we are repeating cross-validation over and over again, it‚Äôs not necessarily unseen data anymore.\n",
    "\n",
    "This may produce overly optimistic results. \n",
    "\n",
    "If our dataset is small and if our validation set is hit too many times, we suffer from **optimization bias** or **overfitting the validation set**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: overfitting the validation set\n",
    "Attribution: [Mark Scmidt](https://www.cs.ubc.ca/~schmidtm/)\n",
    "\n",
    "This exercise helps explain the concept of overfitting on the validation set.\n",
    "\n",
    "Consider a multiple-choice (a,b,c,d) \"test\" with 10 questions:\n",
    "\n",
    "- If you choose answers randomly, the expected grade is 25% (no bias).\n",
    "- If you fill out two tests randomly and pick the best, the expected grade is 33%.\n",
    "    - overfitting ~8%.\n",
    "- If you take the best among 10 random tests, the expected grade is ~47%.\n",
    "- If you take the best among 100, the expected grade is ~62%.\n",
    "- If you take the best among 1000, the expected grade is ~73%.\n",
    "    - You have so many \"chances\" that you expect to do well.\n",
    "    \n",
    "**But on new questions, the \"random choice\" accuracy is still 25%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected grade among the best of 1 tests is : 0.25\n",
      "The expected grade among the best of 2 tests is : 0.33\n",
      "The expected grade among the best of 10 tests is : 0.47\n",
      "The expected grade among the best of 100 tests is : 0.62\n",
      "The expected grade among the best of 1000 tests is : 0.74\n"
     ]
    }
   ],
   "source": [
    "# Code attributed to Rodolfo Lourenzutti \n",
    "\n",
    "number_tests = [1, 2, 10, 100, 1000]\n",
    "for ntests in number_tests:\n",
    "    y = np.zeros(10000)\n",
    "    for i in range(10000):\n",
    "        y[i] = np.max(np.random.binomial(10.0, 0.25, ntests))\n",
    "    print(\n",
    "        \"The expected grade among the best of %d tests is : %0.2f\"\n",
    "        % (ntests, np.mean(y) / 10.0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we instead used a 100-question test then:\n",
    "  \n",
    "- Expected grade from best over 1 randomly-filled tests is 25%.\n",
    "- Expected grade from best over 2 randomly-filled tests is ~27%.\n",
    "- Expected grade from best over 10 randomly-filled tests is ~32%.\n",
    "- Expected grade from best over 100 randomly-filled tests is ~36%.\n",
    "- Expected grade from best over 1000 randomly-filled tests is ~40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected grade among the best of 1 tests is : 0.25\n",
      "The expected grade among the best of 2 tests is : 0.27\n",
      "The expected grade among the best of 10 tests is : 0.32\n",
      "The expected grade among the best of 100 tests is : 0.36\n",
      "The expected grade among the best of 1000 tests is : 0.40\n"
     ]
    }
   ],
   "source": [
    "# Code attributed to Rodolfo Lourenzutti \n",
    "\n",
    "number_tests = [1, 2, 10, 100, 1000]\n",
    "for ntests in number_tests:\n",
    "    y = np.zeros(10000)\n",
    "    for i in range(10000):\n",
    "        y[i] = np.max(np.random.binomial(100.0, 0.25, ntests))\n",
    "    print(\n",
    "        \"The expected grade among the best of %d tests is : %0.2f\"\n",
    "        % (ntests, np.mean(y) / 100.0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization bias **grows with the number of things we try**.   \n",
    "But, optimization bias **shrinks quickly with the number of examples**.   \n",
    "But it‚Äôs still non-zero and growing if you over-use your validation set!  \n",
    "\n",
    "\n",
    "Essentially our odds of doing well on a multiple-choice exam (if we are guessing) increases the more times we can repeat and randomly take the exam again. \n",
    "\n",
    "Because we have so many chances you‚Äôll eventually do well and perhaps this is not representative of your knowledge (remember you are randomly guessing) \n",
    "\n",
    "The same occurs with selecting hyperparameters. \n",
    "\n",
    "The more hyperparameters values and combinations we try, the more likely we will randomly get a better scoring model by chance and not because the model represents the data well.  \n",
    "\n",
    "This overfitting can be decreased somewhat by increasing the number of questions or in our case, the number of examples we have. \n",
    "\n",
    "TLDR: If your test score is lower than your validation score, it may be because did so much hyperparameter optimization that you got lucky and the bigger data set that you have, the better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice\n",
    "\n",
    "1\\. Which method will attempt to find the optimal hyperparameter for the data by searching every combination possible of hyperparameter values given?    \n",
    "2\\. Which method gives you fine-grained control over the amount of time spent searching?    \n",
    "3\\. If I want to search for the most optimal hyperparameter values among 3 different hyperparameters each with 3 different values how many trials of cross-validation would be needed?    \n",
    "\n",
    "$x= [1,2,3]$   \n",
    "$y= [4,5,6]$     \n",
    "$z= [7,8,9]$    \n",
    " \n",
    "\n",
    "**True or False** \n",
    "\n",
    "4\\. A Larger `n_iter` will take longer but will search over more hyperparameter values.    \n",
    "5\\. Automated hyperparameter optimization can only be used for multiple hyperparameters.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Solutions!\n",
    ":class: dropdown\n",
    "\n",
    "1. Exhaustive Grid Search (`GridSearchCV`)\n",
    "2. Randomized Grid Search (`RandomizedSearchCV`)\n",
    "3. $3 * 3 * 3 = 27$\n",
    "4. True\n",
    "5. False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice - Coding  \n",
    "\n",
    "We are going to practice grid search using our basketball dataset that we have seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the data\n",
    "bball_df = pd.read_csv('data/bball.csv')\n",
    "bball_df = bball_df[(bball_df['position'] =='G') | (bball_df['position'] =='F')]\n",
    "\n",
    "# Define X and y\n",
    "X = bball_df.loc[:, ['height', 'weight', 'salary']]\n",
    "y = bball_df['position']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "bb_pipe = Pipeline(\n",
    "            steps=[(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                   (\"scaler\", StandardScaler()),\n",
    "                   (\"knn\", KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using the pipeline `bb_pipe` provided, create a grid of parameters to search over `param_grid`. Search over the values 1, 5, 10, 20, 30, 40, and 50 for the hyperparameter `n_neighbors` and 'uniform' and 'distance' for the hyperparameter `weights` (make sure to call them appropriately). \n",
    "2. Use `GridSearchCV` to hyperparameter tune using cross-validate equal to 10 folds. Make sure to specify the arguments `verbose=2` and `n_jobs=-1`.\n",
    "3. Train your  pipeline with grid search.\n",
    "4. Find the best hyperparameter values. Make sure to print these results.\n",
    "5. Lastly, score your model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We've Learned Today<a id=\"9\"></a>\n",
    "\n",
    "- How to predict by using naive Bayes.\n",
    "- How to use `scikit-learn`'s `MultiNomialNB`.\n",
    "- What `predict_proba` is. \n",
    "- Why we need smoothing in  naive Bayes.\n",
    "- How to carry out hyperparameter optimization using `sklearn`'s `GridSearchCV` and `RandomizedSearchCV`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "274.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
