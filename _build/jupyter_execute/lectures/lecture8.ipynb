{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 8 - Forming good ML questions from business objectives and Feature Selection\n",
    "\n",
    "*Hayley Boyce, Wednesday, May 12th, 2021*\n",
    "\n",
    "**Attribution:** \n",
    "\n",
    "- Tomas Beuzen - previous BAIT 509 Lecture 6\n",
    "- Varada Kolhatkar - Heavily guiding me with Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our libraries\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import sys\n",
    "sys.path.append('code/')\n",
    "from display_tree import display_tree\n",
    "from plot_classifier import plot_classifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing and pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "import scipy\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Keeping \n",
    "\n",
    "- Project instructions are out!\n",
    "- Time in class for groups! \n",
    " - Assignment 3 was released yesterday!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture Learning Objectives \n",
    "\n",
    "- In the context of supervised learning, form statistical questions  from business questions/objectives.\n",
    "- Understand the different forms your client may expect you to communicate results. \n",
    "- Explain the general concept of feature selection.\n",
    "- Discuss and compare different feature selection methods at a high level.\n",
    "- Use sklearn's implementation of recursive feature elimination (RFE).\n",
    "- Implement the forward search algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five Minute Recap/ Lightning Questions \n",
    "\n",
    "- What is the name of the function used to bound our values between 0 and 1\n",
    "- What is the name of the function that gives \"hard\" predictions?\n",
    "- What is the name of the function that gives \"soft\" predictions?\n",
    "- What is the hyperparameter we learned for Ridge and how does it affect the Fundamental Trade-off?\n",
    "- What is the hyperparameter we learned for Logistic Regression and how does it affect the Fundamental Trade-off?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some lingering questions\n",
    "\n",
    "- How can we start forming good business questions that can be addressed with Machine Learning? \n",
    "- How to select features for our models? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forming statistical questions to answer business objectives\n",
    "\n",
    "So far you've seen how to solve predictive problems using machine learning but today, we are going to look at the process involved in asking the questions and problems faced by organizations. \n",
    "\n",
    "\n",
    "Generally, there are four parts of a machine learning analysis. In order from high to low level:\n",
    "\n",
    "1. **The business question/objective**\n",
    "2. **The statistical question/objective**\n",
    "3. **The data and model**\n",
    "4. **The data product**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a machine learning analysis is about distilling from the highest level to the lowest level. As such, there are three distillations to keep in mind: 1-2, 2-3, and 3-4:\n",
    "\n",
    "- **1-2 is about asking the right questions**\n",
    "- **2-3 is about building a useful model**\n",
    "- **3-4 is about communicating the results**\n",
    "\n",
    "<center><img src=\"https://images.unsplash.com/photo-1511225317751-5c2d61819d58?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=2734&q=80\" width=\"50%\"></center>\n",
    "\n",
    "     \n",
    "     \n",
    "    \n",
    "Note that an analysis isn’t a linear progression through these “steps”; rather, the process is iterative. This is because none of the components are independent. Making progress on any of the three distillations gives you more information as to what the problem is.\n",
    "\n",
    "We’ll look at each of these distillations in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1 - 2) Asking useful statistical questions\n",
    "\n",
    "- Usually, a company is not served up a machine learning problem, complete with data and a description of the response and predictors.\n",
    "    - Companies don't exactly know what question is the right question but they do know what they want  to be accomplished. \n",
    "- Instead, they’re faced with some high-level objective/question that we’ll call the **business question/objective**.\n",
    "- This question needs refining to a **statistical question/objective** – one that is directly addressable by machine learning.\n",
    "\n",
    "Example: \n",
    "\n",
    "- My Capstone Case study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business objectives: examples\n",
    "- This [altexsoft blog post](https://www.altexsoft.com/blog/business/supervised-learning-use-cases-low-hanging-fruit-in-data-science-for-businesses/) is a great introduction to business use cases of data science/ML\n",
    "- Examples of business objectives (for which machine learning is a relevant approach)\n",
    "    - Reduce the amount of spam email received\n",
    "    - Early prediction of product failure\n",
    "    - Find undervalued mines\n",
    "    - Make a transit system more efficient\n",
    "    - Hire efficient staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refining business objectives to statistical objectives\n",
    "\n",
    "<img src='https://media.giphy.com/media/bLcMOxvIak4iZieaut/giphy.gif' width=\"50%\"> \n",
    "\n",
    "- Statistical objectives need to be specific\n",
    "- Remember that supervised learning is about predicting a response $Y$ from predictors $X_1,…,X_p$\n",
    "- So we need to refine our business objectives to a statistical question(s) we can answer\n",
    "- This typically involves:\n",
    "    - Identifying the **response variable** ($Y$) that is most aligned with the business objective.\n",
    "    - Identifying the **data** (observations + features) that will be used for model development/testing.\n",
    "    - Note: part of this is the task of feature selection (a topic that we've covered briefly) – but, this is also largely, a human decision based on what we think is more informative, as well as a resource questions (what data is actually available?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical objectives: examples\n",
    "Statistical objectives corresponding to the above business objective examples might be:\n",
    "\n",
    "| Business Objective | Statistical Question |\n",
    "| :--- | :--- |\n",
    "| Reduce the amount of spam email received | <ul><li>$Y$ = classifying an email as spam/not spam <li> $X$ = words present in name and the body of email and other metadata (sender email, time, etc.) <li> Cases of spam will be gathered over time as employees identify emails as spam/not spam. The model can be improved as misclassifications are encountered.</ul>\n",
    "| Early prediction of product failure, (Kickstarter?) | <ul><li>$Y$ = classifying a product as faulty/not faulty <li> $X$ = Relevant features chosen by an expert <li> Data obtained from the test facility</ul>\n",
    "| Find undervalued mines | <ul><li>$Y$ = total volume of gold and silver at a site <li> $X$ =  concentrations of other minerals found in drill samples, geographic information, historical data, etc <li> Data obtained from mines where total volumes are already known</ul>\n",
    "| Make a transit system more efficient | <ul><li>$Y$ = predict the time it takes a bus to travel between set stops <li> $X$ = time of day/week/year, weather, etc. <li> Use data from company server tracking bus movements</ul>\n",
    "| Hire efficient staff | <ul><li>$Y$ = predict monthly sales <li> $X$ = a personality test, years of work experience, field of experience, etc. <li> Use data based on current employees</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical questions are not the full picture!\n",
    "- Almost always, the business objective is more complex than the statistical question.\n",
    "- By refining a business objective to a statistical one, we may lose part of the essence of the business objective.\n",
    "- It’s important to have a sense of the ways in which your statistical objective falls short, and the ways in which it’s on the mark, so that you keep an idea of the big picture.\n",
    "- For example, predicting whether a new staff hire will be efficient or not is a useful statistical question, but doesn't consider why a company might be attracting certain applicants, how long staff will remain, how staff work together, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical objectives unrelated to supervised learning\n",
    "\n",
    "- We are only focussing on statistical questions related to supervised learning and prediction in this course\n",
    "- But there are other kinds of questions you can ask too\n",
    "- Consider the following example\n",
    "\n",
    "**Business objective**: To gain insight into the productivity of two branches of a company.\n",
    "\n",
    "Examples of statistical questions:\n",
    "\n",
    "- **Hypothesis testing**: Is the mean number of sick days per employee different between two branches of a company?\n",
    "    - Supervised learning doesn’t cover testing for differences.\n",
    "- **Unsupervised learning**: What is the mean sentiment of the internal discussion channels from both branches?\n",
    "    - There is no data of feature + response here, as required by supervised learning (by definition).\n",
    "- **Statistical inference**: Estimate the mean difference in monthly revenue generated by both branches, along with how certain you are with that estimate.\n",
    "    - Supervised learning typically isn’t concerned about communicating how certain your estimate is. (BUT it should be and changes are being made to change this!)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2 - 3) Building a useful model\n",
    "- This is really the main focus of this course, This is the meat/beyond meat patty in your burger! \n",
    "- This involves using ML algorithms (kNN, loess, decision trees, etc) to build a predictive model from data\n",
    "- You always should include a baseline model to assess how well the models you build are giving you some leg up. \n",
    "- A simple model like logistic regression does as well as a more complex approach! At the very least, they can help guide you on what more complex approaches to take next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3 - 4) Communicating results\n",
    "\n",
    "- So you've distilled your business objectives to a statistical question.\n",
    "- You've developed a model to answer the statistical question.\n",
    "- Now your model needs to be delivered and used by others (or your future self)!\n",
    "- The final delivery is often called \"the data product\" because it may consist of a variety of things:\n",
    "    - a report\n",
    "    - a presentation\n",
    "    - an app\n",
    "    - a dashboard\n",
    "    - a software package/pipeline\n",
    "- Sometimes the client requests a specific data product -> But note that their suggestion might not always be the best option. \n",
    "    - Perhaps they request a report and presentation communicating your findings, when a more appropriate product also includes an interactive app that allows them to explore your findings for themselves.\n",
    "- Either way, the key here is communication. Two import challenges (relevant to your final project):\n",
    "    - Using appropriate language: there is a lot of jargon in ML, the key is to talk more about the output and the general idea of your model(s), but not machine learning or statistical jargon.\n",
    "    - Communication with visual design: this is about choosing what visuals are the most effective for communicating. -> Plug: https://viz-learn.mds.ubc.ca/en/\n",
    "- Usually, the first step is to set up a framework for your data product. For a report, this means outlining what you intend to write about, and where.\n",
    "- Showing it to your client is useful as a sanity check to see that you’re about to produce something that the client currently sees as being potentially useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice \n",
    "\n",
    "1. What question is usually more complex?\n",
    "2. What model needs to be made for all problems?\n",
    "3. In supervised learning, once we have our business objective, part of our statistical question is identifying what?\n",
    "\n",
    "**True or False:**\n",
    "4. When writing your reports, it's important to consider who is reading it.   \n",
    "5. Sometimes you may need to dig a little to figure out exactly what the client wants.    \n",
    "6. In supervised learning, we should take into consideration the uncertainty of our models.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection \n",
    "\n",
    "### Motivation \n",
    "\n",
    "Remember the curse of dimensionality? \n",
    "\n",
    "<img src='imgs/curse.png' width=\"50%\"> \n",
    "\n",
    "We spoke about this briefly when we discussed $k$-nn and how when we add many different dimensions (features) it can confuse the model with any irrelevant features and the model can disintegrate into predictions no better than random guessing.\n",
    "Reasons like this are why we need to be careful about which features we include.\n",
    "\n",
    "Reasons like this is why we need to be careful about which features we include. \n",
    "\n",
    "When we choose the best set of features we call this **Feature Selection**. \n",
    "\n",
    "Feature selection a lot of the time can be done using domain knowledge and manually however we can also use tools that help us either tell us:\n",
    "\n",
    "- which features are most important to a model \n",
    "- or that can select a number of features that will result with the optimal validation score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-76.4813</td>\n",
       "      <td>44.2307</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-81.2496</td>\n",
       "      <td>42.9837</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-66.0580</td>\n",
       "      <td>45.2788</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-73.2533</td>\n",
       "      <td>45.3057</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-67.9245</td>\n",
       "      <td>47.1652</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     longitude  latitude country\n",
       "160   -76.4813   44.2307  Canada\n",
       "127   -81.2496   42.9837  Canada\n",
       "169   -66.0580   45.2788  Canada\n",
       "188   -73.2533   45.3057  Canada\n",
       "187   -67.9245   47.1652  Canada"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df = pd.read_csv(\"data/canada_usa_cities.csv\")\n",
    "train_df, test_df = train_test_split(cities_df, test_size=0.2, random_state=123)\n",
    "X_train, y_train = train_df.drop(columns=[\"country\"], axis=1), train_df[\"country\"]\n",
    "X_test, y_test = test_df.drop(columns=[\"country\"], axis=1), test_df[\"country\"]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance \n",
    "\n",
    "Remember our Decision Tree models? Well, we can find out which features are most important in a model using an attribute called `feature_importances_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23330056, 0.76669944])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(max_depth=5)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that most of the importance is on the column `latitude`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we graph this, the root of the decision tree will usually reflect the top feature. Just like we can see here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"539pt\" height=\"414pt\"\n",
       " viewBox=\"0.00 0.00 538.50 414.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 410)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-410 534.5,-410 534.5,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"282.5,-406 177.5,-406 177.5,-368 282.5,-368 282.5,-406\"/>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-390.8\" font-family=\"Times,serif\" font-size=\"14.00\">latitude &lt;= 42.9</text>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-375.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"221.5,-332 102.5,-332 102.5,-294 221.5,-294 221.5,-332\"/>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-316.8\" font-family=\"Times,serif\" font-size=\"14.00\">latitude &lt;= 42.096</text>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-301.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = USA</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M212.84,-367.83C204.85,-359.37 195.2,-349.15 186.46,-339.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"188.8,-337.28 179.39,-332.41 183.71,-342.09 188.8,-337.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"178.68\" y=\"-353.7\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"358.5,-332 239.5,-332 239.5,-294 358.5,-294 358.5,-332\"/>\n",
       "<text text-anchor=\"middle\" x=\"299\" y=\"-316.8\" font-family=\"Times,serif\" font-size=\"14.00\">latitude &lt;= 55.958</text>\n",
       "<text text-anchor=\"middle\" x=\"299\" y=\"-301.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>0&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M247.41,-367.83C255.52,-359.37 265.32,-349.15 274.18,-339.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"276.96,-342.05 281.35,-332.41 271.91,-337.21 276.96,-342.05\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.89\" y=\"-353.71\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"86,-257 0,-257 0,-221 86,-221 86,-257\"/>\n",
       "<text text-anchor=\"middle\" x=\"43\" y=\"-235.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = USA</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.97,-293.83C116.29,-284.34 96.94,-272.64 80.31,-262.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"81.75,-259.35 71.38,-257.17 78.12,-265.34 81.75,-259.35\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"223.5,-258 104.5,-258 104.5,-220 223.5,-220 223.5,-258\"/>\n",
       "<text text-anchor=\"middle\" x=\"164\" y=\"-242.8\" font-family=\"Times,serif\" font-size=\"14.00\">latitude &lt;= 42.324</text>\n",
       "<text text-anchor=\"middle\" x=\"164\" y=\"-227.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = USA</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M162.5,-293.83C162.72,-286.13 162.97,-276.97 163.21,-268.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"166.71,-268.51 163.49,-258.41 159.71,-268.31 166.71,-268.51\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"103.5,-183 4.5,-183 4.5,-147 103.5,-147 103.5,-183\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-161.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M136.24,-219.83C121.88,-210.43 104.2,-198.86 88.91,-188.85\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.52,-185.72 80.23,-183.17 86.68,-191.58 90.52,-185.72\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"208,-183 122,-183 122,-147 208,-147 208,-183\"/>\n",
       "<text text-anchor=\"middle\" x=\"165\" y=\"-161.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = USA</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M164.25,-219.83C164.36,-211.89 164.49,-202.41 164.62,-193.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"168.12,-193.47 164.76,-183.42 161.12,-193.37 168.12,-193.47\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"350.5,-258 245.5,-258 245.5,-220 350.5,-220 350.5,-258\"/>\n",
       "<text text-anchor=\"middle\" x=\"298\" y=\"-242.8\" font-family=\"Times,serif\" font-size=\"14.00\">latitude &lt;= 49.0</text>\n",
       "<text text-anchor=\"middle\" x=\"298\" y=\"-227.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M298.75,-293.83C298.64,-286.13 298.51,-276.97 298.39,-268.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"301.89,-268.36 298.26,-258.41 294.9,-268.46 301.89,-268.36\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"455,-257 369,-257 369,-221 455,-221 455,-257\"/>\n",
       "<text text-anchor=\"middle\" x=\"412\" y=\"-235.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = USA</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>6&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M327.51,-293.83C342.41,-284.34 360.78,-272.64 376.58,-262.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"378.5,-265.5 385.05,-257.17 374.74,-259.59 378.5,-265.5\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"364,-184 230,-184 230,-146 364,-146 364,-184\"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-168.8\" font-family=\"Times,serif\" font-size=\"14.00\">longitude &lt;= &#45;94.582</text>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-153.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M297.75,-219.83C297.64,-212.13 297.51,-202.97 297.39,-194.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"300.89,-194.36 297.26,-184.41 293.9,-194.46 300.89,-194.36\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"481.5,-183 382.5,-183 382.5,-147 481.5,-147 481.5,-183\"/>\n",
       "<text text-anchor=\"middle\" x=\"432\" y=\"-161.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>7&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M331.81,-219.83C349.8,-210.17 372.06,-198.2 391.03,-188.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"392.89,-190.99 400.04,-183.17 389.58,-184.82 392.89,-190.99\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"290,-110 150,-110 150,-72 290,-72 290,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"220\" y=\"-94.8\" font-family=\"Times,serif\" font-size=\"14.00\">longitude &lt;= &#45;123.222</text>\n",
       "<text text-anchor=\"middle\" x=\"220\" y=\"-79.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = USA</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M277.57,-145.83C268.27,-137.13 256.98,-126.58 246.87,-117.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"249.12,-114.44 239.42,-110.16 244.34,-119.55 249.12,-114.44\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"442,-110 308,-110 308,-72 442,-72 442,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-94.8\" font-family=\"Times,serif\" font-size=\"14.00\">longitude &lt;= &#45;69.246</text>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-79.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>8&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M316.68,-145.83C326.11,-137.13 337.54,-126.58 347.78,-117.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"350.35,-119.52 355.32,-110.16 345.6,-114.37 350.35,-119.52\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"169.5,-36 70.5,-36 70.5,0 169.5,0 169.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"120\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M194.51,-71.9C181.66,-62.78 165.96,-51.63 152.28,-41.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.25,-39.02 144.07,-36.09 150.2,-44.73 154.25,-39.02\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"274,-36 188,-36 188,0 274,0 274,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"231\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = USA</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222.83,-71.72C224.05,-63.89 225.49,-54.59 226.82,-45.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"230.29,-46.42 228.37,-36 223.38,-45.35 230.29,-46.42\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"413.5,-36 314.5,-36 314.5,0 413.5,0 413.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M372.17,-71.72C370.95,-63.89 369.51,-54.59 368.18,-45.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"371.62,-45.35 366.63,-36 364.71,-46.42 371.62,-45.35\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"530.5,-36 431.5,-36 431.5,0 530.5,0 530.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"481\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M402.02,-71.9C415.64,-62.78 432.29,-51.63 446.78,-41.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"449.13,-44.56 455.49,-36.09 445.23,-38.75 449.13,-44.56\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x12e3d2dc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "filenames": {
       "image/svg+xml": "/Users/icics-user/Documents/BAIT509/BAIT509/_build/jupyter_execute/lectures/lecture8_24_0.svg"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('code/')\n",
    "from display_tree import display_tree\n",
    "display_tree(X_train.columns, dt_model, \"imgs/decision_tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New housing data \n",
    "\n",
    "I know at this point you are probably annoyed and bored of housing data, but good, interesting open-source data is hard to come by. For this example I really want to show you an example with LOTS of features. \n",
    "\n",
    "For this example, I really want to show you an example with LOTS of features.\n",
    "Here is (yet another) housing dataset we acquired from [this GitHub repo](https://github.com/melindaleung/Ames-Iowa-Housing-Dataset), originally created by Dean De Cock. (We are using the raw data so we do not need to store it and import it simply from the url)\n",
    "\n",
    "\n",
    "**Attribution:** \n",
    "\n",
    "The Ames Housing dataset was compiled by Dean De Cock for use in data science education. \n",
    "\n",
    "His publication can be found [here](http://jse.amstat.org/v19n3/decock.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1444 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                      \n",
       "1             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "2             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "3             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "4             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "5             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
       "Id                                    ...                                      \n",
       "1            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "2            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
       "3            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "4            Lvl    AllPub    Corner  ...        0    NaN    NaN         NaN   \n",
       "5            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
       "...          ...       ...       ...  ...      ...    ...    ...         ...   \n",
       "1456         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "1457         Lvl    AllPub    Inside  ...        0    NaN  MnPrv         NaN   \n",
       "1458         Lvl    AllPub    Inside  ...        0    NaN  GdPrv        Shed   \n",
       "1459         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "1460         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "\n",
       "     MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "Id                                                               \n",
       "1          0      2    2008        WD         Normal     208500  \n",
       "2          0      5    2007        WD         Normal     181500  \n",
       "3          0      9    2008        WD         Normal     223500  \n",
       "4          0      2    2006        WD        Abnorml     140000  \n",
       "5          0     12    2008        WD         Normal     250000  \n",
       "...      ...    ...     ...       ...            ...        ...  \n",
       "1456       0      8    2007        WD         Normal     175000  \n",
       "1457       0      2    2010        WD         Normal     210000  \n",
       "1458    2500      5    2010        WD         Normal     266500  \n",
       "1459       0      4    2010        WD         Normal     142125  \n",
       "1460       0      6    2008        WD         Normal     147500  \n",
       "\n",
       "[1444 rows x 80 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ames_df = pd.read_csv('https://raw.githubusercontent.com/melindaleung/Ames-Iowa-Housing-Dataset/master/data/ames%20iowa%20housing.csv', index_col=0)\n",
    "ames_df = ames_df[(ames_df['SaleCondition'] != 'Alloca') &  (ames_df['SaleCondition'] != 'AdjLand')]\n",
    "ames_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1444 entries, 1 to 1460\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1444 non-null   int64  \n",
      " 1   MSZoning       1444 non-null   object \n",
      " 2   LotFrontage    1187 non-null   float64\n",
      " 3   LotArea        1444 non-null   int64  \n",
      " 4   Street         1444 non-null   object \n",
      " 5   Alley          91 non-null     object \n",
      " 6   LotShape       1444 non-null   object \n",
      " 7   LandContour    1444 non-null   object \n",
      " 8   Utilities      1444 non-null   object \n",
      " 9   LotConfig      1444 non-null   object \n",
      " 10  LandSlope      1444 non-null   object \n",
      " 11  Neighborhood   1444 non-null   object \n",
      " 12  Condition1     1444 non-null   object \n",
      " 13  Condition2     1444 non-null   object \n",
      " 14  BldgType       1444 non-null   object \n",
      " 15  HouseStyle     1444 non-null   object \n",
      " 16  OverallQual    1444 non-null   int64  \n",
      " 17  OverallCond    1444 non-null   int64  \n",
      " 18  YearBuilt      1444 non-null   int64  \n",
      " 19  YearRemodAdd   1444 non-null   int64  \n",
      " 20  RoofStyle      1444 non-null   object \n",
      " 21  RoofMatl       1444 non-null   object \n",
      " 22  Exterior1st    1444 non-null   object \n",
      " 23  Exterior2nd    1444 non-null   object \n",
      " 24  MasVnrType     1437 non-null   object \n",
      " 25  MasVnrArea     1437 non-null   float64\n",
      " 26  ExterQual      1444 non-null   object \n",
      " 27  ExterCond      1444 non-null   object \n",
      " 28  Foundation     1444 non-null   object \n",
      " 29  BsmtQual       1411 non-null   object \n",
      " 30  BsmtCond       1411 non-null   object \n",
      " 31  BsmtExposure   1410 non-null   object \n",
      " 32  BsmtFinType1   1411 non-null   object \n",
      " 33  BsmtFinSF1     1444 non-null   int64  \n",
      " 34  BsmtFinType2   1410 non-null   object \n",
      " 35  BsmtFinSF2     1444 non-null   int64  \n",
      " 36  BsmtUnfSF      1444 non-null   int64  \n",
      " 37  TotalBsmtSF    1444 non-null   int64  \n",
      " 38  Heating        1444 non-null   object \n",
      " 39  HeatingQC      1444 non-null   object \n",
      " 40  CentralAir     1444 non-null   object \n",
      " 41  Electrical     1443 non-null   object \n",
      " 42  1stFlrSF       1444 non-null   int64  \n",
      " 43  2ndFlrSF       1444 non-null   int64  \n",
      " 44  LowQualFinSF   1444 non-null   int64  \n",
      " 45  GrLivArea      1444 non-null   int64  \n",
      " 46  BsmtFullBath   1444 non-null   int64  \n",
      " 47  BsmtHalfBath   1444 non-null   int64  \n",
      " 48  FullBath       1444 non-null   int64  \n",
      " 49  HalfBath       1444 non-null   int64  \n",
      " 50  BedroomAbvGr   1444 non-null   int64  \n",
      " 51  KitchenAbvGr   1444 non-null   int64  \n",
      " 52  KitchenQual    1444 non-null   object \n",
      " 53  TotRmsAbvGrd   1444 non-null   int64  \n",
      " 54  Functional     1444 non-null   object \n",
      " 55  Fireplaces     1444 non-null   int64  \n",
      " 56  FireplaceQu    766 non-null    object \n",
      " 57  GarageType     1367 non-null   object \n",
      " 58  GarageYrBlt    1367 non-null   float64\n",
      " 59  GarageFinish   1367 non-null   object \n",
      " 60  GarageCars     1444 non-null   int64  \n",
      " 61  GarageArea     1444 non-null   int64  \n",
      " 62  GarageQual     1367 non-null   object \n",
      " 63  GarageCond     1367 non-null   object \n",
      " 64  PavedDrive     1444 non-null   object \n",
      " 65  WoodDeckSF     1444 non-null   int64  \n",
      " 66  OpenPorchSF    1444 non-null   int64  \n",
      " 67  EnclosedPorch  1444 non-null   int64  \n",
      " 68  3SsnPorch      1444 non-null   int64  \n",
      " 69  ScreenPorch    1444 non-null   int64  \n",
      " 70  PoolArea       1444 non-null   int64  \n",
      " 71  PoolQC         6 non-null      object \n",
      " 72  Fence          279 non-null    object \n",
      " 73  MiscFeature    53 non-null     object \n",
      " 74  MiscVal        1444 non-null   int64  \n",
      " 75  MoSold         1444 non-null   int64  \n",
      " 76  YrSold         1444 non-null   int64  \n",
      " 77  SaleType       1444 non-null   object \n",
      " 78  SaleCondition  1444 non-null   object \n",
      " 79  SalePrice      1444 non-null   int64  \n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 913.8+ KB\n"
     ]
    }
   ],
   "source": [
    "ames_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use `.info()` to identify our categorical and numeric features. I split my features and identify my target. \n",
    "\n",
    "The target variable for this question is `SaleCondition` and we are doing classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(ames_df, test_size=0.2, random_state=77)\n",
    "\n",
    "X_train = train_df.drop(columns=['SaleCondition', 'PoolQC', 'MiscFeature', 'Alley'])\n",
    "X_test =  test_df.drop(columns=['SaleCondition', 'PoolQC', 'MiscFeature', 'Alley'])\n",
    "\n",
    "y_train = train_df[['SaleCondition']]\n",
    "y_test = test_df[['SaleCondition']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note, you should be looking at these individually but I'm being a little lazy here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X_train.select_dtypes('number').columns.to_list()\n",
    "categorical_features = X_train.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our numeric features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSSubClass',\n",
       " 'LotFrontage',\n",
       " 'LotArea',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'MasVnrArea',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtFinSF2',\n",
       " 'BsmtUnfSF',\n",
       " 'TotalBsmtSF',\n",
       " '1stFlrSF',\n",
       " '2ndFlrSF',\n",
       " 'LowQualFinSF',\n",
       " 'GrLivArea',\n",
       " 'BsmtFullBath',\n",
       " 'BsmtHalfBath',\n",
       " 'FullBath',\n",
       " 'HalfBath',\n",
       " 'BedroomAbvGr',\n",
       " 'KitchenAbvGr',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'GarageYrBlt',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'WoodDeckSF',\n",
       " 'OpenPorchSF',\n",
       " 'EnclosedPorch',\n",
       " '3SsnPorch',\n",
       " 'ScreenPorch',\n",
       " 'PoolArea',\n",
       " 'MiscVal',\n",
       " 'MoSold',\n",
       " 'YrSold',\n",
       " 'SalePrice']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are our categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'Fence',\n",
       " 'SaleType']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to make our pipelines and column transformer. \n",
    "\n",
    "We can also cross-validate, but here my main goal is to show you how to get our feature importances from our pipeline! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.064192\n",
       "score_time     0.011967\n",
       "test_score     0.862338\n",
       "train_score    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_pipe = make_pipeline(SimpleImputer(strategy='median'),\n",
    "                            StandardScaler())\n",
    "categoric_pipe = make_pipeline(SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "                            OneHotEncoder(dtype=int, handle_unknown=\"ignore\"))\n",
    "\n",
    "preprocessor = make_column_transformer((numeric_pipe, numeric_features),\n",
    "                                       (categoric_pipe, categorical_features))\n",
    "\n",
    "main_pipe = make_pipeline(preprocessor, DecisionTreeClassifier())\n",
    "\n",
    "\n",
    "scores = cross_validate(main_pipe, X_train, y_train, return_train_score=True)\n",
    "\n",
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we fit our pipeline outside of `cross_validate()` we can use `feature_importances_` to get our percentages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.83693524e-03, 1.83123069e-02, 1.73629734e-02, 4.60432228e-03,\n",
       "       0.00000000e+00, 5.03597750e-03, 6.71463666e-03, 0.00000000e+00,\n",
       "       3.04088314e-02, 2.66956175e-03, 6.82007753e-03, 1.09469307e-02,\n",
       "       8.72396338e-03, 0.00000000e+00, 0.00000000e+00, 9.87778750e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.04386254e-02, 0.00000000e+00, 1.39656847e-02, 0.00000000e+00,\n",
       "       3.37670181e-02, 0.00000000e+00, 1.68241792e-02, 1.04412794e-02,\n",
       "       1.11496574e-02, 8.81379235e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.81520736e-02, 4.12816564e-02,\n",
       "       4.18455631e-02, 0.00000000e+00, 0.00000000e+00, 5.26208261e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.87770143e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.83693524e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.45248691e-03, 0.00000000e+00,\n",
       "       5.39569017e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 5.46763271e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.31655214e-03,\n",
       "       5.35008117e-03, 0.00000000e+00, 1.31095287e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.60150340e-03, 0.00000000e+00, 4.31655214e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.85792341e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "       4.18400114e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.67652343e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.31655214e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.58612630e-03,\n",
       "       0.00000000e+00, 2.69428006e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.05036850e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       5.19397183e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.67865917e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 9.54245445e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       7.67387047e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       4.27544212e-03, 0.00000000e+00, 0.00000000e+00, 1.70803741e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.83693524e-03, 0.00000000e+00, 0.00000000e+00, 2.26547155e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 9.91899161e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.27277248e-03, 0.00000000e+00,\n",
       "       9.22155719e-04, 0.00000000e+00, 5.03597750e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.55326651e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 4.31655214e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.22359798e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.03107628e-03, 1.84468040e-03, 1.31581162e-03,\n",
       "       0.00000000e+00, 5.90742993e-02, 3.52070508e-03, 0.00000000e+00,\n",
       "       5.42732877e-03, 0.00000000e+00, 0.00000000e+00, 4.65536319e-01,\n",
       "       5.24870965e-03, 0.00000000e+00])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_pipe.fit(X_train, y_train)\n",
    "feats_importance = main_pipe.named_steps['decisiontreeclassifier'].feature_importances_\n",
    "feats_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here, is we don't know which value corresponds to which feature! \n",
    "\n",
    "Let's first take a look at how many features we have now after preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feats_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok 286, let's get the feature names after preprocessing.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain the categorical features and combine them with the  numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = preprocessor.named_transformers_['pipeline-2'].named_steps[\n",
    "    'onehotencoder'].get_feature_names(categorical_features).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feat_names = numeric_features + cat_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that we have the name number of feature names as we do feature_importance values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_feat_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get them into a dataframe now and sort them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>SaleType_New</td>\n",
       "      <td>0.465536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>SaleType_COD</td>\n",
       "      <td>0.0590743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SalePrice</td>\n",
       "      <td>0.0418456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>YrSold</td>\n",
       "      <td>0.0412817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GarageYrBlt</td>\n",
       "      <td>0.033767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>RoofStyle_Shed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>RoofMatl_ClyTile</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>RoofMatl_CompShg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>RoofMatl_Membran</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>SaleType_WD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature feature_importance\n",
       "283      SaleType_New           0.465536\n",
       "277      SaleType_COD          0.0590743\n",
       "36          SalePrice          0.0418456\n",
       "35             YrSold          0.0412817\n",
       "24        GarageYrBlt           0.033767\n",
       "..                ...                ...\n",
       "122    RoofStyle_Shed                  0\n",
       "123  RoofMatl_ClyTile                  0\n",
       "124  RoofMatl_CompShg                  0\n",
       "125  RoofMatl_Membran                  0\n",
       "285       SaleType_WD                  0\n",
       "\n",
       "[286 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.DataFrame(data = [all_feat_names,\n",
    "                                feats_importance.flatten()]).T.rename(columns={0:'feature', 1:'feature_importance'})\n",
    "features_df.sort_values('feature_importance',key= abs, ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `SaleType_New` is the most important feature in our model.\n",
    "\n",
    "From here we can decide to manually remove some of the columns that are not taken into consideration as much.... or we can instead use a tool to help us! \n",
    "\n",
    "Enter - **Recursive feature elimination**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive feature elimination - RFE \n",
    "\n",
    "We can use feature importances to eliminate unimportant features.\n",
    "\n",
    "The basic idea with recursive feature elimination is we: \n",
    "1. We decide $k$ - the number of features to select.\n",
    "2. Assign importances to features, e.g. by fitting a model and looking at coef_ or feature_importances_.\n",
    "3. Remove the least important feature.\n",
    "4. Repeat steps 2-3 until only $k$ features are remaining.\n",
    "\n",
    "**Note that this is not the same as just removing all the less important features in one shot!**\n",
    "\n",
    "Let's take a look at how we can do this. \n",
    "\n",
    "First we import `RFE` from `sklearn.feature_selection`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of simply using `DecisionTreeClassifier`, we can wrap it around the `RFE` function and specify how many features we want with `n_features_to_select`. \n",
    "\n",
    "Here I'm capping the number of features to 30 (an arbitrary number I picked).\n",
    "\n",
    "This is going to take about 1-2 minutes to run because now, it's recursively removing 1 feature at a time and cross-validating on the final result.\n",
    "\n",
    "\n",
    "<img src='imgs/waiting2.png' width=\"50%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.470945</td>\n",
       "      <td>0.011375</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.382802</td>\n",
       "      <td>0.010430</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.073846</td>\n",
       "      <td>0.010113</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.283985</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>0.874459</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.610064</td>\n",
       "      <td>0.011440</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  7.470945    0.011375    0.896104          1.0\n",
       "1  6.382802    0.010430    0.848485          1.0\n",
       "2  7.073846    0.010113    0.857143          1.0\n",
       "3  6.283985    0.010504    0.874459          1.0\n",
       "4  7.610064    0.011440    0.896104          1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_pipe = make_pipeline(preprocessor, RFE(DecisionTreeClassifier(), \n",
    "                                            n_features_to_select=30))\n",
    "\n",
    "scores = cross_validate(main_pipe, X_train, y_train, return_train_score=True)\n",
    "\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       6.964328\n",
       "score_time     0.010772\n",
       "test_score     0.874459\n",
       "train_score    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this mean validation score compared to when the model was using all the features, we can see it increased a bit! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now our next question is how do we set $k$? How do we know how many features is the optimal amount... Well, you guessed it! There is a tool for that too! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFECV\n",
    "\n",
    "You can find the optimal number of features using cross-validation with `RFECV` where the optimal $k$ value is selected based on the highest validation score. \n",
    "\n",
    "You would definitely not want to use the training score! - Why?\n",
    " > Because with training score the more features you add the higher the score, this isn't the case with validation score. \n",
    " \n",
    "We can import `RFECV` from `sklearn.feature_selection` like we did for `RFE`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of `RFE` now we simply use `RFECV` in our pipeline and we do not need to specify the argument `n_features_to_select` like we did with `RFE` since $k$ is selected based on the highest validation score. \n",
    "\n",
    "(*This is also going to take a couple of minutes*)\n",
    "\n",
    "<img src='imgs/waiting1.png' width=\"50%\"> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe = make_pipeline(preprocessor, RFECV(DecisionTreeClassifier(), cv=5))\n",
    "\n",
    "scores = cross_validate(main_pipe, X_train, y_train, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have ~91% for our validation score! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       35.398136\n",
       "score_time      0.011110\n",
       "test_score      0.912554\n",
       "train_score     0.912554\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False]\n"
     ]
    }
   ],
   "source": [
    "main_pipe.fit(X_train,y_train)\n",
    "print(main_pipe.named_steps[\"rfecv\"].support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features selected by RFE:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of features selected by RFE: \",\n",
    "      main_pipe.named_steps[\"rfecv\"].n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SaleType_New'], dtype='<U20')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = all_feat_names\n",
    "support = main_pipe.named_steps[\"rfecv\"].support_\n",
    "RFE_selected_feats = np.array(feature_names)[support]\n",
    "RFE_selected_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFECV selects the features by references their `feature_importances` as well as the validation score after each feature is removed and seeing if it is increasing. \n",
    "\n",
    "When a feature is removed and the validation score is no longer increasing, then it stops removing features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Selection \n",
    "\n",
    "Unlike with RFE where we start with all our features and gradually remove the leat important ones, **Forward Selection** is a process where we start with no features and gradually add them! \n",
    "\n",
    "With RFE we removed the least important feature, whereas with forward selection we add features untill our cross-validation score starts to decreases. \n",
    "\n",
    "Forward Selection does not guaranty finding the best features set but reduces many problems.\n",
    "Computationally cheaper (aka faster!) \n",
    "Overfits less\n",
    "\n",
    "\n",
    "Forward selection is recently implemented in `sklearn` so please make sure it is up to date! You need version 0.24!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import it as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_forward = make_pipeline(preprocessor, \n",
    "                             SequentialFeatureSelector(DecisionTreeClassifier(), \n",
    "                                                       direction='forward',\n",
    "                                                       n_features_to_select=20),\n",
    "                            DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this next cell is going to take a LONG LONG LONG time. \n",
    "\n",
    "<img src='imgs/waiting3.png' width=\"50%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       73.242775\n",
       "score_time      0.010345\n",
       "test_score      0.901299\n",
       "train_score     0.935714\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(pipe_forward, X_train, y_train, \n",
    "                        return_train_score=True)\n",
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice \n",
    "\n",
    "1. As we increase features, which score will always increase? \n",
    "2. Between `RFE` and `RFECV` which one finds the optimal number of features for us?\n",
    "3. Which method starts with all our features and iteratively removes them from our model?\n",
    "4. Which method starts with no features and iteratively adds features?\n",
    "5. Which method does not take into consideration `feature_importance` when adding/removing features? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra time? \n",
    "\n",
    "Breakout rooms in your project groups! \n",
    "\n",
    "Use this time to:\n",
    "\n",
    "- Meet with your team mates;\n",
    "- Think about a project - choose the data and business objective.\n",
    "- Propose a statistical objective to address this.\n",
    "- Also, elaborate on the statistical objective. What’s your plan for the analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We've Learned Today\n",
    "\n",
    "- How to construct a statistical question from a business objective. \n",
    "- What steps are important in building your analysis.\n",
    "- How to discover important features in your model. \n",
    "- the 2 different methods (RFE, Forward selection) to conduct feature selection on your model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}