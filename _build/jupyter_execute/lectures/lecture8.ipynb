{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 8 - Forming good ML questions from business objectives and Feature Selection\n",
    "\n",
    "*Hayley Boyce, Wednesday, May 12th, 2021*\n",
    "\n",
    "**Attribution:** \n",
    "\n",
    "- Tomas Beuzen - previous BAIT 509 Lecture 6\n",
    "- Varada Kolhatkar - Heavily guiding me with Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our libraries\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import sys\n",
    "sys.path.append('code/')\n",
    "from display_tree import display_tree\n",
    "from plot_classifier import plot_classifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing and pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "import scipy\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Keeping \n",
    "\n",
    "- Project instructions are out!\n",
    "- Time in class for groups! \n",
    " - Assignment 3 was released yesterday!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture Learning Objectives \n",
    "\n",
    "- In the context of supervised learning, form statistical questions  from business questions/objectives.\n",
    "- Understand the different forms your client may expect you to communicate results. \n",
    "- Explain the general concept of feature selection.\n",
    "- Discuss and compare different feature selection methods at a high level.\n",
    "- Use sklearn's implementation of recursive feature elimination (RFE).\n",
    "- Implement the forward search algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five Minute Recap/ Lightning Questions \n",
    "\n",
    "- What is the name of the function used to bound our values between 0 and 1\n",
    "- What is the name of the function that gives \"hard\" predictions?\n",
    "- What is the name of the function that gives \"soft\" predictions?\n",
    "- What is the hyperparameter we learned for Ridge and how does it affect the Fundamental Trade-off?\n",
    "- What is the hyperparameter we learned for Logistic Regression and how does it affect the Fundamental Trade-off?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some lingering questions\n",
    "\n",
    "- How can we start forming good business questions that can be addressed with Machine Learning? \n",
    "- How to select features for our models? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forming statistical questions to answer business objectives\n",
    "\n",
    "So far you've seen how to solve predictive problems using machine learning but today, we are going to look at the process involved in asking the questions and problems faced by organizations. \n",
    "\n",
    "\n",
    "Generally, there are four parts of a machine learning analysis. In order from high to low level:\n",
    "\n",
    "1. **The business question/objective**\n",
    "2. **The statistical question/objective**\n",
    "3. **The data and model**\n",
    "4. **The data product**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a machine learning analysis is about distilling from the highest level to the lowest level. As such, there are three distillations to keep in mind: 1-2, 2-3, and 3-4:\n",
    "\n",
    "- **1-2 is about asking the right questions**\n",
    "- **2-3 is about building a useful model**\n",
    "- **3-4 is about communicating the results**\n",
    "\n",
    "<center><img src=\"https://images.unsplash.com/photo-1511225317751-5c2d61819d58?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=2734&q=80\" width=\"50%\"></center>\n",
    "\n",
    "     \n",
    "     \n",
    "    \n",
    "Note that an analysis isn’t a linear progression through these “steps”; rather, the process is iterative. This is because none of the components are independent. Making progress on any of the three distillations gives you more information as to what the problem is.\n",
    "\n",
    "We’ll look at each of these distillations in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1 - 2) Asking useful statistical questions\n",
    "\n",
    "- Usually, a company is not served up a machine learning problem, complete with data and a description of the response and predictors.\n",
    "    - Companies don't exactly know what question is the right question but they do know what they want  to be accomplished. \n",
    "- Instead, they’re faced with some high-level objective/question that we’ll call the **business question/objective**.\n",
    "- This question needs refining to a **statistical question/objective** – one that is directly addressable by machine learning.\n",
    "\n",
    "Example: \n",
    "\n",
    "- My Capstone Case study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business objectives: examples\n",
    "- This [altexsoft blog post](https://www.altexsoft.com/blog/business/supervised-learning-use-cases-low-hanging-fruit-in-data-science-for-businesses/) is a great introduction to business use cases of data science/ML\n",
    "- Examples of business objectives (for which machine learning is a relevant approach)\n",
    "    - Reduce the amount of spam email received\n",
    "    - Early prediction of product failure\n",
    "    - Find undervalued mines\n",
    "    - Make a transit system more efficient\n",
    "    - Hire efficient staff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refining business objectives to statistical objectives\n",
    "\n",
    "<img src='https://media.giphy.com/media/bLcMOxvIak4iZieaut/giphy.gif' width=\"50%\"> \n",
    "\n",
    "- Statistical objectives need to be specific\n",
    "- Remember that supervised learning is about predicting a response $Y$ from predictors $X_1,…,X_p$\n",
    "- So we need to refine our business objectives to a statistical question(s) we can answer\n",
    "- This typically involves:\n",
    "    - Identifying the **response variable** ($Y$) that is most aligned with the business objective.\n",
    "    - Identifying the **data** (observations + features) that will be used for model development/testing.\n",
    "    - Note: part of this is the task of feature selection (a topic that we've covered briefly) – but, this is also largely, a human decision based on what we think is more informative, as well as a resource questions (what data is actually available?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical objectives: examples\n",
    "Statistical objectives corresponding to the above business objective examples might be:\n",
    "\n",
    "| Business Objective | Statistical Question |\n",
    "| :--- | :--- |\n",
    "| Reduce the amount of spam email received | <ul><li>$Y$ = classifying an email as spam/not spam <li> $X$ = words present in name and the body of email and other metadata (sender email, time, etc.) <li> Cases of spam will be gathered over time as employees identify emails as spam/not spam. The model can be improved as misclassifications are encountered.</ul>\n",
    "| Early prediction of product failure, (Kickstarter?) | <ul><li>$Y$ = classifying a product as faulty/not faulty <li> $X$ = Relevant features chosen by an expert <li> Data obtained from the test facility</ul>\n",
    "| Find undervalued mines | <ul><li>$Y$ = total volume of gold and silver at a site <li> $X$ =  concentrations of other minerals found in drill samples, geographic information, historical data, etc <li> Data obtained from mines where total volumes are already known</ul>\n",
    "| Make a transit system more efficient | <ul><li>$Y$ = predict the time it takes a bus to travel between set stops <li> $X$ = time of day/week/year, weather, etc. <li> Use data from company server tracking bus movements</ul>\n",
    "| Hire efficient staff | <ul><li>$Y$ = predict monthly sales <li> $X$ = a personality test, years of work experience, field of experience, etc. <li> Use data based on current employees</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical questions are not the full picture!\n",
    "- Almost always, the business objective is more complex than the statistical question.\n",
    "- By refining a business objective to a statistical one, we may lose part of the essence of the business objective.\n",
    "- It’s important to have a sense of the ways in which your statistical objective falls short, and the ways in which it’s on the mark, so that you keep an idea of the big picture.\n",
    "- For example, predicting whether a new staff hire will be efficient or not is a useful statistical question, but doesn't consider why a company might be attracting certain applicants, how long staff will remain, how staff work together, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical objectives unrelated to supervised learning\n",
    "\n",
    "- We are only focussing on statistical questions related to supervised learning and prediction in this course\n",
    "- But there are other kinds of questions you can ask too\n",
    "- Consider the following example\n",
    "\n",
    "**Business objective**: To gain insight into the productivity of two branches of a company.\n",
    "\n",
    "Examples of statistical questions:\n",
    "\n",
    "- **Hypothesis testing**: Is the mean number of sick days per employee different between two branches of a company?\n",
    "    - Supervised learning doesn’t cover testing for differences.\n",
    "- **Unsupervised learning**: What is the mean sentiment of the internal discussion channels from both branches?\n",
    "    - There is no data of feature + response here, as required by supervised learning (by definition).\n",
    "- **Statistical inference**: Estimate the mean difference in monthly revenue generated by both branches, along with how certain you are with that estimate.\n",
    "    - Supervised learning typically isn’t concerned about communicating how certain your estimate is. (BUT it should be and changes are being made to change this!)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2 - 3) Building a useful model\n",
    "- This is really the main focus of this course, This is the meat/beyond meat patty in your burger! \n",
    "- This involves using ML algorithms (kNN, loess, decision trees, etc) to build a predictive model from data\n",
    "- You always should include a baseline model to assess how well the models you build are giving you some leg up. \n",
    "- A simple model like logistic regression does as well as a more complex approach! At the very least, they can help guide you on what more complex approaches to take next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3 - 4) Communicating results\n",
    "\n",
    "- So you've distilled your business objectives to a statistical question.\n",
    "- You've developed a model to answer the statistical question.\n",
    "- Now your model needs to be delivered and used by others (or your future self)!\n",
    "- The final delivery is often called \"the data product\" because it may consist of a variety of things:\n",
    "    - a report\n",
    "    - a presentation\n",
    "    - an app\n",
    "    - a dashboard\n",
    "    - a software package/pipeline\n",
    "- Sometimes the client requests a specific data product -> But note that their suggestion might not always be the best option. \n",
    "    - Perhaps they request a report and presentation communicating your findings, when a more appropriate product also includes an interactive app that allows them to explore your findings for themselves.\n",
    "- Either way, the key here is communication. Two import challenges (relevant to your final project):\n",
    "    - Using appropriate language: there is a lot of jargon in ML, the key is to talk more about the output and the general idea of your model(s), but not machine learning or statistical jargon.\n",
    "    - Communication with visual design: this is about choosing what visuals are the most effective for communicating. -> Plug: https://viz-learn.mds.ubc.ca/en/\n",
    "- Usually, the first step is to set up a framework for your data product. For a report, this means outlining what you intend to write about, and where.\n",
    "- Showing it to your client is useful as a sanity check to see that you’re about to produce something that the client currently sees as being potentially useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice \n",
    "\n",
    "1. What question is usually more complex?\n",
    "2. What model needs to be made for all problems?\n",
    "3. In supervised learning, once we have our business objective, part of our statistical question is identifying what?\n",
    "\n",
    "**True or False:**\n",
    "\n",
    "4. When writing your reports, it's important to consider who is reading it.     \n",
    "5. Sometimes you may need to dig a little to figure out exactly what the client wants.      \n",
    "6. In supervised learning, we should take into consideration the uncertainty of our models.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection \n",
    "\n",
    "### Motivation \n",
    "\n",
    "Remember the curse of dimensionality? \n",
    "\n",
    "<img src='imgs/curse.png' width=\"50%\"> \n",
    "\n",
    "We spoke about this briefly when we discussed $k$-nn and how when we add many different dimensions (features) it can confuse the model with any irrelevant features and the model can disintegrate into predictions no better than random guessing.\n",
    "\n",
    "Reasons like this are why we need to be careful about which features we include.\n",
    "\n",
    "**Feature selection** can be described as *finding the features (columns) $X$ that are important for predicting $y$ and removing the features that aren’t.*\n",
    "\n",
    "Feature selection can be aided using domain knowledge and manually however we can also use tools that help us either tell us:\n",
    "\n",
    "- which features are most important to a model \n",
    "- or that can select a number of features that will result with the optimal validation score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-76.4813</td>\n",
       "      <td>44.2307</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-81.2496</td>\n",
       "      <td>42.9837</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-66.0580</td>\n",
       "      <td>45.2788</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-73.2533</td>\n",
       "      <td>45.3057</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-67.9245</td>\n",
       "      <td>47.1652</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     longitude  latitude country\n",
       "160   -76.4813   44.2307  Canada\n",
       "127   -81.2496   42.9837  Canada\n",
       "169   -66.0580   45.2788  Canada\n",
       "188   -73.2533   45.3057  Canada\n",
       "187   -67.9245   47.1652  Canada"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df = pd.read_csv(\"data/canada_usa_cities.csv\")\n",
    "train_df, test_df = train_test_split(cities_df, test_size=0.2, random_state=123)\n",
    "X_train, y_train = train_df.drop(columns=[\"country\"], axis=1), train_df[\"country\"]\n",
    "X_test, y_test = test_df.drop(columns=[\"country\"], axis=1), test_df[\"country\"]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance \n",
    "\n",
    "Remember our Decision Tree models? Well, we can find out which features are most important in a model using an attribute called `feature_importances_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23330056, 0.76669944])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(max_depth=5)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that most of the importance is on the column `latitude`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we graph this, the root of the decision tree will usually reflect the top feature. Just like we can see here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"539pt\" height=\"414pt\"\n",
       " viewBox=\"0.00 0.00 538.50 414.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 410)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-410 534.5,-410 534.5,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"282.5,-406 177.5,-406 177.5,-368 282.5,-368 282.5,-406\"/>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-390.8\" font-family=\"Times,serif\" font-size=\"14.00\">latitude &lt;= 42.9</text>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-375.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"221.5,-332 102.5,-332 102.5,-294 221.5,-294 221.5,-332\"/>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-316.8\" font-family=\"Times,serif\" font-size=\"14.00\">latitude &lt;= 42.096</text>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-301.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = USA</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M212.84,-367.83C204.85,-359.37 195.2,-349.15 186.46,-339.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"188.8,-337.28 179.39,-332.41 183.71,-342.09 188.8,-337.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"178.68\" y=\"-353.7\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"358.5,-332 239.5,-332 239.5,-294 358.5,-294 358.5,-332\"/>\n",
       "<text text-anchor=\"middle\" x=\"299\" y=\"-316.8\" font-family=\"Times,serif\" font-size=\"14.00\">latitude &lt;= 55.958</text>\n",
       "<text text-anchor=\"middle\" x=\"299\" y=\"-301.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>0&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M247.41,-367.83C255.52,-359.37 265.32,-349.15 274.18,-339.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"276.96,-342.05 281.35,-332.41 271.91,-337.21 276.96,-342.05\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.89\" y=\"-353.71\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"86,-257 0,-257 0,-221 86,-221 86,-257\"/>\n",
       "<text text-anchor=\"middle\" x=\"43\" y=\"-235.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = USA</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.97,-293.83C116.29,-284.34 96.94,-272.64 80.31,-262.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"81.75,-259.35 71.38,-257.17 78.12,-265.34 81.75,-259.35\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"223.5,-258 104.5,-258 104.5,-220 223.5,-220 223.5,-258\"/>\n",
       "<text text-anchor=\"middle\" x=\"164\" y=\"-242.8\" font-family=\"Times,serif\" font-size=\"14.00\">latitude &lt;= 42.324</text>\n",
       "<text text-anchor=\"middle\" x=\"164\" y=\"-227.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = USA</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M162.5,-293.83C162.72,-286.13 162.97,-276.97 163.21,-268.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"166.71,-268.51 163.49,-258.41 159.71,-268.31 166.71,-268.51\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"103.5,-183 4.5,-183 4.5,-147 103.5,-147 103.5,-183\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-161.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M136.24,-219.83C121.88,-210.43 104.2,-198.86 88.91,-188.85\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.52,-185.72 80.23,-183.17 86.68,-191.58 90.52,-185.72\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"208,-183 122,-183 122,-147 208,-147 208,-183\"/>\n",
       "<text text-anchor=\"middle\" x=\"165\" y=\"-161.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = USA</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M164.25,-219.83C164.36,-211.89 164.49,-202.41 164.62,-193.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"168.12,-193.47 164.76,-183.42 161.12,-193.37 168.12,-193.47\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"350.5,-258 245.5,-258 245.5,-220 350.5,-220 350.5,-258\"/>\n",
       "<text text-anchor=\"middle\" x=\"298\" y=\"-242.8\" font-family=\"Times,serif\" font-size=\"14.00\">latitude &lt;= 49.0</text>\n",
       "<text text-anchor=\"middle\" x=\"298\" y=\"-227.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M298.75,-293.83C298.64,-286.13 298.51,-276.97 298.39,-268.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"301.89,-268.36 298.26,-258.41 294.9,-268.46 301.89,-268.36\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"455,-257 369,-257 369,-221 455,-221 455,-257\"/>\n",
       "<text text-anchor=\"middle\" x=\"412\" y=\"-235.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = USA</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>6&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M327.51,-293.83C342.41,-284.34 360.78,-272.64 376.58,-262.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"378.5,-265.5 385.05,-257.17 374.74,-259.59 378.5,-265.5\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"364,-184 230,-184 230,-146 364,-146 364,-184\"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-168.8\" font-family=\"Times,serif\" font-size=\"14.00\">longitude &lt;= &#45;94.582</text>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-153.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M297.75,-219.83C297.64,-212.13 297.51,-202.97 297.39,-194.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"300.89,-194.36 297.26,-184.41 293.9,-194.46 300.89,-194.36\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"481.5,-183 382.5,-183 382.5,-147 481.5,-147 481.5,-183\"/>\n",
       "<text text-anchor=\"middle\" x=\"432\" y=\"-161.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>7&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M331.81,-219.83C349.8,-210.17 372.06,-198.2 391.03,-188.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"392.89,-190.99 400.04,-183.17 389.58,-184.82 392.89,-190.99\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"290,-110 150,-110 150,-72 290,-72 290,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"220\" y=\"-94.8\" font-family=\"Times,serif\" font-size=\"14.00\">longitude &lt;= &#45;123.222</text>\n",
       "<text text-anchor=\"middle\" x=\"220\" y=\"-79.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = USA</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M277.57,-145.83C268.27,-137.13 256.98,-126.58 246.87,-117.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"249.12,-114.44 239.42,-110.16 244.34,-119.55 249.12,-114.44\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"442,-110 308,-110 308,-72 442,-72 442,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-94.8\" font-family=\"Times,serif\" font-size=\"14.00\">longitude &lt;= &#45;69.246</text>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-79.8\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>8&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M316.68,-145.83C326.11,-137.13 337.54,-126.58 347.78,-117.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"350.35,-119.52 355.32,-110.16 345.6,-114.37 350.35,-119.52\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"169.5,-36 70.5,-36 70.5,0 169.5,0 169.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"120\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M194.51,-71.9C181.66,-62.78 165.96,-51.63 152.28,-41.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.25,-39.02 144.07,-36.09 150.2,-44.73 154.25,-39.02\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"274,-36 188,-36 188,0 274,0 274,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"231\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = USA</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222.83,-71.72C224.05,-63.89 225.49,-54.59 226.82,-45.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"230.29,-46.42 228.37,-36 223.38,-45.35 230.29,-46.42\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"413.5,-36 314.5,-36 314.5,0 413.5,0 413.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M372.17,-71.72C370.95,-63.89 369.51,-54.59 368.18,-45.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"371.62,-45.35 366.63,-36 364.71,-46.42 371.62,-45.35\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"530.5,-36 431.5,-36 431.5,0 530.5,0 530.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"481\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">class = Canada</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M402.02,-71.9C415.64,-62.78 432.29,-51.63 446.78,-41.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"449.13,-44.56 455.49,-36.09 445.23,-38.75 449.13,-44.56\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1054c6cd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "filenames": {
       "image/svg+xml": "/Users/icics-user/Documents/BAIT509/BAIT509/_build/jupyter_execute/lectures/lecture8_24_0.svg"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('code/')\n",
    "from display_tree import display_tree\n",
    "display_tree(X_train.columns, dt_model, \"imgs/decision_tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New housing data \n",
    "\n",
    "I know at this point you are probably annoyed and bored of housing data, but good, interesting open-source data is hard to come by. For this example, I really want to show you an example with LOTS of features. \n",
    "\n",
    "Here is (yet another) housing dataset we acquired from [this GitHub repo](https://github.com/melindaleung/Ames-Iowa-Housing-Dataset), originally created by Dean De Cock. \n",
    "*(We are using the raw data so we do not need to store it and import it simply from the url.)*\n",
    "\n",
    "\n",
    "**Attribution:** \n",
    "\n",
    "The Ames Housing dataset was compiled by Dean De Cock for use in data science education. \n",
    "\n",
    "His publication can be found [here](http://jse.amstat.org/v19n3/decock.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                      \n",
       "1             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "2             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "3             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "4             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "5             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
       "Id                                    ...                                      \n",
       "1            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "2            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
       "3            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "4            Lvl    AllPub    Corner  ...        0    NaN    NaN         NaN   \n",
       "5            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
       "...          ...       ...       ...  ...      ...    ...    ...         ...   \n",
       "1456         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "1457         Lvl    AllPub    Inside  ...        0    NaN  MnPrv         NaN   \n",
       "1458         Lvl    AllPub    Inside  ...        0    NaN  GdPrv        Shed   \n",
       "1459         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "1460         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "\n",
       "     MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "Id                                                               \n",
       "1          0      2    2008        WD         Normal     208500  \n",
       "2          0      5    2007        WD         Normal     181500  \n",
       "3          0      9    2008        WD         Normal     223500  \n",
       "4          0      2    2006        WD       Abnormal     140000  \n",
       "5          0     12    2008        WD         Normal     250000  \n",
       "...      ...    ...     ...       ...            ...        ...  \n",
       "1456       0      8    2007        WD         Normal     175000  \n",
       "1457       0      2    2010        WD         Normal     210000  \n",
       "1458    2500      5    2010        WD         Normal     266500  \n",
       "1459       0      4    2010        WD         Normal     142125  \n",
       "1460       0      6    2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 80 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ames_df = pd.read_csv('https://raw.githubusercontent.com/melindaleung/Ames-Iowa-Housing-Dataset/master/data/ames%20iowa%20housing.csv', index_col=0)\n",
    "ames_df.loc[ames_df['SaleCondition'] != 'Normal', 'SaleCondition'] = 'Abnormal'\n",
    "ames_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1460 entries, 1 to 1460\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1460 non-null   int64  \n",
      " 1   MSZoning       1460 non-null   object \n",
      " 2   LotFrontage    1201 non-null   float64\n",
      " 3   LotArea        1460 non-null   int64  \n",
      " 4   Street         1460 non-null   object \n",
      " 5   Alley          91 non-null     object \n",
      " 6   LotShape       1460 non-null   object \n",
      " 7   LandContour    1460 non-null   object \n",
      " 8   Utilities      1460 non-null   object \n",
      " 9   LotConfig      1460 non-null   object \n",
      " 10  LandSlope      1460 non-null   object \n",
      " 11  Neighborhood   1460 non-null   object \n",
      " 12  Condition1     1460 non-null   object \n",
      " 13  Condition2     1460 non-null   object \n",
      " 14  BldgType       1460 non-null   object \n",
      " 15  HouseStyle     1460 non-null   object \n",
      " 16  OverallQual    1460 non-null   int64  \n",
      " 17  OverallCond    1460 non-null   int64  \n",
      " 18  YearBuilt      1460 non-null   int64  \n",
      " 19  YearRemodAdd   1460 non-null   int64  \n",
      " 20  RoofStyle      1460 non-null   object \n",
      " 21  RoofMatl       1460 non-null   object \n",
      " 22  Exterior1st    1460 non-null   object \n",
      " 23  Exterior2nd    1460 non-null   object \n",
      " 24  MasVnrType     1452 non-null   object \n",
      " 25  MasVnrArea     1452 non-null   float64\n",
      " 26  ExterQual      1460 non-null   object \n",
      " 27  ExterCond      1460 non-null   object \n",
      " 28  Foundation     1460 non-null   object \n",
      " 29  BsmtQual       1423 non-null   object \n",
      " 30  BsmtCond       1423 non-null   object \n",
      " 31  BsmtExposure   1422 non-null   object \n",
      " 32  BsmtFinType1   1423 non-null   object \n",
      " 33  BsmtFinSF1     1460 non-null   int64  \n",
      " 34  BsmtFinType2   1422 non-null   object \n",
      " 35  BsmtFinSF2     1460 non-null   int64  \n",
      " 36  BsmtUnfSF      1460 non-null   int64  \n",
      " 37  TotalBsmtSF    1460 non-null   int64  \n",
      " 38  Heating        1460 non-null   object \n",
      " 39  HeatingQC      1460 non-null   object \n",
      " 40  CentralAir     1460 non-null   object \n",
      " 41  Electrical     1459 non-null   object \n",
      " 42  1stFlrSF       1460 non-null   int64  \n",
      " 43  2ndFlrSF       1460 non-null   int64  \n",
      " 44  LowQualFinSF   1460 non-null   int64  \n",
      " 45  GrLivArea      1460 non-null   int64  \n",
      " 46  BsmtFullBath   1460 non-null   int64  \n",
      " 47  BsmtHalfBath   1460 non-null   int64  \n",
      " 48  FullBath       1460 non-null   int64  \n",
      " 49  HalfBath       1460 non-null   int64  \n",
      " 50  BedroomAbvGr   1460 non-null   int64  \n",
      " 51  KitchenAbvGr   1460 non-null   int64  \n",
      " 52  KitchenQual    1460 non-null   object \n",
      " 53  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 54  Functional     1460 non-null   object \n",
      " 55  Fireplaces     1460 non-null   int64  \n",
      " 56  FireplaceQu    770 non-null    object \n",
      " 57  GarageType     1379 non-null   object \n",
      " 58  GarageYrBlt    1379 non-null   float64\n",
      " 59  GarageFinish   1379 non-null   object \n",
      " 60  GarageCars     1460 non-null   int64  \n",
      " 61  GarageArea     1460 non-null   int64  \n",
      " 62  GarageQual     1379 non-null   object \n",
      " 63  GarageCond     1379 non-null   object \n",
      " 64  PavedDrive     1460 non-null   object \n",
      " 65  WoodDeckSF     1460 non-null   int64  \n",
      " 66  OpenPorchSF    1460 non-null   int64  \n",
      " 67  EnclosedPorch  1460 non-null   int64  \n",
      " 68  3SsnPorch      1460 non-null   int64  \n",
      " 69  ScreenPorch    1460 non-null   int64  \n",
      " 70  PoolArea       1460 non-null   int64  \n",
      " 71  PoolQC         7 non-null      object \n",
      " 72  Fence          281 non-null    object \n",
      " 73  MiscFeature    54 non-null     object \n",
      " 74  MiscVal        1460 non-null   int64  \n",
      " 75  MoSold         1460 non-null   int64  \n",
      " 76  YrSold         1460 non-null   int64  \n",
      " 77  SaleType       1460 non-null   object \n",
      " 78  SaleCondition  1460 non-null   object \n",
      " 79  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 923.9+ KB\n"
     ]
    }
   ],
   "source": [
    "ames_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use `.info()` to identify our categorical and numeric features. I split my features and identify my target. \n",
    "\n",
    "The target variable for this question is `SaleCondition` and we are doing classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(ames_df, test_size=0.2, random_state=77)\n",
    "\n",
    "X_train = train_df.drop(columns=['SaleCondition', 'PoolQC', 'MiscFeature', 'Alley'])\n",
    "X_test =  test_df.drop(columns=['SaleCondition', 'PoolQC', 'MiscFeature', 'Alley'])\n",
    "\n",
    "y_train = train_df['SaleCondition']\n",
    "y_test = test_df['SaleCondition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note, you should be looking at these individually but I'm being a little lazy here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X_train.select_dtypes('number').columns.to_list()\n",
    "categorical_features = X_train.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our numeric features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSSubClass',\n",
       " 'LotFrontage',\n",
       " 'LotArea',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'MasVnrArea',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtFinSF2',\n",
       " 'BsmtUnfSF',\n",
       " 'TotalBsmtSF',\n",
       " '1stFlrSF',\n",
       " '2ndFlrSF',\n",
       " 'LowQualFinSF',\n",
       " 'GrLivArea',\n",
       " 'BsmtFullBath',\n",
       " 'BsmtHalfBath',\n",
       " 'FullBath',\n",
       " 'HalfBath',\n",
       " 'BedroomAbvGr',\n",
       " 'KitchenAbvGr',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'GarageYrBlt',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'WoodDeckSF',\n",
       " 'OpenPorchSF',\n",
       " 'EnclosedPorch',\n",
       " '3SsnPorch',\n",
       " 'ScreenPorch',\n",
       " 'PoolArea',\n",
       " 'MiscVal',\n",
       " 'MoSold',\n",
       " 'YrSold',\n",
       " 'SalePrice']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are our categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'Fence',\n",
       " 'SaleType']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to make our pipelines and column transformer. \n",
    "\n",
    "We can also cross-validate, but here my main goal is to show you how to get our feature importances from our pipeline! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.099587\n",
       "score_time     0.010683\n",
       "test_score     0.900704\n",
       "train_score    0.937073\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_pipe = make_pipeline(SimpleImputer(strategy='median'),\n",
    "                            StandardScaler())\n",
    "categoric_pipe = make_pipeline(SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "                            OneHotEncoder(dtype=int, handle_unknown=\"ignore\"))\n",
    "\n",
    "preprocessor = make_column_transformer((numeric_pipe, numeric_features),\n",
    "                                       (categoric_pipe, categorical_features))\n",
    "\n",
    "main_pipe = make_pipeline(preprocessor, LogisticRegression(max_iter=1000))\n",
    "\n",
    "\n",
    "scores = cross_validate(main_pipe, X_train, y_train, return_train_score=True)\n",
    "\n",
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we fit our pipeline outside of `cross_validate()` we can use `coef_` to get our features that contribute to our predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18958839e-01,  2.80437565e-02,  2.49130507e-01,\n",
       "        -1.40577328e-01,  2.31798834e-01,  2.65544331e-01,\n",
       "         8.50348998e-02,  6.52906677e-02, -3.13882034e-01,\n",
       "        -7.97876987e-02,  1.05264740e-01, -2.45667334e-01,\n",
       "        -2.51739997e-01,  1.04131789e-01,  8.63238306e-02,\n",
       "        -9.51492234e-02,  1.72613332e-01, -1.84019116e-01,\n",
       "         1.70443856e-01, -5.28290734e-02,  4.55105832e-02,\n",
       "        -5.80079522e-02, -2.77296489e-01,  6.36542212e-02,\n",
       "         2.58992646e-01, -2.51809696e-01,  2.73972987e-01,\n",
       "         1.16505219e-01, -3.43890387e-02,  1.50307516e-01,\n",
       "         5.76032866e-03, -1.22385918e-01, -2.22702119e-01,\n",
       "         3.89040317e-01,  9.84750685e-02,  3.18748625e-01,\n",
       "         8.07870515e-01, -5.43912484e-01, -2.88791745e-01,\n",
       "        -3.89542925e-01,  5.73547320e-01,  6.48679034e-01,\n",
       "         2.11951560e-01, -2.11972360e-01,  3.63746362e-01,\n",
       "         6.26228554e-02, -3.86788012e-01, -3.96020057e-02,\n",
       "        -2.83569179e-01, -2.52294113e-01,  1.61988878e-01,\n",
       "         3.73853614e-01, -2.08000925e-05, -3.55140696e-01,\n",
       "        -3.70345439e-02,  2.24427654e-01,  8.95856444e-02,\n",
       "         7.81411419e-02,  7.50966736e-01,  1.87977662e-01,\n",
       "        -9.38965198e-01,  6.31309534e-01,  1.56054959e-01,\n",
       "        -1.05636659e+00,  1.51781722e-01, -6.47077610e-01,\n",
       "         9.39778122e-01, -6.74202514e-01,  5.30054735e-01,\n",
       "        -2.60443488e-01,  2.75200135e-01,  1.66192064e-01,\n",
       "         8.30646952e-01, -1.26519531e-01, -1.95030237e-01,\n",
       "        -4.78993513e-01, -9.92116098e-01,  4.26070374e-01,\n",
       "        -2.72630043e-01,  2.61803275e-01,  6.55104632e-01,\n",
       "        -4.54961908e-01,  1.06256161e-01, -1.52522176e-01,\n",
       "        -5.43387027e-02,  2.34928944e-01, -1.00317824e-01,\n",
       "        -4.67378338e-01, -2.41550501e-01,  2.13982659e-01,\n",
       "         3.39287808e-01, -3.19643886e-01,  2.08194481e-01,\n",
       "         3.67404801e-01, -5.54245239e-01,  1.01170535e-01,\n",
       "         2.32518679e-01,  1.43186661e-03, -1.44430886e-01,\n",
       "        -2.01365849e-05,  2.33119361e-01,  1.30435020e-01,\n",
       "        -3.76844639e-01,  5.35351565e-01,  1.44394638e-01,\n",
       "        -3.90428100e-01,  8.75057365e-02, -2.00538899e-01,\n",
       "         4.12724564e-01, -2.53132774e-01, -1.74934058e-01,\n",
       "         9.30653024e-01,  2.87215952e-01, -1.04772393e+00,\n",
       "         4.57153212e-02, -6.74098519e-01, -2.18557392e-01,\n",
       "         1.62030340e-01,  3.60068688e-01,  1.45392011e-01,\n",
       "         2.25144072e-01,  5.44271071e-05,  1.82967951e-01,\n",
       "         7.89862218e-02,  4.86755439e-02, -5.68767168e-01,\n",
       "         1.13392139e-01,  1.44670085e-01, -3.67086430e-01,\n",
       "         8.44859596e-02, -3.67058918e-01,  2.68303184e-01,\n",
       "         1.34567901e-01,  2.31434171e-01,  1.12426593e-01,\n",
       "         2.24874308e-01,  1.17863260e-02,  3.43144548e-01,\n",
       "        -6.70356418e-01,  4.77501814e-01, -4.37524305e-01,\n",
       "        -4.47288030e-01,  4.00768496e-01,  2.11840761e-01,\n",
       "         1.74053880e-01, -2.51820740e-01,  1.11264608e+00,\n",
       "         1.34567901e-01,  2.50389659e-01,  2.77777003e-03,\n",
       "        -8.58230453e-01, -7.20476021e-03, -3.89664900e-01,\n",
       "        -8.69852816e-01, -4.34668652e-01, -6.76196375e-02,\n",
       "         9.54086294e-01,  3.86788170e-02, -4.97420517e-01,\n",
       "         4.61282162e-01,  4.76509455e-01, -6.69151081e-02,\n",
       "        -3.73476792e-01, -2.13005004e-02, -1.17026315e-01,\n",
       "         5.23385140e-02,  8.59675011e-02,  7.92024071e-02,\n",
       "        -8.69455333e-03, -1.31723460e-01,  1.96342696e-01,\n",
       "        -1.35147889e-01, -1.88544558e-01,  1.90352188e-01,\n",
       "        -1.68708155e-01,  4.38281040e-01, -3.12345756e-01,\n",
       "         4.09444401e-02,  3.15034172e-02,  1.49814155e-02,\n",
       "        -1.00368837e-02,  6.94173890e-02, -1.05886138e-01,\n",
       "         5.19940295e-01, -2.81921366e-01, -2.56031695e-01,\n",
       "         1.23878103e-01, -1.05886138e-01,  7.13518816e-02,\n",
       "         7.41418709e-02, -2.50009366e-01,  1.89350904e-01,\n",
       "        -8.48560912e-02, -6.92821419e-02,  3.53292929e-01,\n",
       "        -1.66739663e-02,  2.40792039e-01,  2.15239176e-01,\n",
       "        -6.17502698e-01, -1.05886138e-01,  2.83580448e-01,\n",
       "        -1.48796728e-01,  1.25557244e-01, -2.62424998e-01,\n",
       "         1.89986156e-01, -1.08691711e-01, -7.92312121e-02,\n",
       "         3.06131849e-02, -4.94729734e-01,  5.27850443e-01,\n",
       "        -1.71411787e-01,  4.81233967e-02,  5.95336960e-02,\n",
       "        -4.54720774e-01,  2.86731562e-01,  7.51870519e-01,\n",
       "         1.25311067e-02, -5.96433214e-01,  1.23862962e-01,\n",
       "        -1.23883762e-01,  2.85546173e-01,  4.03609395e-01,\n",
       "        -4.59112126e-01, -4.23918118e-01,  1.93853877e-01,\n",
       "        -9.76188829e-01,  5.88611295e-01,  6.30855332e-02,\n",
       "         3.24471201e-01,  4.10383570e-01, -1.75731458e-01,\n",
       "        -3.24507708e-01,  5.90105708e-01,  4.26751764e-01,\n",
       "        -6.51255727e-01, -2.75766950e-01, -3.39802934e-01,\n",
       "         4.13633738e-01,  1.93353027e-02,  5.31959397e-01,\n",
       "        -6.41596222e-02, -5.60986681e-01,  7.45320060e-02,\n",
       "         5.26191977e-01, -5.91524719e-01, -2.69964975e-01,\n",
       "        -1.22415812e-01,  4.77544014e-01, -9.43832913e-02,\n",
       "        -2.13879058e-01,  1.31840293e-01,  1.76401255e-01,\n",
       "        -9.43832913e-02,  2.86789640e-02,  2.12638163e-01,\n",
       "        -6.62487740e-03, -3.12318528e-01,  1.71988770e-01,\n",
       "        -9.43832913e-02,  2.86789640e-02,  5.62313667e-01,\n",
       "        -5.19994269e-01,  1.32379688e-01, -1.09015558e-01,\n",
       "        -9.43832913e-02,  5.17278098e-02,  2.54400540e-01,\n",
       "        -3.06149150e-01,  2.33419989e-01, -1.11614579e-01,\n",
       "        -2.44520667e-01, -2.24168880e-01,  3.46863338e-01,\n",
       "         1.44769226e-01, -3.33369381e-01,  2.55671163e-01,\n",
       "         4.35447588e-01,  4.81352399e-01,  9.43771644e-01,\n",
       "        -3.84055151e+00, -6.86552476e-01,  2.59944055e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_pipe.fit(X_train, y_train)\n",
    "feats_coef = main_pipe.named_steps['logisticregression'].coef_\n",
    "feats_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here, is we don't know which value corresponds to which feature! \n",
    "\n",
    "Let's first take a look at how many features we have now after preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 282)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_coef.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 282 is refering to the number of features after preprocessing!\n",
    "\n",
    "Let's get the feature names after preprocessing.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain the categorical features and combine them with the  numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = preprocessor.named_transformers_['pipeline-2'].named_steps[\n",
    "    'onehotencoder'].get_feature_names(categorical_features).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feat_names = numeric_features + cat_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that we have the same number of feature names as we do coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_feat_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get them into a dataframe now and sort them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>feature_coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>SaleType_New</td>\n",
       "      <td>-3.84055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>SaleType_WD</td>\n",
       "      <td>2.59944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Exterior2nd_BrkFace</td>\n",
       "      <td>1.11265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Neighborhood_BrDale</td>\n",
       "      <td>-1.05637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>HouseStyle_SFoyer</td>\n",
       "      <td>-1.04772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Exterior2nd_HdBoard</td>\n",
       "      <td>0.00277777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Condition2_PosA</td>\n",
       "      <td>0.00143187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>RoofMatl_ClyTile</td>\n",
       "      <td>5.44271e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Utilities_AllPub</td>\n",
       "      <td>-2.08001e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Condition2_RRAe</td>\n",
       "      <td>-2.01366e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature feature_coefs\n",
       "279         SaleType_New      -3.84055\n",
       "281          SaleType_WD       2.59944\n",
       "146  Exterior2nd_BrkFace       1.11265\n",
       "63   Neighborhood_BrDale      -1.05637\n",
       "113    HouseStyle_SFoyer      -1.04772\n",
       "..                   ...           ...\n",
       "149  Exterior2nd_HdBoard    0.00277777\n",
       "97       Condition2_PosA    0.00143187\n",
       "121     RoofMatl_ClyTile   5.44271e-05\n",
       "52      Utilities_AllPub  -2.08001e-05\n",
       "99       Condition2_RRAe  -2.01366e-05\n",
       "\n",
       "[282 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.DataFrame(data = [all_feat_names,\n",
    "                                feats_coef.flatten()]).T.rename(columns={0:'feature', 1:'feature_coefs'})\n",
    "features_df.sort_values('feature_coefs',key= abs, ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `SaleType_New` is the most important feature in our model.\n",
    "\n",
    "From here we can decide to manually remove some of the columns that are not taken into consideration as much.... or we can instead use a tool to help us! \n",
    "\n",
    "Enter - **Recursive feature elimination**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive feature elimination - RFE \n",
    "\n",
    "We can use feature importances to eliminate unimportant features.\n",
    "\n",
    "The basic idea with recursive feature elimination is we: \n",
    "1. We decide $k$ - the number of features to select.\n",
    "2. Assign importances to features, e.g. by fitting a model and looking at coef_ or feature_importances_.\n",
    "3. Remove the least important feature.\n",
    "4. Repeat steps 2-3 until only $k$ features are remaining.\n",
    "\n",
    "**Note that this is not the same as just removing all the less important features in one shot!**\n",
    "\n",
    "Let's take a look at how we can do this. \n",
    "\n",
    "First we import `RFE` from `sklearn.feature_selection`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of simply using `DecisionTreeClassifier`, we can wrap it around the `RFE` function and specify how many features we want with `n_features_to_select`. \n",
    "\n",
    "Here I'm capping the number of features to 30 (an arbitrary number I picked).\n",
    "\n",
    "This is going to take about 1-2 minutes to run because now, it's recursively removing 1 feature at a time and cross-validating on the final result.\n",
    "\n",
    "\n",
    "<img src='imgs/waiting2.png' width=\"50%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.512086</td>\n",
       "      <td>0.010259</td>\n",
       "      <td>0.901709</td>\n",
       "      <td>0.918630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.754893</td>\n",
       "      <td>0.010093</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.926124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.472141</td>\n",
       "      <td>0.011094</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.919700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.415113</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>0.922747</td>\n",
       "      <td>0.914439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.015225</td>\n",
       "      <td>0.010336</td>\n",
       "      <td>0.901288</td>\n",
       "      <td>0.920856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_score  train_score\n",
       "0   9.512086    0.010259    0.901709     0.918630\n",
       "1  10.754893    0.010093    0.880342     0.926124\n",
       "2  10.472141    0.011094    0.910256     0.919700\n",
       "3  10.415113    0.010304    0.922747     0.914439\n",
       "4  10.015225    0.010336    0.901288     0.920856"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_pipe = make_pipeline(preprocessor, RFE(LogisticRegression(max_iter=1000), \n",
    "                                            n_features_to_select=30))\n",
    "\n",
    "scores = cross_validate(main_pipe, X_train, y_train, return_train_score=True)\n",
    "\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       10.233892\n",
       "score_time      0.010417\n",
       "test_score      0.903268\n",
       "train_score     0.919950\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this mean validation score compared to when the model was using all the features, we can see it increased a tiny bit! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now our next question is how do we set $k$? How do we know how many features is the optimal amount... Well, you guessed it! There is a tool for that too! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFECV\n",
    "\n",
    "You can find the optimal number of features using cross-validation with `RFECV` where the optimal $k$ value is selected based on the highest validation score. \n",
    "\n",
    "You would definitely not want to use the training score! - Why?\n",
    " > Because with training score the more features you add the higher the score, this isn't the case with validation score. \n",
    " \n",
    "We can import `RFECV` from `sklearn.feature_selection` like we did for `RFE`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of `RFE` now we simply use `RFECV` in our pipeline and we do not need to specify the argument `n_features_to_select` like we did with `RFE` since $k$ is selected based on the highest validation score. \n",
    "\n",
    "(*This is also going to take a couple of minutes*)\n",
    "\n",
    "<img src='imgs/waiting1.png' width=\"50%\"> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipe = make_pipeline(preprocessor, RFECV(LogisticRegression(max_iter=1000), cv=5))\n",
    "\n",
    "scores = cross_validate(main_pipe, X_train, y_train, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have ~91% for our validation score! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       58.883550\n",
       "score_time      0.011878\n",
       "test_score      0.907546\n",
       "train_score     0.910961\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False  True False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      "  True False False  True False False  True  True False False False False\n",
      "  True False False False False  True False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False  True False  True False False False False\n",
      " False False False False False  True False False  True False False False\n",
      " False False False False False False  True False False  True False False\n",
      " False False  True False False False  True False False  True False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False  True False False False False False  True\n",
      " False False False False False False False  True False  True False False\n",
      " False False False False  True  True False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "main_pipe.fit(X_train,y_train)\n",
    "print(main_pipe.named_steps[\"rfecv\"].support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features selected by RFE:  36\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of features selected by RFE: \",\n",
    "      main_pipe.named_steps[\"rfecv\"].n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MSZoning_C (all)', 'MSZoning_RH', 'LandSlope_Gtl',\n",
       "       'LandSlope_Sev', 'Neighborhood_BrDale', 'Neighborhood_CollgCr',\n",
       "       'Neighborhood_Crawfor', 'Neighborhood_Mitchel',\n",
       "       'Neighborhood_NridgHt', 'Condition2_Artery', 'HouseStyle_2.5Unf',\n",
       "       'HouseStyle_SFoyer', 'RoofStyle_Flat', 'RoofMatl_Tar&Grv',\n",
       "       'Exterior1st_AsbShng', 'Exterior1st_Stone', 'Exterior1st_Wd Sdng',\n",
       "       'Exterior2nd_BrkFace', 'Exterior2nd_ImStucc', 'Exterior2nd_Stone',\n",
       "       'Exterior2nd_Wd Sdng', 'Foundation_Slab', 'BsmtFinType2_LwQ',\n",
       "       'Heating_GasW', 'HeatingQC_Gd', 'Electrical_Mix', 'KitchenQual_Ex',\n",
       "       'Functional_Min2', 'Functional_Mod', 'FireplaceQu_missing',\n",
       "       'GarageQual_Po', 'SaleType_ConLI', 'SaleType_ConLw',\n",
       "       'SaleType_New', 'SaleType_Oth', 'SaleType_WD'], dtype='<U20')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = all_feat_names\n",
    "support = main_pipe.named_steps[\"rfecv\"].support_\n",
    "RFE_selected_feats = np.array(feature_names)[support]\n",
    "RFE_selected_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFECV selects the features by references their `feature_importances`/`coefs_` as well as the validation score after each feature is removed and seeing if it is increasing. \n",
    "\n",
    "When a feature is removed and the validation score is no longer increasing, then it stops removing features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Selection \n",
    "\n",
    "Unlike with RFE where we start with all our features and gradually remove the leat important ones, **Forward Selection** is a process where we start with no features and gradually add them! \n",
    "\n",
    "With RFE we removed the least important feature, whereas with forward selection we add features untill our cross-validation score starts to decreases. \n",
    "\n",
    "Forward Selection does not guaranty finding the best features set but reduces many problems.\n",
    "Computationally cheaper (aka faster!) \n",
    "Overfits less\n",
    "\n",
    "\n",
    "Forward selection is recently implemented in `sklearn` so please make sure it is up to date! You need version 0.24!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import it as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_forward = make_pipeline(preprocessor, \n",
    "                             SequentialFeatureSelector(LogisticRegression(max_iter=1000), \n",
    "                                                       direction='forward',\n",
    "                                                       n_features_to_select=20),\n",
    "                            LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this next cell is going to take a LONG LONG LONG time. \n",
    "\n",
    "<img src='imgs/waiting3.png' width=\"50%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       255.511478\n",
       "score_time       0.012293\n",
       "test_score       0.903272\n",
       "train_score      0.912886\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(pipe_forward, X_train, y_train, \n",
    "                        return_train_score=True)\n",
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice \n",
    "\n",
    "1. As we increase features, which score will always increase? \n",
    "2. Between `RFE` and `RFECV` which one finds the optimal number of features for us?\n",
    "3. Which method starts with all our features and iteratively removes them from our model?\n",
    "4. Which method starts with no features and iteratively adds features?\n",
    "5. Which method does not take into consideration `feature_importances_`/`coefs_` when adding/removing features? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra time? Project time\n",
    "\n",
    "First -> Project expectations. \n",
    "\n",
    "Breakout rooms in your project groups! \n",
    "\n",
    "Use this time to:\n",
    "\n",
    "- Meet with your team mates;\n",
    "- Think about a project - choose the data and business objective.\n",
    "- Propose a statistical objective to address this.\n",
    "- Also, elaborate on the statistical objective. What’s your plan for the analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We've Learned Today\n",
    "\n",
    "- How to construct a statistical question from a business objective. \n",
    "- What steps are important in building your analysis.\n",
    "- How to discover important features in your model. \n",
    "- the 2 different methods (RFE, Forward selection) to conduct feature selection on your model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}