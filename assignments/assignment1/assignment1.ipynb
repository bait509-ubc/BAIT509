{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAIT 509 Assignment 1: An introduction to Decision Trees, $k$-NN, Cross-validation and ML Fundamentals\n",
    "\n",
    "__Evaluates__: Lectures 1 - 3. \n",
    "\n",
    "__Rubrics__: Your solutions will be assessed primarily on the accuracy of your coding, as well as the clarity and correctness of your written responses. The MDS rubrics provide a good guide as to what is expected of you in your responses to the assignment questions and how the TAs will grade your answers. See the following links for more details:\n",
    "\n",
    "- [mechanics_rubric](https://github.com/UBC-MDS/public/blob/master/rubric/rubric_mech.md): submit an assignment correctly.\n",
    "- [accuracy rubric](https://github.com/UBC-MDS/public/blob/master/rubric/rubric_accuracy.md): evaluating your code.\n",
    "- [reasoning rubric](https://github.com/UBC-MDS/public/blob/master/rubric/rubric_reasoning.md): evaluating your written responses.\n",
    "- [autograde rubric](https://github.com/UBC-MDS/public/blob/master/rubric/rubric_autograde.md): evaluating questions that are either right or wrong (can be done either manually or automatically).\n",
    "\n",
    "## Tidy Submission \n",
    "rubric={mechanics:2}\n",
    "\n",
    "- Complete this assignment by filling out this jupyter notebook.\n",
    "- Any place you see `...` or `____`, you must fill in the function, variable, or data to complete the code.\n",
    "- Use proper English, spelling, and grammar.\n",
    "- You will submit two files on Canvas:\n",
    "    1. This jupyter notebook file containing your responses ( an `.ipynb` file); and,\n",
    "    2. An `.html` file of your completed notebook that will render directly on Canvas without having to be downloaded.\n",
    "        - To generate this html file you can click `File` -> `Export Notebook As` -> `HTML` in JupyterLab or type the following into a terminal `jupyter nbconvert --to html_embed assignment.ipynb`).\n",
    "    \n",
    " <br>  \n",
    "\n",
    " Submit your assignment through UBC Canvas by the deadline listed there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and learning goals <a name=\"in\"></a>\n",
    "<hr>\n",
    "\n",
    "Welcome to the assignment! In this assignment, you will work on the following:\n",
    "\n",
    "- create `X` (feature vectors) and `y` (targets) from a given dataset.  \n",
    "- use the `fit` and `predict` paradigms in `sklearn`.\n",
    "- use the `score` method in `sklearn` to calculate classification accuracy. \n",
    "- use `train_test_split` for data splitting and explain the importance of shuffling during data splitting. \n",
    "- train a decision tree using `sklearn`.\n",
    "- build a decision tree classifier on a real-world dataset.\n",
    "- build a $k$-nn classifier and explore different hyperparameters.\n",
    "- discuss the relationship between train accuracy and test accuracy and overfitting.\n",
    "- Choose an appropriate hyperparameter value for your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Decision trees with a toy dataset <a name=\"1\"></a>\n",
    "<hr>\n",
    "\n",
    "Suppose you have three different job offers with comparable salaries and job descriptions. You want to decide which one to accept, and you want to make this decision based on which job is likely to make you happy. Being a very systematic person, you come up with three features associated with the offers, which are important for your happiness: whether the colleagues are supportive, work-hour flexibility, and whether the company is a start-up or not (the columns `Supportive`, `Flexible` and `Startup` respectively). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "offer_data = {\n",
    "    # Features\n",
    "    \"Supportive\": [1, 0, 0],\n",
    "    \"Flexible\": [0, 0, 1],\n",
    "    \"Startup\": [0, 1, 1],\n",
    "    # Target\n",
    "    \"target\": [\"?\", \"?\", \"?\"],\n",
    "}\n",
    "\n",
    "offer_df = pd.DataFrame(offer_data)\n",
    "offer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you ask the following questions to some of your friends (who you think have similar notions of happiness) regarding their jobs:\n",
    "\n",
    "1. Do you have supportive colleagues? (1 for 'yes' and 0 for 'no')\n",
    "2. Do you have flexible work hours? (1 for 'yes' and 0 for 'no')\n",
    "3. Do you work for a start-up? (1 for 'start up' and 0 for 'non start up')\n",
    "4. Are you happy with your job? (happy or unhappy)\n",
    "\n",
    "You get the following data from this survey. You want to train a machine learning model using this data and then use this model to predict which job is likely to make you happy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_data = {\n",
    "    # Features\n",
    "    \"Supportive\": [1, 1, 1, 0, 0, 1, 1, 0, 1, 0],\n",
    "    \"Flexible\": [1, 1, 0, 1, 1, 0, 1, 0, 0, 0],\n",
    "    \"Startup\": [1, 0, 1, 0, 1, 0, 0, 1, 1, 0],\n",
    "    # Target\n",
    "    \"target\": [\n",
    "        \"happy\",\n",
    "        \"happy\",\n",
    "        \"happy\",\n",
    "        \"unhappy\",\n",
    "        \"unhappy\",\n",
    "        \"happy\",\n",
    "        \"happy\",\n",
    "        \"unhappy\",\n",
    "        \"unhappy\",\n",
    "        \"unhappy\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "train_df = pd.DataFrame(happiness_data)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Decision stump by hand \n",
    "rubric={autograde:2}\n",
    "\n",
    "If you manually built a decision stump (decision tree with only 1 split) by splitting on the condition `Supportive == 1` by hand, how would you predict each of the employees? \n",
    "\n",
    "Save your prediction for each employee as a string element in a list named `predict_employees`. \n",
    "Example:\n",
    "\n",
    "```\n",
    "predict_employees = ['happy', 'unhappy', 'unhappy',  'unhappy', 'unhappy', 'happy', 'happy', 'happy',  'unhappy',  'unhappy'] \n",
    "```\n",
    "\n",
    "(Note: you do not need to use a model here. By looking at the target column and the feature `Supportive` what rows would you predict to have which labels?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2232b48971264b1e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Replace the `...` with your list of hapiness predictions\n",
    "predict_employees = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Decision stump accuracy\n",
    "\n",
    "rubric={autograde:2}\n",
    "\n",
    "What training accuracy would you get with this decision stump above?\n",
    "\n",
    "Save the accuracy as a decimal in an object named `supportive_colleagues_acc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dd1cf91f6f070a32",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "supportive_colleagues_acc = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create `X`, `y`\n",
    "rubric={mechanics:2}\n",
    "\n",
    "Recall that in `scikit-learn` before building a classifier we need to create `X` (features) and `y` (target). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "From `train_df`, create `X` and `y`; save them in objects named `X` and `y`, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cb2d9fa55c6e0328",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = ...\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 `fit` a decision tree classifier \n",
    "rubric={accuracy:2}\n",
    "\n",
    "The idea of a machine learning algorithm is to *fit* the best model on the given training data, `X` (features) and `y` (their corresponding targets) and then using this model to *predict* targets for new examples. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Build a decision tree named `toy_tree` and fit it on the toy data using `sklearn`'s [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). Don't forget to make the necessary import(s) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-84c1c80f6e0c176b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "toy_tree = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 `score` \n",
    "rubric={accuracy:2}\n",
    "\n",
    "Score the decision tree on the training data (`X` and `y`).\n",
    "Save the results in an object named `toy_score` and output the score at the end of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b4572e8a317a9421",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "toy_score = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Explain training score\n",
    "rubric={reasoning:2}\n",
    "\n",
    "Do you get perfect training accuracy? Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Getting features\n",
    "\n",
    "rubric={accuracy:2}\n",
    "\n",
    "The first `offer_df` dataframe has no target values and we want to use the model we just made to make predictions. \n",
    "Drop the column `target` from the object and rename this dataframe `test_X`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b24fd045d6ab0223",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_X = ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 `predict`\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Now make predictions on the jobs offered in `test_X`. Save the predictions in an object named `predicted`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Happy job\n",
    "rubric={reasoning:2}\n",
    "\n",
    "Looking at the predictions, in which job you are likely to be happy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Decision trees on a real dataset <a name=\"2\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introducing the Spotify Song Attributes dataset\n",
    " \n",
    "For the rest of the assignment, you'll be using Kaggle's [Spotify Song Attributes](https://www.kaggle.com/geomack/spotifyclassification/home) dataset.\n",
    "The dataset contains a number of features of songs from 2017 and **a binary target variable representing whether the user liked the song or not** (1 = liked, 0 = did not like). See the documentation of all the features [here](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/). The supervised machine learning task for this dataset is predicting  whether the user likes a song or not given a number of song features.\n",
    "\n",
    "This dataset is publicly available on Kaggle, but not licensed to be freely distributed. So we do not provide this dataset, and you will have to download it yourself and add it to the same folder as this assignment. Follow the steps below to get the data CSV. \n",
    "\n",
    "- If you do not have an account with Kaggle, you will first need to create one. (It's free.) \n",
    "- Login to your account and [download the data](https://www.kaggle.com/geomack/spotifyclassification/).  \n",
    "- (You should always) Read the [terms and conditions](https://www.kaggle.com/terms) before using the data.\n",
    "- Save the CSV in the same folder as you saved this notebook file. (You DO NOT submit this `.csv` file on canva)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starter code below reads the data CSV file into the notebook. make sure you named the csv file `spotify.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df = pd.read_csv(\"spotify.csv\", index_col=0)\n",
    "spotify_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Split your data\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Split your `spotify_df` into your train and test splits.  Name the training data `train_df` and the testing data `test_df` using an 80/20 train to test split. Set your `random_state` to 77 to keep it consistent and facilitate grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the splits to train_df and test_df\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Explaining histograms \n",
    "\n",
    "rubric={reasoning:3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b33320bcf667584a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "A good thing to do before starting to train our models\n",
    "would be to explore the features visually so that we have an idea of what the data looks like.\n",
    "It is often beneficial to view the distributions of data for each feature.\n",
    "\n",
    "I have created histograms below for each of the features,\n",
    "showing the distribution for each target class.\n",
    "Study these histograms and then answer in 1-2 sentences which features and split values you think might be useful in differentiating the target classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "alt.Chart(train_df.sort_values(by='target')).mark_bar(opacity=0.6).encode(\n",
    "    alt.X(alt.repeat(), type='quantitative', bin=alt.Bin(maxbins=50)),\n",
    "    alt.Y('count()', stack=None),\n",
    "    alt.Color('target:N')\n",
    ").properties(\n",
    "    height=200\n",
    ").repeat(\n",
    "    [\"acousticness\", \"danceability\", \"tempo\", \"instrumentalness\", \"energy\", \"valence\"],\n",
    "    columns=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Cross-validation and model building <a name=\"3\"></a>\n",
    "<hr>\n",
    "Recall that in machine learning what we care about is generalization; we want to build models that generalize well on unseen examples. One way to ensure this is by splitting the data into training data and test data, building and tuning the model only using the training data, and then doing the final assessment on the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided you with some starter code that separates `train_df` and `test_df` into their respective features and target objects. We removed the columns `song_title` and `artist` from the feature objects since they would need additional processing to be used in our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns = ['song_title', 'artist','target'])\n",
    "y_train = train_df['target']\n",
    "X_test = test_df.drop(columns = ['song_title', 'artist','target'])\n",
    "y_test = test_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Building a Dummy Classifier\n",
    "rubric={accuracy:3}\n",
    "\n",
    "Build a `DummyClassifier` using the strategy `most_frequent`.\n",
    "\n",
    "Train it on `X_train` and `y_train`. Score it on the train **and** test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Building a Decision Tree Classifier\n",
    "rubric={accuracy:3}\n",
    "\n",
    "Build a Decision Tree classifier without setting any hyperparameters. Cross-validate with the appropriate objects, passing `return_train_score=True` and setting the number of folds to 10. (See the note in lecture 2 for help).\n",
    "\n",
    "Display the scores from `.cross_validate()` in a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = ...\n",
    "dt_cv_scores = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3 Decision Tree training and validation scores\n",
    "rubric={accuracy:1, reasoning:1}\n",
    "\n",
    "What are the mean validation and train scores? In 1-2 sentences, explain your results. Is your model overfitting or underfitting? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cv_means = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Building a $k$-NN Classifier\n",
    "rubric={accuracy:3}\n",
    "\n",
    "Build a $k$-NN classifier using the default hyperparameters. Cross-validate with the appropriate objects, passing `return_train_score=True` and setting the number of folds to 10.\n",
    "\n",
    "Display the scores from `.cross_validate()` in a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = ...\n",
    "knn_cv_scores = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.5 $k$-NN training and validation scores \n",
    "rubric={accuracy:1, reasoning:1}\n",
    "\n",
    "What are the mean validation and train scores for your $k$-NN classifier? In 1-2 sentences, explain your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv_mean = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Compare the models\n",
    "rubric={reasoning:2}\n",
    "\n",
    "In 1-2 sentences, compare the 3 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Hyperparameters <a name=\"5\"></a>\n",
    "<hr>\n",
    "\n",
    "We explored the `max_depth` hyperparameter of the `DecisionTreeClassifier` in lecture 2 but in this assignment, you'll explore another hyperparameter, `min_samples_split`. See the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for more details on this hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 `min_samples_splits`\n",
    "rubric={accuracy:5}\n",
    "\n",
    "Using 10-fold cross-validation and the training set only, find an appropriate value within the range 5 to 105 for the `min_samples_split` hyperparameter for a decision tree classifier.\n",
    "\n",
    "For each `min_samples_split` value:\n",
    "\n",
    "- Create a `DecisionTreeClassifier` object with the `min_samples_split` value.\n",
    "- Run 10-fold cross-validation with this `min_samples_split` using `cross_validate` to get the mean train and validation accuracies. Remember to use `return_train_score` argument to get the training score in each fold. \n",
    "\n",
    "In a pandas dataframe, for each `min_samples_split` show the mean train and cross-validation score. \n",
    "\n",
    "*Hint: We did something similar in lecture 2 (under **The \"Fundamental Tradeoff\" of Supervised Learning**) which you can refer to if you need help.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dicts = ...\n",
    "\n",
    "# Iterate over the hyperparameter values\n",
    "...\n",
    "\n",
    "results_df = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Plotting and interpreting\n",
    "rubric={accuracy:3, viz:1}\n",
    "\n",
    "Using whatever tool you like for plotting,  make a plot with the `min_samples_split` of the decision tree on the *x*-axis and the accuracy on the train and validation sets on the *y*-axis. \n",
    "\n",
    "(Again we did this in lecture 2 if you need any guidance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_plot = ...\n",
    "\n",
    "# Display the plot\n",
    "accuracy_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Picking `min_samples_split`\n",
    "rubric={accuracy:1, reasoning:2}\n",
    "\n",
    "Based on your results from 4.2, what `min_samples_split` value would you pick in your final model? In 1-2 sentences briefly explain why you chose this particular value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which value of min_samples_split is the best\n",
    "best_split = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Final model\n",
    "rubric={accuracy:2,reasoning:1}\n",
    "\n",
    "Train a decision tree classifier with the best `min_samples_split` using `X_train` and `y_train` and now carry out a final assessment by obtaining the test score on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission to Canvas\n",
    "\n",
    "**PLEASE READ: When you are ready to submit your assignment do the following:**\n",
    "\n",
    "- Read through your solutions\n",
    "- **Restart your kernel and clear output and rerun your cells from top to bottom** \n",
    "- Makes sure that none of your code is broken \n",
    "- Convert your notebook to .html format by going to File -> Export Notebook As... -> Export Notebook to HTML\n",
    "- Upload your `.ipynb` file and the `.html` file to Canvas under Assignment1. \n",
    "- **DO NOT** upload any `.csv` files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations on finishing Assignment 1!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:bait]",
   "language": "python",
   "name": "conda-env-bait-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
