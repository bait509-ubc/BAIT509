
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>9. Classification and Regression Metrics &#8212; BAIT 509&lt;br&gt;Business Applications of Machine Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="canonical" href="https://bait509-ubc.github.io/BAIT509/intro.html/lectures/lecture9.html" />
    <link rel="shortcut icon" href="../_static/bait_logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="10. Data Science Ethics" href="lecture10a.html" />
    <link rel="prev" title="8. Business Objectives/Statistical Questions and Feature Selection" href="lecture8.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/bait_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">BAIT 509<br>Business Applications of Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Things You Should Know
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/who.html">
   Who: Quan Nguyen
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/how.html">
   How: The Course Structure
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/what.html">
   What: Learning Outcomes
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="lecture1.html">
   1. Intro to ML &amp;  Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture2.html">
   2. Splitting and Cross-validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture3.html">
   3. Baseline models &amp; k-Nearest Neighbours
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture4.html">
   4. kNN regression, Support Vector Machines, and Feature Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture5.html">
   5. Preprocessing Categorical Features and Column Transformer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture6.html">
   6. Naive Bayes and Hyperparameter Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture7.html">
   7. Linear Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture8.html">
   8. Business Objectives/Statistical Questions and Feature Selection
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   9. Classification and Regression Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture10a.html">
   10. Data Science Ethics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture10b.html">
   11. Multi-Class Classification (Optional)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/attribution.html">
   Attribution
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/bait509-ubc/BAIT509/issues/new?title=Issue%20on%20page%20%2Flectures/lecture9.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/lectures/lecture9.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lecture-learning-objectives">
   9.1. Lecture Learning Objectives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#five-minute-recap-lightning-questions">
   9.2. Five Minute Recap/ Lightning Questions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-lingering-questions">
     9.2.1. Some lingering questions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introducing-evaluation-metrics">
   9.3. Introducing Evaluation Metrics
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#baseline">
     9.3.1. Baseline
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification-metrics-and-tools">
   9.4. Classification Metrics and tools
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-positive-and-negative">
     9.4.1. What is “positive” and “negative”?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#confusion-matrix">
     9.4.2. Confusion Matrix
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#confusion-matrix-components">
       9.4.2.1. Confusion Matrix components
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accuracy-is-only-part-of-the-story">
     9.4.3. Accuracy is only part of the story…
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recall">
     9.4.4. Recall
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#precision">
     9.4.5. Precision
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualization-of-precision-and-recall">
     9.4.6. Visualization of precision and recall
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#f1-score">
     9.4.7. f1 score
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-report">
     9.4.8. Classification report
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#macro-average-vs-weighted-average">
       9.4.8.1. Macro average vs weighted average
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#imbalanced-datasets">
     9.4.9. Imbalanced datasets
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#addressing-class-imbalance">
       9.4.9.1. Addressing class imbalance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#handling-imbalance">
       9.4.9.2. Handling imbalance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#changing-the-training-procedure-class-weight">
       9.4.9.3. Changing the training procedure:
       <code class="docutils literal notranslate">
        <span class="pre">
         class_weight
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#are-we-doing-better-with-class-weight-balanced">
       9.4.9.4. Are we doing better with
       <code class="docutils literal notranslate">
        <span class="pre">
         class_weight="balanced"
        </span>
       </code>
       ?
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice">
   9.5. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-metrics">
   9.6. Regression Metrics
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-squared-error-mse">
     9.6.1. Mean squared error (MSE)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-disadvantages">
       9.6.1.1. The disadvantages
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#root-mean-squared-error-rmse">
     9.6.2. Root mean squared error  (RMSE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mape-mean-absolute-percent-error-mape">
     9.6.3. MAPE - Mean Absolute Percent Error (MAPE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#r-2-r-squared">
     9.6.4.
     <span class="math notranslate nohighlight">
      \(R^2\)
     </span>
     (R squared)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   9.7. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#passing-different-scoring-methods">
   9.8. Passing Different Scoring Methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-validation">
     9.8.1. Cross-validation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-about-hyperparameter-tuning">
     9.8.2. What about hyperparameter tuning?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#and-with-classification">
     9.8.3. … and with Classification?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   9.9. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice-coding">
   9.10. Let’s Practice - Coding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-we-ve-learned-today">
   9.11. What We’ve Learned Today
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Classification and Regression Metrics</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lecture-learning-objectives">
   9.1. Lecture Learning Objectives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#five-minute-recap-lightning-questions">
   9.2. Five Minute Recap/ Lightning Questions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-lingering-questions">
     9.2.1. Some lingering questions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introducing-evaluation-metrics">
   9.3. Introducing Evaluation Metrics
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#baseline">
     9.3.1. Baseline
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification-metrics-and-tools">
   9.4. Classification Metrics and tools
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-positive-and-negative">
     9.4.1. What is “positive” and “negative”?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#confusion-matrix">
     9.4.2. Confusion Matrix
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#confusion-matrix-components">
       9.4.2.1. Confusion Matrix components
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accuracy-is-only-part-of-the-story">
     9.4.3. Accuracy is only part of the story…
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recall">
     9.4.4. Recall
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#precision">
     9.4.5. Precision
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualization-of-precision-and-recall">
     9.4.6. Visualization of precision and recall
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#f1-score">
     9.4.7. f1 score
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification-report">
     9.4.8. Classification report
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#macro-average-vs-weighted-average">
       9.4.8.1. Macro average vs weighted average
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#imbalanced-datasets">
     9.4.9. Imbalanced datasets
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#addressing-class-imbalance">
       9.4.9.1. Addressing class imbalance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#handling-imbalance">
       9.4.9.2. Handling imbalance
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#changing-the-training-procedure-class-weight">
       9.4.9.3. Changing the training procedure:
       <code class="docutils literal notranslate">
        <span class="pre">
         class_weight
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#are-we-doing-better-with-class-weight-balanced">
       9.4.9.4. Are we doing better with
       <code class="docutils literal notranslate">
        <span class="pre">
         class_weight="balanced"
        </span>
       </code>
       ?
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice">
   9.5. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-metrics">
   9.6. Regression Metrics
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-squared-error-mse">
     9.6.1. Mean squared error (MSE)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-disadvantages">
       9.6.1.1. The disadvantages
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#root-mean-squared-error-rmse">
     9.6.2. Root mean squared error  (RMSE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mape-mean-absolute-percent-error-mape">
     9.6.3. MAPE - Mean Absolute Percent Error (MAPE)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#r-2-r-squared">
     9.6.4.
     <span class="math notranslate nohighlight">
      \(R^2\)
     </span>
     (R squared)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   9.7. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#passing-different-scoring-methods">
   9.8. Passing Different Scoring Methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-validation">
     9.8.1. Cross-validation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-about-hyperparameter-tuning">
     9.8.2. What about hyperparameter tuning?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#and-with-classification">
     9.8.3. … and with Classification?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   9.9. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice-coding">
   9.10. Let’s Practice - Coding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-we-ve-learned-today">
   9.11. What We’ve Learned Today
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="classification-and-regression-metrics">
<h1><span class="section-number">9. </span>Classification and Regression Metrics<a class="headerlink" href="#classification-and-regression-metrics" title="Permalink to this headline">#</a></h1>
<div class="section" id="lecture-learning-objectives">
<h2><span class="section-number">9.1. </span>Lecture Learning Objectives<a class="headerlink" href="#lecture-learning-objectives" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Explain why accuracy is not always the best metric in ML.</p></li>
<li><p>Explain components of a confusion matrix.</p></li>
<li><p>Define precision, recall, and f1-score and use them to evaluate different classifiers.</p></li>
<li><p>Identify whether there is class imbalance and whether you need to deal with it.</p></li>
<li><p>Explain <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> and use it to deal with data imbalance.</p></li>
<li><p>Appropriately select a scoring metric given a regression problem.</p></li>
<li><p>Interpret and communicate the meanings of different scoring metrics on regression problems. MSE, RMSE, <span class="math notranslate nohighlight">\(R^2\)</span>, MAPE.</p></li>
<li><p>Apply different scoring functions with <code class="docutils literal notranslate"><span class="pre">cross_validate</span></code>, <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> and <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code>.</p></li>
</ul>
</div>
<div class="section" id="five-minute-recap-lightning-questions">
<h2><span class="section-number">9.2. </span>Five Minute Recap/ Lightning Questions<a class="headerlink" href="#five-minute-recap-lightning-questions" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>What is the difference between a business and a statistical question?</p></li>
<li><p>Should we ever question our clients’ requests?</p></li>
<li><p>What is an important feature?</p></li>
<li><p>What are some types of feature selection methods?</p></li>
</ul>
<div class="section" id="some-lingering-questions">
<h3><span class="section-number">9.2.1. </span>Some lingering questions<a class="headerlink" href="#some-lingering-questions" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>How can we measure our model’s success besides using accuracy or <span class="math notranslate nohighlight">\(R2\)</span>?</p></li>
<li><p>How should we interpret our model score if we have data where there is a lot of one class and very few of another?</p></li>
</ul>
</div>
</div>
<div class="section" id="introducing-evaluation-metrics">
<h2><span class="section-number">9.3. </span>Introducing Evaluation Metrics<a class="headerlink" href="#introducing-evaluation-metrics" title="Permalink to this headline">#</a></h2>
<p>Up until this point, we have been scoring our models the same way every time.
We’ve been using the percentage of correctly predicted examples for classification problems and the <span class="math notranslate nohighlight">\(R^2\)</span> metric for regression problems.
Let’s discuss how we need to expand our horizons and why it’s important to evaluate our models in other ways.</p>
<p>To help explain why accuracy isn’t always the most beneficial option, we are going back to the creditcard data set from the first class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>


<span class="n">cc_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/creditcard_sample.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;latin-1&#39;</span><span class="p">)</span>
<span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cc_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">111</span><span class="p">)</span>
<span class="n">train_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2210</th>
      <td>139995.0</td>
      <td>0.000822</td>
      <td>0.176378</td>
      <td>-0.081084</td>
      <td>-2.240657</td>
      <td>0.266328</td>
      <td>-1.458596</td>
      <td>0.658240</td>
      <td>-0.340358</td>
      <td>-1.124072</td>
      <td>...</td>
      <td>0.574194</td>
      <td>1.741723</td>
      <td>-0.110379</td>
      <td>0.053146</td>
      <td>-0.692897</td>
      <td>-0.207781</td>
      <td>0.460053</td>
      <td>0.307173</td>
      <td>15.00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>98478</th>
      <td>139199.0</td>
      <td>1.898426</td>
      <td>-0.544627</td>
      <td>0.021055</td>
      <td>0.233999</td>
      <td>-0.690212</td>
      <td>0.343812</td>
      <td>-0.976358</td>
      <td>0.241278</td>
      <td>0.957517</td>
      <td>...</td>
      <td>0.118648</td>
      <td>0.439855</td>
      <td>0.323290</td>
      <td>0.749224</td>
      <td>-0.580108</td>
      <td>0.317277</td>
      <td>-0.005703</td>
      <td>-0.034896</td>
      <td>23.36</td>
      <td>0</td>
    </tr>
    <tr>
      <th>75264</th>
      <td>147031.0</td>
      <td>1.852468</td>
      <td>-0.216744</td>
      <td>-1.956124</td>
      <td>0.360745</td>
      <td>0.415657</td>
      <td>-0.577488</td>
      <td>0.229426</td>
      <td>-0.215398</td>
      <td>0.913203</td>
      <td>...</td>
      <td>-0.198389</td>
      <td>-0.526080</td>
      <td>0.093325</td>
      <td>0.322035</td>
      <td>-0.030224</td>
      <td>-0.113123</td>
      <td>-0.022952</td>
      <td>0.000988</td>
      <td>109.54</td>
      <td>0</td>
    </tr>
    <tr>
      <th>66130</th>
      <td>50102.0</td>
      <td>-0.999481</td>
      <td>0.849393</td>
      <td>-0.556091</td>
      <td>0.259464</td>
      <td>2.298113</td>
      <td>3.728162</td>
      <td>-0.258322</td>
      <td>1.353233</td>
      <td>-0.503258</td>
      <td>...</td>
      <td>-0.082967</td>
      <td>-0.136016</td>
      <td>0.092160</td>
      <td>1.009201</td>
      <td>0.216844</td>
      <td>-0.236471</td>
      <td>0.201575</td>
      <td>0.101621</td>
      <td>20.24</td>
      <td>0</td>
    </tr>
    <tr>
      <th>82331</th>
      <td>41819.0</td>
      <td>-0.417792</td>
      <td>1.027810</td>
      <td>1.560763</td>
      <td>-0.029187</td>
      <td>-0.076807</td>
      <td>-0.904689</td>
      <td>0.688554</td>
      <td>-0.056332</td>
      <td>-0.369867</td>
      <td>...</td>
      <td>-0.229592</td>
      <td>-0.609212</td>
      <td>-0.019424</td>
      <td>0.356282</td>
      <td>-0.198697</td>
      <td>0.072055</td>
      <td>0.264011</td>
      <td>0.120743</td>
      <td>2.69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>105747</th>
      <td>86420.0</td>
      <td>1.539769</td>
      <td>-0.710190</td>
      <td>-0.779133</td>
      <td>0.972778</td>
      <td>0.521677</td>
      <td>1.992379</td>
      <td>-0.538152</td>
      <td>0.592431</td>
      <td>0.530753</td>
      <td>...</td>
      <td>-0.020365</td>
      <td>-0.203199</td>
      <td>0.323143</td>
      <td>-0.793579</td>
      <td>-0.611899</td>
      <td>-0.926726</td>
      <td>0.073134</td>
      <td>-0.018315</td>
      <td>147.80</td>
      <td>0</td>
    </tr>
    <tr>
      <th>102486</th>
      <td>113038.0</td>
      <td>-0.509300</td>
      <td>1.128383</td>
      <td>-0.876960</td>
      <td>-0.568208</td>
      <td>0.819440</td>
      <td>-0.749178</td>
      <td>0.903256</td>
      <td>0.068764</td>
      <td>0.068195</td>
      <td>...</td>
      <td>-0.391476</td>
      <td>-0.860542</td>
      <td>0.061769</td>
      <td>0.387231</td>
      <td>-0.334076</td>
      <td>0.101585</td>
      <td>0.085727</td>
      <td>-0.194219</td>
      <td>44.99</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4820</th>
      <td>142604.0</td>
      <td>1.906919</td>
      <td>-0.398941</td>
      <td>0.275837</td>
      <td>1.736308</td>
      <td>-0.710844</td>
      <td>0.682936</td>
      <td>-1.180614</td>
      <td>0.443751</td>
      <td>0.047498</td>
      <td>...</td>
      <td>-0.022269</td>
      <td>-0.163610</td>
      <td>0.499126</td>
      <td>0.731827</td>
      <td>-1.088328</td>
      <td>2.005337</td>
      <td>-0.153967</td>
      <td>-0.061703</td>
      <td>3.75</td>
      <td>0</td>
    </tr>
    <tr>
      <th>10196</th>
      <td>139585.0</td>
      <td>2.106285</td>
      <td>-0.102411</td>
      <td>-1.815538</td>
      <td>0.256847</td>
      <td>0.340938</td>
      <td>-1.002490</td>
      <td>0.373141</td>
      <td>-0.314247</td>
      <td>0.541619</td>
      <td>...</td>
      <td>-0.060222</td>
      <td>-0.047904</td>
      <td>0.124192</td>
      <td>0.771908</td>
      <td>0.144864</td>
      <td>0.645126</td>
      <td>-0.117185</td>
      <td>-0.074093</td>
      <td>5.41</td>
      <td>0</td>
    </tr>
    <tr>
      <th>77652</th>
      <td>148922.0</td>
      <td>2.157147</td>
      <td>-1.138329</td>
      <td>-0.775495</td>
      <td>-0.887122</td>
      <td>-1.019818</td>
      <td>-0.489387</td>
      <td>-1.024161</td>
      <td>-0.069089</td>
      <td>0.329227</td>
      <td>...</td>
      <td>0.282963</td>
      <td>0.802273</td>
      <td>0.037861</td>
      <td>-0.642100</td>
      <td>-0.101534</td>
      <td>-0.046669</td>
      <td>-0.001974</td>
      <td>-0.052120</td>
      <td>39.99</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>85504 rows × 31 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(85504, 31)
</pre></div>
</div>
</div>
</div>
<p>We can see this is a quite large dataset!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>...</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
      <td>85504.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>111177.965218</td>
      <td>0.069621</td>
      <td>-0.035379</td>
      <td>-0.296593</td>
      <td>-0.028028</td>
      <td>0.086975</td>
      <td>-0.030399</td>
      <td>0.025395</td>
      <td>-0.017036</td>
      <td>0.042680</td>
      <td>...</td>
      <td>0.017353</td>
      <td>0.052381</td>
      <td>0.012560</td>
      <td>-0.009845</td>
      <td>-0.048255</td>
      <td>-0.014074</td>
      <td>-0.003047</td>
      <td>-0.002209</td>
      <td>92.724942</td>
      <td>0.004128</td>
    </tr>
    <tr>
      <th>std</th>
      <td>48027.531032</td>
      <td>2.108440</td>
      <td>1.780371</td>
      <td>1.631892</td>
      <td>1.466457</td>
      <td>1.452847</td>
      <td>1.354052</td>
      <td>1.361786</td>
      <td>1.258107</td>
      <td>1.131435</td>
      <td>...</td>
      <td>0.776954</td>
      <td>0.755315</td>
      <td>0.670336</td>
      <td>0.607638</td>
      <td>0.548000</td>
      <td>0.481118</td>
      <td>0.414234</td>
      <td>0.369266</td>
      <td>271.297276</td>
      <td>0.064121</td>
    </tr>
    <tr>
      <th>min</th>
      <td>406.000000</td>
      <td>-56.407510</td>
      <td>-72.715728</td>
      <td>-33.680984</td>
      <td>-5.683171</td>
      <td>-40.427726</td>
      <td>-26.160506</td>
      <td>-43.557242</td>
      <td>-73.216718</td>
      <td>-13.434066</td>
      <td>...</td>
      <td>-34.830382</td>
      <td>-10.933144</td>
      <td>-36.666000</td>
      <td>-2.824849</td>
      <td>-8.696627</td>
      <td>-2.534330</td>
      <td>-9.895244</td>
      <td>-8.656570</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>50814.000000</td>
      <td>-0.886089</td>
      <td>-0.634044</td>
      <td>-1.228706</td>
      <td>-0.871992</td>
      <td>-0.622997</td>
      <td>-0.801849</td>
      <td>-0.550769</td>
      <td>-0.234941</td>
      <td>-0.616671</td>
      <td>...</td>
      <td>-0.225345</td>
      <td>-0.524692</td>
      <td>-0.160006</td>
      <td>-0.365718</td>
      <td>-0.375934</td>
      <td>-0.331664</td>
      <td>-0.074373</td>
      <td>-0.058973</td>
      <td>5.990000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>133031.500000</td>
      <td>0.064451</td>
      <td>0.027790</td>
      <td>-0.206322</td>
      <td>-0.099292</td>
      <td>0.060853</td>
      <td>-0.300730</td>
      <td>0.076727</td>
      <td>0.001596</td>
      <td>0.003678</td>
      <td>...</td>
      <td>-0.008602</td>
      <td>0.074564</td>
      <td>0.002990</td>
      <td>0.027268</td>
      <td>-0.062231</td>
      <td>-0.061101</td>
      <td>-0.003718</td>
      <td>-0.003411</td>
      <td>22.660000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>148203.000000</td>
      <td>1.832261</td>
      <td>0.796311</td>
      <td>0.767406</td>
      <td>0.635543</td>
      <td>0.735001</td>
      <td>0.374897</td>
      <td>0.632747</td>
      <td>0.310501</td>
      <td>0.658517</td>
      <td>...</td>
      <td>0.215080</td>
      <td>0.622089</td>
      <td>0.177875</td>
      <td>0.458784</td>
      <td>0.317849</td>
      <td>0.230836</td>
      <td>0.088166</td>
      <td>0.076868</td>
      <td>80.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>172788.000000</td>
      <td>2.451888</td>
      <td>22.057729</td>
      <td>4.187811</td>
      <td>16.715537</td>
      <td>34.801666</td>
      <td>23.917837</td>
      <td>44.054461</td>
      <td>19.587773</td>
      <td>9.234623</td>
      <td>...</td>
      <td>27.202839</td>
      <td>10.503090</td>
      <td>20.803344</td>
      <td>3.979637</td>
      <td>7.519589</td>
      <td>3.155327</td>
      <td>10.507884</td>
      <td>33.847808</td>
      <td>19656.530000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 31 columns</p>
</div></div></div>
</div>
<p>We see that the columns are all scaled and numerical.</p>
<p>You don’t need to worry about this now. The original columns have been transformed already for confidentiality and our benefit so now there are no categorical features.</p>
<p>Let’s separate <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> for train and test splits.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_big</span><span class="p">,</span> <span class="n">y_train_big</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]),</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]),</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We are going to be talking about evaluation metrics and it’s easier to do so if we use an explicit validation set instead of using cross-validation.</p>
<p>Our data is large enough so it shouldn’t be a problem.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_train_big</span><span class="p">,</span>  <span class="n">y_train_big</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="baseline">
<h3><span class="section-number">9.3.1. </span>Baseline<a class="headerlink" href="#baseline" title="Permalink to this headline">#</a></h3>
<p>Just like and predictive question, we start our analysis by building a simple <code class="docutils literal notranslate"><span class="pre">DummyClassifier</span></code> model as our baseline.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>

<span class="n">dummy</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;most_frequent&quot;</span><span class="p">)</span>
<span class="n">dummy</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">dummy</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9958564458998864
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dummy</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9959067519101824
</pre></div>
</div>
</div>
</div>
<p>Almost 100% accuracy? This is supposed to be a baseline model! How is it getting such high accuracy?
Should we just deploy this <code class="docutils literal notranslate"><span class="pre">DummyClassifier</span></code> model for fraud detection?</p>
<p>Not so fast…
If we look at the distribution of fraudulent labels to non-fraudulent labels, we can see there is an imbalance in the classes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Class
0    0.995872
1    0.004128
Name: proportion, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Here the <code class="docutils literal notranslate"><span class="pre">0</span></code> class is a Non fraud transaction, and the <code class="docutils literal notranslate"><span class="pre">1</span></code> class is a Fraud transaction.
We can see here that there are MANY Non fraud transactions and only a tiny handful of Fraud transactions.
So, what would be a good accuracy here? 99.9%? 99.99%?</p>
<p>Let’s see if a logistic regression model would get a higher score than the Dummary model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
       <span class="p">(</span><span class="n">StandardScaler</span><span class="p">()),</span>
       <span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">))</span>
<span class="p">)</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.172872
score_time     0.002629
test_score     0.998830
train_score    0.998993
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>This seems slightly better than <code class="docutils literal notranslate"><span class="pre">DummyClassifier</span></code>, but the question is can it really identify fraudulent transactions?
The “Fraud” class is the class that we want to spot. The class we are interested in.
Let’s looks at some new metrics that can help us assess how well our model is doing overall and not just for the majority class label.</p>
</div>
</div>
<div class="section" id="classification-metrics-and-tools">
<h2><span class="section-number">9.4. </span>Classification Metrics and tools<a class="headerlink" href="#classification-metrics-and-tools" title="Permalink to this headline">#</a></h2>
<div class="section" id="what-is-positive-and-negative">
<h3><span class="section-number">9.4.1. </span>What is “positive” and “negative”?<a class="headerlink" href="#what-is-positive-and-negative" title="Permalink to this headline">#</a></h3>
<p>There are two kinds of binary classification problems:</p>
<ul class="simple">
<li><p>Distinguishing between two classes</p></li>
<li><p>Spotting a specific class (fraud transaction, spam, disease)</p></li>
</ul>
<p>In the case of spotting problems, the thing that we are interested in spotting is considered “positive”
(not related to how a logistic regression model internall defines a “positive” and “negative” class).
In our example, we want to spot <strong>fraudulent</strong> transactions and so fraudulent is the “positive” class.</p>
</div>
<div class="section" id="confusion-matrix">
<h3><span class="section-number">9.4.2. </span>Confusion Matrix<a class="headerlink" href="#confusion-matrix" title="Permalink to this headline">#</a></h3>
<p>A <strong>confusion matrix</strong> is a table that visualizes the performance of an algorithm. It shows the possible labels and how many of each label the model predicts correctly and incorrectly.</p>
<p>Here we first fit and predict the model,
and then show it’s confusion matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>


<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
<span class="n">cm</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[25541,     6],
       [   25,    80]])
</pre></div>
</div>
</div>
</div>
<div class="section" id="confusion-matrix-components">
<h4><span class="section-number">9.4.2.1. </span>Confusion Matrix components<a class="headerlink" href="#confusion-matrix-components" title="Permalink to this headline">#</a></h4>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>X</p></th>
<th class="head"><p>predict negative</p></th>
<th class="head"><p>predict positive</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>negative example</p></td>
<td><p>True negative (TN)</p></td>
<td><p>False positive (FP)</p></td>
</tr>
<tr class="row-odd"><td><p>positive example</p></td>
<td><p>False negative (FN)</p></td>
<td><p>True positive (TP)</p></td>
</tr>
</tbody>
</table>
<p>Remember the Fraud is considered “positive” in this case and Non fraud is considered “negative”.</p>
<p>The 4 quadrants of the confusion matrix can be explained as follows. These positions will change depending on what values we deem as the positive label.</p>
<ul class="simple">
<li><p><strong>True negative (TN)</strong>: Examples that are negatively labelled that the model correctly predicts. This is in the top left quadrant.</p></li>
<li><p><strong>False positive (FP)</strong>: Examples that are negatively labelled that the model incorrectly predicts as positive. This is in the top right quadrant.</p></li>
<li><p><strong>False negative (FN)</strong>:  Examples that are positively labelled that the model incorrectly predicts as negative. This is in the bottom left quadrant.</p></li>
<li><p><strong>True positive (TP)</strong>:  Examples that are positively labelled that the model correctly predicted as positive. This is in the bottom right quadrant.</p></li>
</ul>
<p>Instead of looking just at the numbers and remembering what each category represents,
we can use the <code class="docutils literal notranslate"><span class="pre">ConfusionMatrixDisplay</span></code> class
(the <code class="docutils literal notranslate"><span class="pre">plot_confusion_matrix</span></code> function in earlier version of sklearn)
to visualize how well our model is doing classifying each target class.</p>
<p>We can use <code class="docutils literal notranslate"><span class="pre">classes</span></code> to see which position each label takes so we can designate them more comprehensive labels in our plot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span><span class="o">.</span><span class="n">classes_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 1])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">ConfusionMatrixDisplay</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span> <span class="c1"># bigger font sizes</span>
<span class="n">ConfusionMatrixDisplay</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Non fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;Fraud&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x179d97e50&gt;
</pre></div>
</div>
<img alt="../_images/lecture9_33_1.png" src="../_images/lecture9_33_1.png" />
</div>
</div>
<p>In fact,
we don’t even need to manually create the confusion matrix before plotting it,
but can instead build it straight from the fitted estimator.
In this case, we only need to fit the model before visualizing it
(the predictions are done automatically on the validation/test data set that we pass in)
This results in a 2 by 2 matrix with the labels <code class="docutils literal notranslate"><span class="pre">Non</span> <span class="pre">fraud</span></code> and <code class="docutils literal notranslate"><span class="pre">Fraud</span></code> on each axis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># We already did this above, but adding it here for clarity</span>

<span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
    <span class="n">pipe</span><span class="p">,</span>
    <span class="n">X_valid</span><span class="p">,</span>
    <span class="n">y_valid</span><span class="p">,</span>
    <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Non fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;Fraud&quot;</span><span class="p">],</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture9_35_0.png" src="../_images/lecture9_35_0.png" />
</div>
</div>
<p><strong>Looking at the plotting arguments:</strong></p>
<ul class="simple">
<li><p>Similar to other <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> functions, we pass the model/pipeline followed by the feature table and then the target values.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">display_labels</span></code> will show more descriptive labels. without this argument, it would simply show the classes we have in the data (<code class="docutils literal notranslate"><span class="pre">0</span></code>, <code class="docutils literal notranslate"><span class="pre">1</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">values_format</span></code> will determine how the numbers are displayed. Specifying <code class="docutils literal notranslate"><span class="pre">d</span></code> avoids scientific notation for large numbers (not needed in this example).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cmap</span></code> is the colour argument! The default is <code class="docutils literal notranslate"><span class="pre">viridis</span></code> but other values such as <code class="docutils literal notranslate"><span class="pre">Blues</span></code>, <code class="docutils literal notranslate"><span class="pre">Purples</span></code>, <code class="docutils literal notranslate"><span class="pre">RdPu</span></code> or other colour schemes from <a class="reference external" href="https://matplotlib.org/stable/tutorials/colors/colormaps.html">here</a> are also possible.</p></li>
</ul>
</div>
</div>
<div class="section" id="accuracy-is-only-part-of-the-story">
<h3><span class="section-number">9.4.3. </span>Accuracy is only part of the story…<a class="headerlink" href="#accuracy-is-only-part-of-the-story" title="Permalink to this headline">#</a></h3>
<p>We have been using <code class="docutils literal notranslate"><span class="pre">.score</span></code> to assess our models, which returns accuracy by default
for classification models.
We just saw that accuracy can be  misleading when we have a class imbalance,
so maybe there are other metrics that are more suitable in these cases?</p>
<p><em>Note that the metrics we are going to discuss will only help us assess our model assessment.
Further into this lecture we’ll talk about a few ways to address the class imbalance problem as well.</em></p>
<p>To understand the metrics we are going to talk about next,
we will need our values for the four different quadrants in the confusion matrix.
We are going to split up the values in the matrix into four separate variables</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">TN</span></code> for the True Negatives</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FP</span></code> for the False Positives</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FN</span></code> for the False Negatives</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TP</span></code> for the True Positives</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span><span class="p">,</span> <span class="n">TP</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s look at the first metric, “Recall”</p>
</div>
<div class="section" id="recall">
<h3><span class="section-number">9.4.4. </span>Recall<a class="headerlink" href="#recall" title="Permalink to this headline">#</a></h3>
<p><em>“Among all positive examples, how many did the model identify?”</em></p>
<p>Recall is the ability of the classifier to find all the positive samples.
You can think of this as “What was the model’s recall/hit rate out of <strong>all the truly positive observations</strong>”.
The denominator in the equation below is all the truly positive values.</p>
<div class="math notranslate nohighlight">
\[ \text{recall} = \frac{\text{Number of correctly identified positives}}{\text{Total number of true positives}} = \frac{TP}{TP + FN} \]</div>
<p>In binary classification,
recall is sometimes used more generally for either the positive or negative class:
recall of the positive class is also known as “sensitivity”
and recall of the negative class is “specificity”,
which are terms you might recognize from your statistics classes.
In machine learning we almost always refer to “sensitivity” when we just say “recall”.</p>
<p>Since Fraud is our positive label, we see the correctly identified labels in the bottom right quadrant and the ones that we missed in the bottom left quadrant.</p>
<!-- <img src='imgs/recall.png' width="50%">  -->
<p><img alt="image.png" src="../_images/cm-recall.png" /></p>
<p>So here we take our true positives and we divide by all the positive labels in our validation set (the predictions the model incorrectly labelled as negative (the false negatives) as well as those correctly labelled as positive).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;True Positives:&#39;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;False Negatives:&#39;</span><span class="p">,</span> <span class="n">FN</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True Positives: 80
False Negatives: 25
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">recall</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>
<span class="n">recall</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.762
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="precision">
<h3><span class="section-number">9.4.5. </span>Precision<a class="headerlink" href="#precision" title="Permalink to this headline">#</a></h3>
<p><em>“Among the positive examples you identified, how many were actually positive?”</em></p>
<p>Precision is the ability of the classifier to avoid putting a positive label on a negative observation.
You can think of this as “How precise are the model’s <strong>predictions</strong>?”.
The denominator in the equation below is all the predicted positive values.</p>
<div class="math notranslate nohighlight">
\[ \text{precision} = \frac{\text{Number of correctly identified positives}}{\text{Total number of predicted positives}} = \frac{TP}{TP + FP} \]</div>
<p>With Fraud as our positive label,  we see the correctly identified Fraudulent cases in the bottom right quadrant and the labels we incorrectly labelled as Frauds in the top right.</p>
<!-- <img src='imgs/precision.png' width="50%">  -->
<p><img alt="image.png" src="../_images/cm-precision.png" /></p>
<p>So here we take our true positives and we divide by all the positive labels that our model predicted.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;True Positives:&#39;</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;False Positives:&#39;</span><span class="p">,</span> <span class="n">FP</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True Positives: 80
False Positives: 6
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">precision</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>
<span class="n">precision</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.93
</pre></div>
</div>
</div>
</div>
<p>Of course, we’d like to have both high precision and recall but the balance depends on our domain,
and which type of error we think is more important to avoid.
For credit card fraud detection,
recall is really important (catching frauds),
precision is less important (reducing false positives)
since there likely will be a manual review process in place to look closer at the predicted frauds
and prevent false accusations
(whereas there likely are too many observations to have a manual review process for all the potentially missed frauds).</p>
</div>
<div class="section" id="visualization-of-precision-and-recall">
<h3><span class="section-number">9.4.6. </span>Visualization of precision and recall<a class="headerlink" href="#visualization-of-precision-and-recall" title="Permalink to this headline">#</a></h3>
<p>In case you find the concepts above hard to follow or remember,
I am including this schematic as a visual aid</p>
<p><img alt="image.png" src="../_images/recall-precision-schematic.png" /></p>
<p>Source: https://en.wikipedia.org/wiki/Precision_and_recall</p>
</div>
<div class="section" id="f1-score">
<h3><span class="section-number">9.4.7. </span>f1 score<a class="headerlink" href="#f1-score" title="Permalink to this headline">#</a></h3>
<p>Sometimes we need a single score to maximize, e.g., when doing hyperparameter tuning via RandomizedSearchCV.
Accuracy is often a not the ideal choice,
and we might care about both the precision and recall.
One way of combining these two into a single score is to average them.
However,
in machine learning,
we usually use a different way of averaging these metrics together,
which is called the “harmonic mean”.
The advantage of this is that it penalizes the model more for performing poorly in either of the precision or recall,
whether if we just took the common arithmetic mean,
the model could compensate e.g. for a low recall with a high precision and still get a high overall score.</p>
<p>The harmonic mean of the precision and recall is called the <code class="docutils literal notranslate"><span class="pre">f1</span></code> score:</p>
<div class="math notranslate nohighlight">
\[ \text{f1} = 2 * \frac{\text{precision} * \text{recall}}{\text{precision} + \text{recall}} \]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision:&#39;</span><span class="p">,</span> <span class="n">precision</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Recall:&#39;</span><span class="p">,</span> <span class="n">recall</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Precision: 0.9302
Recall: 0.7619
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f1_score</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">)</span>
<span class="n">f1_score</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.838
</pre></div>
</div>
</div>
</div>
<p>We could calculate all these evaluation metrics by hand
using the formulas we have covered so far:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">)]</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)]</span> 
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;recall&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)]</span> 
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;f1 score&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">)]</span> 

<span class="n">measures_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">measures_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>accuracy</th>
      <th>precision</th>
      <th>recall</th>
      <th>f1 score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.998792</td>
      <td>0.930233</td>
      <td>0.761905</td>
      <td>0.837696</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>… or we can use <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> which has functions for these metrics.</p>
<p>Here we are importing <code class="docutils literal notranslate"><span class="pre">accuracy_score</span></code>, <code class="docutils literal notranslate"><span class="pre">precision_score</span></code>, <code class="docutils literal notranslate"><span class="pre">recall_score</span></code>, <code class="docutils literal notranslate"><span class="pre">f1_score</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span>


<span class="n">pred_cv</span> <span class="o">=</span>  <span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span> 

<span class="n">data</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pred_cv</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pred_cv</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;recall&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pred_cv</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;f1 score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pred_cv</span><span class="p">))</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;by-hand&#39;</span><span class="p">,</span> <span class="s1">&#39;sklearn&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>accuracy</th>
      <th>precision</th>
      <th>recall</th>
      <th>f1 score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>by-hand</th>
      <td>0.998792</td>
      <td>0.930233</td>
      <td>0.761905</td>
      <td>0.837696</td>
    </tr>
    <tr>
      <th>sklearn</th>
      <td>0.998792</td>
      <td>0.930233</td>
      <td>0.761905</td>
      <td>0.837696</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>And you can see the scores match.</p>
<p>We can even go one step further and “observe” the scores using a <em>Classification report</em></p>
</div>
<div class="section" id="classification-report">
<h3><span class="section-number">9.4.8. </span>Classification report<a class="headerlink" href="#classification-report" title="Permalink to this headline">#</a></h3>
<p>Similar to how a confusion matrix shows the False and True negative and positive labels, a classification report shows us an assortment of metrics, however, we can’t flatten or obtain the results from it and only see what is printed as the output.</p>
<p>We can import <code class="docutils literal notranslate"><span class="pre">classification_report</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
</pre></div>
</div>
</div>
</div>
<p>In our function, we specify the true labels, followed by the predictions our model made.</p>
<p>The argument <code class="docutils literal notranslate"><span class="pre">target_names</span></code>, gives more descriptive labels similar to what <code class="docutils literal notranslate"><span class="pre">display_labels</span></code> did when plotting the confusion matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="n">classification_report</span><span class="p">(</span>
        <span class="n">y_valid</span><span class="p">,</span>
        <span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">),</span>
        <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;non fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;Fraud&quot;</span><span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

   non fraud       1.00      1.00      1.00     25547
       Fraud       0.93      0.76      0.84       105

    accuracy                           1.00     25652
   macro avg       0.96      0.88      0.92     25652
weighted avg       1.00      1.00      1.00     25652
</pre></div>
</div>
</div>
</div>
<p>Note that what you consider “positive” (Fraud in our case) is important when calculating precision, recall, and f1-score.
If you flip what is considered positive or negative, we’ll end up with different True Positive, False Positive, True Negatives and False Negatives, and hence different precision, recall, and f1-scores.
The <code class="docutils literal notranslate"><span class="pre">support</span></code> column just shows the number of examples in each class.</p>
<p>You might be wondering about the two lines at the end of this report,
so let’s cover that next.</p>
<div class="section" id="macro-average-vs-weighted-average">
<h4><span class="section-number">9.4.8.1. </span>Macro average vs weighted average<a class="headerlink" href="#macro-average-vs-weighted-average" title="Permalink to this headline">#</a></h4>
<p>These are the average for the positive and negative class in each of the metrics.</p>
<ul class="simple">
<li><p><strong>Macro average</strong> gives equal importance to all classes irrespective of the number of observations (support) in each class.</p></li>
<li><p><strong>Weighted average</strong> weighs the average by the number of observations (support) in each class.</p></li>
</ul>
<p>Which one is relevant, depends upon whether you think each class should have the same weight or each sample should have the same weight.
These metrics are often useful when predicting multiple classes which we will briefly discuss later on.</p>
<p>In addition to this lecture, my wonderful colleague <a class="reference external" href="https://kvarada.github.io/">Varada Kolhatkar</a> has made a cheat sheet for these metrics available in a larger size <a class="reference external" href="https://raw.githubusercontent.com/UBC-MDS/introduction-machine-learning/master/static/module7/evaluation-metrics.png">here</a>.</p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/UBC-MDS/introduction-machine-learning/master/static/module7/evaluation-metrics.png"><img alt="404 image" src="https://raw.githubusercontent.com/UBC-MDS/introduction-machine-learning/master/static/module7/evaluation-metrics.png" style="width: 90%;" /></a>
</div>
</div>
<div class="section" id="imbalanced-datasets">
<h3><span class="section-number">9.4.9. </span>Imbalanced datasets<a class="headerlink" href="#imbalanced-datasets" title="Permalink to this headline">#</a></h3>
<p>A class imbalance typically refers to having many more examples of one class than another in one’s training set.
We’ve seen this in our fraud dataset where our <code class="docutils literal notranslate"><span class="pre">class</span></code> target column had many more non-fraud than fraud examples.
Real-world data is often imbalanced and can be seen in scenarios such as:</p>
<ul class="simple">
<li><p>Ad clicking data (Only around ~0.01% of ads are clicked.)</p></li>
<li><p>Spam classification datasets.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Class
0    0.995856
1    0.004144
Name: proportion, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="section" id="addressing-class-imbalance">
<h4><span class="section-number">9.4.9.1. </span>Addressing class imbalance<a class="headerlink" href="#addressing-class-imbalance" title="Permalink to this headline">#</a></h4>
<p>A very important question to ask yourself: <em><strong>“Why do I have a class imbalance?”</strong></em></p>
<ul class="simple">
<li><p>Is it because of my data collection methods?</p>
<ul>
<li><p>If it’s the data collection, then that means the you need to rethink how you have collected the data and if you can recollect it to balance the classes (note: it might be dangerous to go out and just collect new observations of the least common class since these would be collected after the original data and if the data changed over time, these newly collected observations will be different than the old one not because of their class, but because of the date they were collected.</p></li>
</ul>
</li>
<li><p>Is it because one class is much rarer than the other?</p>
<ul>
<li><p>If it’s because one is rarer than the other in the true data distribution, you need to think about which type of error is more important to the stakeholders and prioritize how you train the model and how you assess its performance.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="handling-imbalance">
<h4><span class="section-number">9.4.9.2. </span>Handling imbalance<a class="headerlink" href="#handling-imbalance" title="Permalink to this headline">#</a></h4>
<p>Can we change the model itself so that it considers the errors that are important to us?</p>
<p>There are two common approaches to this:</p>
<ol class="simple">
<li><p><strong>Changing the training procedure</strong></p></li>
<li><p><strong>Changing the data (not in this course)</strong></p>
<ul class="simple">
<li><p>Undersampling</p></li>
<li><p>Oversampling</p></li>
</ul>
</li>
</ol>
</div>
<div class="section" id="changing-the-training-procedure-class-weight">
<h4><span class="section-number">9.4.9.3. </span>Changing the training procedure: <code class="docutils literal notranslate"><span class="pre">class_weight</span></code><a class="headerlink" href="#changing-the-training-procedure-class-weight" title="Permalink to this headline">#</a></h4>
<p>If you look for example, in the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html">documentation for the SVM classifier</a>, or <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regression#sklearn.linear_model.LogisticRegression">Logistic Regression</a> we see <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> as a parameter.</p>
<a class="reference internal image-reference" href="../_images/weights-sklearn.png"><img alt="404 image" src="../_images/weights-sklearn.png" style="width: 100%;" /></a>
<p>How can this help use work with class imbalances?</p>
<p>The default <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> is 1 for all classes;
which means that all classes are equally important.
By setting the class weight to another value,
we can say that errors on one class are more important than errors on another class,
and when we perform the final computation of the error score,
this class’s errors will have more weight and contribute more to the final error score.</p>
<p>Let’s see an example.</p>
<p>First, let’s build a model where we keep the class_weights as the default.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_default</span><span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">lr_default</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
    <span class="n">lr_default</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span>
    <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Non fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;Fraud&quot;</span><span class="p">],</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture9_76_0.png" src="../_images/lecture9_76_0.png" />
</div>
</div>
<p>Now let’s rebuild our pipeline but using the <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> argument and setting it as <code class="docutils literal notranslate"><span class="pre">class_weight={1:100}</span></code>.
This is equivalent to saying “repeat every positive example 100x in the training set”,
but repeating data would slow down the code, whereas this doesn’t
since it just weights the error on the second class 100x more than the first class.
In the context of our data, we are saying that a false negative is 100x more problematic than a false positive.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_100</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="p">{</span><span class="mi">1</span><span class="p">:</span><span class="mi">100</span><span class="p">})</span>
<span class="n">lr_100</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
    <span class="n">lr_100</span><span class="p">,</span>
    <span class="n">X_valid</span><span class="p">,</span>
    <span class="n">y_valid</span><span class="p">,</span>
    <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Non fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;Fraud&quot;</span><span class="p">],</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture9_79_0.png" src="../_images/lecture9_79_0.png" />
</div>
</div>
<p>Notice that we now have reduced false negatives and predicted more true positives this time.
But, as a consequence, we pay a price since now we are also increasing false positives.</p>
<p>We can also set <code class="docutils literal notranslate"><span class="pre">class_weight=&quot;balanced&quot;</span></code>.
This sets the weights automatically so that the classes are “equal”,
by automatically adjust weights inversely proportional to class frequencies in the input data.
So if there is 10x less of class 2 in the data,
its errors will be weighted 10x in the computation of the final score.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_balanced</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s2">&quot;balanced&quot;</span><span class="p">)</span>
<span class="n">lr_balanced</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
    <span class="n">lr_balanced</span><span class="p">,</span>
    <span class="n">X_valid</span><span class="p">,</span>
    <span class="n">y_valid</span><span class="p">,</span>
    <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Non fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;Fraud&quot;</span><span class="p">],</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture9_82_0.png" src="../_images/lecture9_82_0.png" />
</div>
</div>
<p>Again, we have reduced the number of false negatives and increased the number of true positives but we have many more false positives now!
Overall, we can say that our weight adjustments are making the model more likely to make the prediction “fraud” on a sample.</p>
</div>
<div class="section" id="are-we-doing-better-with-class-weight-balanced">
<h4><span class="section-number">9.4.9.4. </span>Are we doing better with <code class="docutils literal notranslate"><span class="pre">class_weight=&quot;balanced&quot;</span></code>?<a class="headerlink" href="#are-we-doing-better-with-class-weight-balanced" title="Permalink to this headline">#</a></h4>
<p>Let’s compare some metrics and find out.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_default</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9988305005457664
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_balanced</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9676048651177296
</pre></div>
</div>
</div>
</div>
<p>Changing the class weight will <strong>generally reduce accuracy</strong>.
The original model was trying to maximize accuracy. Now you’re telling it to do something different.
But we know now that accuracy isn’t the only metric that matters.
Let’s explain why this happens.</p>
<p>Since there are so many more negative examples than positive ones, false-positives affect accuracy much more than false negatives.
Thus, precision matters a lot more than recall in this accuracy calculation.
So, the default method trades off a lot of recall for a bit of precision.
We are paying a “fee” in precision for a greater recall value.</p>
</div>
</div>
</div>
<div class="section" id="let-s-practice">
<h2><span class="section-number">9.5. </span>Let’s Practice<a class="headerlink" href="#let-s-practice" title="Permalink to this headline">#</a></h2>
<a class="reference internal image-reference" href="../_images/Q_cm.png"><img alt="404 image" src="../_images/Q_cm.png" style="width: 60%;" /></a>
<p>Use the diagram above to answer the questions.</p>
<p>1. How many examples did the model of this matrix correctly label as “Guard”?<br />
2. If <strong>Forward</strong> is the positive label, how many <em><strong>false-positive</strong></em> values are there?<br />
3. How many examples does the model incorrectly predict?<br />
4. What is the recall of the confusion matrix assuming that <strong>Forward</strong> is the positive label?<br />
5. What is the precision of the confusion matrix assuming that <strong>Forward</strong> is the positive label?<br />
6. What is the f1 score assuming that <strong>Forward</strong> is the positive label?</p>
<p><strong>True or False:</strong></p>
<p>7. In spam classification, false positives are often more damaging than false negatives (assume “positive” means the email is spam, “negative” means it’s not).<br />
8. In medical diagnosis, high recall is often more important than high precision.<br />
9. The weighted average in the classification report gives equal importance to all classes.<br />
10. Setting <code class="docutils literal notranslate"><span class="pre">class_weight={1:100}</span></code> will make each example of the second class label be counted 100 times.</p>
<div class="dropdown admonition">
<p class="admonition-title">Solutions!</p>
<ol class="simple">
<li><p>26</p></li>
<li><p>4</p></li>
<li><p>7</p></li>
<li><p><span class="math notranslate nohighlight">\(0.86 = 19/22\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(0.83 = 19/23\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\( 2 * \frac{0.86 * 0.83}{0.86 + 0.83} = 0.84\)</span></p></li>
<li><p>True</p></li>
<li><p>True</p></li>
<li><p>False</p></li>
<li><p>True</p></li>
</ol>
</div>
</div>
<div class="section" id="regression-metrics">
<h2><span class="section-number">9.6. </span>Regression Metrics<a class="headerlink" href="#regression-metrics" title="Permalink to this headline">#</a></h2>
<p>For this part, since we need to use data that corresponds to a regression problem, we are bringing back our <a class="reference external" href="https://www.kaggle.com/harrywang/housing">California housing dataset</a>.</p>
<p>We want to predict the median house value for different locations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">housing_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/housing.csv&quot;</span><span class="p">)</span>
<span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">housing_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>


<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">rooms_per_household</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;total_rooms&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">],</span>
                           <span class="n">bedrooms_per_household</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;total_bedrooms&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">],</span>
                           <span class="n">population_per_household</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;population&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">])</span>
                        
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">rooms_per_household</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;total_rooms&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">],</span>
                         <span class="n">bedrooms_per_household</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;total_bedrooms&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">],</span>
                         <span class="n">population_per_household</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;population&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">])</span>
                         
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;total_rooms&#39;</span><span class="p">,</span> <span class="s1">&#39;total_bedrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;population&#39;</span><span class="p">])</span>  
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;total_rooms&#39;</span><span class="p">,</span> <span class="s1">&#39;total_bedrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;population&#39;</span><span class="p">])</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">])</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">]</span>

<span class="n">numeric_features</span> <span class="o">=</span> <span class="p">[</span> <span class="s2">&quot;longitude&quot;</span><span class="p">,</span> <span class="s2">&quot;latitude&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;housing_median_age&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;households&quot;</span><span class="p">,</span> <span class="s2">&quot;median_income&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;rooms_per_household&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;bedrooms_per_household&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;population_per_household&quot;</span><span class="p">]</span>
                     
<span class="n">categorical_features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ocean_proximity&quot;</span><span class="p">]</span>

<span class="n">X_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>households</th>
      <th>median_income</th>
      <th>ocean_proximity</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6051</th>
      <td>-117.75</td>
      <td>34.04</td>
      <td>22.0</td>
      <td>602.0</td>
      <td>3.1250</td>
      <td>INLAND</td>
      <td>4.897010</td>
      <td>1.056478</td>
      <td>4.318937</td>
    </tr>
    <tr>
      <th>20113</th>
      <td>-119.57</td>
      <td>37.94</td>
      <td>17.0</td>
      <td>20.0</td>
      <td>3.4861</td>
      <td>INLAND</td>
      <td>17.300000</td>
      <td>6.500000</td>
      <td>2.550000</td>
    </tr>
    <tr>
      <th>14289</th>
      <td>-117.13</td>
      <td>32.74</td>
      <td>46.0</td>
      <td>708.0</td>
      <td>2.6604</td>
      <td>NEAR OCEAN</td>
      <td>4.738701</td>
      <td>1.084746</td>
      <td>2.057910</td>
    </tr>
    <tr>
      <th>13665</th>
      <td>-117.31</td>
      <td>34.02</td>
      <td>18.0</td>
      <td>285.0</td>
      <td>5.2139</td>
      <td>INLAND</td>
      <td>5.733333</td>
      <td>0.961404</td>
      <td>3.154386</td>
    </tr>
    <tr>
      <th>14471</th>
      <td>-117.23</td>
      <td>32.88</td>
      <td>18.0</td>
      <td>1458.0</td>
      <td>1.8580</td>
      <td>NEAR OCEAN</td>
      <td>3.817558</td>
      <td>1.004801</td>
      <td>4.323045</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We are going to bring in our previous pipelines and fit our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">make_column_transformer</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>

<span class="n">numeric_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">steps</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)),</span> 
           <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">())]</span>
<span class="p">)</span>

<span class="n">categorical_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">steps</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="s2">&quot;missing&quot;</span><span class="p">)),</span>
           <span class="p">(</span><span class="s2">&quot;onehot&quot;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">))]</span>
<span class="p">)</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
<span class="p">(</span><span class="n">numeric_transformer</span><span class="p">,</span> <span class="n">numeric_features</span><span class="p">),</span>
        <span class="p">(</span><span class="n">categorical_transformer</span><span class="p">,</span> <span class="n">categorical_features</span><span class="p">),</span> 
    <span class="n">remainder</span><span class="o">=</span><span class="s1">&#39;passthrough&#39;</span><span class="p">)</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">())</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>As you know, since we aren’t doing classification anymore, so we can’t just check for equality.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predicted_y</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predicted_y</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([111740., 117380., 187700., ..., 271420., 265180.,  60860.])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_train</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([113600., 137500., 170100., ..., 286200., 412500.,  59300.])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">predicted_y</span> <span class="o">==</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c1"># &quot;Accuracy&quot;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.01232773471145564
</pre></div>
</div>
</div>
</div>
<p>The predicted values will rarely be exactly the same as the real ones.
Instead, we need a score that reflects how right/wrong each prediction is or how close we are to the actual numeric value.</p>
<p>We are going to discuss 4 different ones lightly but, if you want to see more regression metrics in detail, you can refer to the <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics">sklearn documentation</a>.</p>
<div class="section" id="mean-squared-error-mse">
<h3><span class="section-number">9.6.1. </span>Mean squared error (MSE)<a class="headerlink" href="#mean-squared-error-mse" title="Permalink to this headline">#</a></h3>
<p>Mean Squared Error is a common measure for error and it is the same as taking the residual sum of squares (RSS, which we saw in linear regression) and dividing it on the number of samples to get an average error per sample.</p>
<div class="math notranslate nohighlight">
\[MSE = \frac{1}{\text{total samples}} \displaystyle\sum_{i=1}^{\text{total samples}} (\text{true}_i - {\text{predicted}_i})^2\]</div>
<div class="math notranslate nohighlight">
\[MSE = \frac{1}{n} \displaystyle\sum_{i=1}^{n} (y_i - {f(x_i)})^2\]</div>
<p>We calculate this by calculating the difference between the predicted and actual value, square it and sum all these values for every example in the data.
The higher the MSE, the worse the model performs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">((</span><span class="n">y_train</span> <span class="o">-</span> <span class="n">predicted_y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2570054492.048064
</pre></div>
</div>
</div>
</div>
<p>Perfect predictions would have MSE = 0 (no error in any predictions).</p>
<p>We can use <code class="docutils literal notranslate"><span class="pre">mean_squared_error</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn.metrics</span></code> again instead of calculating this ourselves.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2570054492.048064
</pre></div>
</div>
</div>
</div>
<div class="section" id="the-disadvantages">
<h4><span class="section-number">9.6.1.1. </span>The disadvantages<a class="headerlink" href="#the-disadvantages" title="Permalink to this headline">#</a></h4>
<p>If we look at MSE value, it’s huge.
Having a mean error of 2.5 billion certainly sounds like a lot,
but is it bad?
How do we know how big a “good” error is?</p>
<p>Unlike classification, in regression, our target has units.
In this case, our target column is the median housing value which is in dollars.
That means that the mean squared error is in dollars<span class="math notranslate nohighlight">\(^2\)</span>.
This is a benefit in the sense that our error has units,
however the units itself are not that helpful (what is a squared dollar?).
Having problem-specific units can also make it hard to compare between models
and develop an intuition for what is a good value
since the score depends on the scale of the targets.
If we were working in cents instead of dollars, our MSE would be 10,000 X (100<sup>2</sup>) higher!</p>
</div>
</div>
<div class="section" id="root-mean-squared-error-rmse">
<h3><span class="section-number">9.6.2. </span>Root mean squared error  (RMSE)<a class="headerlink" href="#root-mean-squared-error-rmse" title="Permalink to this headline">#</a></h3>
<p>The MSE we had before was in <span class="math notranslate nohighlight">\(dollars^2\)</span>,
so an intuitive way to make this more interpretable
would be to take the square root of the value to get the units in dollars.
This is a more relatable metric and it is called the root mean squared error, or RMSE.</p>
<p>This is the square root of <span class="math notranslate nohighlight">\(MSE\)</span>.</p>
<div class="math notranslate nohighlight">
\[RMSE = \sqrt{MSE}\]</div>
<div class="math notranslate nohighlight">
\[RMSE =  \sqrt{\frac{1}{\text{total samples}} \displaystyle\sum_{i=1}^{\text{total samples}} (\text{true}_i - {\text{predicted}_i})^2}\]</div>
<div class="math notranslate nohighlight">
\[RMSE = \sqrt{\frac{1}{n} \displaystyle\sum_{i=1}^{n} (y_i - {f(x_i)})^2}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2570054492.048064
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>50695.704867849156
</pre></div>
</div>
</div>
</div>
<p>This now has the units in dollars.  Instead of 2 billion dollars squared, our error measurement is around $50,000.
This is interpretable for a single prediction,
but how would it work to report an RMSE for an entire dataset?</p>
<p>Let’s plot the predicted vs the true housing prices here.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">predicted</span> <span class="o">=</span> <span class="n">predicted_y</span><span class="p">)</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;median_house_value&#39;</span><span class="p">:</span> <span class="s1">&#39;true&#39;</span><span class="p">})</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">predicted</span> <span class="o">=</span> <span class="n">predicted_y</span><span class="p">)</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;median_house_value&#39;</span><span class="p">:</span> <span class="s1">&#39;true&#39;</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="s1">&#39;--k&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">12</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">12</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;true price&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;predicted price&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture9_112_0.png" src="../_images/lecture9_112_0.png" />
</div>
</div>
<p>When we plot our predictions versus the examples’ actual value, we can see cases where our prediction is way off.
Points under the line <span class="math notranslate nohighlight">\(y=x\)</span> means we’re under-predicting price, points over the line means we’re over-predicting price.</p>
<p><em>Question: Is an RMSE of $30,000 acceptable?</em></p>
<ul class="simple">
<li><p>For a house worth $600k, it seems reasonable! That’s a 5% error.</p></li>
<li><p>For a house worth $60k, that is terrible. It’s a 50% error.</p></li>
</ul>
<p>RMSE is in absolute units and does not account for the original value of the prediction.
So how can we adjust to this?</p>
<p>…Enter <strong>MAPE</strong>!</p>
</div>
<div class="section" id="mape-mean-absolute-percent-error-mape">
<h3><span class="section-number">9.6.3. </span>MAPE - Mean Absolute Percent Error (MAPE)<a class="headerlink" href="#mape-mean-absolute-percent-error-mape" title="Permalink to this headline">#</a></h3>
<p>Instead of computing the absolute error,
we can calculate a percentage error for each example.
Now the errors are both positive (predict too high) and negative (predict too low).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">percent_errors</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_y</span> <span class="o">-</span> <span class="n">y_train</span><span class="p">)</span><span class="o">/</span><span class="n">y_train</span> <span class="o">*</span> <span class="mf">100.</span>
<span class="n">percent_errors</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>6051     -1.637324
20113   -14.632727
14289    10.346855
13665     6.713070
14471   -10.965854
Name: median_house_value, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>We can look at the absolute percent error which now shows us how far off we were independent of direction.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">percent_errors</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>6051      1.637324
20113    14.632727
14289    10.346855
13665     6.713070
14471    10.965854
Name: median_house_value, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>And like MSE, we can take the average over all the examples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">percent_errors</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>18.192997502985218
</pre></div>
</div>
</div>
</div>
<p>This is called <strong>Mean Absolute Percent Error (MAPE)</strong>.
The value is quite interpretable. We can see that on average, we have around 18% error in our predicted median housing valuation.</p>
<p>However,
it is worth pointing out that MAPE also has drawbacks,
most notably that it don’t work well with non-positive values
and that it is biased towards low forecasts,
which makes it unsuitable for predictive models where large errors are expected
(for more details, see https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8279135/).
MAPE is still commonly used because of its ease of interpretation
and there there are variations of MAPE to asses these shortcoming,
most notably symmetric MAPE (SMAPE)).</p>
<!-- For example, for the actual value 100 and estimated value of 90, the MAPE is 0.10. For the same estimated value and actual value of 80, the MAPE is 0.125. Therefore when using MAPE as an objective function, the estimator prefers smaller values and can be biased towards negative errors. --></div>
<div class="section" id="r-2-r-squared">
<h3><span class="section-number">9.6.4. </span><span class="math notranslate nohighlight">\(R^2\)</span> (R squared)<a class="headerlink" href="#r-2-r-squared" title="Permalink to this headline">#</a></h3>
<p>We’ve seen this before!
This is the score that <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> uses by default when you call <code class="docutils literal notranslate"><span class="pre">.score()</span></code> so we’ve already seen <span class="math notranslate nohighlight">\(R^2\)</span> in our regression problems.
You can <a href="https://en.wikipedia.org/wiki/Coefficient_of_determination" target="_blank">read about it here</a> but we are going to just give you the quick notes.</p>
<p>Intuition: <span class="math notranslate nohighlight">\(R^2\)</span> is the residual sum of squares normalized to the total sum of squares. In other words, it is the proportion of the variation in the target feature that the model is able to explain using the variation in the input features.</p>
<ul class="simple">
<li><p>1 = Perfect score, all the variation in the target variable can be explained by the model applied to the input features.</p></li>
<li><p>0 = None of the variation in the target variable can be explained by the model applied to the input features. There is no predictive value in the model as we would achieve the same result by constantly predicting constantly predicting the mean of the data.</p></li>
<li><p>&lt; 0 = The model is performing worse than constantly predicting the mean of the data.</p></li>
</ul>
<p>We can use the default scoring from <code class="docutils literal notranslate"><span class="pre">.score()</span></code> or we can calculate <span class="math notranslate nohighlight">\(R^2\)</span> using <code class="docutils literal notranslate"><span class="pre">r2_score</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(R^2\)</span> is a great default to use for reporting the performance of regression models,
and if you need something that is easier to interpret (such as a percentage)
or an error with units,
you can opt for one of the other metrics above
(there are more notes on R2 versus MAPE in pubmed article I linked to in the MAPE section).</p>
<p>Note that we can reverse the variables in the calculation of MSE but not R<sup>2</sup>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">predicted_y</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2570054492.048064
2570054492.048064
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">predicted_y</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8059396097446094
0.742915970464153
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="id1">
<h2><span class="section-number">9.7. </span>Let’s Practice<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h2>
<p>1. Which measurement will have units which are the square values of the target column units?<br />
2. For which of the following is it possible to have negative values?<br />
3. Which measurement is expressed as a percentage?<br />
4. Calculate the MSE from the values given below.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Observation</p></th>
<th class="head"><p>True Value</p></th>
<th class="head"><p>Predicted Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>4</p></td>
<td><p>5</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>12</p></td>
<td><p>10</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>6</p></td>
<td><p>9</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>9</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>3</p></td>
<td><p>3</p></td>
</tr>
</tbody>
</table>
<p><strong>True or False:</strong></p>
<p>5. We can still use recall and precision for regression problems but now we have other measurements we can use as well.<br />
6. A lower RMSE value indicates a better model.<br />
7. In regression problems, calculating <span class="math notranslate nohighlight">\(R^2\)</span>  using <code class="docutils literal notranslate"><span class="pre">r2_score()</span></code> and <code class="docutils literal notranslate"><span class="pre">.score()</span></code> (with default values) will produce the same results.</p>
<div class="dropdown admonition">
<p class="admonition-title">Solutions!</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(MSE\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(R^2\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(MAPE\)</span></p></li>
<li><p>3</p></li>
<li><p>False</p></li>
<li><p>True</p></li>
<li><p>True</p></li>
</ol>
</div>
</div>
<div class="section" id="passing-different-scoring-methods">
<h2><span class="section-number">9.8. </span>Passing Different Scoring Methods<a class="headerlink" href="#passing-different-scoring-methods" title="Permalink to this headline">#</a></h2>
<p>We now know about all these metrics; how do we implement them?
We are lucky because it’s relatively easy and can be applied to both classification and regression problems.</p>
<p>Let’s start with regression and our regression measurements.
This means bringing back our California housing dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>households</th>
      <th>median_income</th>
      <th>ocean_proximity</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6051</th>
      <td>-117.75</td>
      <td>34.04</td>
      <td>22.0</td>
      <td>602.0</td>
      <td>3.1250</td>
      <td>INLAND</td>
      <td>4.897010</td>
      <td>1.056478</td>
      <td>4.318937</td>
    </tr>
    <tr>
      <th>20113</th>
      <td>-119.57</td>
      <td>37.94</td>
      <td>17.0</td>
      <td>20.0</td>
      <td>3.4861</td>
      <td>INLAND</td>
      <td>17.300000</td>
      <td>6.500000</td>
      <td>2.550000</td>
    </tr>
    <tr>
      <th>14289</th>
      <td>-117.13</td>
      <td>32.74</td>
      <td>46.0</td>
      <td>708.0</td>
      <td>2.6604</td>
      <td>NEAR OCEAN</td>
      <td>4.738701</td>
      <td>1.084746</td>
      <td>2.057910</td>
    </tr>
    <tr>
      <th>13665</th>
      <td>-117.31</td>
      <td>34.02</td>
      <td>18.0</td>
      <td>285.0</td>
      <td>5.2139</td>
      <td>INLAND</td>
      <td>5.733333</td>
      <td>0.961404</td>
      <td>3.154386</td>
    </tr>
    <tr>
      <th>14471</th>
      <td>-117.23</td>
      <td>32.88</td>
      <td>18.0</td>
      <td>1458.0</td>
      <td>1.8580</td>
      <td>NEAR OCEAN</td>
      <td>3.817558</td>
      <td>1.004801</td>
      <td>4.323045</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>And our pipelines.</p>
<p>This time we are using <span class="math notranslate nohighlight">\(k\)</span>-nn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">numeric_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">steps</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)),</span> 
           <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">())]</span>
<span class="p">)</span>

<span class="n">categorical_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">steps</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="s2">&quot;missing&quot;</span><span class="p">)),</span>
           <span class="p">(</span><span class="s2">&quot;onehot&quot;</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">))]</span>
<span class="p">)</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
<span class="p">(</span><span class="n">numeric_transformer</span><span class="p">,</span> <span class="n">numeric_features</span><span class="p">),</span>
        <span class="p">(</span><span class="n">categorical_transformer</span><span class="p">,</span> <span class="n">categorical_features</span><span class="p">),</span> 
    <span class="n">remainder</span><span class="o">=</span><span class="s1">&#39;passthrough&#39;</span><span class="p">)</span>

<span class="n">pipe_regression</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="cross-validation">
<h3><span class="section-number">9.8.1. </span>Cross-validation<a class="headerlink" href="#cross-validation" title="Permalink to this headline">#</a></h3>
<p>Normally after building our pipelines, we would now either do cross-validation or hyperparameter tuning but let’s start with the <code class="docutils literal notranslate"><span class="pre">cross_validate()</span></code> function.</p>
<p>All the possible scoring metrics that this argument accepts are available <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter">here in the sklearn documentation</a>.
Directly from the docs:</p>
<blockquote>
<div><p>All scorer objects follow the convention that higher return values are better than lower return values. Thus metrics which measure the distance between the model and the data, like metrics.mean_squared_error, are available as neg_mean_squared_error which return the negated value of the metric.</p>
</div></blockquote>
<p>So if we wanted the RMSE measure, we would specify <code class="docutils literal notranslate"><span class="pre">neg_mean_squared_error</span></code> and the negated value of the metric will be returned in our dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span>
        <span class="n">pipe_regression</span><span class="p">,</span>
        <span class="n">X_train</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">,</span> 
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.032128</td>
      <td>0.226627</td>
      <td>0.695818</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.030844</td>
      <td>0.210495</td>
      <td>0.707483</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.031129</td>
      <td>0.217490</td>
      <td>0.713788</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.030537</td>
      <td>0.209025</td>
      <td>0.686938</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.027322</td>
      <td>0.171605</td>
      <td>0.724608</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span>
        <span class="n">pipe_regression</span><span class="p">,</span>
        <span class="n">X_train</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">,</span> 
        <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;neg_root_mean_squared_error&#39;</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.031523</td>
      <td>0.212269</td>
      <td>-62462.584290</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.027885</td>
      <td>0.198421</td>
      <td>-63437.715015</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.027871</td>
      <td>0.203763</td>
      <td>-62613.202523</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.027251</td>
      <td>0.227063</td>
      <td>-64204.295214</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.027771</td>
      <td>0.172859</td>
      <td>-59217.838633</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now our cross-validation returns percentages!</p>
<p>We can also return multiple scoring measures together by making a dictionary and then specifying the dictionary in the <code class="docutils literal notranslate"><span class="pre">scoring</span></code> argument.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scoring</span><span class="o">=</span><span class="p">{</span>
    <span class="s2">&quot;neg_mse&quot;</span><span class="p">:</span> <span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">,</span>    
    <span class="s2">&quot;neg_rmse&quot;</span><span class="p">:</span> <span class="s2">&quot;neg_root_mean_squared_error&quot;</span><span class="p">,</span>    
    <span class="s2">&quot;mape_score&quot;</span><span class="p">:</span> <span class="s1">&#39;neg_mean_absolute_percentage_error&#39;</span><span class="p">,</span>
    <span class="s2">&quot;r2&quot;</span><span class="p">:</span> <span class="s2">&quot;r2&quot;</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span>
        <span class="n">pipe_regression</span><span class="p">,</span>
        <span class="n">X_train</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_neg_mse</th>
      <th>test_neg_rmse</th>
      <th>test_mape_score</th>
      <th>test_r2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.030613</td>
      <td>0.214975</td>
      <td>-3.901574e+09</td>
      <td>-62462.584290</td>
      <td>-0.227097</td>
      <td>0.695818</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.027247</td>
      <td>0.203607</td>
      <td>-4.024344e+09</td>
      <td>-63437.715015</td>
      <td>-0.227546</td>
      <td>0.707483</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.028034</td>
      <td>0.205147</td>
      <td>-3.920413e+09</td>
      <td>-62613.202523</td>
      <td>-0.222369</td>
      <td>0.713788</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.027603</td>
      <td>0.208715</td>
      <td>-4.122192e+09</td>
      <td>-64204.295214</td>
      <td>-0.230167</td>
      <td>0.686938</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.027986</td>
      <td>0.175747</td>
      <td>-3.506752e+09</td>
      <td>-59217.838633</td>
      <td>-0.210335</td>
      <td>0.724608</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>If we set <code class="docutils literal notranslate"><span class="pre">return_train_score=True</span></code> we would return a validation and training score for each measurement!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span>
        <span class="n">pipe_regression</span><span class="p">,</span>
        <span class="n">X_train</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
        <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_neg_mse</th>
      <th>train_neg_mse</th>
      <th>test_neg_rmse</th>
      <th>train_neg_rmse</th>
      <th>test_mape_score</th>
      <th>train_mape_score</th>
      <th>test_r2</th>
      <th>train_r2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.030596</td>
      <td>0.213980</td>
      <td>-3.901574e+09</td>
      <td>-2.646129e+09</td>
      <td>-62462.584290</td>
      <td>-51440.540539</td>
      <td>-0.227097</td>
      <td>-0.184210</td>
      <td>0.695818</td>
      <td>0.801659</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.028104</td>
      <td>0.199698</td>
      <td>-4.024344e+09</td>
      <td>-2.627996e+09</td>
      <td>-63437.715015</td>
      <td>-51263.979666</td>
      <td>-0.227546</td>
      <td>-0.184691</td>
      <td>0.707483</td>
      <td>0.799575</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.027226</td>
      <td>0.204043</td>
      <td>-3.920413e+09</td>
      <td>-2.678975e+09</td>
      <td>-62613.202523</td>
      <td>-51758.817852</td>
      <td>-0.222369</td>
      <td>-0.186750</td>
      <td>0.713788</td>
      <td>0.795944</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.027180</td>
      <td>0.206620</td>
      <td>-4.122192e+09</td>
      <td>-2.636180e+09</td>
      <td>-64204.295214</td>
      <td>-51343.743586</td>
      <td>-0.230167</td>
      <td>-0.185108</td>
      <td>0.686938</td>
      <td>0.801232</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.027144</td>
      <td>0.173949</td>
      <td>-3.506752e+09</td>
      <td>-2.239671e+09</td>
      <td>-59217.838633</td>
      <td>-47325.157312</td>
      <td>-0.210335</td>
      <td>-0.169510</td>
      <td>0.724608</td>
      <td>0.832498</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="what-about-hyperparameter-tuning">
<h3><span class="section-number">9.8.2. </span>What about hyperparameter tuning?<a class="headerlink" href="#what-about-hyperparameter-tuning" title="Permalink to this headline">#</a></h3>
<p>We can do exactly the same thing we saw above with <code class="docutils literal notranslate"><span class="pre">cross_validate()</span></code> but instead with <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> and <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>


<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;kneighborsregressor__n_neighbors&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]}</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">pipe_regression</span><span class="p">,</span>
    <span class="n">param_grid</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
    <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> 
    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_absolute_percentage_error&#39;</span>
<span class="p">);</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;kneighborsregressor__n_neighbors&#39;: 5}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.2235027119616972
</pre></div>
</div>
</div>
</div>
<p>If we used another scoring metric,
we might end up with another results for the best hyperparameter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># &#39;max_error&#39; is a metric we haven&#39;t talked about and it is not that useful,</span>
<span class="c1"># I just use it here to show that the choice of metric can influence the returned best hyperparameters.</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">pipe_regression</span><span class="p">,</span>
    <span class="n">param_grid</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
    <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> 
    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;max_error&#39;</span>
<span class="p">);</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;kneighborsregressor__n_neighbors&#39;: 100}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-373468.55
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="and-with-classification">
<h3><span class="section-number">9.8.3. </span>… and with Classification?<a class="headerlink" href="#and-with-classification" title="Permalink to this headline">#</a></h3>
<p>Let’s bring back our credit card data set and build our pipeline.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cc_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">111</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]),</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]),</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We can use <code class="docutils literal notranslate"><span class="pre">class_weight='balanced'</span></code> in our classifier…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>


<span class="n">dt_model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">100</span><span class="p">)}</span>
</pre></div>
</div>
</div>
</div>
<p>… and tune our model for the thing we care about.</p>
<p>In this case, we are specifying the <code class="docutils literal notranslate"><span class="pre">f1</span></code> score.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>
<span class="n">grid_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
    <span class="n">dt_model</span><span class="p">,</span>
    <span class="n">param_grid</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">2080</span>
<span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 3 folds for each of 6 candidates, totalling 18 fits
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[CV] END .......................................max_depth=65; total time=   2.3s
[CV] END .......................................max_depth=12; total time=   2.4s
[CV] END .......................................max_depth=69; total time=   2.5s
[CV] END .......................................max_depth=69; total time=   2.6s
[CV] END .......................................max_depth=12; total time=   2.6s
[CV] END .......................................max_depth=12; total time=   2.7s
[CV] END .......................................max_depth=65; total time=   2.6s
[CV] END .......................................max_depth=69; total time=   3.1s
[CV] END ........................................max_depth=4; total time=   2.0s
[CV] END ........................................max_depth=4; total time=   1.9s
[CV] END ........................................max_depth=4; total time=   2.0s
[CV] END .......................................max_depth=43; total time=   2.8s
[CV] END .......................................max_depth=65; total time=   2.9s
[CV] END .......................................max_depth=43; total time=   3.0s
[CV] END .......................................max_depth=43; total time=   3.0s
[CV] END .......................................max_depth=62; total time=   2.7s
[CV] END .......................................max_depth=62; total time=   2.1s
[CV] END .......................................max_depth=62; total time=   2.1s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;max_depth&#39;: 69}
</pre></div>
</div>
</div>
</div>
<p>This returns the <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> value that results in the highest <code class="docutils literal notranslate"><span class="pre">f1</span></code> score, not the <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> with the highest accuracy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Validation performance</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7877624963028689
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Test performance</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7698113207547169
</pre></div>
</div>
</div>
</div>
<p>Let’s look at our recall score to compare to the next section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7338129496402878
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span><span class="n">grid_search</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture9_161_0.png" src="../_images/lecture9_161_0.png" />
</div>
</div>
<p>If we now tune hyperparameters based on their recall score instead of precision,
you will se that we select a different value for <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>
and that our recall score is higher with this value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span>
    <span class="n">dt_model</span><span class="p">,</span>
    <span class="n">param_grid</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;recall&#39;</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">2080</span>
<span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 3 folds for each of 6 candidates, totalling 18 fits
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[CV] END .......................................max_depth=69; total time=   2.3s
[CV] END .......................................max_depth=12; total time=   2.4s
[CV] END .......................................max_depth=65; total time=   2.5s
[CV] END .......................................max_depth=12; total time=   2.5s
[CV] END .......................................max_depth=69; total time=   2.7s
[CV] END .......................................max_depth=69; total time=   2.7s
[CV] END .......................................max_depth=12; total time=   2.7s
[CV] END .......................................max_depth=65; total time=   2.7s
[CV] END ........................................max_depth=4; total time=   1.6s
[CV] END ........................................max_depth=4; total time=   1.6s
[CV] END ........................................max_depth=4; total time=   1.8s
[CV] END .......................................max_depth=65; total time=   2.5s
[CV] END .......................................max_depth=43; total time=   2.5s
[CV] END .......................................max_depth=62; total time=   2.1s
[CV] END .......................................max_depth=43; total time=   2.5s
[CV] END .......................................max_depth=43; total time=   2.5s
[CV] END .......................................max_depth=62; total time=   2.0s
[CV] END .......................................max_depth=62; total time=   1.8s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;max_depth&#39;: 4}
</pre></div>
</div>
</div>
</div>
<p>This returns the <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> value that results in the highest <code class="docutils literal notranslate"><span class="pre">f1</span></code> score, not the <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> with the highest accuracy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Validation performance</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8839152059491043
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Test performance</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.841726618705036
</pre></div>
</div>
</div>
</div>
<p>As you can see above,
our recall score is now higher
(remember that the default scoring method changes to the metric used during hyperparameter optimization)
If we look at our f1 score we can see that it is worse than before,
as expected.
When we are optimizing on recall alone,
we are only trying to catch as many of the true positives as possible
and don’t care about that we are incorrectly classifying many negatives as positives
which will lead to a lower precision and f1 score.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.1984732824427481
</pre></div>
</div>
</div>
</div>
<p>In the confusion matrix,
we have many more values in the top right quadrant
because there is no penalty for incorrectly classifying observations here when just using recall.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span> <span class="n">grid_search</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture9_171_0.png" src="../_images/lecture9_171_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="id2">
<h2><span class="section-number">9.9. </span>Let’s Practice<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h2>
<p><strong>True or False:</strong></p>
<ol class="simple">
<li><p>We are limited to the scoring measures offered from sklearn.</p></li>
<li><p>If we specify the scoring method in <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> and <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code>, <code class="docutils literal notranslate"><span class="pre">best_param_</span></code>  will return the parameters with the best specified measure.*</p></li>
</ol>
<div class="dropdown admonition">
<p class="admonition-title">Solutions!</p>
<ol class="simple">
<li><p>False, we could also specify our own scorer function https://scikit-learn.org/stable/modules/model_evaluation.html#scoring</p></li>
<li><p>True</p></li>
</ol>
</div>
</div>
<div class="section" id="let-s-practice-coding">
<h2><span class="section-number">9.10. </span>Let’s Practice - Coding<a class="headerlink" href="#let-s-practice-coding" title="Permalink to this headline">#</a></h2>
<p>Let’s bring back the Pokémon dataset that we saw previously.</p>
<p>This time let’s try to predict whether a Pokémon has a legendary status or not based on their other attributes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pk_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/pokemon.csv&#39;</span><span class="p">)</span>

<span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">pk_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X_train_big</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;legendary&#39;</span><span class="p">])</span>
<span class="n">y_train_big</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;legendary&#39;</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;legendary&#39;</span><span class="p">])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;legendary&#39;</span><span class="p">]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_train_big</span><span class="p">,</span> 
    <span class="n">y_train_big</span><span class="p">,</span> 
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> 
    <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">X_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>legendary
0    359
1     33
Name: count, dtype: int64
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>deck_no</th>
      <th>attack</th>
      <th>defense</th>
      <th>sp_attack</th>
      <th>sp_defense</th>
      <th>speed</th>
      <th>capture_rt</th>
      <th>total_bs</th>
      <th>type</th>
      <th>gen</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>124</th>
      <td>Electabuzz</td>
      <td>125</td>
      <td>83</td>
      <td>57</td>
      <td>95</td>
      <td>85</td>
      <td>105</td>
      <td>45</td>
      <td>490</td>
      <td>electric</td>
      <td>1</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Butterfree</td>
      <td>12</td>
      <td>45</td>
      <td>50</td>
      <td>90</td>
      <td>80</td>
      <td>70</td>
      <td>45</td>
      <td>395</td>
      <td>bug</td>
      <td>1</td>
    </tr>
    <tr>
      <th>77</th>
      <td>Rapidash</td>
      <td>78</td>
      <td>100</td>
      <td>70</td>
      <td>80</td>
      <td>80</td>
      <td>105</td>
      <td>60</td>
      <td>500</td>
      <td>fire</td>
      <td>1</td>
    </tr>
    <tr>
      <th>405</th>
      <td>Budew</td>
      <td>406</td>
      <td>30</td>
      <td>35</td>
      <td>50</td>
      <td>70</td>
      <td>55</td>
      <td>255</td>
      <td>280</td>
      <td>grass</td>
      <td>4</td>
    </tr>
    <tr>
      <th>799</th>
      <td>Necrozma</td>
      <td>800</td>
      <td>107</td>
      <td>101</td>
      <td>127</td>
      <td>89</td>
      <td>79</td>
      <td>3</td>
      <td>600</td>
      <td>psychic</td>
      <td>7</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Nidoking</td>
      <td>34</td>
      <td>102</td>
      <td>77</td>
      <td>85</td>
      <td>75</td>
      <td>85</td>
      <td>45</td>
      <td>505</td>
      <td>poison</td>
      <td>1</td>
    </tr>
    <tr>
      <th>458</th>
      <td>Snover</td>
      <td>459</td>
      <td>62</td>
      <td>50</td>
      <td>62</td>
      <td>60</td>
      <td>40</td>
      <td>120</td>
      <td>334</td>
      <td>grass</td>
      <td>4</td>
    </tr>
    <tr>
      <th>234</th>
      <td>Smeargle</td>
      <td>235</td>
      <td>20</td>
      <td>35</td>
      <td>20</td>
      <td>45</td>
      <td>75</td>
      <td>45</td>
      <td>250</td>
      <td>normal</td>
      <td>2</td>
    </tr>
    <tr>
      <th>287</th>
      <td>Vigoroth</td>
      <td>288</td>
      <td>80</td>
      <td>80</td>
      <td>55</td>
      <td>55</td>
      <td>90</td>
      <td>120</td>
      <td>440</td>
      <td>normal</td>
      <td>3</td>
    </tr>
    <tr>
      <th>561</th>
      <td>Yamask</td>
      <td>562</td>
      <td>30</td>
      <td>85</td>
      <td>55</td>
      <td>65</td>
      <td>30</td>
      <td>190</td>
      <td>303</td>
      <td>ghost</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
<p>392 rows × 11 columns</p>
</div></div></div>
</div>
<p>Let’s do cross-validation and look at the scores from cross-validation of not just accuracy, but precision and recall and the f1 score as well.</p>
<ol class="simple">
<li><p>Build a pipeline containing the column transformer and an SVC model and set <code class="docutils literal notranslate"><span class="pre">class_weight=&quot;balanced&quot;</span></code> in the SVM classifier.</p></li>
<li><p>Perform cross-validation using cross-validate on the training split using the scoring measures accuracy, precision, recall and f1. Save the results in a dataframe.</p></li>
</ol>
<p><strong>Solutions</strong></p>
<p>1.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>


<span class="n">num_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">SimpleImputer</span><span class="p">(),</span>
    <span class="n">StandardScaler</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">cat_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">),</span>
    <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">num_cols</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="s1">&#39;number&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span>

<span class="n">num_cols</span> <span class="o">=</span> <span class="p">[</span>
 <span class="s1">&#39;capture_rt&#39;</span><span class="p">,</span>
 <span class="s1">&#39;total_bs&#39;</span><span class="p">,</span>
 <span class="s1">&#39;gen&#39;</span><span class="p">]</span>
<span class="n">cat_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">]</span>

<span class="n">preprocessing</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
    <span class="p">(</span><span class="n">num_pipe</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">),</span>
    <span class="p">(</span><span class="n">cat_pipe</span><span class="p">,</span> <span class="n">cat_cols</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">main_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">preprocessing</span><span class="p">,</span>
    <span class="n">SVC</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>2.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span>
        <span class="n">main_pipe</span><span class="p">,</span>
        <span class="n">X_valid</span><span class="p">,</span>
        <span class="n">y_valid</span><span class="p">,</span>
        <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="s1">&#39;recall&#39;</span><span class="p">,</span> <span class="s1">&#39;f1&#39;</span><span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_accuracy</th>
      <th>test_precision</th>
      <th>test_recall</th>
      <th>test_f1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.015617</td>
      <td>0.007359</td>
      <td>0.941176</td>
      <td>0.666667</td>
      <td>0.666667</td>
      <td>0.666667</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.006605</td>
      <td>0.008269</td>
      <td>0.941176</td>
      <td>0.666667</td>
      <td>0.666667</td>
      <td>0.666667</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.006800</td>
      <td>0.006950</td>
      <td>0.911765</td>
      <td>0.500000</td>
      <td>0.666667</td>
      <td>0.571429</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.007100</td>
      <td>0.008601</td>
      <td>0.939394</td>
      <td>0.500000</td>
      <td>0.500000</td>
      <td>0.500000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.007335</td>
      <td>0.006308</td>
      <td>0.909091</td>
      <td>0.500000</td>
      <td>0.333333</td>
      <td>0.400000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="what-we-ve-learned-today">
<h2><span class="section-number">9.11. </span>What We’ve Learned Today<a class="headerlink" href="#what-we-ve-learned-today" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>The components of a confusion matrix.</p></li>
<li><p>How to calculate precision, recall, and f1-score.</p></li>
<li><p>How to implement the <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> argument.</p></li>
<li><p>Some of the different scoring metrics used in assessing regression problems; MSE, RMSE, <span class="math notranslate nohighlight">\(R^2\)</span>, MAPE.</p></li>
<li><p>How to apply different scoring functions with <code class="docutils literal notranslate"><span class="pre">cross_validate</span></code>, <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> and <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code>.</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="lecture8.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">8. </span>Business Objectives/Statistical Questions and Feature Selection</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="lecture10a.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">10. </span>Data Science Ethics</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Quan Nguyen<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>