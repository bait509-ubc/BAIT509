
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4. kNN regression, Support Vector Machines, and Feature Preprocessing &#8212; BAIT 509&lt;br&gt;Business Applications of Machine Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="canonical" href="https://bait509-ubc.github.io/BAIT509/intro.html/lectures/lecture4.html" />
    <link rel="shortcut icon" href="../_static/bait_logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5. Preprocessing Categorical Features and Column Transformer" href="lecture5.html" />
    <link rel="prev" title="3. Baseline models &amp; k-Nearest Neighbours" href="lecture3.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/bait_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">BAIT 509<br>Business Applications of Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Things You Should Know
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/who.html">
   Who: Quan Nguyen
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/how.html">
   How: The Course Structure
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/what.html">
   What: Learning Outcomes
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="lecture1.html">
   1. Intro to ML &amp;  Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture2.html">
   2. Splitting and Cross-validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture3.html">
   3. Baseline models &amp; k-Nearest Neighbours
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   4. kNN regression, Support Vector Machines, and Feature Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture5.html">
   5. Preprocessing Categorical Features and Column Transformer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture6.html">
   6. Naive Bayes and Hyperparameter Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture7.html">
   7. Linear Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture8.html">
   8. Business Objectives/Statistical Questions and Feature Selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture9.html">
   9. Classification and Regression Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture10a.html">
   10. Data Science Ethics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture10b.html">
   11. Multi-Class Classification (Optional)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/attribution.html">
   Attribution
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/bait509-ubc/BAIT509/issues/new?title=Issue%20on%20page%20%2Flectures/lecture4.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/lectures/lecture4.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lecture-learning-objectives">
   4.1. Lecture Learning Objectives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#five-minute-recap-lightning-questions">
   4.2. Five Minute Recap/ Lightning Questions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-lingering-questions">
     4.2.1. Some lingering questions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-with-k-nn">
   4.3. Regression with
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -NN
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pros-and-cons-of-k-nearest-neighbours">
   4.4. Pros and Cons of 𝑘 -Nearest Neighbours
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pros">
     4.4.1. Pros:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cons">
     4.4.2. Cons:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice">
   4.5. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#support-vector-machines-svms-with-rbf-kernel">
   4.6. Support Vector Machines (SVMs) with RBF Kernel
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperparameters-of-svm">
     4.6.1. Hyperparameters of SVM
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gamma-and-the-fundamental-trade-off">
       4.6.1.1.
       <code class="docutils literal notranslate">
        <span class="pre">
         gamma
        </span>
       </code>
       and the fundamental trade-off
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#c-and-the-fundamental-trade-off">
       4.6.1.2.
       <code class="docutils literal notranslate">
        <span class="pre">
         C
        </span>
       </code>
       and the fundamental trade-off
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   4.7. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice-coding">
   4.8. Let’s Practice - Coding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing">
   4.9. Preprocessing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-importance-of-preprocessing-an-example-of-why">
     4.9.1. The importance of Preprocessing - An Example of Why
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#basketball-dataset">
       4.9.1.1. Basketball dataset
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sklearn-s-predict-vs-transform">
     4.9.2. Sklearn’s
     <em>
      predict
     </em>
     vs
     <em>
      transform
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#common-preprocessing-techniques">
     4.9.3. Common preprocessing techniques
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   4.10. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#california-housing-data-a-case-study">
   4.11. California housing data (A case study)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#when-is-it-ok-process-the-data-before-splitting-of-the-test-portion">
     4.11.1. When is it OK process the data before splitting of the test portion?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing-imputation">
   4.12. Preprocessing: Imputation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-we-don-t-drop-the-rows">
     4.12.1. Why we don’t drop the rows
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-we-don-t-drop-the-column">
     4.12.2. Why we don’t drop the column
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-we-use-imputation">
     4.12.3. Why we use imputation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#more-sophisticated-imputation-methods">
     4.12.4. More sophisticated imputation methods
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing-scaling">
   4.13. Preprocessing: Scaling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   4.14. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-transformations-and-the-golden-rule">
   4.15. Feature transformations and the golden rule
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bad-methodology-1-scaling-the-data-separately">
     4.15.1. Bad methodology 1: Scaling the data separately
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bad-methodology-2-scaling-the-data-together">
     4.15.2. Bad methodology 2: Scaling the data together
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pipelines">
   4.16. Pipelines
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   4.17. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   4.18. Let’s Practice - Coding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-we-ve-learned-today-a-id-9-a">
   4.19. What We’ve Learned Today
   <a id="9">
   </a>
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>kNN regression, Support Vector Machines, and Feature Preprocessing</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lecture-learning-objectives">
   4.1. Lecture Learning Objectives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#five-minute-recap-lightning-questions">
   4.2. Five Minute Recap/ Lightning Questions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#some-lingering-questions">
     4.2.1. Some lingering questions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-with-k-nn">
   4.3. Regression with
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -NN
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pros-and-cons-of-k-nearest-neighbours">
   4.4. Pros and Cons of 𝑘 -Nearest Neighbours
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pros">
     4.4.1. Pros:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cons">
     4.4.2. Cons:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice">
   4.5. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#support-vector-machines-svms-with-rbf-kernel">
   4.6. Support Vector Machines (SVMs) with RBF Kernel
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperparameters-of-svm">
     4.6.1. Hyperparameters of SVM
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gamma-and-the-fundamental-trade-off">
       4.6.1.1.
       <code class="docutils literal notranslate">
        <span class="pre">
         gamma
        </span>
       </code>
       and the fundamental trade-off
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#c-and-the-fundamental-trade-off">
       4.6.1.2.
       <code class="docutils literal notranslate">
        <span class="pre">
         C
        </span>
       </code>
       and the fundamental trade-off
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   4.7. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice-coding">
   4.8. Let’s Practice - Coding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing">
   4.9. Preprocessing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-importance-of-preprocessing-an-example-of-why">
     4.9.1. The importance of Preprocessing - An Example of Why
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#basketball-dataset">
       4.9.1.1. Basketball dataset
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sklearn-s-predict-vs-transform">
     4.9.2. Sklearn’s
     <em>
      predict
     </em>
     vs
     <em>
      transform
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#common-preprocessing-techniques">
     4.9.3. Common preprocessing techniques
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   4.10. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#california-housing-data-a-case-study">
   4.11. California housing data (A case study)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#when-is-it-ok-process-the-data-before-splitting-of-the-test-portion">
     4.11.1. When is it OK process the data before splitting of the test portion?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing-imputation">
   4.12. Preprocessing: Imputation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-we-don-t-drop-the-rows">
     4.12.1. Why we don’t drop the rows
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-we-don-t-drop-the-column">
     4.12.2. Why we don’t drop the column
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-we-use-imputation">
     4.12.3. Why we use imputation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#more-sophisticated-imputation-methods">
     4.12.4. More sophisticated imputation methods
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preprocessing-scaling">
   4.13. Preprocessing: Scaling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   4.14. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-transformations-and-the-golden-rule">
   4.15. Feature transformations and the golden rule
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bad-methodology-1-scaling-the-data-separately">
     4.15.1. Bad methodology 1: Scaling the data separately
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bad-methodology-2-scaling-the-data-together">
     4.15.2. Bad methodology 2: Scaling the data together
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pipelines">
   4.16. Pipelines
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   4.17. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   4.18. Let’s Practice - Coding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-we-ve-learned-today-a-id-9-a">
   4.19. What We’ve Learned Today
   <a id="9">
   </a>
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="knn-regression-support-vector-machines-and-feature-preprocessing">
<h1><span class="section-number">4. </span>kNN regression, Support Vector Machines, and Feature Preprocessing<a class="headerlink" href="#knn-regression-support-vector-machines-and-feature-preprocessing" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importing common libraries that we have been using previously</span>
<span class="kn">import</span> <span class="nn">altair</span> <span class="k">as</span> <span class="nn">alt</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span><span class="p">,</span> <span class="n">DummyRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">euclidean_distances</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">),</span> <span class="s2">&quot;code&quot;</span><span class="p">))</span>
<span class="kn">from</span> <span class="nn">plotting_functions</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="lecture-learning-objectives">
<h2><span class="section-number">4.1. </span>Lecture Learning Objectives<a class="headerlink" href="#lecture-learning-objectives" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Explain kNN for regression.</p></li>
<li><p>Explain the concept of SVMs</p></li>
<li><p>Use SVMs with the RBF kernel.</p></li>
<li><p>Identify when to implement feature transformations such as imputation and scaling.</p></li>
<li><p>Describe the difference between normalizing and standardizing and be able to use scikit-learn’s <code class="docutils literal notranslate"><span class="pre">MinMaxScaler()</span></code> and <code class="docutils literal notranslate"><span class="pre">StandardScaler()</span></code> to pre-process numeric features.</p></li>
<li><p>Apply <code class="docutils literal notranslate"><span class="pre">sklearn.pipeline.Pipeline</span></code> to build a machine learning pipeline.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> for applying numerical feature transformations to the data.</p></li>
<li><p>Discuss the golden rule in the context of feature transformations.</p></li>
</ul>
</div>
<div class="section" id="five-minute-recap-lightning-questions">
<h2><span class="section-number">4.2. </span>Five Minute Recap/ Lightning Questions<a class="headerlink" href="#five-minute-recap-lightning-questions" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>When using a Dummy Regressor what value does the model predict for unseen data?</p></li>
<li><p>When using a Dummy Classifier (the one we examined in lecture) what class does the model predict for unseen data?</p></li>
<li><p>What is the name of the distance metric used in the <span class="math notranslate nohighlight">\(k\)</span>-nn model we looked at?</p></li>
<li><p>If a dataset has 14 features and 1 target column, how many dimensions will the feature vector be?</p></li>
<li><p>What is the hyperparameter name of the <span class="math notranslate nohighlight">\(k\)</span>-nn classifier we looked at last lecture?</p></li>
</ul>
<div class="section" id="some-lingering-questions">
<h3><span class="section-number">4.2.1. </span>Some lingering questions<a class="headerlink" href="#some-lingering-questions" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>How does a <span class="math notranslate nohighlight">\(k\)</span>-nn Regressor work?</p></li>
<li><p>Are we ready to do machine learning on real-world datasets?</p></li>
<li><p>We’ve looked at data with numeric features but what do we do if we have features with categories or string values?</p></li>
<li><p>What happens if we are missing data in our features?</p></li>
<li><p>Is there a cleaner way to do all the steps we need to do?</p></li>
</ul>
</div>
</div>
<div class="section" id="regression-with-k-nn">
<h2><span class="section-number">4.3. </span>Regression with <span class="math notranslate nohighlight">\(k\)</span>-NN<a class="headerlink" href="#regression-with-k-nn" title="Permalink to this headline">#</a></h2>
<p>In <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbour regression, we take the average of <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbours instead of the majority vote.</p>
<p>Let’s look at an example.</p>
<p>Here we are creating some synthetic data with fifty examples and only one feature.</p>
<p>We only have one feature of <code class="docutils literal notranslate"><span class="pre">length</span></code> and our goal is to predict <code class="docutils literal notranslate"><span class="pre">weight</span></code>.</p>
<p>Regression plots more naturally in 1D, classification in 2D, but of course we can do either for any <span class="math notranslate nohighlight">\(d\)</span></p>
<p>Right now, do not worry about the code and only focus on data and our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">X_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">n</span><span class="p">)</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_1</span><span class="p">[:,</span><span class="kc">None</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;length&#39;</span><span class="p">])</span>
<span class="n">X</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.017641</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.044818</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.091420</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.144858</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.181941</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span><span class="mi">2</span> <span class="o">+</span> <span class="n">X_1</span><span class="p">[:,</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="mi">5</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">])</span>
<span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>weight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.879136</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.997894</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.478710</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.085554</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.966069</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">snake_X_train</span><span class="p">,</span> <span class="n">snake_X_test</span><span class="p">,</span> <span class="n">snake_y_train</span><span class="p">,</span> <span class="n">snake_y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s visualize our training data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">source</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">snake_X_train</span><span class="p">,</span> <span class="n">snake_y_train</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">scatter</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span><span class="o">.</span><span class="n">mark_point</span><span class="p">(</span><span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
    <span class="n">alt</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="s1">&#39;length:Q&#39;</span><span class="p">),</span>
    <span class="n">alt</span><span class="o">.</span><span class="n">Y</span><span class="p">(</span><span class="s1">&#39;weight:Q&#39;</span><span class="p">))</span>

<span class="n">scatter</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
  #altair-viz-60720bf3af6b41ccaeb8ec4b6ee8d436.vega-embed {
    width: 100%;
    display: flex;
  }

  #altair-viz-60720bf3af6b41ccaeb8ec4b6ee8d436.vega-embed details,
  #altair-viz-60720bf3af6b41ccaeb8ec4b6ee8d436.vega-embed details summary {
    position: relative;
  }
</style>
<div id="altair-viz-60720bf3af6b41ccaeb8ec4b6ee8d436"></div>
<script type="text/javascript">
  var VEGA_DEBUG = (typeof VEGA_DEBUG == "undefined") ? {} : VEGA_DEBUG;
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== "altair-viz-60720bf3af6b41ccaeb8ec4b6ee8d436") {
      outputDiv = document.getElementById("altair-viz-60720bf3af6b41ccaeb8ec4b6ee8d436");
    }
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm/vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm/vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm/vega-lite@5.15.1?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm/vega-embed@6?noext",
    };

    function maybeLoadScript(lib, version) {
      var key = `${lib.replace("-", "")}_version`;
      return (VEGA_DEBUG[key] == version) ?
        Promise.resolve(paths[lib]) :
        new Promise(function(resolve, reject) {
          var s = document.createElement('script');
          document.getElementsByTagName("head")[0].appendChild(s);
          s.async = true;
          s.onload = () => {
            VEGA_DEBUG[key] = version;
            return resolve(paths[lib]);
          };
          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
          s.src = paths[lib];
        });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else {
      maybeLoadScript("vega", "5")
        .then(() => maybeLoadScript("vega-lite", "5.15.1"))
        .then(() => maybeLoadScript("vega-embed", "6"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 300, "continuousHeight": 300}}, "data": {"name": "data-b6b36d9253ffa44549ee85a5d64b6eb6"}, "mark": {"type": "point", "color": "green", "filled": true}, "encoding": {"x": {"field": "length", "type": "quantitative"}, "y": {"field": "weight", "type": "quantitative"}}, "height": 300, "width": 500, "$schema": "https://vega.github.io/schema/vega-lite/v5.15.1.json", "datasets": {"data-b6b36d9253ffa44549ee85a5d64b6eb6": [{"length": 0.8636790430972607, "weight": 4.576361037001124}, {"length": 1.9261422504970944, "weight": 13.202452240297143}, {"length": 0.4635223269063644, "weight": 3.036717957612905}, {"length": 1.659269208383312, "weight": 10.741236182681416}, {"length": 0.19430885385429708, "weight": 1.8282080103323208}, {"length": 0.04481789861428447, "weight": 0.9978944887899464}, {"length": 0.25439884335892937, "weight": 1.4050286615609828}, {"length": 1.1001689778262722, "weight": 6.658544218660192}, {"length": 1.9978725971978604, "weight": 10.793341712878705}, {"length": 1.00228938297457, "weight": 5.816130197227949}, {"length": 1.269087747645001, "weight": 8.14709171213338}, {"length": 0.6155816412329262, "weight": 3.8814700785811547}, {"length": 1.430134918262468, "weight": 10.942452943373507}, {"length": 1.0616820749689326, "weight": 7.050004673208427}, {"length": 0.2842007136313087, "weight": 2.0259473636361065}, {"length": 0.790796632453904, "weight": 5.412164286624593}, {"length": 1.9430446949938083, "weight": 9.969047660376281}, {"length": 0.1448579115838513, "weight": 3.0855539261640805}, {"length": 0.9313538600000172, "weight": 7.126420940707391}, {"length": 1.790821845529422, "weight": 9.666842021995915}, {"length": 0.18194088602394864, "weight": 0.9660688867970529}, {"length": 0.6680020152213719, "weight": 6.6004067700389495}, {"length": 1.481690661909318, "weight": 9.76601245186589}, {"length": 0.5758672037560256, "weight": 3.2341883032876337}, {"length": 1.7746097947686443, "weight": 10.826327046810647}, {"length": 1.0058645065193186, "weight": 6.3989427144772195}, {"length": 1.5222278801204971, "weight": 7.970989072227188}, {"length": 1.5888137071881239, "weight": 10.052971989802893}, {"length": 0.3714529237948939, "weight": 2.5827469509487457}, {"length": 1.2972445915032906, "weight": 7.4175478369773735}, {"length": 1.3271308108279647, "weight": 9.708141426694272}, {"length": 0.9066035456620644, "weight": 6.811819097396922}, {"length": 1.697223012379464, "weight": 8.902665018051042}, {"length": 0.7669692466886153, "weight": 3.9387370250353544}, {"length": 0.6918259683827501, "weight": 4.384694352965299}, {"length": 1.5471471399891856, "weight": 9.877240942967013}, {"length": 1.3842759805475549, "weight": 9.897884290328975}, {"length": 1.1581849350007274, "weight": 6.414029739258383}, {"length": 0.09142003290228187, "weight": 1.4787104396491553}, {"length": 1.832353950861439, "weight": 10.574916090691092}]}}, {"mode": "vega-lite"});
</script></div></div>
</div>
<p>Now let’s try the <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbours regressor on this data.</p>
<p>Then we create our <code class="docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code> object with <code class="docutils literal notranslate"><span class="pre">n_neighbors=1</span></code> so we are only considering 1 neighbour and with <code class="docutils literal notranslate"><span class="pre">uniform</span></code> weights (the default).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>

<span class="n">knnr_1</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">knnr_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">,</span><span class="n">snake_y_train</span><span class="p">);</span>

<span class="n">predicted</span> <span class="o">=</span> <span class="n">knnr_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">)</span>
<span class="n">predicted</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 4.57636104],
       [13.20245224],
       [ 3.03671796],
       [10.74123618],
       [ 1.82820801],
       [ 0.99789449],
       [ 1.40502866],
       [ 6.65854422],
       [10.79334171],
       [ 5.8161302 ],
       [ 8.14709171],
       [ 3.88147008],
       [10.94245294],
       [ 7.05000467],
       [ 2.02594736],
       [ 5.41216429],
       [ 9.96904766],
       [ 3.08555393],
       [ 7.12642094],
       [ 9.66684202],
       [ 0.96606889],
       [ 6.60040677],
       [ 9.76601245],
       [ 3.2341883 ],
       [10.82632705],
       [ 6.39894271],
       [ 7.97098907],
       [10.05297199],
       [ 2.58274695],
       [ 7.41754784],
       [ 9.70814143],
       [ 6.8118191 ],
       [ 8.90266502],
       [ 3.93873703],
       [ 4.38469435],
       [ 9.87724094],
       [ 9.89788429],
       [ 6.41402974],
       [ 1.47871044],
       [10.57491609]])
</pre></div>
</div>
</div>
</div>
<p>If we scored over regressors we get this perfect score of one since we have <code class="docutils literal notranslate"><span class="pre">n_neighbors=1</span></code> we are likely to overfit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knnr_1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">,</span> <span class="n">snake_y_train</span><span class="p">)</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
<p>Plotting this we can see our model is trying to get every example correct since n_neighbors=1. (the mean of 1 point is just going to be the point value)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">),</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">knnr_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">grid</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">,</span> <span class="n">snake_y_train</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;length&quot;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture4_16_0.png" src="../_images/lecture4_16_0.png" />
</div>
</div>
<p>What happens when we use <code class="docutils literal notranslate"><span class="pre">n_neighbors=10</span></code>?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knnr_10</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;uniform&quot;</span><span class="p">)</span>
<span class="n">knnr_10</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">,</span> <span class="n">snake_y_train</span><span class="p">)</span>
<span class="n">knnr_10</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">,</span> <span class="n">snake_y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9254540554756747
</pre></div>
</div>
</div>
</div>
<p>Now we can see we are getting a lower score over the training set. Our score decreased from 1.0 when to had <code class="docutils literal notranslate"><span class="pre">n_neighbors=1</span></code> to now having a score of 0.925.</p>
<p>When we plot our model, we can see that it no longer is trying to get every example correct.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">),</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">knnr_10</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">grid</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">snake_X_train</span><span class="p">,</span> <span class="n">snake_y_train</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;length&quot;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture4_20_0.png" src="../_images/lecture4_20_0.png" />
</div>
</div>
</div>
<div class="section" id="pros-and-cons-of-k-nearest-neighbours">
<h2><span class="section-number">4.4. </span>Pros and Cons of 𝑘 -Nearest Neighbours<a class="headerlink" href="#pros-and-cons-of-k-nearest-neighbours" title="Permalink to this headline">#</a></h2>
<div class="section" id="pros">
<h3><span class="section-number">4.4.1. </span>Pros:<a class="headerlink" href="#pros" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Easy to understand, interpret.</p></li>
<li><p>Simply hyperparameter <span class="math notranslate nohighlight">\(k\)</span> (<code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code>) controlling the fundamental tradeoff.</p></li>
<li><p>Can learn very complex functions given enough data.</p></li>
<li><p>Lazy learning: Takes no time to <code class="docutils literal notranslate"><span class="pre">fit</span></code></p></li>
</ul>
<br>
</div>
<div class="section" id="cons">
<h3><span class="section-number">4.4.2. </span>Cons:<a class="headerlink" href="#cons" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Can potentially be VERY slow during prediction time.</p></li>
<li><p>Often not that great test accuracy compared to the modern approaches.</p></li>
<li><p>Need to scale your features.</p></li>
</ul>
</div>
</div>
<div class="section" id="let-s-practice">
<h2><span class="section-number">4.5. </span>Let’s Practice<a class="headerlink" href="#let-s-practice" title="Permalink to this headline">#</a></h2>
<div class="math notranslate nohighlight">
\[\begin{split} X = \begin{bmatrix}5 &amp; 2\\4 &amp; 3\\  2 &amp; 2\\ 10 &amp; 10\\ 9 &amp; -1\\ 9&amp; 9\end{bmatrix}, \quad y = \begin{bmatrix}0\\0\\1\\1\\1\\2\end{bmatrix}.\end{split}\]</div>
<p>If <span class="math notranslate nohighlight">\(k=3\)</span>, what would you predict for <span class="math notranslate nohighlight">\(x=\begin{bmatrix} 0 &amp; 0\end{bmatrix}\)</span> if we were doing regression rather than classification?</p>
<div class="dropdown admonition">
<p class="admonition-title">Solutions!</p>
<ol class="simple">
<li><p>1/3 (<span class="math notranslate nohighlight">\(\frac{0 + 0 + 1}{3}\)</span>)</p></li>
</ol>
</div>
</div>
<div class="section" id="support-vector-machines-svms-with-rbf-kernel">
<h2><span class="section-number">4.6. </span>Support Vector Machines (SVMs) with RBF Kernel<a class="headerlink" href="#support-vector-machines-svms-with-rbf-kernel" title="Permalink to this headline">#</a></h2>
<p>Another popular similarity-based algorithm is Support Vector Machines (SVM).</p>
<p>Conceptually,
SVMs try to compute which is the best linear decision boundary that can be drawn to separate two (or more) classes.
For data in 2D this would be a line, in 3D it would be a plane/surface and so on.
A general name for this decision boundary is a hyperplane.</p>
<p>With the training data points below (<a class="reference external" href="https://iaviral.medium.com/what-is-support-vector-machine-svm-c1b759db65ba">images in the intro are from this article</a>),
there are multiple linear lines/hyperplanes that we could draw that would perfectly
separate the points.</p>
<p><img alt="image.png" src="../_images/svm1.png" /></p>
<p>So which one is best?
SVMs define “best” as the one with the largest margin to the points from both classes.
In other words, the line that are the most in the middle of the border points in each cluster.
Since the location of the best margin only depends on the border points from each cluster,
these points are called “support points/vectors” (hence the name “support vector machines”).</p>
<p><img alt="image.png" src="../_images/svm2.png" /></p>
<p>Conceptually it makes sense that the line in the middle of both the clusters is chosen,
since we would expect this border to best separate unseen data points.
If we instead put the border really close to the green or red cluster,
we might make a miss-classification on the new data points if they are not in the exact same spots as the training data.
However,
we also don’t want one outlier in the training data to completely change the border
and we have hyperparameters that can control this as we will see soon.</p>
<p>What happens if there is no linear boundary that can be drawn to separate the data
as with the points below?</p>
<p><img alt="image.png" src="../_images/svm3.png" /></p>
<p>A key concept of SVMs is the transformation of existing dimensions into new ones,
where a linear decision boundary can be found.
The transformation function is referred to as a kernel,
and in this case,
we could use a polynomial kernel to create a new dimension such that <span class="math notranslate nohighlight">\(z = x^2 + y^2\)</span>.
If we plot x (or y) vs z, we can see that there is a linear decision boundary in this new dimension,
which perfectly separates the points.</p>
<p><img alt="image.png" src="../_images/svm4.png" /></p>
<p>If we transform this decision boundary back to our original xy-space,
we can see that it has the shape of a ring.
(<a class="reference external" href="https://www.youtube.com/watch?v=OdlNM96sHio&amp;t=0s">Here is an animation of this process to help you visualize it</a>).</p>
<p><img alt="image.png" src="../_images/svm5.png" /></p>
<p>Kernel transformations allows us to use SVMs on data with complex non-linear decision borders in the original data dimensions.
Here, we are going to concentrate on the specific kernel called Radial Basis Functions (RBFs),
which is one of the most common and effective kernels
and also the default in scikit-learn.</p>
<p>Let’s start by reading in out Canadian and USA cities data yet again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cities_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/canada_usa_cities.csv&quot;</span><span class="p">)</span>
<span class="n">cities_train_df</span><span class="p">,</span> <span class="n">cities_test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cities_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">cities_train_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>160</th>
      <td>-76.4813</td>
      <td>44.2307</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>127</th>
      <td>-81.2496</td>
      <td>42.9837</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>169</th>
      <td>-66.0580</td>
      <td>45.2788</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>188</th>
      <td>-73.2533</td>
      <td>45.3057</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>187</th>
      <td>-67.9245</td>
      <td>47.1652</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-76.3305</td>
      <td>44.1255</td>
      <td>USA</td>
    </tr>
    <tr>
      <th>98</th>
      <td>-74.7287</td>
      <td>45.0184</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>66</th>
      <td>-121.4944</td>
      <td>38.5816</td>
      <td>USA</td>
    </tr>
    <tr>
      <th>126</th>
      <td>-79.5656</td>
      <td>43.6436</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>109</th>
      <td>-66.9195</td>
      <td>44.8938</td>
      <td>Canada</td>
    </tr>
  </tbody>
</table>
<p>167 rows × 3 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cities_X_train</span> <span class="o">=</span> <span class="n">cities_train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">])</span>
<span class="n">cities_y_train</span> <span class="o">=</span> <span class="n">cities_train_df</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">]</span>
<span class="n">cities_X_test</span> <span class="o">=</span> <span class="n">cities_test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">])</span>
<span class="n">cities_y_test</span> <span class="o">=</span> <span class="n">cities_test_df</span><span class="p">[</span><span class="s1">&#39;country&#39;</span><span class="p">]</span>

<span class="n">cities_X_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>160</th>
      <td>-76.4813</td>
      <td>44.2307</td>
    </tr>
    <tr>
      <th>127</th>
      <td>-81.2496</td>
      <td>42.9837</td>
    </tr>
    <tr>
      <th>169</th>
      <td>-66.0580</td>
      <td>45.2788</td>
    </tr>
    <tr>
      <th>188</th>
      <td>-73.2533</td>
      <td>45.3057</td>
    </tr>
    <tr>
      <th>187</th>
      <td>-67.9245</td>
      <td>47.1652</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-76.3305</td>
      <td>44.1255</td>
    </tr>
    <tr>
      <th>98</th>
      <td>-74.7287</td>
      <td>45.0184</td>
    </tr>
    <tr>
      <th>66</th>
      <td>-121.4944</td>
      <td>38.5816</td>
    </tr>
    <tr>
      <th>126</th>
      <td>-79.5656</td>
      <td>43.6436</td>
    </tr>
    <tr>
      <th>109</th>
      <td>-66.9195</td>
      <td>44.8938</td>
    </tr>
  </tbody>
</table>
<p>167 rows × 2 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cities_y_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>160    Canada
127    Canada
169    Canada
188    Canada
187    Canada
        ...  
17        USA
98     Canada
66        USA
126    Canada
109    Canada
Name: country, Length: 167, dtype: object
</pre></div>
</div>
</div>
</div>
<p>We can use our training feature table (<span class="math notranslate nohighlight">\(X\)</span>) and target (<span class="math notranslate nohighlight">\(y\)</span>) values by using this new SVM model with (RBF) but with the old set up with <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> and <code class="docutils literal notranslate"><span class="pre">.score()</span></code> that we have seen time and time again.</p>
<p>We import the <code class="docutils literal notranslate"><span class="pre">SVC</span></code> tool from the <code class="docutils literal notranslate"><span class="pre">sklearn.svm</span></code> library (The “C” in SVC represents  <em>Classifier</em>).
To import the regressor we import <code class="docutils literal notranslate"><span class="pre">SVR</span></code> - R for <em>Regressor</em>)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
</pre></div>
</div>
</div>
</div>
<p>We can cross-validate and score exactly how we have done it in previous lectures.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">cities_X_train</span><span class="p">,</span> <span class="n">cities_y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">scores_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
<span class="n">scores_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.005098</td>
      <td>0.001746</td>
      <td>0.735294</td>
      <td>0.714286</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.001753</td>
      <td>0.001185</td>
      <td>0.705882</td>
      <td>0.714286</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.001614</td>
      <td>0.001279</td>
      <td>0.636364</td>
      <td>0.761194</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.001811</td>
      <td>0.001172</td>
      <td>0.696970</td>
      <td>0.723881</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.001568</td>
      <td>0.001114</td>
      <td>0.696970</td>
      <td>0.626866</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm_cv_score</span> <span class="o">=</span> <span class="n">scores_df</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">svm_cv_score</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.002369
score_time     0.001299
test_score     0.694296
train_score    0.708102
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>That validation accuracy does not look too great,
let’s have a look at the decision boundary.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cities_X_train</span><span class="p">,</span> <span class="n">cities_y_train</span><span class="p">)</span>

<span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span>
        <span class="n">svm</span><span class="p">,</span> <span class="n">cities_X_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span> <span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">cities_X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cities_X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">cities_y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x17f39fa00&gt;,
 &lt;matplotlib.lines.Line2D at 0x17f39fca0&gt;]
</pre></div>
</div>
<img alt="../_images/lecture4_36_1.png" src="../_images/lecture4_36_1.png" />
</div>
</div>
<p>It seems like our model is quite simple,
in other words,
it is underfitting
and not using enough of the specific structure of the training data to draw the decision boundary.</p>
<p>To draw a more specific boundary,
we need to tune the SVM hyperparameters.</p>
<div class="section" id="hyperparameters-of-svm">
<h3><span class="section-number">4.6.1. </span>Hyperparameters of SVM<a class="headerlink" href="#hyperparameters-of-svm" title="Permalink to this headline">#</a></h3>
<p>There are  2 main hyperparameters for support vector machines with an RBF kernel;</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">C</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gamma</span></code></p></li>
</ul>
<p>In short, <code class="docutils literal notranslate"><span class="pre">C</span></code> is the cost/penalty the model accepts for wrongly classified examples in the training data;
it trades off correct classification of training examples against maximization of the decision function’s margin.
A lower C will reduce the cost/penalty of incorrectly classifying training data,
which allows the SVM can be more lenient and draw a simpler decision boundary that likely generalizes better,
even if that means getting a few training examples incorrect.</p>
<p>The gamma parameter is specific to the RBF kernel and defines how far the influence of a single training point reaches when constructing the decision boundary.
Low values mean ‘far’, creating a simple decision boundary with low curvature (at really low “gamma”, the RBF kernel behaves as a linear SVM kernel).
High values mean ‘close’, creating a complex decision boundary with high curvature.
Another way of thinking of this is that if you have two dimensional points,
and want to construct a third dimension to separate them,
gamma controls the shape of the “peaks” when the points are raised.
A large gamma gives pointed bumps in the higher dimensions,
whereas a small gamma gives a softer, broader bumps.</p>
<p>You can read more <a class="reference external" href="https://towardsdatascience.com/hyperparameter-tuning-for-support-vector-machines-c-and-gamma-parameters-6a5097416167">in this article</a>
and in the <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html"><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>’s explanation of RBF SVM parameters</a>.</p>
<div class="section" id="gamma-and-the-fundamental-trade-off">
<h4><span class="section-number">4.6.1.1. </span><code class="docutils literal notranslate"><span class="pre">gamma</span></code> and the fundamental trade-off<a class="headerlink" href="#gamma-and-the-fundamental-trade-off" title="Permalink to this headline">#</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">gamma</span></code> controls the complexity of a model, just like other hyperparameters we’ve seen.</p>
<ul class="simple">
<li><p>higher gamma, higher the complexity.</p></li>
<li><p>lower gamma, lower the complexity.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gamma</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">plot_svc_gamma</span><span class="p">(</span>
    <span class="n">gamma</span><span class="p">,</span>
    <span class="n">cities_X_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span>
    <span class="n">cities_y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture4_40_0.png" src="../_images/lecture4_40_0.png" />
</div>
</div>
</div>
<div class="section" id="c-and-the-fundamental-trade-off">
<h4><span class="section-number">4.6.1.2. </span><code class="docutils literal notranslate"><span class="pre">C</span></code> and the fundamental trade-off<a class="headerlink" href="#c-and-the-fundamental-trade-off" title="Permalink to this headline">#</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">C</span></code> also controls the complexity of a model and in turn the fundamental tradeoff.</p>
<ul class="simple">
<li><p>higher <code class="docutils literal notranslate"><span class="pre">C</span></code> values, higher the complexity.</p></li>
<li><p>lower <code class="docutils literal notranslate"><span class="pre">C</span></code> values, lower the complexity.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">C</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">1000.0</span><span class="p">,</span> <span class="mf">100000.0</span><span class="p">]</span>
<span class="n">plot_svc_C</span><span class="p">(</span>
    <span class="n">C</span><span class="p">,</span> <span class="n">cities_X_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">cities_y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture4_42_0.png" src="../_images/lecture4_42_0.png" />
</div>
</div>
<p>Obtaining optimal validation scores requires a hyperparameter search between both <code class="docutils literal notranslate"><span class="pre">gamma</span></code> and <code class="docutils literal notranslate"><span class="pre">C</span></code> to balance the fundamental trade-off.
We will learn how to search over multiple hyperparameters at a time in lecture 5.</p>
</div>
</div>
</div>
<div class="section" id="id1">
<h2><span class="section-number">4.7. </span>Let’s Practice<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h2>
<p><strong>True or False</strong></p>
<ol class="simple">
<li><p>In Scikit Learn’s SVC classifier, large values of gamma tend to result in higher training scores but probably lower validation scores.</p></li>
<li><p>If we increase both <code class="docutils literal notranslate"><span class="pre">gamma</span></code> and <code class="docutils literal notranslate"><span class="pre">C</span></code>, we can’t be certain if the model becomes more complex or less complex.</p></li>
</ol>
<div class="dropdown admonition">
<p class="admonition-title">Solutions!</p>
<ol class="simple">
<li><p>True</p></li>
<li><p>False</p></li>
</ol>
</div>
</div>
<div class="section" id="let-s-practice-coding">
<h2><span class="section-number">4.8. </span>Let’s Practice - Coding<a class="headerlink" href="#let-s-practice-coding" title="Permalink to this headline">#</a></h2>
<p>Below is some starter code that creates your feature table and target column from the data from the <code class="docutils literal notranslate"><span class="pre">bball.csv</span></code> dataset (in the data folder).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bball_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/bball.csv&#39;</span><span class="p">)</span>
<span class="n">bball_df</span> <span class="o">=</span> <span class="n">bball_df</span><span class="p">[(</span><span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;G&#39;</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;F&#39;</span><span class="p">)]</span>

<span class="c1"># Define X and y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">bball_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="s1">&#39;salary&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<ol class="simple">
<li><p>Split the dataset into 4 objects: <code class="docutils literal notranslate"><span class="pre">X_train</span></code>, <code class="docutils literal notranslate"><span class="pre">X_test</span></code>, <code class="docutils literal notranslate"><span class="pre">y_train</span></code>, <code class="docutils literal notranslate"><span class="pre">y_test</span></code>. Make the test set 0.2 (or the train set 0.8) and make sure to use <code class="docutils literal notranslate"><span class="pre">random_state=7</span></code>.</p></li>
<li><p>Create an <code class="docutils literal notranslate"><span class="pre">SVM</span></code> model with <code class="docutils literal notranslate"><span class="pre">gamma</span></code> equal to 0.1 and <code class="docutils literal notranslate"><span class="pre">C</span></code> equal to 10.</p></li>
<li><p>Cross-validate using cross_validate() on the objects X_train and y_train specifying the model and making sure to use 5 fold cross-validation and <code class="docutils literal notranslate"><span class="pre">return_train_score=True</span></code>.</p></li>
<li><p>Calculate the mean training and cross-validation scores.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Split the dataset</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 3. Cross-validate</span>
<span class="n">scores_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.003713</td>
      <td>0.002048</td>
      <td>0.571429</td>
      <td>0.994898</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.002570</td>
      <td>0.001840</td>
      <td>0.571429</td>
      <td>0.994898</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.004793</td>
      <td>0.001971</td>
      <td>0.551020</td>
      <td>0.994898</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.002391</td>
      <td>0.001668</td>
      <td>0.530612</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.002497</td>
      <td>0.001880</td>
      <td>0.571429</td>
      <td>0.994898</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 4. Calculate the mean training and cross-validation scores.</span>
<span class="n">scores_df</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.003193
score_time     0.001881
test_score     0.559184
train_score    0.995918
dtype: float64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="preprocessing">
<h2><span class="section-number">4.9. </span>Preprocessing<a class="headerlink" href="#preprocessing" title="Permalink to this headline">#</a></h2>
<div class="section" id="the-importance-of-preprocessing-an-example-of-why">
<h3><span class="section-number">4.9.1. </span>The importance of Preprocessing - An Example of Why<a class="headerlink" href="#the-importance-of-preprocessing-an-example-of-why" title="Permalink to this headline">#</a></h3>
<p>So far we have seen:</p>
<ul class="simple">
<li><p>Models: Decision trees, 𝑘-NNs, SVMs with RBF kernel.</p></li>
<li><p>Fundamentals: Train-validation-test split, cross-validation, the fundamental tradeoff, the golden rule.</p></li>
</ul>
<p>Now …</p>
<p><strong>Preprocessing</strong>: Transforming input data into a format a machine learning model can use and understand.</p>
<div class="section" id="basketball-dataset">
<h4><span class="section-number">4.9.1.1. </span>Basketball dataset<a class="headerlink" href="#basketball-dataset" title="Permalink to this headline">#</a></h4>
<p>Let’s take a look at the <code class="docutils literal notranslate"><span class="pre">bball.csv</span></code> dataset we just used in practice.</p>
<ul class="simple">
<li><p>Let’s look at the  3 feature columns <code class="docutils literal notranslate"><span class="pre">height</span></code>, <code class="docutils literal notranslate"><span class="pre">weight</span></code> and <code class="docutils literal notranslate"><span class="pre">salary</span></code>.</p></li>
<li><p>Let’s see if these features can help predict the <code class="docutils literal notranslate"><span class="pre">position</span></code> basketball players is.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bball_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/bball.csv&#39;</span><span class="p">)</span>
<span class="n">bball_df</span> <span class="o">=</span> <span class="n">bball_df</span><span class="p">[(</span><span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;G&#39;</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;F&#39;</span><span class="p">)]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">bball_df</span><span class="p">[[</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;salary&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span><span class="n">bball_df</span><span class="p">[</span><span class="s2">&quot;position&quot;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>weight</th>
      <th>height</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>152</th>
      <td>79.4</td>
      <td>1.88</td>
      <td>1588231.0</td>
    </tr>
    <tr>
      <th>337</th>
      <td>82.1</td>
      <td>1.91</td>
      <td>2149560.0</td>
    </tr>
    <tr>
      <th>130</th>
      <td>106.6</td>
      <td>2.03</td>
      <td>6500000.0</td>
    </tr>
    <tr>
      <th>340</th>
      <td>106.1</td>
      <td>2.08</td>
      <td>2961120.0</td>
    </tr>
    <tr>
      <th>50</th>
      <td>96.2</td>
      <td>1.93</td>
      <td>4861207.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>151</th>
      <td>100.7</td>
      <td>2.06</td>
      <td>4464286.0</td>
    </tr>
    <tr>
      <th>120</th>
      <td>97.5</td>
      <td>1.91</td>
      <td>14057730.0</td>
    </tr>
    <tr>
      <th>26</th>
      <td>96.6</td>
      <td>1.93</td>
      <td>21000000.0</td>
    </tr>
    <tr>
      <th>328</th>
      <td>85.7</td>
      <td>1.88</td>
      <td>15643750.0</td>
    </tr>
    <tr>
      <th>139</th>
      <td>97.5</td>
      <td>2.03</td>
      <td>9258000.0</td>
    </tr>
  </tbody>
</table>
<p>245 rows × 3 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>152    G
337    G
130    F
340    F
50     G
      ..
151    F
120    G
26     G
328    G
139    F
Name: position, Length: 245, dtype: object
</pre></div>
</div>
</div>
</div>
<p>First, let’s see what validations scores we get if we simply predict the most occurring target value in the dataset using the dummy classifier model we saw in the last lecture.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dummy</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;most_frequent&quot;</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">dummy</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean training score&#39;</span><span class="p">,</span> <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean validation score&#39;</span><span class="p">,</span> <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean training score 0.57
Mean validation score 0.57
</pre></div>
</div>
</div>
</div>
<p>Here we get a mean validation score for our 5 fold cross_validation (5 is the default) of 57%. Let’s now see how much better a <span class="math notranslate nohighlight">\(k\)</span>-nn model does on the data. We saw that it doesn’t do to well on SVM, let’s see if there is a difference with <span class="math notranslate nohighlight">\(k\)</span>-nn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean training score&#39;</span><span class="p">,</span> <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean validation score&#39;</span><span class="p">,</span> <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean training score 0.7
Mean validation score 0.5
</pre></div>
</div>
</div>
</div>
<p>Ok, not the score we were hoping for.</p>
<p>We are getting a worse score than the dummy classifier. This can’t be right….. and it isn’t and we are going to explain why!</p>
<p>Let’s have a look at just 2 players.</p>
<p>We can see the values in each column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">two_players</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">two_players</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>weight</th>
      <th>height</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>285</th>
      <td>91.2</td>
      <td>1.98</td>
      <td>1882867.0</td>
    </tr>
    <tr>
      <th>236</th>
      <td>112.0</td>
      <td>2.08</td>
      <td>2000000.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>The values in the <code class="docutils literal notranslate"><span class="pre">weight</span></code> column are around 100.</p></li>
<li><p>The values in the <code class="docutils literal notranslate"><span class="pre">height</span></code> column are around 2.</p></li>
<li><p>The values in the <code class="docutils literal notranslate"><span class="pre">salary</span></code> column are much higher at around 2 million.</p></li>
</ul>
<p>Let’s now calculate the distance between the two players.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">euclidean_distances</span><span class="p">(</span><span class="n">two_players</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[     0.        , 117133.00184683],
       [117133.00184683,      0.        ]])
</pre></div>
</div>
</div>
</div>
<p>So the distance between the players is 117133.0018.</p>
<p>What happens if we only consider the salary column?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">euclidean_distances</span><span class="p">(</span><span class="n">two_players</span><span class="p">[[</span><span class="s2">&quot;salary&quot;</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[     0., 117133.],
       [117133.,      0.]])
</pre></div>
</div>
</div>
</div>
<p>It looks like it’s almost the same distance!</p>
<p>The distance is completely dominated by the <code class="docutils literal notranslate"><span class="pre">salary</span></code> column, the feature with the largest values and the <code class="docutils literal notranslate"><span class="pre">weight</span></code> and <code class="docutils literal notranslate"><span class="pre">height</span></code> columns are being ignored in the distance calculation.</p>
<p><strong>Does it matter?</strong></p>
<p>Yes! The scale is based on how data was collected.</p>
<p>Features on a smaller scale can be highly informative and there is no good reason to ignore them.
We want our model to be robust and not sensitive to the scale.</p>
<p><strong>What about for decision trees? Did scale matter then?</strong></p>
<p>No. In decision trees we ask questions on one feature at a time and so the nodes are created independently without considering others.</p>
<p>We have to scale our columns before we use our <span class="math notranslate nohighlight">\(k\)</span>-nn algorithm (and many others) so they are all using a similar range of values!</p>
<p>And you guessed it - Sklearn has tools called transformers for this.</p>
<p>We’ll be using <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>’s <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"><code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code></a> for this example.
We will talk about this type of preprocessing in more detail in a hot minute but for now, concentrate on the syntax.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>                    <span class="c1"># Create feature transformer object, can accept hyperparameters like models can! </span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>                          <span class="c1"># Fitting the transformer on the train split</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>   <span class="c1"># Transforming the train split</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>     <span class="c1"># Transforming the test split</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">sklearn</span></code> uses <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">transform</span></code> paradigms for feature transformations. (In model building it was <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">predict</span></code> or <code class="docutils literal notranslate"><span class="pre">score</span></code>)</p>
<p>We <code class="docutils literal notranslate"><span class="pre">fit</span></code> the transformer on the train split and then <code class="docutils literal notranslate"><span class="pre">transform</span></code> the train split as well as the test split.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>weight</th>
      <th>height</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.552775</td>
      <td>-1.236056</td>
      <td>-0.728809</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.257147</td>
      <td>-0.800950</td>
      <td>-0.670086</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.425407</td>
      <td>0.939473</td>
      <td>-0.214967</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.370661</td>
      <td>1.664650</td>
      <td>-0.585185</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.286690</td>
      <td>-0.510879</td>
      <td>-0.386408</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>240</th>
      <td>0.779404</td>
      <td>1.374579</td>
      <td>-0.427932</td>
    </tr>
    <tr>
      <th>241</th>
      <td>0.429030</td>
      <td>-0.800950</td>
      <td>0.575680</td>
    </tr>
    <tr>
      <th>242</th>
      <td>0.330487</td>
      <td>-0.510879</td>
      <td>1.301942</td>
    </tr>
    <tr>
      <th>243</th>
      <td>-0.862975</td>
      <td>-1.236056</td>
      <td>0.741601</td>
    </tr>
    <tr>
      <th>244</th>
      <td>0.429030</td>
      <td>0.939473</td>
      <td>0.073560</td>
    </tr>
  </tbody>
</table>
<p>245 rows × 3 columns</p>
</div></div></div>
</div>
<p>Now if we look at our features they are all within the same scales as opposed to what it was before:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>weight</th>
      <th>height</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>152</th>
      <td>79.4</td>
      <td>1.88</td>
      <td>1588231.0</td>
    </tr>
    <tr>
      <th>337</th>
      <td>82.1</td>
      <td>1.91</td>
      <td>2149560.0</td>
    </tr>
    <tr>
      <th>130</th>
      <td>106.6</td>
      <td>2.03</td>
      <td>6500000.0</td>
    </tr>
    <tr>
      <th>340</th>
      <td>106.1</td>
      <td>2.08</td>
      <td>2961120.0</td>
    </tr>
    <tr>
      <th>50</th>
      <td>96.2</td>
      <td>1.93</td>
      <td>4861207.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>151</th>
      <td>100.7</td>
      <td>2.06</td>
      <td>4464286.0</td>
    </tr>
    <tr>
      <th>120</th>
      <td>97.5</td>
      <td>1.91</td>
      <td>14057730.0</td>
    </tr>
    <tr>
      <th>26</th>
      <td>96.6</td>
      <td>1.93</td>
      <td>21000000.0</td>
    </tr>
    <tr>
      <th>328</th>
      <td>85.7</td>
      <td>1.88</td>
      <td>15643750.0</td>
    </tr>
    <tr>
      <th>139</th>
      <td>97.5</td>
      <td>2.03</td>
      <td>9258000.0</td>
    </tr>
  </tbody>
</table>
<p>245 rows × 3 columns</p>
</div></div></div>
</div>
</div>
</div>
<div class="section" id="sklearn-s-predict-vs-transform">
<h3><span class="section-number">4.9.2. </span>Sklearn’s <em>predict</em> vs <em>transform</em><a class="headerlink" href="#sklearn-s-predict-vs-transform" title="Permalink to this headline">#</a></h3>
<p>When we make models, we <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">predict</span></code>(<code class="docutils literal notranslate"><span class="pre">score</span></code>) with the syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">X_train_predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
<p>With preprocessing, we replace the <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> step with a <code class="docutils literal notranslate"><span class="pre">.transform()</span></code> step. We can pass <code class="docutils literal notranslate"><span class="pre">y_train</span></code> in <code class="docutils literal notranslate"><span class="pre">fit</span></code> but it’s usually ignored. It allows us to pass it just to be consistent with the usual usage of <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>’s <code class="docutils literal notranslate"><span class="pre">fit</span></code> method.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">transformer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="p">[</span><span class="n">y_train</span><span class="p">])</span>
<span class="n">X_train_transformed</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
<p>We can also carry out fitting and transforming in one call using <code class="docutils literal notranslate"><span class="pre">.fit_transform()</span></code>, but we must be mindful to use it only on the train split and <strong>NOT</strong> on the test split.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_transformed</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s scale our features for this basketball dataset and then compare the results with our original score without scaling.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn_unscaled</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">knn_unscaled</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train score: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">knn_unscaled</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test score: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">knn_unscaled</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train score:  0.71
Test score:  0.45
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn_scaled</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">knn_scaled</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train score: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">knn_scaled</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test score: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">knn_scaled</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train score:  0.94
Test score:  0.89
</pre></div>
</div>
</div>
</div>
<p>The scores with scaled data are now much better compared to the unscaled data in the case of 𝑘-NNs.</p>
<p>We can see now that 𝑘-NN is doing better than the Dummy Classifier when we scaled our features.</p>
<p>We are not carrying out cross-validation here for a reason that we’ll look into soon.</p>
</div>
<div class="section" id="common-preprocessing-techniques">
<h3><span class="section-number">4.9.3. </span>Common preprocessing techniques<a class="headerlink" href="#common-preprocessing-techniques" title="Permalink to this headline">#</a></h3>
<p>Here are some commonly performed feature transformation techniques we will focus on in this lesson.</p>
<ul class="simple">
<li><p>Imputation</p>
<ul>
<li><p>Tackling missing values</p></li>
</ul>
</li>
<li><p>Scaling</p>
<ul>
<li><p>Scaling of numeric features</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="id2">
<h2><span class="section-number">4.10. </span>Let’s Practice<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h2>
<ol class="simple">
<li><p>Name a model that will still produce meaningful predictions with different scaled column values.</p></li>
<li><p>Complete the following statement with one of the alternatives below: Preprocessing is done ______.<br />
a) To the model but before training<br />
b) To the data before training the model<br />
c) To the model after training<br />
d) To the data after training the model</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> is a type of what?</p></li>
</ol>
<p><strong>True or False</strong></p>
<p>4. Columns with lower magnitudes compared to columns with higher magnitudes are less important when making predictions.<br />
5. A model less sensitive to the scale of the data makes it more robust.</p>
<div class="dropdown admonition">
<p class="admonition-title">Solutions!</p>
<ol class="simple">
<li><p>Decision Tree Algorithm</p></li>
<li><p>b) To the data before training the model</p></li>
<li><p>Transformer</p></li>
<li><p>False</p></li>
<li><p>True</p></li>
</ol>
</div>
</div>
<div class="section" id="california-housing-data-a-case-study">
<h2><span class="section-number">4.11. </span>California housing data (A case study)<a class="headerlink" href="#california-housing-data-a-case-study" title="Permalink to this headline">#</a></h2>
<p>For the next few examples of preprocessing,  we are going to be using a dataset exploring the prices of homes in California to demonstrate feature transformation techniques.  The data can be downloaded from this site <a class="reference external" href="https://www.kaggle.com/harrywang/housing">here</a>. Please make sure that you include it in your <code class="docutils literal notranslate"><span class="pre">data</span></code> folder that resides in <code class="docutils literal notranslate"><span class="pre">lectures</span></code>.</p>
<p>This dataset is a modified version of the California Housing dataset available from <a class="reference external" href="https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html">Luís Torgo’s University of Porto website</a></p>
<p>The task is to predict median house values in California districts, given several features from these districts.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">housing_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/housing.csv&quot;</span><span class="p">)</span>
<span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">housing_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

<span class="n">train_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6051</th>
      <td>-117.75</td>
      <td>34.04</td>
      <td>22.0</td>
      <td>2948.0</td>
      <td>636.0</td>
      <td>2600.0</td>
      <td>602.0</td>
      <td>3.1250</td>
      <td>113600.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>20113</th>
      <td>-119.57</td>
      <td>37.94</td>
      <td>17.0</td>
      <td>346.0</td>
      <td>130.0</td>
      <td>51.0</td>
      <td>20.0</td>
      <td>3.4861</td>
      <td>137500.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>14289</th>
      <td>-117.13</td>
      <td>32.74</td>
      <td>46.0</td>
      <td>3355.0</td>
      <td>768.0</td>
      <td>1457.0</td>
      <td>708.0</td>
      <td>2.6604</td>
      <td>170100.0</td>
      <td>NEAR OCEAN</td>
    </tr>
    <tr>
      <th>13665</th>
      <td>-117.31</td>
      <td>34.02</td>
      <td>18.0</td>
      <td>1634.0</td>
      <td>274.0</td>
      <td>899.0</td>
      <td>285.0</td>
      <td>5.2139</td>
      <td>129300.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>14471</th>
      <td>-117.23</td>
      <td>32.88</td>
      <td>18.0</td>
      <td>5566.0</td>
      <td>1465.0</td>
      <td>6303.0</td>
      <td>1458.0</td>
      <td>1.8580</td>
      <td>205000.0</td>
      <td>NEAR OCEAN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>7763</th>
      <td>-118.10</td>
      <td>33.91</td>
      <td>36.0</td>
      <td>726.0</td>
      <td>NaN</td>
      <td>490.0</td>
      <td>130.0</td>
      <td>3.6389</td>
      <td>167600.0</td>
      <td>&lt;1H OCEAN</td>
    </tr>
    <tr>
      <th>15377</th>
      <td>-117.24</td>
      <td>33.37</td>
      <td>14.0</td>
      <td>4687.0</td>
      <td>793.0</td>
      <td>2436.0</td>
      <td>779.0</td>
      <td>4.5391</td>
      <td>180900.0</td>
      <td>&lt;1H OCEAN</td>
    </tr>
    <tr>
      <th>17730</th>
      <td>-121.76</td>
      <td>37.33</td>
      <td>5.0</td>
      <td>4153.0</td>
      <td>719.0</td>
      <td>2435.0</td>
      <td>697.0</td>
      <td>5.6306</td>
      <td>286200.0</td>
      <td>&lt;1H OCEAN</td>
    </tr>
    <tr>
      <th>15725</th>
      <td>-122.44</td>
      <td>37.78</td>
      <td>44.0</td>
      <td>1545.0</td>
      <td>334.0</td>
      <td>561.0</td>
      <td>326.0</td>
      <td>3.8750</td>
      <td>412500.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>19966</th>
      <td>-119.08</td>
      <td>36.21</td>
      <td>20.0</td>
      <td>1911.0</td>
      <td>389.0</td>
      <td>1241.0</td>
      <td>348.0</td>
      <td>2.5156</td>
      <td>59300.0</td>
      <td>INLAND</td>
    </tr>
  </tbody>
</table>
<p>18576 rows × 10 columns</p>
</div></div></div>
</div>
<p>Some column values are mean/median but some are not.</p>
<p>Before we use this data we need to do some <strong>feature engineering</strong>.</p>
<p>That means we are going to transform our data into features that may be more meaningful for our prediction.</p>
<p>Let’s add some new features to the dataset which could help predict the target: <code class="docutils literal notranslate"><span class="pre">median_house_value</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">rooms_per_household</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;total_rooms&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">],</span>
                           <span class="n">bedrooms_per_household</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;total_bedrooms&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">],</span>
                           <span class="n">population_per_household</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;population&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">])</span>

<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">rooms_per_household</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;total_rooms&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">],</span>
                         <span class="n">bedrooms_per_household</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;total_bedrooms&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">],</span>
                         <span class="n">population_per_household</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;population&quot;</span><span class="p">]</span><span class="o">/</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">])</span>

<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;total_rooms&#39;</span><span class="p">,</span> <span class="s1">&#39;total_bedrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;population&#39;</span><span class="p">])</span>  
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;total_rooms&#39;</span><span class="p">,</span> <span class="s1">&#39;total_bedrooms&#39;</span><span class="p">,</span> <span class="s1">&#39;population&#39;</span><span class="p">])</span> 

<span class="n">train_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6051</th>
      <td>-117.75</td>
      <td>34.04</td>
      <td>22.0</td>
      <td>602.0</td>
      <td>3.1250</td>
      <td>113600.0</td>
      <td>INLAND</td>
      <td>4.897010</td>
      <td>1.056478</td>
      <td>4.318937</td>
    </tr>
    <tr>
      <th>20113</th>
      <td>-119.57</td>
      <td>37.94</td>
      <td>17.0</td>
      <td>20.0</td>
      <td>3.4861</td>
      <td>137500.0</td>
      <td>INLAND</td>
      <td>17.300000</td>
      <td>6.500000</td>
      <td>2.550000</td>
    </tr>
    <tr>
      <th>14289</th>
      <td>-117.13</td>
      <td>32.74</td>
      <td>46.0</td>
      <td>708.0</td>
      <td>2.6604</td>
      <td>170100.0</td>
      <td>NEAR OCEAN</td>
      <td>4.738701</td>
      <td>1.084746</td>
      <td>2.057910</td>
    </tr>
    <tr>
      <th>13665</th>
      <td>-117.31</td>
      <td>34.02</td>
      <td>18.0</td>
      <td>285.0</td>
      <td>5.2139</td>
      <td>129300.0</td>
      <td>INLAND</td>
      <td>5.733333</td>
      <td>0.961404</td>
      <td>3.154386</td>
    </tr>
    <tr>
      <th>14471</th>
      <td>-117.23</td>
      <td>32.88</td>
      <td>18.0</td>
      <td>1458.0</td>
      <td>1.8580</td>
      <td>205000.0</td>
      <td>NEAR OCEAN</td>
      <td>3.817558</td>
      <td>1.004801</td>
      <td>4.323045</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>7763</th>
      <td>-118.10</td>
      <td>33.91</td>
      <td>36.0</td>
      <td>130.0</td>
      <td>3.6389</td>
      <td>167600.0</td>
      <td>&lt;1H OCEAN</td>
      <td>5.584615</td>
      <td>NaN</td>
      <td>3.769231</td>
    </tr>
    <tr>
      <th>15377</th>
      <td>-117.24</td>
      <td>33.37</td>
      <td>14.0</td>
      <td>779.0</td>
      <td>4.5391</td>
      <td>180900.0</td>
      <td>&lt;1H OCEAN</td>
      <td>6.016688</td>
      <td>1.017972</td>
      <td>3.127086</td>
    </tr>
    <tr>
      <th>17730</th>
      <td>-121.76</td>
      <td>37.33</td>
      <td>5.0</td>
      <td>697.0</td>
      <td>5.6306</td>
      <td>286200.0</td>
      <td>&lt;1H OCEAN</td>
      <td>5.958393</td>
      <td>1.031564</td>
      <td>3.493544</td>
    </tr>
    <tr>
      <th>15725</th>
      <td>-122.44</td>
      <td>37.78</td>
      <td>44.0</td>
      <td>326.0</td>
      <td>3.8750</td>
      <td>412500.0</td>
      <td>NEAR BAY</td>
      <td>4.739264</td>
      <td>1.024540</td>
      <td>1.720859</td>
    </tr>
    <tr>
      <th>19966</th>
      <td>-119.08</td>
      <td>36.21</td>
      <td>20.0</td>
      <td>348.0</td>
      <td>2.5156</td>
      <td>59300.0</td>
      <td>INLAND</td>
      <td>5.491379</td>
      <td>1.117816</td>
      <td>3.566092</td>
    </tr>
  </tbody>
</table>
<p>18576 rows × 10 columns</p>
</div></div></div>
</div>
<div class="section" id="when-is-it-ok-process-the-data-before-splitting-of-the-test-portion">
<h3><span class="section-number">4.11.1. </span>When is it OK process the data before splitting of the test portion?<a class="headerlink" href="#when-is-it-ok-process-the-data-before-splitting-of-the-test-portion" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Here it would have been OK to add new features before splitting because we are not using any global information in the data but only looking at one row at a time.</p></li>
<li><p>But just to be safe and to avoid accidentally breaking the golden rule, it’s better to do it after splitting.</p></li>
</ul>
</div>
</div>
<div class="section" id="preprocessing-imputation">
<h2><span class="section-number">4.12. </span>Preprocessing: Imputation<a class="headerlink" href="#preprocessing-imputation" title="Permalink to this headline">#</a></h2>
<p>Imputation is handling missing values in our data so let’s explore this a little.</p>
<p>We can <code class="docutils literal notranslate"><span class="pre">.info()</span></code> we can we all the different column dtypes and also all the number of null values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Index: 18576 entries, 6051 to 19966
Data columns (total 10 columns):
 #   Column                    Non-Null Count  Dtype  
---  ------                    --------------  -----  
 0   longitude                 18576 non-null  float64
 1   latitude                  18576 non-null  float64
 2   housing_median_age        18576 non-null  float64
 3   households                18576 non-null  float64
 4   median_income             18576 non-null  float64
 5   median_house_value        18576 non-null  float64
 6   ocean_proximity           18576 non-null  object 
 7   rooms_per_household       18576 non-null  float64
 8   bedrooms_per_household    18391 non-null  float64
 9   population_per_household  18576 non-null  float64
dtypes: float64(9), object(1)
memory usage: 1.6+ MB
</pre></div>
</div>
</div>
</div>
<p>We see that we have all columns with dtype <code class="docutils literal notranslate"><span class="pre">float64</span></code> except for <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code> which appears categorical.</p>
<p>We also notice that the <code class="docutils literal notranslate"><span class="pre">bedrooms_per_household</span></code> column appears to have some <code class="docutils literal notranslate"><span class="pre">Non-Null</span></code> rows (ie missing values).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;bedrooms_per_household&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>185
</pre></div>
</div>
</div>
</div>
<p>Knowing this information let’s build a model.</p>
<p>When we create our feature table and target objects, we are going to drop the categorical variable <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code>.  Currently, we don’t know how to build models with categorical data, but we will shortly. We will return to this column soon.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">,</span> <span class="s2">&quot;ocean_proximity&quot;</span><span class="p">])</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">]</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">,</span> <span class="s2">&quot;ocean_proximity&quot;</span><span class="p">])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">]</span>

<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>What happens when we try to fit our model with this data?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ValueError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">45</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nn">File ~/opt/miniconda3/envs/571/lib/python3.10/site-packages/sklearn/base.py:1152,</span> in <span class="ni">_fit_context.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper</span><span class="nt">(estimator, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1145</span>     <span class="n">estimator</span><span class="o">.</span><span class="n">_validate_params</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1147</span> <span class="k">with</span> <span class="n">config_context</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1148</span>     <span class="n">skip_parameter_validation</span><span class="o">=</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1149</span>         <span class="n">prefer_skip_nested_validation</span> <span class="ow">or</span> <span class="n">global_skip_validation</span>
<span class="g g-Whitespace">   </span><span class="mi">1150</span>     <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1151</span> <span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1152</span>     <span class="k">return</span> <span class="n">fit_method</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~/opt/miniconda3/envs/571/lib/python3.10/site-packages/sklearn/neighbors/_regression.py:218,</span> in <span class="ni">KNeighborsRegressor.fit</span><span class="nt">(self, X, y)</span>
<span class="g g-Whitespace">    </span><span class="mi">196</span> <span class="nd">@_fit_context</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">197</span>     <span class="c1"># KNeighborsRegressor.metric is not validated yet</span>
<span class="g g-Whitespace">    </span><span class="mi">198</span>     <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">False</span>
<span class="g g-Whitespace">    </span><span class="mi">199</span> <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">200</span> <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">201</span>     <span class="sd">&quot;&quot;&quot;Fit the k-nearest neighbors regressor from the training dataset.</span>
<span class="g g-Whitespace">    </span><span class="mi">202</span><span class="sd"> </span>
<span class="g g-Whitespace">    </span><span class="mi">203</span><span class="sd">     Parameters</span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">    </span><span class="mi">216</span><span class="sd">         The fitted k-nearest neighbors regressor.</span>
<span class="g g-Whitespace">    </span><span class="mi">217</span><span class="sd">     &quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">218</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nn">File ~/opt/miniconda3/envs/571/lib/python3.10/site-packages/sklearn/neighbors/_base.py:456,</span> in <span class="ni">NeighborsBase._fit</span><span class="nt">(self, X, y)</span>
<span class="g g-Whitespace">    </span><span class="mi">454</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_tags</span><span class="p">()[</span><span class="s2">&quot;requires_y&quot;</span><span class="p">]:</span>
<span class="g g-Whitespace">    </span><span class="mi">455</span>     <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="n">KDTree</span><span class="p">,</span> <span class="n">BallTree</span><span class="p">,</span> <span class="n">NeighborsBase</span><span class="p">)):</span>
<span class="ne">--&gt; </span><span class="mi">456</span>         <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">457</span>             <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="n">multi_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">458</span>         <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">460</span>     <span class="k">if</span> <span class="n">is_classifier</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">461</span>         <span class="c1"># Classification targets require a specific format</span>
<span class="g g-Whitespace">    </span><span class="mi">462</span>         <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>

<span class="nn">File ~/opt/miniconda3/envs/571/lib/python3.10/site-packages/sklearn/base.py:622,</span> in <span class="ni">BaseEstimator._validate_data</span><span class="nt">(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)</span>
<span class="g g-Whitespace">    </span><span class="mi">620</span>         <span class="n">y</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">check_y_params</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">621</span>     <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">622</span>         <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">check_params</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">623</span>     <span class="n">out</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
<span class="g g-Whitespace">    </span><span class="mi">625</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">no_val_X</span> <span class="ow">and</span> <span class="n">check_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ensure_2d&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>

<span class="nn">File ~/opt/miniconda3/envs/571/lib/python3.10/site-packages/sklearn/utils/validation.py:1146,</span> in <span class="ni">check_X_y</span><span class="nt">(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)</span>
<span class="g g-Whitespace">   </span><span class="mi">1141</span>         <span class="n">estimator_name</span> <span class="o">=</span> <span class="n">_check_estimator_name</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1142</span>     <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1143</span>         <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">estimator_name</span><span class="si">}</span><span class="s2"> requires y to be passed, but the target y is None&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">1144</span>     <span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1146</span> <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1147</span>     <span class="n">X</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1148</span>     <span class="n">accept_sparse</span><span class="o">=</span><span class="n">accept_sparse</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1149</span>     <span class="n">accept_large_sparse</span><span class="o">=</span><span class="n">accept_large_sparse</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1150</span>     <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1151</span>     <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1152</span>     <span class="n">copy</span><span class="o">=</span><span class="n">copy</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1153</span>     <span class="n">force_all_finite</span><span class="o">=</span><span class="n">force_all_finite</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1154</span>     <span class="n">ensure_2d</span><span class="o">=</span><span class="n">ensure_2d</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1155</span>     <span class="n">allow_nd</span><span class="o">=</span><span class="n">allow_nd</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1156</span>     <span class="n">ensure_min_samples</span><span class="o">=</span><span class="n">ensure_min_samples</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1157</span>     <span class="n">ensure_min_features</span><span class="o">=</span><span class="n">ensure_min_features</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1158</span>     <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1159</span>     <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1160</span> <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1162</span> <span class="n">y</span> <span class="o">=</span> <span class="n">_check_y</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">multi_output</span><span class="o">=</span><span class="n">multi_output</span><span class="p">,</span> <span class="n">y_numeric</span><span class="o">=</span><span class="n">y_numeric</span><span class="p">,</span> <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1164</span> <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nn">File ~/opt/miniconda3/envs/571/lib/python3.10/site-packages/sklearn/utils/validation.py:957,</span> in <span class="ni">check_array</span><span class="nt">(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)</span>
<span class="g g-Whitespace">    </span><span class="mi">951</span>         <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">952</span>             <span class="s2">&quot;Found array with dim </span><span class="si">%d</span><span class="s2">. </span><span class="si">%s</span><span class="s2"> expected &lt;= 2.&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">953</span>             <span class="o">%</span> <span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="n">estimator_name</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">954</span>         <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">956</span>     <span class="k">if</span> <span class="n">force_all_finite</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">957</span>         <span class="n">_assert_all_finite</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">958</span>             <span class="n">array</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">959</span>             <span class="n">input_name</span><span class="o">=</span><span class="n">input_name</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">960</span>             <span class="n">estimator_name</span><span class="o">=</span><span class="n">estimator_name</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">961</span>             <span class="n">allow_nan</span><span class="o">=</span><span class="n">force_all_finite</span> <span class="o">==</span> <span class="s2">&quot;allow-nan&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">962</span>         <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">964</span> <span class="k">if</span> <span class="n">ensure_min_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">965</span>     <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>

<span class="nn">File ~/opt/miniconda3/envs/571/lib/python3.10/site-packages/sklearn/utils/validation.py:122,</span> in <span class="ni">_assert_all_finite</span><span class="nt">(X, allow_nan, msg_dtype, estimator_name, input_name)</span>
<span class="g g-Whitespace">    </span><span class="mi">119</span> <span class="k">if</span> <span class="n">first_pass_isfinite</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">120</span>     <span class="k">return</span>
<span class="ne">--&gt; </span><span class="mi">122</span> <span class="n">_assert_all_finite_element_wise</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">123</span>     <span class="n">X</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">124</span>     <span class="n">xp</span><span class="o">=</span><span class="n">xp</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">125</span>     <span class="n">allow_nan</span><span class="o">=</span><span class="n">allow_nan</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">126</span>     <span class="n">msg_dtype</span><span class="o">=</span><span class="n">msg_dtype</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">127</span>     <span class="n">estimator_name</span><span class="o">=</span><span class="n">estimator_name</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">128</span>     <span class="n">input_name</span><span class="o">=</span><span class="n">input_name</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">129</span> <span class="p">)</span>

<span class="nn">File ~/opt/miniconda3/envs/571/lib/python3.10/site-packages/sklearn/utils/validation.py:171,</span> in <span class="ni">_assert_all_finite_element_wise</span><span class="nt">(X, xp, allow_nan, msg_dtype, estimator_name, input_name)</span>
<span class="g g-Whitespace">    </span><span class="mi">154</span> <span class="k">if</span> <span class="n">estimator_name</span> <span class="ow">and</span> <span class="n">input_name</span> <span class="o">==</span> <span class="s2">&quot;X&quot;</span> <span class="ow">and</span> <span class="n">has_nan_error</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">155</span>     <span class="c1"># Improve the error message on how to handle missing values in</span>
<span class="g g-Whitespace">    </span><span class="mi">156</span>     <span class="c1"># scikit-learn.</span>
<span class="g g-Whitespace">    </span><span class="mi">157</span>     <span class="n">msg_err</span> <span class="o">+=</span> <span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">158</span>         <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">estimator_name</span><span class="si">}</span><span class="s2"> does not accept missing values&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">159</span>         <span class="s2">&quot; encoded as NaN natively. For supervised learning, you might want&quot;</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">169</span>         <span class="s2">&quot;#estimators-that-handle-nan-values&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">170</span>     <span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">171</span> <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg_err</span><span class="p">)</span>

<span class="ne">ValueError</span>: Input X contains NaN.
<span class="n">KNeighborsRegressor</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">accept</span> <span class="n">missing</span> <span class="n">values</span> <span class="n">encoded</span> <span class="k">as</span> <span class="n">NaN</span> <span class="n">natively</span><span class="o">.</span> <span class="n">For</span> <span class="n">supervised</span> <span class="n">learning</span><span class="p">,</span> <span class="n">you</span> <span class="n">might</span> <span class="n">want</span> <span class="n">to</span> <span class="n">consider</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span><span class="o">.</span><span class="n">HistGradientBoostingClassifier</span> <span class="ow">and</span> <span class="n">Regressor</span> <span class="n">which</span> <span class="n">accept</span> <span class="n">missing</span> <span class="n">values</span> <span class="n">encoded</span> <span class="k">as</span> <span class="n">NaNs</span> <span class="n">natively</span><span class="o">.</span> <span class="n">Alternatively</span><span class="p">,</span> <span class="n">it</span> <span class="ow">is</span> <span class="n">possible</span> <span class="n">to</span> <span class="n">preprocess</span> <span class="n">the</span> <span class="n">data</span><span class="p">,</span> <span class="k">for</span> <span class="n">instance</span> <span class="n">by</span> <span class="n">using</span> <span class="n">an</span> <span class="n">imputer</span> <span class="n">transformer</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">pipeline</span> <span class="ow">or</span> <span class="n">drop</span> <span class="n">samples</span> <span class="k">with</span> <span class="n">missing</span> <span class="n">values</span><span class="o">.</span> <span class="n">See</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">scikit</span><span class="o">-</span><span class="n">learn</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">stable</span><span class="o">/</span><span class="n">modules</span><span class="o">/</span><span class="n">impute</span><span class="o">.</span><span class="n">html</span> <span class="n">You</span> <span class="n">can</span> <span class="n">find</span> <span class="n">a</span> <span class="nb">list</span> <span class="n">of</span> <span class="nb">all</span> <span class="n">estimators</span> <span class="n">that</span> <span class="n">handle</span> <span class="n">NaN</span> <span class="n">values</span> <span class="n">at</span> <span class="n">the</span> <span class="n">following</span> <span class="n">page</span><span class="p">:</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">scikit</span><span class="o">-</span><span class="n">learn</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">stable</span><span class="o">/</span><span class="n">modules</span><span class="o">/</span><span class="n">impute</span><span class="o">.</span><span class="n">html</span><span class="c1">#estimators-that-handle-nan-values</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">Input</span> <span class="pre">contains</span> <span class="pre">NaN,</span> <span class="pre">infinity</span> <span class="pre">or</span> <span class="pre">a</span> <span class="pre">value</span> <span class="pre">too</span> <span class="pre">large</span> <span class="pre">for</span> <span class="pre">dtype('float64').</span></code></p>
</div></blockquote>
<p>The classifier can’t deal with missing values (NaNs).</p>
<p>How can we deal with this problem?</p>
<div class="section" id="why-we-don-t-drop-the-rows">
<h3><span class="section-number">4.12.1. </span>Why we don’t drop the rows<a class="headerlink" href="#why-we-don-t-drop-the-rows" title="Permalink to this headline">#</a></h3>
<p>We could drop any rows that are missing information but that’s problematic too.</p>
<p>Then we would need to do the same in our test set.</p>
<p>And what happens if we get missing values in our deployment data? what then?</p>
<p>Furthermore, what if the missing values don’t occur at random and we’re systematically dropping certain data?
Perhaps a certain type of house contributes to more missing values.</p>
<p>Dropping the rows is not a great solution, especially if there’s a lot of missing values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(18576, 8)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_no_nan</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">X_train_no_nan</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(18391, 8)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="why-we-don-t-drop-the-column">
<h3><span class="section-number">4.12.2. </span>Why we don’t drop the column<a class="headerlink" href="#why-we-don-t-drop-the-column" title="Permalink to this headline">#</a></h3>
<p>If we drop the column instead of the rows, we are throwing away, in this case, 18391 values just because we don’t have 185 missing values out of a total of 18567.</p>
<p>We are throwing away 99% of the column’s data because we are missing 1%.</p>
<p>But perhaps if we were missing 99.9% of the column values, for example, it would make more sense to drop the column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(18576, 8)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_no_col</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_train_no_col</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(18576, 7)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="why-we-use-imputation">
<h3><span class="section-number">4.12.3. </span>Why we use imputation<a class="headerlink" href="#why-we-use-imputation" title="Permalink to this headline">#</a></h3>
<p>With <strong>Imputation</strong>, we invent values for the missing data.</p>
<p>Using <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>’s <strong>transformer</strong> <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code>, we can impute the <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values in the data with some value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
</pre></div>
</div>
</div>
</div>
<p>We can impute missing values in:</p>
<ul class="simple">
<li><p><strong>Categorical columns</strong>:</p>
<ul>
<li><p>with the most frequent value</p></li>
<li><p>with a constant of our choosing.</p></li>
</ul>
</li>
<li><p><strong>Numeric columns</strong>:</p>
<ul>
<li><p>with the mean  of the column</p></li>
<li><p>with the median of the column</p></li>
<li><p>or a constant of our choosing.</p></li>
</ul>
</li>
</ul>
<p>If I sort the values by <code class="docutils literal notranslate"><span class="pre">bedrooms_per_household</span></code> and look at the end of the dataframe, we can see our missing values in the <code class="docutils literal notranslate"><span class="pre">bedrooms_per_household</span></code> column.</p>
<p>Pay close attention to index 7763 since we are going to look at this row after imputation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;bedrooms_per_household&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>households</th>
      <th>median_income</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>18786</th>
      <td>-122.42</td>
      <td>40.44</td>
      <td>16.0</td>
      <td>181.0</td>
      <td>2.1875</td>
      <td>5.491713</td>
      <td>NaN</td>
      <td>2.734807</td>
    </tr>
    <tr>
      <th>17923</th>
      <td>-121.97</td>
      <td>37.35</td>
      <td>30.0</td>
      <td>386.0</td>
      <td>4.6328</td>
      <td>5.064767</td>
      <td>NaN</td>
      <td>2.588083</td>
    </tr>
    <tr>
      <th>16880</th>
      <td>-122.39</td>
      <td>37.59</td>
      <td>32.0</td>
      <td>715.0</td>
      <td>6.1323</td>
      <td>6.289510</td>
      <td>NaN</td>
      <td>2.581818</td>
    </tr>
    <tr>
      <th>4309</th>
      <td>-118.32</td>
      <td>34.09</td>
      <td>44.0</td>
      <td>726.0</td>
      <td>1.6760</td>
      <td>3.672176</td>
      <td>NaN</td>
      <td>3.163912</td>
    </tr>
    <tr>
      <th>538</th>
      <td>-122.28</td>
      <td>37.78</td>
      <td>29.0</td>
      <td>1273.0</td>
      <td>2.5762</td>
      <td>4.048704</td>
      <td>NaN</td>
      <td>2.938727</td>
    </tr>
    <tr>
      <th>4591</th>
      <td>-118.28</td>
      <td>34.06</td>
      <td>42.0</td>
      <td>1179.0</td>
      <td>1.2254</td>
      <td>2.096692</td>
      <td>NaN</td>
      <td>3.218830</td>
    </tr>
    <tr>
      <th>19485</th>
      <td>-120.98</td>
      <td>37.66</td>
      <td>10.0</td>
      <td>255.0</td>
      <td>0.9336</td>
      <td>3.662745</td>
      <td>NaN</td>
      <td>1.572549</td>
    </tr>
    <tr>
      <th>6962</th>
      <td>-118.05</td>
      <td>33.99</td>
      <td>38.0</td>
      <td>357.0</td>
      <td>3.7328</td>
      <td>4.535014</td>
      <td>NaN</td>
      <td>2.481793</td>
    </tr>
    <tr>
      <th>14970</th>
      <td>-117.01</td>
      <td>32.74</td>
      <td>31.0</td>
      <td>677.0</td>
      <td>2.6973</td>
      <td>5.129985</td>
      <td>NaN</td>
      <td>3.098966</td>
    </tr>
    <tr>
      <th>7763</th>
      <td>-118.10</td>
      <td>33.91</td>
      <td>36.0</td>
      <td>130.0</td>
      <td>3.6389</td>
      <td>5.584615</td>
      <td>NaN</td>
      <td>3.769231</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Using the same <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">transform</span></code> syntax we saw earlier for transformers, we can impute the <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values.</p>
<p>Here we specify <code class="docutils literal notranslate"><span class="pre">strategy=&quot;median&quot;</span></code> which replaces all the missing values with the column median.</p>
<p>We fit on the training data and transform it on the train and test splits.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)</span>
<span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">);</span>
<span class="n">X_train_imp</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_imp</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_imp</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-117.75      ,   34.04      ,   22.        , ...,    4.89700997,
           1.05647841,    4.31893688],
       [-119.57      ,   37.94      ,   17.        , ...,   17.3       ,
           6.5       ,    2.55      ],
       [-117.13      ,   32.74      ,   46.        , ...,    4.73870056,
           1.08474576,    2.0579096 ],
       ...,
       [-121.76      ,   37.33      ,    5.        , ...,    5.95839311,
           1.03156385,    3.49354376],
       [-122.44      ,   37.78      ,   44.        , ...,    4.7392638 ,
           1.02453988,    1.7208589 ],
       [-119.08      ,   36.21      ,   20.        , ...,    5.49137931,
           1.11781609,    3.56609195]])
</pre></div>
</div>
</div>
</div>
<p>Ok, the output of this isn’t a dataframe but a NumPy array!</p>
<p>I can do a bit of wrangling here to take a look at this new array with our previous column labels and as a dataframe.</p>
<p>If I search for our index 7763 which previously contained a <code class="docutils literal notranslate"><span class="pre">NaN</span></code> value, we can see that now I have the median value for the <code class="docutils literal notranslate"><span class="pre">bedrooms_per_household</span></code> column from the <code class="docutils literal notranslate"><span class="pre">X_train</span></code> dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_imp_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">X_train_imp_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="mi">7763</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>households</th>
      <th>median_income</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7763</th>
      <td>-118.1</td>
      <td>33.91</td>
      <td>36.0</td>
      <td>130.0</td>
      <td>3.6389</td>
      <td>5.584615</td>
      <td>1.04886</td>
      <td>3.769231</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;bedrooms_per_household&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0488599348534202
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_imp_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="mi">7763</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>households</th>
      <th>median_income</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7763</th>
      <td>-118.1</td>
      <td>33.91</td>
      <td>36.0</td>
      <td>130.0</td>
      <td>3.6389</td>
      <td>5.584615</td>
      <td>1.04886</td>
      <td>3.769231</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now when we try and fit our model using <code class="docutils literal notranslate"><span class="pre">X_train_imp</span></code>, it works!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5609808539232339
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="more-sophisticated-imputation-methods">
<h3><span class="section-number">4.12.4. </span>More sophisticated imputation methods<a class="headerlink" href="#more-sophisticated-imputation-methods" title="Permalink to this headline">#</a></h3>
<p>Instead of using the most frequent label or an average of all the data when we impute,
we can try to use ML-techniques also for the imputation step.
For example,
we can use an average value from the rows that are the most similar to observation that have a missing value,
by first running a similarity ML-method such as kNN to determine which these rows are
(but note that this is still sensitive to rescaling of the data).
Instead of subsetting the data we can also use different regression methods
to build a function that uses all the existing features to predicted what the value of the missing feature should be.
These methods generally perform better than simple imputation that we use here,
but they also require more careful implementation and higher computational cost.
You can read more about them in these links:</p>
<ul class="simple">
<li><p>https://scikit-learn.org/stable/modules/impute.html</p></li>
<li><p>https://scikit-learn.org/stable/auto_examples/impute/plot_iterative_imputer_variants_comparison.html#sphx-glr-auto-examples-impute-plot-iterative-imputer-variants-comparison-py</p></li>
<li><p>https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779</p></li>
</ul>
</div>
</div>
<div class="section" id="preprocessing-scaling">
<h2><span class="section-number">4.13. </span>Preprocessing: Scaling<a class="headerlink" href="#preprocessing-scaling" title="Permalink to this headline">#</a></h2>
<p>So we’ve seen why scaling is important earlier but let’s take a little bit of a closer look here.
There are many ways to scale your data but we are going to look at 2 of them.</p>
<p><img alt="" src="https://amueller.github.io/COMS4995-s19/slides/aml-05-preprocessing/images/scaler_comparison_scatter.png" /></p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Approach</p></th>
<th class="head"><p>What it does</p></th>
<th class="head"><p>How to update <span class="math notranslate nohighlight">\(X\)</span> (but see below!)</p></th>
<th class="head"><p>sklearn implementation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>normalization</p></td>
<td><p>sets range to <span class="math notranslate nohighlight">\([0,1]\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">-=</span> <span class="pre">np.min(X,axis=0)</span></code><br><code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">/=</span> <span class="pre">np.max(X,axis=0)</span></code></p></td>
<td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"><code class="docutils literal notranslate"><span class="pre">MinMaxScaler()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p>standardization</p></td>
<td><p>sets sample mean to <span class="math notranslate nohighlight">\(0\)</span>, s.d. to <span class="math notranslate nohighlight">\(1\)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">-=</span> <span class="pre">np.mean(X,axis=0)</span></code><br><code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">/=</span>&#160; <span class="pre">np.std(X,axis=0)</span></code></p></td>
<td><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler"><code class="docutils literal notranslate"><span class="pre">StandardScaler()</span></code></a></p></td>
</tr>
</tbody>
</table>
<p>For more resources and articles on this, see <a class="reference external" href="http://www.dataminingblog.com/standardization-vs-normalization/">here</a> and <a class="reference external" href="https://medium.com/&#64;rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc">here</a>.</p>
<p>Let’s see what happens when we use each of them.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">StandardScaler</span>
</pre></div>
</div>
</div>
</div>
<p>First, let’s see how standardization is done first.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled_std</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">)</span>
<span class="n">X_test_scaled_std</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_imp</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_scaled_std</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>households</th>
      <th>median_income</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6051</th>
      <td>0.908140</td>
      <td>-0.743917</td>
      <td>-0.526078</td>
      <td>0.266135</td>
      <td>-0.389736</td>
      <td>-0.210591</td>
      <td>-0.083813</td>
      <td>0.126398</td>
    </tr>
    <tr>
      <th>20113</th>
      <td>-0.002057</td>
      <td>1.083123</td>
      <td>-0.923283</td>
      <td>-1.253312</td>
      <td>-0.198924</td>
      <td>4.726412</td>
      <td>11.166631</td>
      <td>-0.050132</td>
    </tr>
    <tr>
      <th>14289</th>
      <td>1.218207</td>
      <td>-1.352930</td>
      <td>1.380504</td>
      <td>0.542873</td>
      <td>-0.635239</td>
      <td>-0.273606</td>
      <td>-0.025391</td>
      <td>-0.099240</td>
    </tr>
    <tr>
      <th>13665</th>
      <td>1.128188</td>
      <td>-0.753286</td>
      <td>-0.843842</td>
      <td>-0.561467</td>
      <td>0.714077</td>
      <td>0.122307</td>
      <td>-0.280310</td>
      <td>0.010183</td>
    </tr>
    <tr>
      <th>14471</th>
      <td>1.168196</td>
      <td>-1.287344</td>
      <td>-0.843842</td>
      <td>2.500924</td>
      <td>-1.059242</td>
      <td>-0.640266</td>
      <td>-0.190617</td>
      <td>0.126808</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>7763</th>
      <td>0.733102</td>
      <td>-0.804818</td>
      <td>0.586095</td>
      <td>-0.966131</td>
      <td>-0.118182</td>
      <td>0.063110</td>
      <td>-0.099558</td>
      <td>0.071541</td>
    </tr>
    <tr>
      <th>15377</th>
      <td>1.163195</td>
      <td>-1.057793</td>
      <td>-1.161606</td>
      <td>0.728235</td>
      <td>0.357500</td>
      <td>0.235096</td>
      <td>-0.163397</td>
      <td>0.007458</td>
    </tr>
    <tr>
      <th>17730</th>
      <td>-1.097293</td>
      <td>0.797355</td>
      <td>-1.876574</td>
      <td>0.514155</td>
      <td>0.934269</td>
      <td>0.211892</td>
      <td>-0.135305</td>
      <td>0.044029</td>
    </tr>
    <tr>
      <th>15725</th>
      <td>-1.437367</td>
      <td>1.008167</td>
      <td>1.221622</td>
      <td>-0.454427</td>
      <td>0.006578</td>
      <td>-0.273382</td>
      <td>-0.149822</td>
      <td>-0.132875</td>
    </tr>
    <tr>
      <th>19966</th>
      <td>0.242996</td>
      <td>0.272667</td>
      <td>-0.684960</td>
      <td>-0.396991</td>
      <td>-0.711754</td>
      <td>0.025998</td>
      <td>0.042957</td>
      <td>0.051269</td>
    </tr>
  </tbody>
</table>
<p>18576 rows × 8 columns</p>
</div></div></div>
</div>
<p>Here, any negative values represent values that are lower than the calculated feature mean and anything positive and greater than 0 are values greater than the original column mean.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Unscaled training score :&#39;</span><span class="p">,</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Unscaled training score : 0.561
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled_std</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Scaled training score :&#39;</span><span class="p">,</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled_std</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Scaled training score : 0.7978563117812038
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X_train_scaled_norm</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">)</span>
<span class="n">X_test_scaled_norm</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_imp</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_scaled_norm</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>households</th>
      <th>median_income</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6051</th>
      <td>0.657371</td>
      <td>0.159405</td>
      <td>0.411765</td>
      <td>0.098832</td>
      <td>0.181039</td>
      <td>0.028717</td>
      <td>0.021437</td>
      <td>0.002918</td>
    </tr>
    <tr>
      <th>20113</th>
      <td>0.476096</td>
      <td>0.573858</td>
      <td>0.313725</td>
      <td>0.003124</td>
      <td>0.205942</td>
      <td>0.116642</td>
      <td>0.182806</td>
      <td>0.001495</td>
    </tr>
    <tr>
      <th>14289</th>
      <td>0.719124</td>
      <td>0.021254</td>
      <td>0.882353</td>
      <td>0.116264</td>
      <td>0.148998</td>
      <td>0.027594</td>
      <td>0.022275</td>
      <td>0.001099</td>
    </tr>
    <tr>
      <th>13665</th>
      <td>0.701195</td>
      <td>0.157279</td>
      <td>0.333333</td>
      <td>0.046703</td>
      <td>0.325099</td>
      <td>0.034645</td>
      <td>0.018619</td>
      <td>0.001981</td>
    </tr>
    <tr>
      <th>14471</th>
      <td>0.709163</td>
      <td>0.036132</td>
      <td>0.333333</td>
      <td>0.239599</td>
      <td>0.093661</td>
      <td>0.021064</td>
      <td>0.019905</td>
      <td>0.002922</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Looking at the data after normalizing it, we see this time there are no negative values and they all are between 0 and 1.</p>
<p>And the score now?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled_norm</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Scaled training score :&#39;</span><span class="p">,</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled_norm</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Scaled training score : 0.8006485189373813
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Big difference in the KNN training performance after scaling the data.</p></li>
<li><p>But we saw last week that the training score doesn’t tell us much. We should look at the cross-validation score.</p></li>
</ul>
<p>So let’s see how we can do this but first…. let’s practice!</p>
</div>
<div class="section" id="id3">
<h2><span class="section-number">4.14. </span>Let’s Practice<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h2>
<p>1. When/Why do we need to impute our data?<br />
2. If we have <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values in our data, can we simply drop the column missing the data?<br />
3. Which scaling method will never produce negative values?<br />
4. Which scaling method will never produce values greater than 1?<br />
5. Which scaling method will produce values where the range depends on the values in the data?</p>
<p><strong>True or False</strong></p>
<p>6. <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> is a type of transformer.<br />
7. Scaling is a form of transformation.<br />
8. We can use <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> to impute values that are missing from numerical and categorical columns.</p>
<div class="dropdown admonition">
<p class="admonition-title">Solutions!</p>
<ol class="simple">
<li><p>When we have missing data so that sklearn doesn’t give an error.</p></li>
<li><p>No but we can if the majority of the values are missing from the column.</p></li>
<li><p>Normalization (<code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code>)</p></li>
<li><p>Normalization (<code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code>)</p></li>
<li><p>Standardization (<code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code>)</p></li>
<li><p>True</p></li>
<li><p>True</p></li>
<li><p>True</p></li>
</ol>
</div>
</div>
<div class="section" id="feature-transformations-and-the-golden-rule">
<h2><span class="section-number">4.15. </span>Feature transformations and the golden rule<a class="headerlink" href="#feature-transformations-and-the-golden-rule" title="Permalink to this headline">#</a></h2>
<p>How to carry out cross-validation?</p>
<ul class="simple">
<li><p>Last week we saw that cross-validation is a better way to get a realistic assessment of the model.</p></li>
<li><p>Let’s try cross-validation with transformed data.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">X_train_scaled_std</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.009116</td>
      <td>0.160559</td>
      <td>0.696373</td>
      <td>0.794236</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.008147</td>
      <td>0.134536</td>
      <td>0.684447</td>
      <td>0.791467</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.007982</td>
      <td>0.143678</td>
      <td>0.695532</td>
      <td>0.789436</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.007958</td>
      <td>0.144992</td>
      <td>0.679478</td>
      <td>0.793243</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.008038</td>
      <td>0.089106</td>
      <td>0.680657</td>
      <td>0.794820</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>Do you see any problem here?</p></li>
</ul>
<p>We are using our <code class="docutils literal notranslate"><span class="pre">X_train_scaled</span></code> in our <code class="docutils literal notranslate"><span class="pre">cross_validate()</span></code> function which already has all our preprocessing done.</p>
<a class="reference internal image-reference" href="../_images/cross-validation.png"><img alt="../_images/cross-validation.png" src="../_images/cross-validation.png" style="width: 80%;" /></a>
<p>That means that our validation set information is being used to calculate the mean and standard deviation (or min and max values for <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code>) for our training split!</p>
<p>We are allowing information from the validation set to <strong>leak</strong> into the training step.</p>
<p>What was our golden rule of machine learning again? Oh yeah -&gt; <em><strong>Our test data should not influence our training data</strong></em>.</p>
<p>This applies also to our validation data and that it also should not influence our training data.</p>
<p>With imputation and scaling, we are scaling and imputing values based on all the information in the data meaning the training data AND the validation data and so we are not adhering to the golden rule anymore.</p>
<p>Every row in our <code class="docutils literal notranslate"><span class="pre">x_train_scaled</span></code> has now been influenced in a minor way by every other row in <code class="docutils literal notranslate"><span class="pre">x_train_scaled</span></code>.</p>
<p>With scaling every row has been transformed based on all the data before splitting between training and validation.</p>
<p>We need to take care that we are keeping our validation data truly as unseen data.</p>
<p>Before we look at the right approach to this, let’s look at the <strong>WRONG</strong> approaches.</p>
<div class="section" id="bad-methodology-1-scaling-the-data-separately">
<h3><span class="section-number">4.15.1. </span>Bad methodology 1: Scaling the data separately<a class="headerlink" href="#bad-methodology-1-scaling-the-data-separately" title="Permalink to this headline">#</a></h3>
<p>We make our transformer, we fit it on the training data and then transform the training data.</p>
<p>Then, we make a second transformer, fit it on the test data and then transform our test data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">();</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">);</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train_imp</span><span class="p">)</span>


<span class="c1"># Creating a separate object for scaling test data - Not a good idea.</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">();</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_test_imp</span><span class="p">);</span> <span class="c1"># Calling fit on the test data - Yikes! </span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_imp</span><span class="p">)</span> <span class="c1"># Transforming the test data using the scaler fit on test data ... Bad! </span>


<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training score: &quot;</span><span class="p">,</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test score: &quot;</span><span class="p">,</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training score:  0.8
Test score:  0.7
</pre></div>
</div>
</div>
</div>
<p>This is bad because we are using two different StandardScaler objects but we want to apply the same transformation on the training and test splits.</p>
<p>The test data will have different values than the training data producing a different transformation than the training data.</p>
<p>We should never fit on test data, whether it’s to build a model or with a transforming, test data should never be exposed to the fit function.</p>
</div>
<div class="section" id="bad-methodology-2-scaling-the-data-together">
<h3><span class="section-number">4.15.2. </span>Bad methodology 2: Scaling the data together<a class="headerlink" href="#bad-methodology-2-scaling-the-data-together" title="Permalink to this headline">#</a></h3>
<p>The next mistake is when we scale the data together. So instead of splitting our data, we are combining our training and testing and scaling it together.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_imp</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test_imp</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((18576, 8), (2064, 8))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># join the train and test sets back together</span>
<span class="n">XX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">X_train_imp</span><span class="p">,</span> <span class="n">X_test_imp</span><span class="p">))</span><span class="c1">## Don&#39;t do it! </span>
<span class="n">XX</span><span class="o">.</span><span class="n">shape</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(20640, 8)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XX</span><span class="p">)</span>
<span class="n">XX_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">XX</span><span class="p">)</span> 
<span class="n">XX_train</span> <span class="o">=</span> <span class="n">XX_scaled</span><span class="p">[:</span><span class="mi">18576</span><span class="p">]</span>
<span class="n">XX_test</span> <span class="o">=</span> <span class="n">XX_scaled</span><span class="p">[</span><span class="mi">18576</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">()</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XX_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train score: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">XX_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span> <span class="c1"># Misleading score</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test score: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">XX_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span> <span class="c1"># Misleading score</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train score:  0.8
Test score:  0.71
</pre></div>
</div>
</div>
</div>
<p>Here we are scaling the train and test splits together.</p>
<p>The golden rule says that the test data shouldn’t influence the training in any way.</p>
<p>Information from the test split is now affecting the mean for standardization!</p>
<p>This is a clear violation of the golden rule.</p>
<p>So what do we do? Enter ….</p>
</div>
</div>
<div class="section" id="pipelines">
<h2><span class="section-number">4.16. </span>Pipelines<a class="headerlink" href="#pipelines" title="Permalink to this headline">#</a></h2>
<p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html">Scikit-learn Pipeline</a> is here to save the day!</p>
<p>A <strong>pipeline</strong> is a sklearn function that contains a sequence of steps.</p>
<p>Essentially we give it all the actions we want to do with our data such as transformers and models and the pipeline will execute them in steps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s combine the preprocessing and model with pipeline.</p>
<p>we will instruct the pipeline to:</p>
<ol class="simple">
<li><p>Do imputation using <code class="docutils literal notranslate"><span class="pre">SimpleImputer()</span></code> using a strategy of “median”</p></li>
<li><p>Scale our data using <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code></p></li>
<li><p>Build a <code class="docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code>.</p></li>
</ol>
<p>(The last step should be a model and earlier steps should be transformers)</p>
<p>Note: The input for <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> is a list containing tuples (one for each step).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
        <span class="p">(</span><span class="s2">&quot;reg&quot;</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">())</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),
                (&#x27;scaler&#x27;, StandardScaler()), (&#x27;reg&#x27;, KNeighborsRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" ><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),
                (&#x27;scaler&#x27;, StandardScaler()), (&#x27;reg&#x27;, KNeighborsRegressor())])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" ><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">SimpleImputer</label><div class="sk-toggleable__content"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" ><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">KNeighborsRegressor</label><div class="sk-toggleable__content"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Note that we are passing <code class="docutils literal notranslate"><span class="pre">X_train</span></code> and <strong>NOT</strong> the imputed or scaled data here.</p></li>
</ul>
<p>When we call <code class="docutils literal notranslate"><span class="pre">fit</span></code>  the pipeline is carrying out the following steps:</p>
<ul class="simple">
<li><p>Fit <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> on <code class="docutils literal notranslate"><span class="pre">X_train</span></code>.</p></li>
<li><p>Transform <code class="docutils literal notranslate"><span class="pre">X_train</span></code> using the fit <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> to create <code class="docutils literal notranslate"><span class="pre">X_train_imp</span></code>.</p></li>
<li><p>Fit <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> on <code class="docutils literal notranslate"><span class="pre">X_train_imp</span></code>.</p></li>
<li><p>Transform <code class="docutils literal notranslate"><span class="pre">X_train_imp</span></code> using the fit <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> to create <code class="docutils literal notranslate"><span class="pre">X_train_imp_scaled</span></code>.</p></li>
<li><p>Fit the model (<code class="docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code> in our case) on <code class="docutils literal notranslate"><span class="pre">X_train_imp_scaled</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([126500., 117380., 187700., ..., 259500., 308120.,  60860.])
</pre></div>
</div>
</div>
</div>
<p>When we call <code class="docutils literal notranslate"><span class="pre">predict</span></code> on our data, the following steps are carrying out:</p>
<ul class="simple">
<li><p>Transform <code class="docutils literal notranslate"><span class="pre">X_train</span></code> using the fit <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> to create <code class="docutils literal notranslate"><span class="pre">X_train_imp</span></code>.</p></li>
<li><p>Transform <code class="docutils literal notranslate"><span class="pre">X_train_imp</span></code> using the fit <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> to create <code class="docutils literal notranslate"><span class="pre">X_train_imp_scaled</span></code>.</p></li>
<li><p>Predict using the fit model (<code class="docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code> in our case) on <code class="docutils literal notranslate"><span class="pre">X_train_imp_scaled</span></code>.</p></li>
</ul>
<p>It is not fitting any of the data this time.</p>
<a class="reference internal image-reference" href="https://amueller.github.io/COMS4995-s20/slides/aml-04-preprocessing/images/pipeline.png"><img alt="https://amueller.github.io/COMS4995-s20/slides/aml-04-preprocessing/images/pipeline.png" src="https://amueller.github.io/COMS4995-s20/slides/aml-04-preprocessing/images/pipeline.png" style="width: 50%;" /></a>
<p><a class="reference external" href="https://amueller.github.io/COMS4995-s20/slides/aml-04-preprocessing/#18">Source</a></p>
<p>We can’t accidentally re-fit the preprocessor on the test data as we did before.</p>
<p>It automatically makes sure the same transformations are applied to train and test.</p>
<p>Now when we do cross-validation on the pipeline the transformers and the model are refit on each fold.</p>
<p>The pipeline applies the <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> on the train portion of the data and only <code class="docutils literal notranslate"><span class="pre">transform</span></code> on the validation portion in <strong>each fold</strong>.</p>
<p>This is how to avoid the Golden Rule violation!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores_processed</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores_processed</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.022580</td>
      <td>0.157835</td>
      <td>0.693883</td>
      <td>0.792395</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.020257</td>
      <td>0.140336</td>
      <td>0.685017</td>
      <td>0.789108</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.019219</td>
      <td>0.143953</td>
      <td>0.694409</td>
      <td>0.787796</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.019068</td>
      <td>0.147445</td>
      <td>0.677055</td>
      <td>0.792444</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.019125</td>
      <td>0.117869</td>
      <td>0.714494</td>
      <td>0.823421</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores_processed</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.020050
score_time     0.141488
test_score     0.692972
train_score    0.797033
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dummy</span> <span class="o">=</span> <span class="n">DummyRegressor</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">dummy</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.001078
score_time     0.000348
test_score    -0.000838
train_score    0.000000
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>We can trust here now that the scores are not influenced but the training data and all our steps were done efficiently and easily too.</p>
</div>
<div class="section" id="id4">
<h2><span class="section-number">4.17. </span>Let’s Practice<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h2>
<p>1. Which of the following steps cannot be used in a pipeline?</p>
<p>a) Scaling<br />
b) Model building<br />
c) Imputation<br />
d) Data Splitting</p>
<p>2. Why can’t we fit and transform the training and test data together?</p>
<p><strong>True or False</strong></p>
<p>3. We have to be careful of the order we put each transformation and model in a pipeline.<br />
4. Pipelines will fit and transform on both the training and validation folds during cross-validation.</p>
<div class="dropdown admonition">
<p class="admonition-title">Solutions!</p>
<ol class="simple">
<li><p>Data Splitting</p></li>
<li><p>It’s violating the golden rule of keeping the test data separate.</p></li>
<li><p>True</p></li>
<li><p>False</p></li>
</ol>
</div>
</div>
<div class="section" id="id5">
<h2><span class="section-number">4.18. </span>Let’s Practice - Coding<a class="headerlink" href="#id5" title="Permalink to this headline">#</a></h2>
<p>Let’s bring in the basketball dataset again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Loading in the data</span>
<span class="n">bball_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/bball.csv&#39;</span><span class="p">)</span>
<span class="n">bball_df</span> <span class="o">=</span> <span class="n">bball_df</span><span class="p">[(</span><span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;G&#39;</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span> <span class="o">==</span><span class="s1">&#39;F&#39;</span><span class="p">)]</span>

<span class="c1"># Define X and y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">bball_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="s1">&#39;salary&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">bball_df</span><span class="p">[</span><span class="s1">&#39;position&#39;</span><span class="p">]</span>

<span class="c1"># Split the dataset</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ol class="simple">
<li><p>Build a pipeline named <code class="docutils literal notranslate"><span class="pre">bb_pipe</span></code> that:</p>
<ol class="simple">
<li><p>Imputes using “mean” as a strategy,</p></li>
<li><p>scale using <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code></p></li>
<li><p>builds a <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code>.</p></li>
</ol>
</li>
<li><p>Next, do 5 fold cross-validation on the pipeline using <code class="docutils literal notranslate"><span class="pre">X_train</span></code> and <code class="docutils literal notranslate"><span class="pre">y_train</span></code> and save the results in a dataframe.
Take the mean of each column and assess your model.</p></li>
</ol>
<p><strong>Solutions</strong></p>
<p>1.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s2">&quot;imputer&quot;</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">()),</span>
        <span class="p">(</span><span class="s2">&quot;reg&quot;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">())</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>2.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.002501
score_time     0.003170
test_score     0.873469
train_score    0.916327
dtype: float64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="what-we-ve-learned-today-a-id-9-a">
<h2><span class="section-number">4.19. </span>What We’ve Learned Today<a id="9"></a><a class="headerlink" href="#what-we-ve-learned-today-a-id-9-a" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>How the <span class="math notranslate nohighlight">\(k\)</span>NN algorithm works for regression.</p></li>
<li><p>How to build an SVM with RBF kernel model.</p></li>
<li><p>How changing <code class="docutils literal notranslate"><span class="pre">gamma</span></code> and <code class="docutils literal notranslate"><span class="pre">C</span></code> hyperparameters affects the fundamental tradeoff.</p></li>
<li><p>How to imputer values when we are missing data.</p></li>
<li><p>Why it’s important to scale our features.</p></li>
<li><p>How to scales our features.</p></li>
<li><p>How to build a pipeline that executes a number of steps without breaking the golden rule of ML.</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="lecture3.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">3. </span>Baseline models &amp; k-Nearest Neighbours</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="lecture5.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5. </span>Preprocessing Categorical Features and Column Transformer</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Quan Nguyen<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>