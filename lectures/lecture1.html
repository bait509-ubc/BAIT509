
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Intro to ML &amp; Decision Trees &#8212; BAIT 509&lt;br&gt;Business Applications of Machine Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="canonical" href="https://bait509-ubc.github.io/BAIT509/intro.html/lectures/lecture1.html" />
    <link rel="shortcut icon" href="../_static/bait_logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Splitting and Cross-validation" href="lecture2.html" />
    <link rel="prev" title="What: Learning Outcomes" href="../things_to_know/what.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/bait_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">BAIT 509<br>Business Applications of Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Things You Should Know
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/who.html">
   Who: Quan Nguyen
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/how.html">
   How: The Course Structure
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/what.html">
   What: Learning Outcomes
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. Intro to ML &amp;  Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture2.html">
   2. Splitting and Cross-validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture3.html">
   3. Baseline models &amp; k-Nearest Neighbours
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture4.html">
   4. kNN regression, Support Vector Machines, and Feature Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture5.html">
   5. Preprocessing Categorical Features and Column Transformer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture6.html">
   6. Naive Bayes and Hyperparameter Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture7.html">
   7. Linear Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture8.html">
   8. Business Objectives/Statistical Questions and Feature Selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture9.html">
   9. Classification and Regression Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture10a.html">
   10. Data Science Ethics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecture10b.html">
   11. Multi-Class Classification (Optional)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../things_to_know/attribution.html">
   Attribution
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/bait509-ubc/BAIT509/issues/new?title=Issue%20on%20page%20%2Flectures/lecture1.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/lectures/lecture1.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#welcome">
   1.1. Welcome
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#course-learning-objectives">
     1.1.1. Course Learning Objectives
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#course-structure">
     1.1.2. Course Structure
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#python-jupyter-visualizations">
     1.1.3. Python, Jupyter, Visualizations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lecture-learning-objectives">
     1.1.4. Lecture Learning Objectives
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-machine-learning-ml">
   1.2. What is Machine Learning (ML)?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#examples-of-machine-learning">
     1.2.1. Examples of Machine Learning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-1-predict-housing-prices">
       1.2.1.1. Example 1: Predict Housing Prices
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-2-predict-creditcard-default">
       1.2.1.2. Example 2: Predict Creditcard Default
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types-of-machine-learning">
   1.3. Types of Machine Learning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#supervised-learning">
     1.3.1. Supervised Learning:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unsupervised-learning-not-going-into-detail-here">
     1.3.2. UnSupervised Learning: (not going into detail here)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types-of-supervised-learning-classification-vs-regression">
   1.4. Types of Supervised Learning: Classification vs Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification">
     1.4.1. Classification
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression">
     1.4.2. Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice">
   1.5. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tabular-data-and-terminology">
   1.6. Tabular Data and Terminology
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example">
     1.6.1. Example:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decision-tree-algorithm">
   1.7. Decision Tree Algorithm
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-conceptual-introduction-to-decision-trees">
     1.7.1. A conceptual introduction to Decision Trees
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#implimentation-with-scikit-learn">
     1.7.2. Implimentation with Scikit-learn
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-does-predict-work">
     1.7.3. How does
     <code class="docutils literal notranslate">
      <span class="pre">
       .predict()
      </span>
     </code>
     work?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-does-fit-work">
     1.7.4. How does
     <code class="docutils literal notranslate">
      <span class="pre">
       .fit()
      </span>
     </code>
     work?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   1.8. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameters-and-hyperparameters">
   1.9. Parameters and Hyperparameters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameters">
     1.9.1. Parameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperparameters">
     1.9.2. Hyperparameters
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decision-tree-regressor">
   1.10. Decision Tree Regressor
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice-coding">
   1.11. Let’s Practice - Coding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-we-ve-learned-today-a-id-9-a">
   1.12. What We’ve Learned Today
   <a id="9">
   </a>
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Intro to ML &  Decision Trees</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#welcome">
   1.1. Welcome
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#course-learning-objectives">
     1.1.1. Course Learning Objectives
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#course-structure">
     1.1.2. Course Structure
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#python-jupyter-visualizations">
     1.1.3. Python, Jupyter, Visualizations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lecture-learning-objectives">
     1.1.4. Lecture Learning Objectives
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-machine-learning-ml">
   1.2. What is Machine Learning (ML)?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#examples-of-machine-learning">
     1.2.1. Examples of Machine Learning
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-1-predict-housing-prices">
       1.2.1.1. Example 1: Predict Housing Prices
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-2-predict-creditcard-default">
       1.2.1.2. Example 2: Predict Creditcard Default
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types-of-machine-learning">
   1.3. Types of Machine Learning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#supervised-learning">
     1.3.1. Supervised Learning:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unsupervised-learning-not-going-into-detail-here">
     1.3.2. UnSupervised Learning: (not going into detail here)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types-of-supervised-learning-classification-vs-regression">
   1.4. Types of Supervised Learning: Classification vs Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification">
     1.4.1. Classification
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression">
     1.4.2. Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice">
   1.5. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tabular-data-and-terminology">
   1.6. Tabular Data and Terminology
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example">
     1.6.1. Example:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decision-tree-algorithm">
   1.7. Decision Tree Algorithm
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-conceptual-introduction-to-decision-trees">
     1.7.1. A conceptual introduction to Decision Trees
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#implimentation-with-scikit-learn">
     1.7.2. Implimentation with Scikit-learn
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-does-predict-work">
     1.7.3. How does
     <code class="docutils literal notranslate">
      <span class="pre">
       .predict()
      </span>
     </code>
     work?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-does-fit-work">
     1.7.4. How does
     <code class="docutils literal notranslate">
      <span class="pre">
       .fit()
      </span>
     </code>
     work?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   1.8. Let’s Practice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameters-and-hyperparameters">
   1.9. Parameters and Hyperparameters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameters">
     1.9.1. Parameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperparameters">
     1.9.2. Hyperparameters
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#decision-tree-regressor">
   1.10. Decision Tree Regressor
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#let-s-practice-coding">
   1.11. Let’s Practice - Coding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-we-ve-learned-today-a-id-9-a">
   1.12. What We’ve Learned Today
   <a id="9">
   </a>
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="intro-to-ml-decision-trees">
<h1><span class="section-number">1. </span>Intro to ML &amp;  Decision Trees<a class="headerlink" href="#intro-to-ml-decision-trees" title="Permalink to this headline">#</a></h1>
<div class="section" id="welcome">
<h2><span class="section-number">1.1. </span>Welcome<a class="headerlink" href="#welcome" title="Permalink to this headline">#</a></h2>
<p>Welcome to Bait 509 - Business Application of Machine Learning!</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Buckle up because there are going to be a lot of new concepts here but in the lyrics of Trooper “We’re here for a good time,
Not a long time”.</p>
</div>
<div class="section" id="course-learning-objectives">
<h3><span class="section-number">1.1.1. </span>Course Learning Objectives<a class="headerlink" href="#course-learning-objectives" title="Permalink to this headline">#</a></h3>
<ol class="simple">
<li><p>Describe fundamental machine learning concepts such as: supervised and unsupervised learning, regression and classification, overfitting, training/validation/testing error, parameters and hyperparameters, and the golden rule.</p></li>
<li><p>Broadly explain how common machine learning algorithms work, including: naïve Bayes, k-nearest neighbors, decision trees, support vector machines, and logistic regression.</p></li>
<li><p>Identify when and why to apply data pre-processing techniques such as scaling and one-hot encoding.</p></li>
<li><p>Use Python and the scikit-learn package to develop an end-to-end supervised machine learning pipeline.</p></li>
<li><p>Apply and interpret machine learning methods to carry out supervised learning projects and to answer business objectives.</p></li>
</ol>
</div>
<div class="section" id="course-structure">
<h3><span class="section-number">1.1.2. </span>Course Structure<a class="headerlink" href="#course-structure" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>2 lectures per week (Synchonus lecture + class activity)</p></li>
<li><p>My office hours: 2-3 pm Thursday on Zoom</p></li>
<li><p>Course content available on <a class="reference external" href="https://bait509-ubc.github.io/BAIT509/intro.html">this website</a> or on <a class="reference external" href="https://canvas.ubc.ca/courses/82520">Canvas</a>.</p></li>
<li><p>We will be using <a class="reference external" href="https://piazza.com/ubc.ca/winterterm22022/bait509ba12021w2">Piazza</a> for discussions and questions.</p></li>
<li><p>Assessments:</p></li>
</ul>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p>Assessment</p></th>
<th class="text-align:center head"><p>Due</p></th>
<th class="text-align:center head"><p>Weight</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>Assignment 1</p></td>
<td class="text-align:center"><p>Jan 18</p></td>
<td class="text-align:center"><p>20%</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>Quiz</p></td>
<td class="text-align:center"><p>Jan 24</p></td>
<td class="text-align:center"><p>10%</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>Assignment 2</p></td>
<td class="text-align:center"><p>Jan 26</p></td>
<td class="text-align:center"><p>20%</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>Assignment 3</p></td>
<td class="text-align:center"><p>Feb 2</p></td>
<td class="text-align:center"><p>20%</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>Final Project</p></td>
<td class="text-align:center"><p>Feb 12</p></td>
<td class="text-align:center"><p>30%</p></td>
</tr>
</tbody>
</table>
<p>All assessments will be submitted via Canvas.</p>
</div>
<div class="section" id="python-jupyter-visualizations">
<h3><span class="section-number">1.1.3. </span>Python, Jupyter, Visualizations<a class="headerlink" href="#python-jupyter-visualizations" title="Permalink to this headline">#</a></h3>
<ul>
<li><p>In this course we be using Python and Jupyter notebooks for lectures as well as assignments.</p></li>
<li><p>I recommend using the <a class="reference external" href="https://docs.conda.io/en/latest/miniconda.html">Miniconda distribution</a> to install and manage your Python package installations, but you are free to use either Anaconda or pip if you prefer that.</p></li>
<li><p>If you are using Miniconda or Anaconda, you can install a few key packages we will be using in the course, by typing the following at the command line (the “Anaconda prompt” on Windows, and the default terminal application on MacOS/Linux):</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">install</span> <span class="pre">xgboost</span> <span class="pre">jupyter</span> <span class="pre">altair_saver</span> <span class="pre">seaborn</span></code></p>
</div></blockquote>
</li>
<li><p>Otherwise you can use pip and type the following at the command line:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">xgboost</span> <span class="pre">jupyter</span> <span class="pre">altair_saver</span> <span class="pre">seaborn</span></code></p>
</div></blockquote>
</li>
<li><p>Some packages that we will make heavy use of are installed together with the packages above, most notably <code class="docutils literal notranslate"><span class="pre">pandas</span></code>, <code class="docutils literal notranslate"><span class="pre">numpy</span></code>, <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code>, and <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>.</p></li>
<li><p>You will also need install one package via <code class="docutils literal notranslate"><span class="pre">pip</span></code> directly from GitHub (regardless of if you used conda or pip above).</p>
<p><code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">git+git://github.com/mgelbart/plot-classifier.git</span></code></p>
</li>
<li><p>We will be making visualizations for this course and I give the option of plotting using any Python library but I strongly recommend getting familiar with <a class="reference external" href="https://altair-viz.github.io/index.html"><code class="docutils literal notranslate"><span class="pre">altair</span></code></a>. I have 2 very quick slide decks that teach you a bit about how to plot using <code class="docutils literal notranslate"><span class="pre">altair</span></code>.
From the course <a class="reference external" href="https://prog-learn.mds.ubc.ca/en/">Programming in Python for Data Science</a></p>
<ul class="simple">
<li><p>Module 1, exercise 31, 32, 33</p></li>
<li><p>Module 2, exercise 29, 30</p></li>
<li><p>And if you want to dive further there is a whole course dedicated to visualizing plots using <code class="docutils literal notranslate"><span class="pre">altair</span></code> called <a class="reference external" href="https://viz-learn.mds.ubc.ca/en/">Data Visualization</a>.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="lecture-learning-objectives">
<h3><span class="section-number">1.1.4. </span>Lecture Learning Objectives<a class="headerlink" href="#lecture-learning-objectives" title="Permalink to this headline">#</a></h3>
<p>Don’t worry if some of these terms don’t make sense up front, they will after we have covered them during today’s lecture.</p>
<ul class="simple">
<li><p>Explain motivation to study machine learning.</p></li>
<li><p>Differentiate between supervised and unsupervised learning.</p></li>
<li><p>Differentiate between classification and regression problems.</p></li>
<li><p>Explain machine learning terminology such as features, targets, training, and error.</p></li>
<li><p>Explain the <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> and <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> paradigm and use <code class="docutils literal notranslate"><span class="pre">.score()</span></code> method of ML models.</p></li>
<li><p>Broadly describe how decision trees make predictions.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier()</span></code> and <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor()</span></code> to build decision trees using scikit-learn.</p></li>
<li><p>Explain the difference between parameters and hyperparameters.</p></li>
<li><p>Explain how decision boundaries change with <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>.</p></li>
</ul>
</div>
</div>
<div class="section" id="what-is-machine-learning-ml">
<h2><span class="section-number">1.2. </span>What is Machine Learning (ML)?<a class="headerlink" href="#what-is-machine-learning-ml" title="Permalink to this headline">#</a></h2>
<p>Machine learning is all around us. You can find it in things like:</p>
<p><img alt="" src="../_images/examples.png" /></p>
<ul class="simple">
<li><p>Voice assistance</p></li>
<li><p>Google news</p></li>
<li><p>Recommender systems</p></li>
<li><p>Face recognition</p></li>
<li><p>Auto completion</p></li>
<li><p>Stock market predictions</p></li>
<li><p>Character recognition</p></li>
<li><p>Self-driving cars</p></li>
<li><p>Cancer diagnosis</p></li>
<li><p>Drug discovery</p></li>
</ul>
<p>Machine Learning can mean many different things to different people. In this course, we will stick to how it is defined in the seminal textbook <a class="reference external" href="https://www.statlearning.com/">“Introduction to Statistical Learning”</a> which defines Statistical/Machine Learning as a “<em>set of tools for making sense of complex datasets</em>”. As you can hear, this is still rather broad, and we will refine our understanding throughout this course. Let’s start right now by looking at some specific examples of Machine Learning problems.</p>
<div class="section" id="examples-of-machine-learning">
<h3><span class="section-number">1.2.1. </span>Examples of Machine Learning<a class="headerlink" href="#examples-of-machine-learning" title="Permalink to this headline">#</a></h3>
<p><em>In all the the upcoming examples, Don’t worry about the code. Just focus on the input and output in each example.</em></p>
<div class="section" id="example-1-predict-housing-prices">
<h4><span class="section-number">1.2.1.1. </span>Example 1: Predict Housing Prices<a class="headerlink" href="#example-1-predict-housing-prices" title="Permalink to this headline">#</a></h4>
<p><strong>Data Attribution:</strong> <a href="https://www.kaggle.com/harlfoxem/housesalesprediction" target="_blank">house sales prediction dataset.</a></p>
<p>First, let’s read in and have a glance at the dataset we will be using.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/kc_house_data.csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;date&quot;</span><span class="p">])</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>bedrooms</th>
      <th>bathrooms</th>
      <th>sqft_living</th>
      <th>sqft_lot</th>
      <th>floors</th>
      <th>waterfront</th>
      <th>view</th>
      <th>condition</th>
      <th>grade</th>
      <th>sqft_above</th>
      <th>sqft_basement</th>
      <th>yr_built</th>
      <th>yr_renovated</th>
      <th>zipcode</th>
      <th>lat</th>
      <th>long</th>
      <th>sqft_living15</th>
      <th>sqft_lot15</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>221900.0</td>
      <td>3</td>
      <td>1.00</td>
      <td>1180</td>
      <td>5650</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1180</td>
      <td>0</td>
      <td>1955</td>
      <td>0</td>
      <td>98178</td>
      <td>47.5112</td>
      <td>-122.257</td>
      <td>1340</td>
      <td>5650</td>
    </tr>
    <tr>
      <th>1</th>
      <td>538000.0</td>
      <td>3</td>
      <td>2.25</td>
      <td>2570</td>
      <td>7242</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>2170</td>
      <td>400</td>
      <td>1951</td>
      <td>1991</td>
      <td>98125</td>
      <td>47.7210</td>
      <td>-122.319</td>
      <td>1690</td>
      <td>7639</td>
    </tr>
    <tr>
      <th>2</th>
      <td>180000.0</td>
      <td>2</td>
      <td>1.00</td>
      <td>770</td>
      <td>10000</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>6</td>
      <td>770</td>
      <td>0</td>
      <td>1933</td>
      <td>0</td>
      <td>98028</td>
      <td>47.7379</td>
      <td>-122.233</td>
      <td>2720</td>
      <td>8062</td>
    </tr>
    <tr>
      <th>3</th>
      <td>604000.0</td>
      <td>4</td>
      <td>3.00</td>
      <td>1960</td>
      <td>5000</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>7</td>
      <td>1050</td>
      <td>910</td>
      <td>1965</td>
      <td>0</td>
      <td>98136</td>
      <td>47.5208</td>
      <td>-122.393</td>
      <td>1360</td>
      <td>5000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>510000.0</td>
      <td>3</td>
      <td>2.00</td>
      <td>1680</td>
      <td>8080</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>8</td>
      <td>1680</td>
      <td>0</td>
      <td>1987</td>
      <td>0</td>
      <td>98074</td>
      <td>47.6168</td>
      <td>-122.045</td>
      <td>1800</td>
      <td>7503</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>21608</th>
      <td>360000.0</td>
      <td>3</td>
      <td>2.50</td>
      <td>1530</td>
      <td>1131</td>
      <td>3.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>8</td>
      <td>1530</td>
      <td>0</td>
      <td>2009</td>
      <td>0</td>
      <td>98103</td>
      <td>47.6993</td>
      <td>-122.346</td>
      <td>1530</td>
      <td>1509</td>
    </tr>
    <tr>
      <th>21609</th>
      <td>400000.0</td>
      <td>4</td>
      <td>2.50</td>
      <td>2310</td>
      <td>5813</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>8</td>
      <td>2310</td>
      <td>0</td>
      <td>2014</td>
      <td>0</td>
      <td>98146</td>
      <td>47.5107</td>
      <td>-122.362</td>
      <td>1830</td>
      <td>7200</td>
    </tr>
    <tr>
      <th>21610</th>
      <td>402101.0</td>
      <td>2</td>
      <td>0.75</td>
      <td>1020</td>
      <td>1350</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1020</td>
      <td>0</td>
      <td>2009</td>
      <td>0</td>
      <td>98144</td>
      <td>47.5944</td>
      <td>-122.299</td>
      <td>1020</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>21611</th>
      <td>400000.0</td>
      <td>3</td>
      <td>2.50</td>
      <td>1600</td>
      <td>2388</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>8</td>
      <td>1600</td>
      <td>0</td>
      <td>2004</td>
      <td>0</td>
      <td>98027</td>
      <td>47.5345</td>
      <td>-122.069</td>
      <td>1410</td>
      <td>1287</td>
    </tr>
    <tr>
      <th>21612</th>
      <td>325000.0</td>
      <td>2</td>
      <td>0.75</td>
      <td>1020</td>
      <td>1076</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1020</td>
      <td>0</td>
      <td>2008</td>
      <td>0</td>
      <td>98144</td>
      <td>47.5941</td>
      <td>-122.299</td>
      <td>1020</td>
      <td>1357</td>
    </tr>
  </tbody>
</table>
<p>21613 rows × 19 columns</p>
</div></div></div>
</div>
<p>The next step is to divide the rows of the data in one subset that we will use for training the model
and one subset that we will use for testing/evaluating the model.
We will also divide the columns into the ones we want to use as the input “features”
and the one(s) we are trying to predict, the output “target”.
By convention we call the input features <code class="docutils literal notranslate"><span class="pre">X</span></code>
and the target that we are trying to predict for <code class="docutils literal notranslate"><span class="pre">y</span></code>.
Here we want to try to predict the price columns
using the information from all the other columns in the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Split the rows into train and test</span>
<span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Split the columns into intput (X) and output (y)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;price&quot;</span><span class="p">])</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;price&quot;</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;price&quot;</span><span class="p">])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;price&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Next let’s train a of our choice model using the dedicated training data.
Here we are using a model called xgboost,
and since we are trying to predict a numerical value,
we are using the regression xgboost model.
You will see below that a description of the model is outputted
when the code is run,
but for now we don’t need to worry about what this means.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBRegressor</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Finally we want to check how well our model performed.
First we will just eyeball the predicted the prices for the test data
and compare them to the actual prices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;predicted_price&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
    <span class="s2">&quot;actual_price&quot;</span><span class="p">:</span> <span class="n">y_test</span>
<span class="p">})</span>
<span class="n">pred_df</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>predicted_price</th>
      <th>actual_price</th>
      <th>bedrooms</th>
      <th>bathrooms</th>
      <th>sqft_living</th>
      <th>sqft_lot</th>
      <th>floors</th>
      <th>waterfront</th>
      <th>view</th>
      <th>condition</th>
      <th>grade</th>
      <th>sqft_above</th>
      <th>sqft_basement</th>
      <th>yr_built</th>
      <th>yr_renovated</th>
      <th>zipcode</th>
      <th>lat</th>
      <th>long</th>
      <th>sqft_living15</th>
      <th>sqft_lot15</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13248</th>
      <td>333981.62500</td>
      <td>311100.0</td>
      <td>4</td>
      <td>2.25</td>
      <td>2130</td>
      <td>8078</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>7</td>
      <td>1380</td>
      <td>750</td>
      <td>1977</td>
      <td>0</td>
      <td>98055</td>
      <td>47.4482</td>
      <td>-122.209</td>
      <td>2300</td>
      <td>8112</td>
    </tr>
    <tr>
      <th>5309</th>
      <td>615222.43750</td>
      <td>535000.0</td>
      <td>3</td>
      <td>2.50</td>
      <td>2210</td>
      <td>7620</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>8</td>
      <td>2210</td>
      <td>0</td>
      <td>1994</td>
      <td>0</td>
      <td>98052</td>
      <td>47.6938</td>
      <td>-122.130</td>
      <td>1920</td>
      <td>7440</td>
    </tr>
    <tr>
      <th>10962</th>
      <td>329770.06250</td>
      <td>271000.0</td>
      <td>4</td>
      <td>1.50</td>
      <td>1800</td>
      <td>9576</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>7</td>
      <td>1800</td>
      <td>0</td>
      <td>1977</td>
      <td>0</td>
      <td>98045</td>
      <td>47.4664</td>
      <td>-121.747</td>
      <td>1370</td>
      <td>9576</td>
    </tr>
    <tr>
      <th>20976</th>
      <td>565091.62500</td>
      <td>705000.0</td>
      <td>3</td>
      <td>2.50</td>
      <td>1580</td>
      <td>1321</td>
      <td>2.0</td>
      <td>0</td>
      <td>2</td>
      <td>3</td>
      <td>8</td>
      <td>1080</td>
      <td>500</td>
      <td>2014</td>
      <td>0</td>
      <td>98107</td>
      <td>47.6688</td>
      <td>-122.402</td>
      <td>1530</td>
      <td>1357</td>
    </tr>
    <tr>
      <th>19957</th>
      <td>807697.87500</td>
      <td>840000.0</td>
      <td>2</td>
      <td>2.50</td>
      <td>1680</td>
      <td>975</td>
      <td>3.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>9</td>
      <td>1680</td>
      <td>0</td>
      <td>2009</td>
      <td>0</td>
      <td>98119</td>
      <td>47.6321</td>
      <td>-122.361</td>
      <td>1680</td>
      <td>977</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>8527</th>
      <td>820445.50000</td>
      <td>610000.0</td>
      <td>4</td>
      <td>2.75</td>
      <td>2640</td>
      <td>8400</td>
      <td>1.0</td>
      <td>0</td>
      <td>2</td>
      <td>3</td>
      <td>8</td>
      <td>1440</td>
      <td>1200</td>
      <td>1947</td>
      <td>0</td>
      <td>98144</td>
      <td>47.5882</td>
      <td>-122.290</td>
      <td>2610</td>
      <td>6000</td>
    </tr>
    <tr>
      <th>16521</th>
      <td>244517.59375</td>
      <td>187000.0</td>
      <td>3</td>
      <td>2.50</td>
      <td>1730</td>
      <td>1803</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1730</td>
      <td>0</td>
      <td>2005</td>
      <td>0</td>
      <td>98166</td>
      <td>47.4648</td>
      <td>-122.335</td>
      <td>1190</td>
      <td>7980</td>
    </tr>
    <tr>
      <th>17198</th>
      <td>294955.50000</td>
      <td>305000.0</td>
      <td>3</td>
      <td>2.00</td>
      <td>1490</td>
      <td>7697</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1490</td>
      <td>0</td>
      <td>1994</td>
      <td>0</td>
      <td>98059</td>
      <td>47.4852</td>
      <td>-122.164</td>
      <td>1540</td>
      <td>7529</td>
    </tr>
    <tr>
      <th>7539</th>
      <td>936004.12500</td>
      <td>809000.0</td>
      <td>4</td>
      <td>1.50</td>
      <td>1840</td>
      <td>4337</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>8</td>
      <td>1840</td>
      <td>0</td>
      <td>1917</td>
      <td>0</td>
      <td>98112</td>
      <td>47.6312</td>
      <td>-122.307</td>
      <td>2250</td>
      <td>4337</td>
    </tr>
    <tr>
      <th>4853</th>
      <td>787805.25000</td>
      <td>840000.0</td>
      <td>4</td>
      <td>2.25</td>
      <td>2100</td>
      <td>3671</td>
      <td>1.5</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>8</td>
      <td>1750</td>
      <td>350</td>
      <td>1929</td>
      <td>0</td>
      <td>98112</td>
      <td>47.6359</td>
      <td>-122.300</td>
      <td>1800</td>
      <td>4560</td>
    </tr>
  </tbody>
</table>
<p>4323 rows × 20 columns</p>
</div></div></div>
</div>
<p>From this quick glance at the results,
the model seems to do OK
in the sense that it largely understand which houses should be valued more or less,
but the exact values are still a bit off.</p>
<p>There are format metrics to more accurately describe how well our model performed.
We will talk more about this later,
but the general idea is that we can get a number between 0-1
on how good our model is in general
instead of having to look at the prediction for each row individually.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8880546138276236
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="example-2-predict-creditcard-default">
<h4><span class="section-number">1.2.1.2. </span>Example 2: Predict Creditcard Default<a class="headerlink" href="#example-2-predict-creditcard-default" title="Permalink to this headline">#</a></h4>
<p><strong>Data Attribution:</strong> <a href="https://www.kaggle.com/mlg-ulb/creditcardfraud" target="_blank">credit card fraud detection data set</a></p>
<p>Here we will go through the same steps as in the example above,
but rather than trying to determine an exact numerical value,
we are trying to determine a categorical outcome.
In this case we are trying to predict whether a person is likely to default (class = 1) or not (class = 0)
on their credit card
given a bunch of input features.
Note that although we don’t know what the input features are,
the model might still use them
to find which values of which input features are related to defaulting on your credit card.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cc_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/creditcard_sample.csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10_000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">390</span><span class="p">)</span>
<span class="n">cc_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>77244</th>
      <td>148572.0</td>
      <td>-2.192803</td>
      <td>-1.184063</td>
      <td>-0.587411</td>
      <td>-0.624137</td>
      <td>2.856276</td>
      <td>-2.058827</td>
      <td>0.253898</td>
      <td>-0.361502</td>
      <td>0.473344</td>
      <td>...</td>
      <td>-0.006427</td>
      <td>0.627750</td>
      <td>-0.634097</td>
      <td>0.693558</td>
      <td>-0.258117</td>
      <td>-0.753612</td>
      <td>0.538571</td>
      <td>0.305432</td>
      <td>94.47</td>
      <td>0</td>
    </tr>
    <tr>
      <th>112513</th>
      <td>97024.0</td>
      <td>-1.958810</td>
      <td>0.992661</td>
      <td>0.229305</td>
      <td>3.158607</td>
      <td>2.590061</td>
      <td>-1.197520</td>
      <td>1.031590</td>
      <td>0.102072</td>
      <td>-1.639767</td>
      <td>...</td>
      <td>0.300789</td>
      <td>0.423192</td>
      <td>-0.680045</td>
      <td>1.130778</td>
      <td>1.439294</td>
      <td>0.377042</td>
      <td>-0.209320</td>
      <td>-0.242601</td>
      <td>1.51</td>
      <td>0</td>
    </tr>
    <tr>
      <th>98163</th>
      <td>138463.0</td>
      <td>0.123289</td>
      <td>1.079440</td>
      <td>-0.466330</td>
      <td>-0.420373</td>
      <td>1.105829</td>
      <td>-0.739383</td>
      <td>1.156067</td>
      <td>-0.392044</td>
      <td>-0.146092</td>
      <td>...</td>
      <td>0.270423</td>
      <td>1.183270</td>
      <td>-0.297665</td>
      <td>-0.437083</td>
      <td>-0.337571</td>
      <td>-0.177253</td>
      <td>0.097323</td>
      <td>-0.046671</td>
      <td>8.39</td>
      <td>0</td>
    </tr>
    <tr>
      <th>16889</th>
      <td>148014.0</td>
      <td>2.205836</td>
      <td>0.170743</td>
      <td>-2.480998</td>
      <td>-0.183286</td>
      <td>1.001373</td>
      <td>-1.222709</td>
      <td>0.852123</td>
      <td>-0.604090</td>
      <td>0.151221</td>
      <td>...</td>
      <td>0.089298</td>
      <td>0.454132</td>
      <td>-0.180294</td>
      <td>-0.921876</td>
      <td>0.604957</td>
      <td>0.300060</td>
      <td>-0.082035</td>
      <td>-0.087539</td>
      <td>3.85</td>
      <td>0</td>
    </tr>
    <tr>
      <th>30631</th>
      <td>168840.0</td>
      <td>-1.233511</td>
      <td>-0.769039</td>
      <td>-0.311892</td>
      <td>-0.751171</td>
      <td>-0.212926</td>
      <td>-0.962064</td>
      <td>0.092553</td>
      <td>0.402238</td>
      <td>-1.286992</td>
      <td>...</td>
      <td>0.290688</td>
      <td>0.833095</td>
      <td>0.186440</td>
      <td>-0.007625</td>
      <td>-0.434240</td>
      <td>-0.080610</td>
      <td>0.320599</td>
      <td>0.074183</td>
      <td>147.50</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>84485</th>
      <td>41258.0</td>
      <td>1.157116</td>
      <td>-0.227916</td>
      <td>1.122789</td>
      <td>0.671485</td>
      <td>-0.872917</td>
      <td>0.213669</td>
      <td>-0.731842</td>
      <td>0.241341</td>
      <td>0.694209</td>
      <td>...</td>
      <td>-0.060517</td>
      <td>-0.020915</td>
      <td>-0.024279</td>
      <td>0.046264</td>
      <td>0.267848</td>
      <td>0.319370</td>
      <td>0.012120</td>
      <td>0.014212</td>
      <td>11.49</td>
      <td>0</td>
    </tr>
    <tr>
      <th>60723</th>
      <td>22476.0</td>
      <td>1.314683</td>
      <td>0.188203</td>
      <td>-1.150419</td>
      <td>-0.279736</td>
      <td>2.213941</td>
      <td>3.228529</td>
      <td>-0.598057</td>
      <td>0.724365</td>
      <td>1.210910</td>
      <td>...</td>
      <td>-0.493294</td>
      <td>-1.334642</td>
      <td>0.107215</td>
      <td>0.885085</td>
      <td>0.346663</td>
      <td>0.072047</td>
      <td>-0.048533</td>
      <td>0.017192</td>
      <td>1.79</td>
      <td>0</td>
    </tr>
    <tr>
      <th>39885</th>
      <td>143578.0</td>
      <td>1.761024</td>
      <td>-1.325650</td>
      <td>-1.875881</td>
      <td>-0.641276</td>
      <td>0.205655</td>
      <td>0.844432</td>
      <td>-0.280825</td>
      <td>0.202457</td>
      <td>-0.696063</td>
      <td>...</td>
      <td>-0.353462</td>
      <td>-0.740336</td>
      <td>0.172985</td>
      <td>-1.664172</td>
      <td>-0.472072</td>
      <td>0.579761</td>
      <td>-0.060095</td>
      <td>-0.066952</td>
      <td>162.47</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5043</th>
      <td>142589.0</td>
      <td>1.381656</td>
      <td>-2.291059</td>
      <td>-1.357021</td>
      <td>-0.960894</td>
      <td>-0.337165</td>
      <td>1.837831</td>
      <td>-0.860187</td>
      <td>0.524134</td>
      <td>0.025136</td>
      <td>...</td>
      <td>0.066074</td>
      <td>-0.517941</td>
      <td>0.157722</td>
      <td>-0.989422</td>
      <td>-0.771393</td>
      <td>-0.524638</td>
      <td>-0.021692</td>
      <td>-0.006208</td>
      <td>353.36</td>
      <td>0</td>
    </tr>
    <tr>
      <th>50693</th>
      <td>52408.0</td>
      <td>-1.121774</td>
      <td>1.046825</td>
      <td>1.449851</td>
      <td>-0.853597</td>
      <td>-0.697472</td>
      <td>-0.891311</td>
      <td>-0.019569</td>
      <td>0.531940</td>
      <td>-0.019775</td>
      <td>...</td>
      <td>-0.095875</td>
      <td>-0.278814</td>
      <td>0.167095</td>
      <td>0.637857</td>
      <td>-0.326769</td>
      <td>0.659947</td>
      <td>0.175923</td>
      <td>0.061234</td>
      <td>4.13</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>10000 rows × 31 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cc_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">413</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">])</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
<span class="c1"># This will output a warning which refers to a change in the default behavior and that can be ignored for now</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[13:14:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1637426272325/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective &#39;binary:logistic&#39; was changed from &#39;error&#39; to &#39;logloss&#39;. Explicitly set eval_metric if you&#39;d like to restore the old behavior.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;predicted_price&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
    <span class="s2">&quot;actual_price&quot;</span><span class="p">:</span> <span class="n">y_test</span>
<span class="p">})</span>
<span class="n">pred_df</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>predicted_price</th>
      <th>actual_price</th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>...</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>111132</th>
      <td>0</td>
      <td>0</td>
      <td>99190.0</td>
      <td>-0.136738</td>
      <td>0.564715</td>
      <td>0.157284</td>
      <td>-0.719750</td>
      <td>1.175614</td>
      <td>0.920017</td>
      <td>0.387763</td>
      <td>...</td>
      <td>-0.287078</td>
      <td>-0.316661</td>
      <td>-0.524482</td>
      <td>0.151172</td>
      <td>-1.542696</td>
      <td>-0.796923</td>
      <td>0.209887</td>
      <td>0.253875</td>
      <td>0.062003</td>
      <td>3.99</td>
    </tr>
    <tr>
      <th>121903</th>
      <td>0</td>
      <td>0</td>
      <td>130274.0</td>
      <td>2.113383</td>
      <td>-0.084617</td>
      <td>-1.462568</td>
      <td>0.004176</td>
      <td>0.250580</td>
      <td>-0.800686</td>
      <td>0.175293</td>
      <td>...</td>
      <td>-0.149559</td>
      <td>0.283130</td>
      <td>1.187823</td>
      <td>-0.185627</td>
      <td>-0.560881</td>
      <td>0.563192</td>
      <td>-0.204496</td>
      <td>0.021032</td>
      <td>-0.060979</td>
      <td>1.04</td>
    </tr>
    <tr>
      <th>87849</th>
      <td>0</td>
      <td>0</td>
      <td>39423.0</td>
      <td>-1.841569</td>
      <td>-0.924729</td>
      <td>0.683529</td>
      <td>-1.240802</td>
      <td>-0.040076</td>
      <td>-1.644745</td>
      <td>0.028578</td>
      <td>...</td>
      <td>-0.295739</td>
      <td>-0.287965</td>
      <td>-0.448146</td>
      <td>-0.241471</td>
      <td>0.458841</td>
      <td>-0.488022</td>
      <td>0.795167</td>
      <td>0.016911</td>
      <td>-0.297358</td>
      <td>88.00</td>
    </tr>
    <tr>
      <th>134</th>
      <td>1</td>
      <td>1</td>
      <td>70270.0</td>
      <td>-1.512516</td>
      <td>1.133139</td>
      <td>-1.601052</td>
      <td>2.813401</td>
      <td>-2.664503</td>
      <td>-0.310371</td>
      <td>-1.520895</td>
      <td>...</td>
      <td>1.249586</td>
      <td>0.729828</td>
      <td>0.485286</td>
      <td>0.567005</td>
      <td>0.323586</td>
      <td>0.040871</td>
      <td>0.825814</td>
      <td>0.414482</td>
      <td>0.267265</td>
      <td>318.11</td>
    </tr>
    <tr>
      <th>115580</th>
      <td>0</td>
      <td>0</td>
      <td>129611.0</td>
      <td>1.983675</td>
      <td>-0.563139</td>
      <td>-0.556800</td>
      <td>0.070248</td>
      <td>-0.240229</td>
      <td>0.532842</td>
      <td>-0.824306</td>
      <td>...</td>
      <td>-0.073943</td>
      <td>0.036475</td>
      <td>0.226705</td>
      <td>0.117428</td>
      <td>-0.331401</td>
      <td>-0.147280</td>
      <td>-0.700302</td>
      <td>0.072757</td>
      <td>-0.019535</td>
      <td>39.42</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>68059</th>
      <td>0</td>
      <td>0</td>
      <td>46546.0</td>
      <td>-1.906055</td>
      <td>1.330466</td>
      <td>0.822306</td>
      <td>-0.209197</td>
      <td>-0.246915</td>
      <td>-0.205031</td>
      <td>0.117844</td>
      <td>...</td>
      <td>-0.147033</td>
      <td>-0.109164</td>
      <td>-0.433282</td>
      <td>0.235205</td>
      <td>-0.022674</td>
      <td>-0.248697</td>
      <td>0.035313</td>
      <td>-0.444826</td>
      <td>0.234728</td>
      <td>13.28</td>
    </tr>
    <tr>
      <th>21742</th>
      <td>0</td>
      <td>0</td>
      <td>150611.0</td>
      <td>-4.853459</td>
      <td>3.917655</td>
      <td>-1.728775</td>
      <td>1.001013</td>
      <td>-2.521175</td>
      <td>0.154400</td>
      <td>-2.298054</td>
      <td>...</td>
      <td>-0.151779</td>
      <td>-0.365927</td>
      <td>-1.562024</td>
      <td>0.294809</td>
      <td>0.576851</td>
      <td>0.807743</td>
      <td>-0.796429</td>
      <td>-0.363074</td>
      <td>-0.100201</td>
      <td>20.93</td>
    </tr>
    <tr>
      <th>7003</th>
      <td>0</td>
      <td>0</td>
      <td>145475.0</td>
      <td>-0.574999</td>
      <td>-0.249851</td>
      <td>1.507838</td>
      <td>-2.183949</td>
      <td>-0.233760</td>
      <td>-0.089817</td>
      <td>-0.177221</td>
      <td>...</td>
      <td>0.374122</td>
      <td>0.029454</td>
      <td>0.063281</td>
      <td>-0.215382</td>
      <td>0.318620</td>
      <td>0.596239</td>
      <td>-0.236673</td>
      <td>0.014326</td>
      <td>-0.184974</td>
      <td>55.95</td>
    </tr>
    <tr>
      <th>45985</th>
      <td>0</td>
      <td>0</td>
      <td>53355.0</td>
      <td>1.257516</td>
      <td>0.097742</td>
      <td>-0.299899</td>
      <td>0.869715</td>
      <td>0.715477</td>
      <td>1.119524</td>
      <td>-0.116036</td>
      <td>...</td>
      <td>-0.170771</td>
      <td>-0.174101</td>
      <td>-0.300020</td>
      <td>-0.275479</td>
      <td>-1.704110</td>
      <td>0.849335</td>
      <td>-0.220576</td>
      <td>0.031867</td>
      <td>-0.014047</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>87194</th>
      <td>0</td>
      <td>0</td>
      <td>45069.0</td>
      <td>1.076270</td>
      <td>-1.898885</td>
      <td>0.065107</td>
      <td>-1.316359</td>
      <td>-1.669659</td>
      <td>-0.382944</td>
      <td>-0.846787</td>
      <td>...</td>
      <td>0.133069</td>
      <td>-0.286476</td>
      <td>-1.098696</td>
      <td>-0.130274</td>
      <td>-0.534818</td>
      <td>0.108739</td>
      <td>-0.380314</td>
      <td>-0.013497</td>
      <td>0.062206</td>
      <td>263.70</td>
    </tr>
  </tbody>
</table>
<p>2000 rows × 32 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9985
</pre></div>
</div>
</div>
</div>
<p>A score this high means that almost all observations were correctly predicted!</p>
</div>
</div>
</div>
<div class="section" id="types-of-machine-learning">
<h2><span class="section-number">1.3. </span>Types of Machine Learning<a class="headerlink" href="#types-of-machine-learning" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><strong>Supervised learning</strong> (this course)</p></li>
<li><p>Unsupervised learning</p></li>
</ul>
<div class="section" id="supervised-learning">
<h3><span class="section-number">1.3.1. </span>Supervised Learning:<a class="headerlink" href="#supervised-learning" title="Permalink to this headline">#</a></h3>
<blockquote>
<div><p>Example: Labelling emails as spam or not</p>
</div></blockquote>
<ul class="simple">
<li><p>In supervised machine learning, we have a set of observations usually denoted with an uppercase <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p></li>
<li><p>We also have a set of corresponding targets usually denoted with a lowercase <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p></li>
<li><p>Our goal is to define a function that relates <code class="docutils literal notranslate"><span class="pre">X</span></code> to <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p></li>
<li><p>We then use this function to predict the targets of new examples.</p></li>
</ul>
<br>
<br>
<a class="reference internal image-reference" href="../_images/sup-learning.png"><img alt="404 image" src="../_images/sup-learning.png" style="width: 75%;" /></a>
</div>
<div class="section" id="unsupervised-learning-not-going-into-detail-here">
<h3><span class="section-number">1.3.2. </span>UnSupervised Learning: (not going into detail here)<a class="headerlink" href="#unsupervised-learning-not-going-into-detail-here" title="Permalink to this headline">#</a></h3>
<blockquote>
<div><p>Example: Categorizing Google News articles.</p>
</div></blockquote>
<ul class="simple">
<li><p>In unsupervised learning, we are not given target labels and are instead only given observations <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p></li>
<li><p>We apply an algorithm to try find patterns/structure in our data and divide the observations into groups/clusters that share similar characteristics from our data.</p></li>
<li><p>E.g. it could be that we want find out if there are groups of business that operate similarly based a few key business metrics. We might not know up front how many groups there are in the data, and an unsupervised clustering algorithm could help us understand if there e.g. are two very distinct set of strategies that business employ (two clusters), or if there is a big mix and no clear structure at all in our data.</p></li>
<li><p>Another example can be seen below, we might get input images of cats and dogs and ask the algorithm to cluster them together based on any property that can be extracted from the images (color, size, shapes, etc).</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/unsup-learning.png"><img alt="404 image" src="../_images/unsup-learning.png" style="width: 75%;" /></a>
</div>
</div>
<div class="section" id="types-of-supervised-learning-classification-vs-regression">
<h2><span class="section-number">1.4. </span>Types of Supervised Learning: Classification vs Regression<a class="headerlink" href="#types-of-supervised-learning-classification-vs-regression" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Classification</p></li>
<li><p>Regression</p></li>
</ul>
<div class="section" id="classification">
<h3><span class="section-number">1.4.1. </span>Classification<a class="headerlink" href="#classification" title="Permalink to this headline">#</a></h3>
<p><strong>Classification</strong> predicting among two or more categories, also known as classes.</p>
<ul class="simple">
<li><p><em>Example1</em>: Predict whether a customer will default on their credit card or not.</p></li>
<li><p><em>Example2</em>: Predict if an animal is a reptile, mammal or bird.</p></li>
</ul>
</div>
<div class="section" id="regression">
<h3><span class="section-number">1.4.2. </span>Regression<a class="headerlink" href="#regression" title="Permalink to this headline">#</a></h3>
<p><strong>Regression</strong> predicting a continuous (in other words, a number) value.</p>
<ul class="simple">
<li><p>Example1: Predict housing prices</p></li>
<li><p>Example2: Predict the length of a snake.</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/classification-vs-regression2.png"><img alt="404 image" src="../_images/classification-vs-regression2.png" style="width: 90%;" /></a>
</div>
</div>
<div class="section" id="let-s-practice">
<h2><span class="section-number">1.5. </span>Let’s Practice<a class="headerlink" href="#let-s-practice" title="Permalink to this headline">#</a></h2>
<p><strong>Are the following supervised or unsupervised problems?</strong></p>
<p>1. Finding groups of similar properties in a real estate data set.<br />
2. Predicting real estate prices based on house features like number of rooms, learning from past sales as examples.<br />
3. Identifying groups of animals given features such as “number of legs”, “wings/no wings”, “fur/no fur”, etc.<br />
4. Detecting heart disease in patients based on different test results and history.<br />
5. Grouping articles on different topics from different news sources (something like Google News app).</p>
<p><strong>Are the following classification or regression problems?</strong></p>
<p>6. Predicting the price of a house based on features such as number of rooms and the year built.<br />
7. Predicting if a house will sell or not based on features like the price of the house, number of rooms, etc.<br />
8. Predicting your grade in BAIT 509 based on past grades.<br />
9. Predicting whether you should bicycle tomorrow or not based on the weather forecast.<br />
10. Predicting a cereal’s manufacturer given the nutritional information.</p>
<div class="dropdown admonition">
<p class="admonition-title">Solutions!</p>
<ol class="simple">
<li><p>Unsupervised</p></li>
<li><p>Supervised</p></li>
<li><p>Unsupervised</p></li>
<li><p>Supervised</p></li>
<li><p>Unsupervised</p></li>
<li><p>Regression</p></li>
<li><p>Classification</p></li>
<li><p>Regression</p></li>
<li><p>Classification</p></li>
<li><p>Classification</p></li>
</ol>
</div>
</div>
<div class="section" id="tabular-data-and-terminology">
<h2><span class="section-number">1.6. </span>Tabular Data and Terminology<a class="headerlink" href="#tabular-data-and-terminology" title="Permalink to this headline">#</a></h2>
<p>Basic terminology used in ML:</p>
<ul class="simple">
<li><p><strong>examples/observations</strong> = rows</p></li>
<li><p><strong>features/variables</strong> = inputs (columns)</p></li>
<li><p><strong>targets</strong> = outputs (one special column)</p></li>
<li><p><strong>training</strong> = learning = fitting</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/sup-ML-terminology2.png"><img alt="404 image" src="../_images/sup-ML-terminology2.png" style="width: 90%;" /></a>
<div class="section" id="example">
<h3><span class="section-number">1.6.1. </span>Example:<a class="headerlink" href="#example" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>This <a class="reference external" href="http://simplemaps.com/static/demos/resources/us-cities/cities.csv">dataset</a> contains longtitude and latitude data for 400 cities in the US.</p></li>
<li><p>Each city is labelled as <code class="docutils literal notranslate"><span class="pre">red</span></code> or <code class="docutils literal notranslate"><span class="pre">blue</span></code> depending on how they voted in the 2012 election.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/cities_USA.csv&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">89</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lon</th>
      <th>lat</th>
      <th>vote</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>146</th>
      <td>-82.155358</td>
      <td>38.008878</td>
      <td>red</td>
    </tr>
    <tr>
      <th>33</th>
      <td>-92.744478</td>
      <td>31.226442</td>
      <td>red</td>
    </tr>
    <tr>
      <th>389</th>
      <td>-96.505225</td>
      <td>47.070528</td>
      <td>blue</td>
    </tr>
    <tr>
      <th>297</th>
      <td>-87.964364</td>
      <td>42.159843</td>
      <td>blue</td>
    </tr>
    <tr>
      <th>230</th>
      <td>-88.137965</td>
      <td>40.374736</td>
      <td>blue</td>
    </tr>
    <tr>
      <th>292</th>
      <td>-87.686544</td>
      <td>42.030220</td>
      <td>blue</td>
    </tr>
    <tr>
      <th>91</th>
      <td>-92.787976</td>
      <td>35.042732</td>
      <td>red</td>
    </tr>
    <tr>
      <th>198</th>
      <td>-80.305106</td>
      <td>39.702072</td>
      <td>red</td>
    </tr>
    <tr>
      <th>369</th>
      <td>-92.697108</td>
      <td>45.321757</td>
      <td>blue</td>
    </tr>
    <tr>
      <th>392</th>
      <td>-101.189807</td>
      <td>47.460163</td>
      <td>red</td>
    </tr>
    <tr>
      <th>377</th>
      <td>-99.772543</td>
      <td>46.005476</td>
      <td>red</td>
    </tr>
    <tr>
      <th>199</th>
      <td>-76.344101</td>
      <td>39.751754</td>
      <td>blue</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(12, 3)
</pre></div>
</div>
</div>
</div>
<p>In this dataset, we have:</p>
<ul class="simple">
<li><p>2 <strong>features</strong>, (3 columns = 2 <strong>features</strong> + 1 target) and,</p></li>
<li><p>20 <strong>examples</strong>.</p></li>
</ul>
<p>Our <strong>target</strong> column is <code class="docutils literal notranslate"><span class="pre">vote</span></code> since that is what we are interesting in predicting.</p>
</div>
</div>
<div class="section" id="decision-tree-algorithm">
<h2><span class="section-number">1.7. </span>Decision Tree Algorithm<a class="headerlink" href="#decision-tree-algorithm" title="Permalink to this headline">#</a></h2>
<div class="section" id="a-conceptual-introduction-to-decision-trees">
<h3><span class="section-number">1.7.1. </span>A conceptual introduction to Decision Trees<a class="headerlink" href="#a-conceptual-introduction-to-decision-trees" title="Permalink to this headline">#</a></h3>
<p>Shown below is some hypothetical data with 2 features (x and y axes) and 1 target (with 2 classes).<br />
The supervised learning problem here is to predict whether a particular observaton belongs to the <font color='blue'><strong>BLUE</strong></font> or <font color='orange'><strong>ORANGE</strong></font> class.<br />
A fairly intuitive way to do this is to simply use thresholds to split the data up.</p>
<a class="reference internal image-reference" href="../_images/scatter_dt1.png"><img alt="404 image" src="../_images/scatter_dt1.png" style="width: 40%;" /></a>
<p>For example, we can <strong>split</strong> the data at <code class="docutils literal notranslate"><span class="pre">Feature_1</span> <span class="pre">=</span> <span class="pre">0.47</span></code>.<br />
Everything <strong>less than</strong> the split we can classify as <font color='orange'><strong>ORANGE</strong></font>.<br />
Everything <strong>greater than</strong> the split we can classify as <font color='blue'><strong>BLUE</strong></font>.<br />
By this method, we can successfully classify 7 / 9 observations.</p>
<a class="reference internal image-reference" href="../_images/scatter_dt2.png"><img alt="404 image" src="../_images/scatter_dt2.png" style="width: 40%;" /></a>
<p>But we don’t have to stop there, we can make another split!<br />
Let’s now split the section that is greater than <code class="docutils literal notranslate"><span class="pre">Feature_1</span> <span class="pre">=</span> <span class="pre">0.47</span></code>, using <code class="docutils literal notranslate"><span class="pre">Feature_2</span> <span class="pre">=</span> <span class="pre">0.52</span></code>.
We now have the following conditions:</p>
<ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">Feature_1</span> <span class="pre">&gt;</span> <span class="pre">0.47</span></code> and <code class="docutils literal notranslate"><span class="pre">Feature_2</span> <span class="pre">&lt;</span> <span class="pre">0.52</span></code> classify as <font color='blue'><strong>BLUE</strong></font>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">Feature_1</span> <span class="pre">&gt;</span> <span class="pre">0.47</span></code> and <code class="docutils literal notranslate"><span class="pre">Feature_2</span> <span class="pre">&gt;</span> <span class="pre">0.52</span></code> classify as <font color='orange'><strong>ORANGE</strong></font>.</p></li>
</ul>
<p>Using these rules, we now successfully classify 8 / 9 observations.</p>
<a class="reference internal image-reference" href="../_images/scatter_dt3.png"><img alt="404 image" src="../_images/scatter_dt3.png" style="width: 40%;" /></a>
<p>Okay, let’s add one more threshhold.<br />
Let’s make a final split of the section that is less than <code class="docutils literal notranslate"><span class="pre">Feature_1</span> <span class="pre">=</span> <span class="pre">0.47</span></code>, using <code class="docutils literal notranslate"><span class="pre">Feature_2</span> <span class="pre">=</span> <span class="pre">0.6</span></code>.<br />
By this methodology we have successfully classified all of our data.</p>
<a class="reference internal image-reference" href="../_images/scatter_dt4.png"><img alt="404 image" src="../_images/scatter_dt4.png" style="width: 40%;" /></a>
<p>What we’ve really done here is create a group of <code class="docutils literal notranslate"><span class="pre">if</span></code> statements:</p>
<ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">Feature_1</span> <span class="pre">&lt;</span> <span class="pre">0.47</span></code> and <code class="docutils literal notranslate"><span class="pre">Feature_2</span> <span class="pre">&lt;</span> <span class="pre">0.6</span></code> classify as <font color='orange'><strong>ORANGE</strong></font></p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">Feature_1</span> <span class="pre">&lt;</span> <span class="pre">0.47</span></code> and <code class="docutils literal notranslate"><span class="pre">Feature_2</span> <span class="pre">&gt;</span> <span class="pre">0.6</span></code> classify as <font color='blue'><strong>BLUE</strong></font></p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">Feature_1</span> <span class="pre">&gt;</span> <span class="pre">0.47</span></code> and <code class="docutils literal notranslate"><span class="pre">Feature_2</span> <span class="pre">&lt;</span> <span class="pre">0.52</span></code> classify as <font color='blue'><strong>BLUE</strong></font></p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">Feature_1</span> <span class="pre">&gt;</span> <span class="pre">0.47</span></code> and <code class="docutils literal notranslate"><span class="pre">Feature_2</span> <span class="pre">&gt;</span> <span class="pre">0.52</span></code> classify as <font color='orange'><strong>ORANGE</strong></font></p></li>
</ul>
<p>This is easier to visualize as a tree:</p>
<a class="reference internal image-reference" href="../_images/toy_tree.png"><img alt="404 image" src="../_images/toy_tree.png" style="width: 40%;" /></a>
<p>We just made our first decision tree!</p>
<p>Before we go forward with learning about decision tree classifiers and reggressors we need to understand the structure of a decision tree.
Here is the key terminology that you will have to know:</p>
<ul class="simple">
<li><p><strong>Root</strong>: Where we start making our conditions.</p></li>
<li><p><strong>Branch</strong>:  A branch connects to the next node (statement). Each branch represents either true or false.</p></li>
<li><p><strong>Internal node</strong>: conditions within the tree.</p></li>
<li><p><strong>Leaf</strong>: the value predicted from the conditions.</p></li>
<li><p><strong>Tree depth</strong>: The longest path from the root to a leaf.</p></li>
</ul>
<p>With the decision tree algorithm in machine learning, the tree can have at most two nodes resulting from it, also known as children.</p>
<p>If a tree only has a depth of 1, we call that a <strong>decision stump</strong>.</p>
<a class="reference internal image-reference" href="../_images/lingo_tree.png"><img alt="404 image" src="../_images/lingo_tree.png" style="width: 55%;" /></a>
<p>This tree  and the one in our example above, both have a depth of 2.</p>
<p>Trees do not need to be balanced. (You’ll see this shortly)</p>
</div>
<div class="section" id="implimentation-with-scikit-learn">
<h3><span class="section-number">1.7.2. </span>Implimentation with Scikit-learn<a class="headerlink" href="#implimentation-with-scikit-learn" title="Permalink to this headline">#</a></h3>
<p>Before we build any model (we are getting to that so hang tight), we need to make sure we have the right “parts” aka inputs and outputs.</p>
<p>That means we need to split up our tabular data into the features and the target, also known as <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p><span class="math notranslate nohighlight">\(X\)</span> is all of our features in our data, which we also call our <em><strong>feature table</strong></em>. <br>
<span class="math notranslate nohighlight">\(y\)</span> is our target, which is what we are predicting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;vote&quot;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;vote&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lon</th>
      <th>lat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>146</th>
      <td>-82.155358</td>
      <td>38.008878</td>
    </tr>
    <tr>
      <th>33</th>
      <td>-92.744478</td>
      <td>31.226442</td>
    </tr>
    <tr>
      <th>389</th>
      <td>-96.505225</td>
      <td>47.070528</td>
    </tr>
    <tr>
      <th>297</th>
      <td>-87.964364</td>
      <td>42.159843</td>
    </tr>
    <tr>
      <th>230</th>
      <td>-88.137965</td>
      <td>40.374736</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>146     red
33      red
389    blue
297    blue
230    blue
Name: vote, dtype: object
</pre></div>
</div>
</div>
</div>
<p>There are several machine learning libraries available to use but for this course, we will be using the  Scikit-learn (hereafter, referred to as sklearn) library, which is a popular (41.6k stars on Github) Machine Learning library for Python.</p>
<ul class="simple">
<li><p>We generally import a particular ML algorithm using the following syntax:</p></li>
</ul>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">sklearn.module</span> <span class="pre">import</span> <span class="pre">algorithm</span></code></p>
</div></blockquote>
<p>The decision tree classification algorithm (<code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code>) sits within the <code class="docutils literal notranslate"><span class="pre">tree</span></code> module.<br />
(Note there is also a Decision Tree Regression algorithm in this module which we’ll come to later…)<br />
Let’s import the classifier using the following code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
</pre></div>
</div>
</div>
</div>
<p>We can begin creating a model by instantiating an instance of the algorithm class.<br />
Here we are naming our decision tree model <code class="docutils literal notranslate"><span class="pre">model</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DecisionTreeClassifier()
</pre></div>
</div>
</div>
</div>
<p>At this point we just have the framework of a model.<br />
We can’t do anything with our algorithm yet, because it hasn’t seen any data!<br />
We need to give our algorithm some data to learn/train/fit a model.</p>
<p>We can now use the <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> method to train our model using the feature <code class="docutils literal notranslate"><span class="pre">X</span></code> and target <code class="docutils literal notranslate"><span class="pre">y</span></code> data we just separated.<br />
When we call fit on our model object, the actual learning happens.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DecisionTreeClassifier()
</pre></div>
</div>
</div>
</div>
<p>Now we’ve used data to learn a model, let’s take a look at the model we made!<br />
The code below prints out our model structure for us (like the tree we made ourselves earlier)</p>
<p>The way to read the decision tree visualization below
is that if the condition on top of a box is true,
then you follow the left arrow and if it is false you follow the right arrow.
<code class="docutils literal notranslate"><span class="pre">samples</span></code> indicated how many observations there are in the node
and <code class="docutils literal notranslate"><span class="pre">values</span></code> how many of those are <code class="docutils literal notranslate"><span class="pre">[blue,</span> <span class="pre">red]</span></code>.
The class of each node indicated what class most samples in that node belong to.
Note that you need to make sure that the feature and class names are passed in the correct order,
and the best way to do this is to crosscheck with the next plot we will make,
but for now you can rely on that I have put these in the expected order.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">plot_tree</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="n">plot_tree</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">unique</span><span class="p">()[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">impurity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># We need to create a figure to control the overall plot size</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture1_70_0.png" src="../_images/lecture1_70_0.png" />
</div>
</div>
<p>We can better visualize what’s going on by actually plotting our data and the model’s  <strong>decision boundaries</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">plot_classifier</span> <span class="kn">import</span> <span class="n">plot_classifier</span>


<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_classifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">ticks</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;lon&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/joel/miniconda3/envs/bait/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(
</pre></div>
</div>
<img alt="../_images/lecture1_72_1.png" src="../_images/lecture1_72_1.png" />
</div>
</div>
<p>In this plot the shaded regions show what our model predicts for different feature values.<br />
The scatter points are our actual 20 observations.<br />
From the above plot, we can see that our model is classifying all our observations correctly, but there’s an easier way to find out how our model is doing.<br />
We can predict the target of examples by calling <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> on the classifier object.<br />
Let’s see what it predicts for a single randomly new observation first:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_ex</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">87.4</span><span class="p">,</span> <span class="mi">59</span><span class="p">]</span>
<span class="n">new_example</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="n">new_ex</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lon&quot;</span><span class="p">,</span> <span class="s2">&quot;lat&quot;</span><span class="p">])</span>
<span class="n">new_example</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lon</th>
      <th>lat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-87.4</td>
      <td>59</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new_example</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;blue&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<p>we get a prediction of <code class="docutils literal notranslate"><span class="pre">blue</span></code> for this example!</p>
<p>We can also predict on our whole feature table - Here, we are predicting on all of X.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;red&#39;, &#39;red&#39;, &#39;blue&#39;, &#39;blue&#39;, &#39;blue&#39;, &#39;blue&#39;, &#39;red&#39;, &#39;red&#39;, &#39;blue&#39;,
       &#39;red&#39;, &#39;red&#39;, &#39;blue&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;true_values&#39;</span> <span class="p">:</span> <span class="n">y</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="s1">&#39;predicted&#39;</span> <span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>true_values</th>
      <th>predicted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>red</td>
      <td>red</td>
    </tr>
    <tr>
      <th>1</th>
      <td>red</td>
      <td>red</td>
    </tr>
    <tr>
      <th>2</th>
      <td>blue</td>
      <td>blue</td>
    </tr>
    <tr>
      <th>3</th>
      <td>blue</td>
      <td>blue</td>
    </tr>
    <tr>
      <th>4</th>
      <td>blue</td>
      <td>blue</td>
    </tr>
    <tr>
      <th>5</th>
      <td>blue</td>
      <td>blue</td>
    </tr>
    <tr>
      <th>6</th>
      <td>red</td>
      <td>red</td>
    </tr>
    <tr>
      <th>7</th>
      <td>red</td>
      <td>red</td>
    </tr>
    <tr>
      <th>8</th>
      <td>blue</td>
      <td>blue</td>
    </tr>
    <tr>
      <th>9</th>
      <td>red</td>
      <td>red</td>
    </tr>
    <tr>
      <th>10</th>
      <td>red</td>
      <td>red</td>
    </tr>
    <tr>
      <th>11</th>
      <td>blue</td>
      <td>blue</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Or if we just want to know how many we got right, in the classification setting, we can use  <code class="docutils literal notranslate"><span class="pre">score()</span></code> which gives the accuracy of the model, i.e., the proportion of correctly predicted examples.</p>
<p>Sometimes we will also see people reporting <strong>error</strong>, which is usually 1 - accuracy.</p>
<p>Our model has an accurary of 100% (or 0% error)!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="how-does-predict-work">
<h3><span class="section-number">1.7.3. </span>How does <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> work?<a class="headerlink" href="#how-does-predict-work" title="Permalink to this headline">#</a></h3>
<p>For us to see how our algorithm predicts for each example, all we have to do is return to our Decision Tree.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_tree</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">unique</span><span class="p">()[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">impurity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture1_82_0.png" src="../_images/lecture1_82_0.png" />
</div>
</div>
<p>Let’s use our <code class="docutils literal notranslate"><span class="pre">new_example</span></code> object for this example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_example</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lon</th>
      <th>lat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-87.4</td>
      <td>59</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>First we start at the root.</p></li>
<li><p>Is <code class="docutils literal notranslate"><span class="pre">lon</span></code> &lt;= -102…? False, so we go down the right branch.</p></li>
<li><p>Is <code class="docutils literal notranslate"><span class="pre">lon</span></code> &lt;= -82…? True , so we go down the left branch.</p></li>
<li><p>Is <code class="docutils literal notranslate"><span class="pre">lat</span></code> &lt;= 41…? False , so we go down the left branch.</p></li>
<li><p>Is <code class="docutils literal notranslate"><span class="pre">lon</span></code> &lt;= -91…? False , so we go down the left branch.</p></li>
<li><p>Is <code class="docutils literal notranslate"><span class="pre">lat</span></code> &lt;= 42…? False , so we go down the left branch and arrive at blue!</p></li>
</ul>
<p>Let’s check this using predict again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new_example</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;blue&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<p>Nice!</p>
</div>
<div class="section" id="how-does-fit-work">
<h3><span class="section-number">1.7.4. </span>How does <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> work?<a class="headerlink" href="#how-does-fit-work" title="Permalink to this headline">#</a></h3>
<p>Or “How does do Decision Trees decide what values to split on?”</p>
<p>We will not go into detail here,
but in general the algorithm is trying to maximize the homogeneity of the target variable
within each of the groups created from a split.
In other words,
observations on the left of a split should all be similar to each other
and observation on the right of the split should all be similar to each other.</p>
<p>There are different ways to measure similarity between observations
and some of the most common metrics include:</p>
<ul class="simple">
<li><p>Gini Index</p></li>
<li><p>Information gain</p></li>
<li><p>Cross entropy</p></li>
</ul>
<p>You can read more about these metrics here)[https://en.wikipedia.org/wiki/Decision_tree_learning#Metrics]</p>
</div>
</div>
<div class="section" id="id1">
<h2><span class="section-number">1.8. </span>Let’s Practice<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h2>
<p>Using the data <code class="docutils literal notranslate"><span class="pre">candybars.csv</span></code> from the datafolder to aswer the following questions:</p>
<p>1. How many features are there?<br />
2. How many observations are there?<br />
3. What would be a suitable target with this data?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">candy_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/candybars.csv&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">candy_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>chocolate</th>
      <th>peanuts</th>
      <th>caramel</th>
      <th>nougat</th>
      <th>cookie_wafer_rice</th>
      <th>coconut</th>
      <th>white_chocolate</th>
      <th>multi</th>
      <th>availability</th>
    </tr>
    <tr>
      <th>candy bar</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CoffeeCrisp</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>Butterfinger</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>Skor</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>Smarties</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>Twix</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>ReesesPeanutButterCups</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>3Musketeers</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>Kinder Surprise</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>M&amp;Ms</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>Glosettes</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>KitKat</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>Babe Ruth</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>Caramilk</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>Aero</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>Mars</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>Payday</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>Snickers</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>Crunchie</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>Wonderbar</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>100Grand</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>Take5</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>Whatchamacallits</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>AlmondJoy</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>OhHenry</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>CookiesandCream</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>Both</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">candy_df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(25, 9)
</pre></div>
</div>
</div>
</div>
<p><strong>Answer as either <code class="docutils literal notranslate"><span class="pre">fit</span></code>  or <code class="docutils literal notranslate"><span class="pre">predict</span></code>:</strong></p>
<ol class="simple">
<li><p>Is called first (before the other one).</p></li>
<li><p>Only takes X as an argument.</p></li>
<li><p>In scikit-learn, we can ignore its output.</p></li>
</ol>
<p><strong>Quick Questions:</strong></p>
<ol class="simple">
<li><p>What is the top node in a decision tree called?</p></li>
<li><p>What Python structure/syntax are the nodes in a decision tree similar to?</p></li>
</ol>
<div class="dropdown admonition">
<p class="admonition-title">Solutions!</p>
<ol class="simple">
<li><p>8</p></li>
<li><p>25</p></li>
<li><p>Probably <code class="docutils literal notranslate"><span class="pre">availability</span></code> but we could use the other features as well.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fit</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">predict</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fit</span></code></p></li>
<li><p>the root</p></li>
<li><p>if/else conditions</p></li>
</ol>
</div>
</div>
<div class="section" id="parameters-and-hyperparameters">
<h2><span class="section-number">1.9. </span>Parameters and Hyperparameters<a class="headerlink" href="#parameters-and-hyperparameters" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><em><strong>Parameters</strong></em>:  Derived during training and automatically set by the model.</p></li>
<li><p><em><strong>Hyperparameters</strong></em>: Can be set before training by the data scientist to influence how the model sets it parameters.</p></li>
</ul>
<p>E.g., we can tell the tree to use a certain metric (a hyperparameter)
to derive the splits at each leaf (the parameters of the model).</p>
<div class="section" id="parameters">
<h3><span class="section-number">1.9.1. </span>Parameters<a class="headerlink" href="#parameters" title="Permalink to this headline">#</a></h3>
<p>When you call <code class="docutils literal notranslate"><span class="pre">fit</span></code> (the training stage of building your model), <strong>parameters</strong> get set, like the split variables and split thresholds.</p>
<a class="reference internal image-reference" href="../_images/parameters.png"><img alt="404 image" src="../_images/parameters.png" style="width: 30%;" /></a>
</div>
<div class="section" id="hyperparameters">
<h3><span class="section-number">1.9.2. </span>Hyperparameters<a class="headerlink" href="#hyperparameters" title="Permalink to this headline">#</a></h3>
<p>But even before calling <code class="docutils literal notranslate"><span class="pre">fit</span></code> on a specific data set, we can set some some “knobs” which that control the learning which are called <strong>hyperparameters</strong>.</p>
<p>In scikit-learn, hyperparameters are set in the constructor.</p>
<p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code>is a hyperparameter (of many) that lets us decide and set how “deep” we allow our tree to grow.</p>
<p>Let’s practice by making a decision stump (A tree with a depth of 1). Our last model was made where we set the depth to “unlimited” so we need to initial a new model and train a new where where we set the <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> hyperparameter.</p>
<p>Let’s see what the tree looks like now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_1</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">model_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DecisionTreeClassifier(max_depth=1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_tree</span><span class="p">(</span>
    <span class="n">model_1</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">unique</span><span class="p">()[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">impurity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture1_99_0.png" src="../_images/lecture1_99_0.png" />
</div>
</div>
<p>We see that it’s a depth of one and split on <code class="docutils literal notranslate"><span class="pre">lon</span></code> at -102.165.</p>
<ul class="simple">
<li><p>The hyperparameter <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>  is being set by us at 1.</p></li>
<li><p>The parameter <code class="docutils literal notranslate"><span class="pre">lon</span></code> is set by the algorithm at -102.165.</p></li>
</ul>
<p>We can see the decision boundary at <code class="docutils literal notranslate"><span class="pre">lon</span></code>= -102.165 with the vertical line in the plot below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">plot_classifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">model_1</span><span class="p">,</span> <span class="n">ticks</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;lon&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/joel/miniconda3/envs/bait/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(
</pre></div>
</div>
<img alt="../_images/lecture1_102_1.png" src="../_images/lecture1_102_1.png" />
</div>
</div>
<ul class="simple">
<li><p>Looking  at the score of this model, we get an accuracy of 75%.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8333333333333334
</pre></div>
</div>
</div>
</div>
<p>Let’s try growing a more complex tree model and now set <code class="docutils literal notranslate"><span class="pre">max_depth</span> <span class="pre">=</span> <span class="pre">3</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_3</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_tree</span><span class="p">(</span>
    <span class="n">model_3</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
    <span class="n">class_names</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">unique</span><span class="p">()[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">impurity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture1_107_0.png" src="../_images/lecture1_107_0.png" />
</div>
</div>
<p>This has 4 splits in the tree so we expect 4 decision boundaries (2 on <code class="docutils literal notranslate"><span class="pre">lon</span></code> and 2 on <code class="docutils literal notranslate"><span class="pre">lat</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_classifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">model_3</span><span class="p">,</span> <span class="n">ticks</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;lon&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;lat&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/joel/miniconda3/envs/bait/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(
</pre></div>
</div>
<img alt="../_images/lecture1_109_1.png" src="../_images/lecture1_109_1.png" />
</div>
</div>
<ul class="simple">
<li><p>Looking at the score of this model now get an accuracy of 90%!</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_3</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
<p>We see here that as <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> increases, the accuracy of the training data does as well.</p>
<p>Doing this isn’t always the best idea and we’ll explain this a little bit later on.</p>
<ul class="simple">
<li><p>This is just one of many other hyperparameters for decision trees that you can explore -&gt; link <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" target="_blank">here</a> There are many other hyperparameters for decision trees that you can explore at the link <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" target="_blank">here</a>.</p></li>
</ul>
<p>To summarize this section:</p>
<ul class="simple">
<li><p><strong>parameters</strong> are automatically learned by an algorithm during training</p></li>
<li><p><strong>hyperparameters</strong> are specified before training</p></li>
</ul>
</div>
</div>
<div class="section" id="decision-tree-regressor">
<h2><span class="section-number">1.10. </span>Decision Tree Regressor<a class="headerlink" href="#decision-tree-regressor" title="Permalink to this headline">#</a></h2>
<p>We saw that we can use decision trees for classification problems but we can also use this decision tree algorithm for regression problems.</p>
<p>Instead of using Gini impurity (which we briefly mentioned this above), we can use <a href="https://scikit-learn.org/stable/modules/tree.html#mathematical-formulation" target="_blank">some other criteria</a> for splitting.</p>
<p>(A common one is mean squared error (MSE) which we will discuss shortly)</p>
<p><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> supports regression using decision trees with <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor()</span></code> and the <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> and <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> paradigm that is similar to classification.</p>
<p>Let’s do an example using the <code class="docutils literal notranslate"><span class="pre">kc_house_data</span></code> we saw in example 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/kc_house_data.csv&quot;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;date&quot;</span><span class="p">])</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>bedrooms</th>
      <th>bathrooms</th>
      <th>sqft_living</th>
      <th>sqft_lot</th>
      <th>floors</th>
      <th>waterfront</th>
      <th>view</th>
      <th>condition</th>
      <th>grade</th>
      <th>sqft_above</th>
      <th>sqft_basement</th>
      <th>yr_built</th>
      <th>yr_renovated</th>
      <th>zipcode</th>
      <th>lat</th>
      <th>long</th>
      <th>sqft_living15</th>
      <th>sqft_lot15</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>221900.0</td>
      <td>3</td>
      <td>1.00</td>
      <td>1180</td>
      <td>5650</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1180</td>
      <td>0</td>
      <td>1955</td>
      <td>0</td>
      <td>98178</td>
      <td>47.5112</td>
      <td>-122.257</td>
      <td>1340</td>
      <td>5650</td>
    </tr>
    <tr>
      <th>1</th>
      <td>538000.0</td>
      <td>3</td>
      <td>2.25</td>
      <td>2570</td>
      <td>7242</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>2170</td>
      <td>400</td>
      <td>1951</td>
      <td>1991</td>
      <td>98125</td>
      <td>47.7210</td>
      <td>-122.319</td>
      <td>1690</td>
      <td>7639</td>
    </tr>
    <tr>
      <th>2</th>
      <td>180000.0</td>
      <td>2</td>
      <td>1.00</td>
      <td>770</td>
      <td>10000</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>6</td>
      <td>770</td>
      <td>0</td>
      <td>1933</td>
      <td>0</td>
      <td>98028</td>
      <td>47.7379</td>
      <td>-122.233</td>
      <td>2720</td>
      <td>8062</td>
    </tr>
    <tr>
      <th>3</th>
      <td>604000.0</td>
      <td>4</td>
      <td>3.00</td>
      <td>1960</td>
      <td>5000</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>7</td>
      <td>1050</td>
      <td>910</td>
      <td>1965</td>
      <td>0</td>
      <td>98136</td>
      <td>47.5208</td>
      <td>-122.393</td>
      <td>1360</td>
      <td>5000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>510000.0</td>
      <td>3</td>
      <td>2.00</td>
      <td>1680</td>
      <td>8080</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>8</td>
      <td>1680</td>
      <td>0</td>
      <td>1987</td>
      <td>0</td>
      <td>98074</td>
      <td>47.6168</td>
      <td>-122.045</td>
      <td>1800</td>
      <td>7503</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>21608</th>
      <td>360000.0</td>
      <td>3</td>
      <td>2.50</td>
      <td>1530</td>
      <td>1131</td>
      <td>3.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>8</td>
      <td>1530</td>
      <td>0</td>
      <td>2009</td>
      <td>0</td>
      <td>98103</td>
      <td>47.6993</td>
      <td>-122.346</td>
      <td>1530</td>
      <td>1509</td>
    </tr>
    <tr>
      <th>21609</th>
      <td>400000.0</td>
      <td>4</td>
      <td>2.50</td>
      <td>2310</td>
      <td>5813</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>8</td>
      <td>2310</td>
      <td>0</td>
      <td>2014</td>
      <td>0</td>
      <td>98146</td>
      <td>47.5107</td>
      <td>-122.362</td>
      <td>1830</td>
      <td>7200</td>
    </tr>
    <tr>
      <th>21610</th>
      <td>402101.0</td>
      <td>2</td>
      <td>0.75</td>
      <td>1020</td>
      <td>1350</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1020</td>
      <td>0</td>
      <td>2009</td>
      <td>0</td>
      <td>98144</td>
      <td>47.5944</td>
      <td>-122.299</td>
      <td>1020</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>21611</th>
      <td>400000.0</td>
      <td>3</td>
      <td>2.50</td>
      <td>1600</td>
      <td>2388</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>8</td>
      <td>1600</td>
      <td>0</td>
      <td>2004</td>
      <td>0</td>
      <td>98027</td>
      <td>47.5345</td>
      <td>-122.069</td>
      <td>1410</td>
      <td>1287</td>
    </tr>
    <tr>
      <th>21612</th>
      <td>325000.0</td>
      <td>2</td>
      <td>0.75</td>
      <td>1020</td>
      <td>1076</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1020</td>
      <td>0</td>
      <td>2008</td>
      <td>0</td>
      <td>98144</td>
      <td>47.5941</td>
      <td>-122.299</td>
      <td>1020</td>
      <td>1357</td>
    </tr>
  </tbody>
</table>
<p>21613 rows × 19 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;price&quot;</span><span class="p">])</span>
<span class="n">X</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bedrooms</th>
      <th>bathrooms</th>
      <th>sqft_living</th>
      <th>sqft_lot</th>
      <th>floors</th>
      <th>waterfront</th>
      <th>view</th>
      <th>condition</th>
      <th>grade</th>
      <th>sqft_above</th>
      <th>sqft_basement</th>
      <th>yr_built</th>
      <th>yr_renovated</th>
      <th>zipcode</th>
      <th>lat</th>
      <th>long</th>
      <th>sqft_living15</th>
      <th>sqft_lot15</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>1.00</td>
      <td>1180</td>
      <td>5650</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1180</td>
      <td>0</td>
      <td>1955</td>
      <td>0</td>
      <td>98178</td>
      <td>47.5112</td>
      <td>-122.257</td>
      <td>1340</td>
      <td>5650</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>2.25</td>
      <td>2570</td>
      <td>7242</td>
      <td>2.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>2170</td>
      <td>400</td>
      <td>1951</td>
      <td>1991</td>
      <td>98125</td>
      <td>47.7210</td>
      <td>-122.319</td>
      <td>1690</td>
      <td>7639</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>1.00</td>
      <td>770</td>
      <td>10000</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>6</td>
      <td>770</td>
      <td>0</td>
      <td>1933</td>
      <td>0</td>
      <td>98028</td>
      <td>47.7379</td>
      <td>-122.233</td>
      <td>2720</td>
      <td>8062</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>3.00</td>
      <td>1960</td>
      <td>5000</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>7</td>
      <td>1050</td>
      <td>910</td>
      <td>1965</td>
      <td>0</td>
      <td>98136</td>
      <td>47.5208</td>
      <td>-122.393</td>
      <td>1360</td>
      <td>5000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
      <td>2.00</td>
      <td>1680</td>
      <td>8080</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>8</td>
      <td>1680</td>
      <td>0</td>
      <td>1987</td>
      <td>0</td>
      <td>98074</td>
      <td>47.6168</td>
      <td>-122.045</td>
      <td>1800</td>
      <td>7503</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;price&quot;</span><span class="p">]</span>
<span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    221900.0
1    538000.0
2    180000.0
3    604000.0
4    510000.0
Name: price, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>We can see that instead of predicting a categorical column like we did with <code class="docutils literal notranslate"><span class="pre">vote</span></code> before, our target column is now numeric.</p>
<p>Instead of importing <code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code>, we import <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code>.</p>
<p>We follow the same steps as before and can even set hyperparameters as we did in classification.</p>
<p>Here, when we build our model, we are specifying a <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> of 3.</p>
<p>This means our decision tree is going to be constrained to a depth of 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="n">depth</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">reg_model</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">reg_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DecisionTreeRegressor(max_depth=3, random_state=1)
</pre></div>
</div>
</div>
</div>
<p>Let’s look at the tree it produces our leaves used to contain a categorical value for prediction, but this time we see our leaves are predicting numerical values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_tree</span><span class="p">(</span>
    <span class="n">reg_model</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
    <span class="n">impurity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/lecture1_122_0.png" src="../_images/lecture1_122_0.png" />
</div>
</div>
<p>Let’s see what our model predicts for a single example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="mi">0</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bedrooms</th>
      <th>bathrooms</th>
      <th>sqft_living</th>
      <th>sqft_lot</th>
      <th>floors</th>
      <th>waterfront</th>
      <th>view</th>
      <th>condition</th>
      <th>grade</th>
      <th>sqft_above</th>
      <th>sqft_basement</th>
      <th>yr_built</th>
      <th>yr_renovated</th>
      <th>zipcode</th>
      <th>lat</th>
      <th>long</th>
      <th>sqft_living15</th>
      <th>sqft_lot15</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>1.0</td>
      <td>1180</td>
      <td>5650</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>7</td>
      <td>1180</td>
      <td>0</td>
      <td>1955</td>
      <td>0</td>
      <td>98178</td>
      <td>47.5112</td>
      <td>-122.257</td>
      <td>1340</td>
      <td>5650</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reg_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([269848.39378011])
</pre></div>
</div>
</div>
</div>
<p>Our model predicts a housing price of $269848.39</p>
<p>Should we see what the true value is?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="mi">0</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    221900.0
Name: price, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>The true value is $221900.0, but how well did it score?</p>
<p>With regression problems we can’t use accuracy for a scoring method so instead when we use <code class="docutils literal notranslate"><span class="pre">.score()</span></code>  it returns somethings called an <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" target="_blank"> 𝑅2 (r squared) score</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reg_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6069320183816143
</pre></div>
</div>
</div>
</div>
<p>The maximum 𝑅2 is 1 for perfect predictions,
0 means that the same value would be predicted regardless of the input value,
and a negative value would mean that the model is performing worse than outputting a constant value
(e.g. the higher the actual value, the lower the prediction is).</p>
</div>
<div class="section" id="let-s-practice-coding">
<h2><span class="section-number">1.11. </span>Let’s Practice - Coding<a class="headerlink" href="#let-s-practice-coding" title="Permalink to this headline">#</a></h2>
<p>Using the data <code class="docutils literal notranslate"><span class="pre">candybars.csv</span></code> from the datafolder (or going to exercise 7 <a class="reference external" href="https://ml-learn.mds.ubc.ca/en/module2">here</a>)  for the following:</p>
<ol class="simple">
<li><p>Define two objects named <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> which contain the features and target column respectively.</p></li>
<li><p>Using sklearn, create 3 different decision tree classifiers using 3 different <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> values based on this data.</p></li>
<li><p>What is the accuracy of each classifier on the training data?</p></li>
<li><p>a) Which <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> value would you choose to predict this data? <br>
b) Would you choose the same <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> value to predict new data?</p></li>
<li><p>Do you think most of the computational effort for a decision tree takes place in the <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> stage or <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> stage?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">candy_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/candybars.csv&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">candy_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>chocolate</th>
      <th>peanuts</th>
      <th>caramel</th>
      <th>nougat</th>
      <th>cookie_wafer_rice</th>
      <th>coconut</th>
      <th>white_chocolate</th>
      <th>multi</th>
      <th>availability</th>
    </tr>
    <tr>
      <th>candy bar</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CoffeeCrisp</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>Butterfinger</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>Skor</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>Smarties</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>Twix</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>ReesesPeanutButterCups</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>3Musketeers</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>Kinder Surprise</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>M&amp;Ms</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>Glosettes</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>KitKat</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>Babe Ruth</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>Caramilk</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>Aero</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>Mars</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>Payday</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>Snickers</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>Crunchie</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>Wonderbar</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Canada</td>
    </tr>
    <tr>
      <th>100Grand</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>Take5</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>Whatchamacallits</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>AlmondJoy</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>America</td>
    </tr>
    <tr>
      <th>OhHenry</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Both</td>
    </tr>
    <tr>
      <th>CookiesandCream</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>Both</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><strong>Solutions</strong></p>
<p>1.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">candy_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;availability&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">candy_df</span><span class="p">[</span><span class="s1">&#39;availability&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>2 and 3.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2/3.</span>
<span class="n">dt2</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">dt2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">dt2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.84
</pre></div>
</div>
</div>
</div>
<p>2 and 3.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2/3.</span>
<span class="n">dt5</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">min_samples_split</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">dt5</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">dt5</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.72
</pre></div>
</div>
</div>
</div>
<p>2 and 3.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2/3.</span>
<span class="n">dt10</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">min_samples_split</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">dt10</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">dt10</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.64
</pre></div>
</div>
</div>
</div>
<p>4.</p>
<div class="toggle docutils container">
<p>In this example, the best performance on the training data is given when <code class="docutils literal notranslate"><span class="pre">min_samples_split=2</span></code>.
We don’t know if this generalizes best to predicting unseen data,
and to find out we would need to evaluate the different hyperparameter values on a validation data set,
ideally using cross-validation, which we will talk about next lecture.</p>
</div>
<p>5.</p>
<div class="toggle docutils container">
<p>The fit stage is more computationally expensive since this is where the optimal feature splits are being computed.
The predict stage is using these already created rules to classify new points.</p>
</div>
</div>
<div class="section" id="what-we-ve-learned-today-a-id-9-a">
<h2><span class="section-number">1.12. </span>What We’ve Learned Today<a id="9"></a><a class="headerlink" href="#what-we-ve-learned-today-a-id-9-a" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>What is machine learning (supervised/unsupervised, classification/regression)</p></li>
<li><p>Machine learning terminology</p></li>
<li><p>What is the decision tree algorithm and how does it work</p></li>
<li><p>The scikit-learn library</p></li>
<li><p>Parameters and hyperparameters</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-env-bait-py"
        },
        kernelOptions: {
            kernelName: "conda-env-bait-py",
            path: "./lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-env-bait-py'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../things_to_know/what.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">What: Learning Outcomes</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="lecture2.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2. </span>Splitting and Cross-validation</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Quan Nguyen<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>