{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline models & k-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture Learning Objectives \n",
    "\n",
    "- Use `DummyClassifier` and `DummyRegressor` as baselines for machine learning problems.\n",
    "- Explain the notion of similarity-based algorithms .\n",
    "- Broadly describe how KNNs use distances.\n",
    "- Discuss the effect of using a small/large value of the hyperparameter $K$ when using the KNN algorithm \n",
    "- Describe the problem of the curse of dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five Minute Recap/ Lightning Questions \n",
    "\n",
    "- What are the 4 types of data/splits that we discussed last class?\n",
    "- What is the \"Golden Rule of Machine Learning\"?\n",
    "- What do we use to split our data?\n",
    "- What is overfitting and underfitting? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some lingering questions\n",
    "\n",
    "- Are decision trees the most basic model?\n",
    "- What other models can we build?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models\n",
    "\n",
    "We saw in the last 2 lectures how to build decision tree models which are based on rules (if-else statements), but how can we be sure that these models are doing a good job besides just accuracy? \n",
    "\n",
    "Back in high school in chemistry or biology, we've all likely seen and heard of the \"control group\" where we have an experimental group, does not receive any experimental treatment.  This control group increases the reliability of the results, often through a comparison between control measurements and the other measurements. \n",
    "\n",
    "\n",
    "Our baseline model is something like a control group in the sense that it provides a way to sanity-check your machine learning model. We make baseline models not to use for prediction purposes, but as a reference point when we are building other more sophisticated models.\n",
    "\n",
    "So what is a baseline model then? \n",
    "\n",
    "- Baseline: A simple machine learning algorithm based on simple rules of thumb. For example, \n",
    "    - most frequent baseline: always predicts the most frequent label in the training set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier\n",
    "\n",
    "We are going to build a most frequent baseline model which always predicts the most frequently labelled in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-80.162475</td>\n",
       "      <td>25.692104</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-80.214360</td>\n",
       "      <td>25.944083</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-80.094133</td>\n",
       "      <td>26.234314</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-80.248086</td>\n",
       "      <td>26.291902</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-81.789963</td>\n",
       "      <td>26.348035</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>-97.460476</td>\n",
       "      <td>48.225094</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>-96.551116</td>\n",
       "      <td>48.591592</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>-166.519855</td>\n",
       "      <td>53.887114</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>-163.733617</td>\n",
       "      <td>67.665859</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>-145.423115</td>\n",
       "      <td>68.077395</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lon        lat  vote\n",
       "1    -80.162475  25.692104  blue\n",
       "2    -80.214360  25.944083  blue\n",
       "3    -80.094133  26.234314  blue\n",
       "4    -80.248086  26.291902  blue\n",
       "5    -81.789963  26.348035  blue\n",
       "..          ...        ...   ...\n",
       "396  -97.460476  48.225094   red\n",
       "397  -96.551116  48.591592  blue\n",
       "398 -166.519855  53.887114   red\n",
       "399 -163.733617  67.665859   red\n",
       "400 -145.423115  68.077395   red\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "voting_df = pd.read_csv('data/cities_USA.csv', index_col=0)\n",
    "voting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature table\n",
    "X = voting_df.drop(columns='vote')\n",
    "\n",
    "# the target variable\n",
    "y = voting_df[['vote']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build our model, in the same way as we built a decision tree model but this time using `DummyClassifier`. \n",
    "\n",
    "Since we are using a \"most frequent\" baseline model, we specify the argument `strategy` as `\"most_frequent\"`\n",
    "\n",
    "There are other options that you you read about in the [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) but you just need to know `most_frequent` for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lecture, we stated that it's at this point that we would usually perform cross-validation\n",
    "to evaluate the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Dummy Classifiers, we won't need to because we are not hyperparameter tuning. We are using this just to get a base training score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.578125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we see what our model predicts on the feature table for our training split `X_train`, our model will predict the most occurring class from our training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vote\n",
       "blue    185\n",
       "red     135\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue'],\n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also now take the test score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a good example of when we occasionally have test scores better than the training scores.\n",
    "\n",
    "In this case, it's higher because our test split has a higher proportion of observations that are of class blue and so more of them will be predicted correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we build a decision tree, we can compare it to the baseline model score.\n",
    "\n",
    "Here we use crossvalidation to score the model although we are not tuning any hyperparameters.\n",
    "It is general a good idea to get into the habit of doing this for all models except baseline/dummy models,\n",
    "because the split can influence the model score (this is true to a much lesser extent for baseline models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_score     0.884375\n",
       "train_score    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "scores = cross_validate(dt_clf, X_train, y_train, cv=10, return_train_score=True)\n",
    "pd.DataFrame(scores).mean()[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8875"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.fit(X_train, y_train)\n",
    "dt_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our decision tree is doing better than a model build on this simple \"most frequently\" occurring model. \n",
    "This makes us trust our model a little more\n",
    "and we know that it has identified some structure in the data that is more complicated than simply predicting the most common label.\n",
    "This is especially important if we have an unbalanced training data set with much more of one label than of another,\n",
    "but there are also more sophisticated strategies to handle that situation,\n",
    "which we will discuss later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Regressor\n",
    "\n",
    "For a Dummy regressor, the same principles can be applied but by using different strategies.\n",
    "\n",
    "[“mean”, “median”, “quantile”, “constant”](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html?highlight=dummyregressor)\n",
    "\n",
    "The one we are going to become most familiar with is:\n",
    "\n",
    "**Average (mean) target value:** always predicts the mean of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "0      221900.0         3       1.00         1180      5650     1.0   \n",
       "1      538000.0         3       2.25         2570      7242     2.0   \n",
       "2      180000.0         2       1.00          770     10000     1.0   \n",
       "3      604000.0         4       3.00         1960      5000     1.0   \n",
       "4      510000.0         3       2.00         1680      8080     1.0   \n",
       "...         ...       ...        ...          ...       ...     ...   \n",
       "21608  360000.0         3       2.50         1530      1131     3.0   \n",
       "21609  400000.0         4       2.50         2310      5813     2.0   \n",
       "21610  402101.0         2       0.75         1020      1350     2.0   \n",
       "21611  400000.0         3       2.50         1600      2388     2.0   \n",
       "21612  325000.0         2       0.75         1020      1076     2.0   \n",
       "\n",
       "       waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
       "0               0     0          3      7        1180              0   \n",
       "1               0     0          3      7        2170            400   \n",
       "2               0     0          3      6         770              0   \n",
       "3               0     0          5      7        1050            910   \n",
       "4               0     0          3      8        1680              0   \n",
       "...           ...   ...        ...    ...         ...            ...   \n",
       "21608           0     0          3      8        1530              0   \n",
       "21609           0     0          3      8        2310              0   \n",
       "21610           0     0          3      7        1020              0   \n",
       "21611           0     0          3      8        1600              0   \n",
       "21612           0     0          3      7        1020              0   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0          1955             0    98178  47.5112 -122.257           1340   \n",
       "1          1951          1991    98125  47.7210 -122.319           1690   \n",
       "2          1933             0    98028  47.7379 -122.233           2720   \n",
       "3          1965             0    98136  47.5208 -122.393           1360   \n",
       "4          1987             0    98074  47.6168 -122.045           1800   \n",
       "...         ...           ...      ...      ...      ...            ...   \n",
       "21608      2009             0    98103  47.6993 -122.346           1530   \n",
       "21609      2014             0    98146  47.5107 -122.362           1830   \n",
       "21610      2009             0    98144  47.5944 -122.299           1020   \n",
       "21611      2004             0    98027  47.5345 -122.069           1410   \n",
       "21612      2008             0    98144  47.5941 -122.299           1020   \n",
       "\n",
       "       sqft_lot15  \n",
       "0            5650  \n",
       "1            7639  \n",
       "2            8062  \n",
       "3            5000  \n",
       "4            7503  \n",
       "...           ...  \n",
       "21608        1509  \n",
       "21609        7200  \n",
       "21610        2007  \n",
       "21611        1287  \n",
       "21612        1357  \n",
       "\n",
       "[21613 rows x 19 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df = pd.read_csv(\"data/kc_house_data.csv\")\n",
    "house_df = house_df.drop(columns=[\"id\", \"date\"])\n",
    "house_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let get our `X` and `y` objects and split our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house_df.drop(columns=[\"price\"])\n",
    "y = house_df[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to make sure we split our data with baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to import `DummyRegressor` and construct our model. \n",
    "\n",
    "We specify `strategy=\"mean\"` however this is the default value so technically we don't need to specify this. \n",
    "\n",
    "We train our model and again, it's not needed to cross-validate for this type of algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyRegressor()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "\n",
    "dummy_reg = DummyRegressor(strategy=\"mean\")\n",
    "dummy_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we predict on our training data, we see it's making the same prediction for each observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([539306.46784268, 539306.46784268, 539306.46784268, ...,\n",
       "       539306.46784268, 539306.46784268, 539306.46784268])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we compare the mean value of the target, we see that our model is simply predicting the average of the training data which is exactly what we expect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "539306.4678426837"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does it do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an $R^2$ value of 0.0. \n",
    "\n",
    "When a model has an  $R^2$=0 that means that the model is doing no better than a model that using the mean which is exactly the case here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the test score we see that our model get's a slightly negative value,\n",
    "which means that it is doing a little worse than constantly predicting the mean of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00010814646015933072"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice \n",
    "\n",
    "1\\. Below we have the output of `y_train.value_counts()`\n",
    "\n",
    "```\n",
    "Position\n",
    "Forward     13\n",
    "Defense      7\n",
    "Goalie       2\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "In this scenario, what would a `DummyClassifier(strategy='most_frequent')` model predict on the following observation: \n",
    "\n",
    "\n",
    "```\n",
    "   No.  Age  Height  Weight  Experience     Salary\n",
    "1   83   34     191     210          11  3200000.0\n",
    "```\n",
    "\n",
    "2\\. When using a regression model, which of the following is not a possible return value from .score(X,y) ?\n",
    "\n",
    "a) 0.0    \n",
    "b) 1.0    \n",
    "c) -0.1    \n",
    "d) 1.5    \n",
    "    \n",
    "    \n",
    "3\\.  Below are the values for `y` that were used to train  `DummyRegressor(strategy='mean')`:\n",
    "\n",
    "```\n",
    "Grade\n",
    "0     75\n",
    "1     80\n",
    "2     90\n",
    "3     95\n",
    "4     85\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "What value will the model predict for every example?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Solutions!\n",
    ":class: dropdown\n",
    "\n",
    "1. `Forward`\n",
    "2. d) 1.5\n",
    "3. 85\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity/analogy-based models\n",
    "\n",
    "Let's switch topics from baseline models and talked about the concept of similarity based models.\n",
    "\n",
    "Suppose you are given the following training images with the corresponding actor's name as the label.\n",
    "Then we are given an unseen test images of the same actors but from different angles and are asked to label a given test example.\n",
    "\n",
    "An intuitive way to classify the test example is by finding the most \"similar\" example from the training images and use that label for the test example.  \n",
    "\n",
    "<img src='imgs/knn-motivation.png' width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: \n",
    "\n",
    "Suppose we are given many images and their labels.\n",
    "\n",
    "`X` = set of pictures \n",
    "\n",
    "`y` = names associated with those pictures. \n",
    "\n",
    "Then we are given a new unseen test example, a picture in this particular case.\n",
    "\n",
    "\n",
    "<img src='imgs/test_pic.png' width=\"5%\">\n",
    "\n",
    "\n",
    "We want to find out the label for this new test picture. \n",
    "\n",
    "Naturally, we would try and find the most similar picture in our training set and using the label of the most similar picture as the label of this new test example. \n",
    "\n",
    "That's the basic idea behind similarity/analogy-based algorithms.\n",
    "\n",
    "This is different from Decision trees, where we tried to learn a set of rules/conditions to label observations correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity/Analogy-based models in real life\n",
    "\n",
    "\n",
    "- <a href=\"https://www.hertasecurity.com/en\" target=\"_blank\">Herta's High-tech Facial Recognition</a>\n",
    "\n",
    "<img src=\"imgs/face_rec.png\"  width = \"20%\" alt=\"404 image\" />\n",
    "\n",
    "- Recommendation systems \n",
    "\n",
    "<img src=\"imgs/book_rec.png\"  width = \"90%\" alt=\"404 image\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology \n",
    "\n",
    "In analogy-based algorithms, our goal is to come up with a way to find similarities between examples.\n",
    "\"similarity\" is a bit ambiguous so we need some terminology.\n",
    "\n",
    "\n",
    "- data: think of observations (rows) as points in a high dimensional space. \n",
    "- Each feature: Additional dimension. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"imgs/3d-table.png\"  width = \"60%\" alt=\"404 image\" />\n",
    "\n",
    "Above we have: \n",
    "- Three features; speed attack and defense. \n",
    "- 7 points in this three-dimensional space.\n",
    "\n",
    "Let's go back to our Canada/USA cities dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-76.4813</td>\n",
       "      <td>44.2307</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-81.2496</td>\n",
       "      <td>42.9837</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-66.0580</td>\n",
       "      <td>45.2788</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-73.2533</td>\n",
       "      <td>45.3057</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-67.9245</td>\n",
       "      <td>47.1652</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-76.3305</td>\n",
       "      <td>44.1255</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-74.7287</td>\n",
       "      <td>45.0184</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-121.4944</td>\n",
       "      <td>38.5816</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>-79.5656</td>\n",
       "      <td>43.6436</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-66.9195</td>\n",
       "      <td>44.8938</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     longitude  latitude country\n",
       "160   -76.4813   44.2307  Canada\n",
       "127   -81.2496   42.9837  Canada\n",
       "169   -66.0580   45.2788  Canada\n",
       "188   -73.2533   45.3057  Canada\n",
       "187   -67.9245   47.1652  Canada\n",
       "..         ...       ...     ...\n",
       "17    -76.3305   44.1255     USA\n",
       "98    -74.7287   45.0184  Canada\n",
       "66   -121.4944   38.5816     USA\n",
       "126   -79.5656   43.6436  Canada\n",
       "109   -66.9195   44.8938  Canada\n",
       "\n",
       "[167 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df = pd.read_csv(\"data/canada_usa_cities.csv\")\n",
    "cities_train_df, cities_test_df = train_test_split(cities_df, test_size=0.2, random_state=123)\n",
    "cities_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2 features, so 2 dimensions (`longitude` and `latitude`)  and 167 points.\n",
    "Visualizing this in 2 dimensions gives us the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-95d26a72a560425a9875f4921be0e45f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-95d26a72a560425a9875f4921be0e45f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-95d26a72a560425a9875f4921be0e45f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-66158384001fb6a73b6445c49f67d5ce\"}, \"mark\": {\"type\": \"circle\", \"opacity\": 0.6, \"size\": 20}, \"encoding\": {\"color\": {\"field\": \"country\", \"scale\": {\"domain\": [\"Canada\", \"USA\"], \"range\": [\"red\", \"blue\"]}, \"type\": \"nominal\"}, \"x\": {\"field\": \"longitude\", \"scale\": {\"domain\": [-140, -40]}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"latitude\", \"scale\": {\"domain\": [20, 60]}, \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-66158384001fb6a73b6445c49f67d5ce\": [{\"longitude\": -76.4813, \"latitude\": 44.2307, \"country\": \"Canada\"}, {\"longitude\": -81.2496, \"latitude\": 42.9837, \"country\": \"Canada\"}, {\"longitude\": -66.058, \"latitude\": 45.2788, \"country\": \"Canada\"}, {\"longitude\": -73.2533, \"latitude\": 45.3057, \"country\": \"Canada\"}, {\"longitude\": -67.9245, \"latitude\": 47.1652, \"country\": \"Canada\"}, {\"longitude\": -120.3394, \"latitude\": 50.6758, \"country\": \"Canada\"}, {\"longitude\": -106.651, \"latitude\": 35.0841, \"country\": \"USA\"}, {\"longitude\": -79.6902, \"latitude\": 44.3893, \"country\": \"Canada\"}, {\"longitude\": -84.3201, \"latitude\": 46.5239, \"country\": \"Canada\"}, {\"longitude\": -98.4951, \"latitude\": 29.4246, \"country\": \"USA\"}, {\"longitude\": -77.0366, \"latitude\": 38.895, \"country\": \"USA\"}, {\"longitude\": -93.3968, \"latitude\": 48.6114, \"country\": \"Canada\"}, {\"longitude\": -67.2799, \"latitude\": 45.2004, \"country\": \"Canada\"}, {\"longitude\": -122.8565, \"latitude\": 49.3144, \"country\": \"Canada\"}, {\"longitude\": -63.572, \"latitude\": 44.68, \"country\": \"Canada\"}, {\"longitude\": -68.3219, \"latitude\": 47.3556, \"country\": \"USA\"}, {\"longitude\": -97.1385, \"latitude\": 49.8955, \"country\": \"Canada\"}, {\"longitude\": -122.3295, \"latitude\": 49.0521, \"country\": \"Canada\"}, {\"longitude\": -87.6244, \"latitude\": 41.8756, \"country\": \"USA\"}, {\"longitude\": -68.5897, \"latitude\": 47.2587, \"country\": \"USA\"}, {\"longitude\": -73.4467, \"latitude\": 45.5172, \"country\": \"Canada\"}, {\"longitude\": -63.5859, \"latitude\": 44.6486, \"country\": \"Canada\"}, {\"longitude\": -97.7437, \"latitude\": 30.2711, \"country\": \"USA\"}, {\"longitude\": -79.0247, \"latitude\": 43.8504, \"country\": \"Canada\"}, {\"longitude\": -111.9639, \"latitude\": 49.0017, \"country\": \"Canada\"}, {\"longitude\": -129.9912, \"latitude\": 55.9383, \"country\": \"Canada\"}, {\"longitude\": -78.9186, \"latitude\": 42.9131, \"country\": \"Canada\"}, {\"longitude\": -71.7985, \"latitude\": 45.0126, \"country\": \"Canada\"}, {\"longitude\": -95.9929, \"latitude\": 36.1557, \"country\": \"USA\"}, {\"longitude\": -123.0833, \"latitude\": 49.0167, \"country\": \"Canada\"}, {\"longitude\": -94.5648, \"latitude\": 48.7227, \"country\": \"Canada\"}, {\"longitude\": -118.7148, \"latitude\": 50.4165, \"country\": \"Canada\"}, {\"longitude\": -97.2049, \"latitude\": 48.9988, \"country\": \"USA\"}, {\"longitude\": -122.7933, \"latitude\": 49.2843, \"country\": \"Canada\"}, {\"longitude\": -97.1056, \"latitude\": 32.7019, \"country\": \"USA\"}, {\"longitude\": -72.5565, \"latitude\": 46.3327, \"country\": \"Canada\"}, {\"longitude\": -75.1635, \"latitude\": 39.9527, \"country\": \"USA\"}, {\"longitude\": -110.9748, \"latitude\": 32.2229, \"country\": \"USA\"}, {\"longitude\": -67.2781, \"latitude\": 45.189, \"country\": \"USA\"}, {\"longitude\": -83.0466, \"latitude\": 42.3316, \"country\": \"USA\"}, {\"longitude\": -79.7599, \"latitude\": 43.6858, \"country\": \"Canada\"}, {\"longitude\": -84.3201, \"latitude\": 46.5239, \"country\": \"Canada\"}, {\"longitude\": -106.6608, \"latitude\": 52.1318, \"country\": \"Canada\"}, {\"longitude\": -83.0007, \"latitude\": 39.9623, \"country\": \"USA\"}, {\"longitude\": -75.7106, \"latitude\": 45.4284, \"country\": \"Canada\"}, {\"longitude\": -52.7151, \"latitude\": 47.5617, \"country\": \"Canada\"}, {\"longitude\": -113.508, \"latitude\": 53.5354, \"country\": \"Canada\"}, {\"longitude\": -76.6108, \"latitude\": 39.2909, \"country\": \"USA\"}, {\"longitude\": -97.5533, \"latitude\": 48.7531, \"country\": \"USA\"}, {\"longitude\": -66.9843, \"latitude\": 44.8607, \"country\": \"USA\"}, {\"longitude\": -113.8184, \"latitude\": 52.2698, \"country\": \"Canada\"}, {\"longitude\": -113.2966, \"latitude\": 53.5257, \"country\": \"Canada\"}, {\"longitude\": -79.4394, \"latitude\": 43.8801, \"country\": \"Canada\"}, {\"longitude\": -66.9905, \"latitude\": 44.9065, \"country\": \"USA\"}, {\"longitude\": -112.0741, \"latitude\": 33.4484, \"country\": \"USA\"}, {\"longitude\": -130.0437, \"latitude\": 55.9773, \"country\": \"USA\"}, {\"longitude\": -75.7887, \"latitude\": 45.3113, \"country\": \"Canada\"}, {\"longitude\": -80.8431, \"latitude\": 35.2272, \"country\": \"USA\"}, {\"longitude\": -79.6667, \"latitude\": 43.4474, \"country\": \"Canada\"}, {\"longitude\": -121.8906, \"latitude\": 37.3362, \"country\": \"USA\"}, {\"longitude\": -85.7039, \"latitude\": 38.2092, \"country\": \"USA\"}, {\"longitude\": -73.6515, \"latitude\": 45.7081, \"country\": \"Canada\"}, {\"longitude\": -122.4199, \"latitude\": 37.779, \"country\": \"USA\"}, {\"longitude\": -79.4109, \"latitude\": 43.7615, \"country\": \"Canada\"}, {\"longitude\": -67.9245, \"latitude\": 47.1652, \"country\": \"Canada\"}, {\"longitude\": -111.9626, \"latitude\": 48.9971, \"country\": \"USA\"}, {\"longitude\": -79.0359, \"latitude\": 43.1726, \"country\": \"USA\"}, {\"longitude\": -73.6875, \"latitude\": 45.5089, \"country\": \"Canada\"}, {\"longitude\": -111.8315, \"latitude\": 33.4151, \"country\": \"USA\"}, {\"longitude\": -114.0626, \"latitude\": 51.0534, \"country\": \"Canada\"}, {\"longitude\": -73.6289, \"latitude\": 45.468, \"country\": \"Canada\"}, {\"longitude\": -75.9774, \"latitude\": 36.853, \"country\": \"USA\"}, {\"longitude\": -79.3839, \"latitude\": 43.6535, \"country\": \"Canada\"}, {\"longitude\": -87.9225, \"latitude\": 43.035, \"country\": \"USA\"}, {\"longitude\": -72.7218, \"latitude\": 45.399, \"country\": \"Canada\"}, {\"longitude\": -117.1628, \"latitude\": 32.7174, \"country\": \"USA\"}, {\"longitude\": -67.4297, \"latitude\": 45.5634, \"country\": \"USA\"}, {\"longitude\": -83.0466, \"latitude\": 42.3316, \"country\": \"USA\"}, {\"longitude\": -123.1374, \"latitude\": 49.1632, \"country\": \"Canada\"}, {\"longitude\": -119.4983, \"latitude\": 49.8893, \"country\": \"Canada\"}, {\"longitude\": -79.8729, \"latitude\": 43.2561, \"country\": \"Canada\"}, {\"longitude\": -122.5997, \"latitude\": 49.2197, \"country\": \"Canada\"}, {\"longitude\": -80.2632, \"latitude\": 43.1408, \"country\": \"Canada\"}, {\"longitude\": -79.2441, \"latitude\": 43.158, \"country\": \"Canada\"}, {\"longitude\": -97.2089, \"latitude\": 49.0061, \"country\": \"Canada\"}, {\"longitude\": -94.6002, \"latitude\": 48.7124, \"country\": \"USA\"}, {\"longitude\": -102.5496, \"latitude\": 48.9959, \"country\": \"USA\"}, {\"longitude\": -83.0353, \"latitude\": 42.3171, \"country\": \"Canada\"}, {\"longitude\": -71.889, \"latitude\": 45.4033, \"country\": \"Canada\"}, {\"longitude\": -66.6458, \"latitude\": 45.9664, \"country\": \"Canada\"}, {\"longitude\": -71.0692, \"latitude\": 48.406, \"country\": \"Canada\"}, {\"longitude\": -84.3902, \"latitude\": 33.7491, \"country\": \"USA\"}, {\"longitude\": -122.7436, \"latitude\": 48.9881, \"country\": \"USA\"}, {\"longitude\": -102.548, \"latitude\": 49.0014, \"country\": \"Canada\"}, {\"longitude\": -104.6173, \"latitude\": 50.4488, \"country\": \"Canada\"}, {\"longitude\": -122.3301, \"latitude\": 47.6038, \"country\": \"USA\"}, {\"longitude\": -123.114, \"latitude\": 49.2609, \"country\": \"Canada\"}, {\"longitude\": -71.0583, \"latitude\": 42.3603, \"country\": \"USA\"}, {\"longitude\": -134.4197, \"latitude\": 58.3019, \"country\": \"USA\"}, {\"longitude\": -75.4864, \"latitude\": 44.6943, \"country\": \"USA\"}, {\"longitude\": -82.4405, \"latitude\": 42.9816, \"country\": \"USA\"}, {\"longitude\": -71.3998, \"latitude\": 46.8884, \"country\": \"Canada\"}, {\"longitude\": -122.6742, \"latitude\": 45.5202, \"country\": \"USA\"}, {\"longitude\": -67.9353, \"latitude\": 47.1575, \"country\": \"USA\"}, {\"longitude\": -69.265, \"latitude\": 47.5052, \"country\": \"Canada\"}, {\"longitude\": -97.3327, \"latitude\": 32.7532, \"country\": \"USA\"}, {\"longitude\": -123.365, \"latitude\": 48.4283, \"country\": \"Canada\"}, {\"longitude\": -68.3281, \"latitude\": 47.3644, \"country\": \"Canada\"}, {\"longitude\": -78.8784, \"latitude\": 42.8867, \"country\": \"USA\"}, {\"longitude\": -79.5268, \"latitude\": 43.7942, \"country\": \"Canada\"}, {\"longitude\": -79.6457, \"latitude\": 43.5903, \"country\": \"Canada\"}, {\"longitude\": -79.4608, \"latitude\": 46.3092, \"country\": \"Canada\"}, {\"longitude\": -95.9384, \"latitude\": 41.2587, \"country\": \"USA\"}, {\"longitude\": -79.0615, \"latitude\": 43.0844, \"country\": \"USA\"}, {\"longitude\": -79.7967, \"latitude\": 43.3249, \"country\": \"Canada\"}, {\"longitude\": -69.2275, \"latitude\": 47.4562, \"country\": \"USA\"}, {\"longitude\": -123.0833, \"latitude\": 49.0833, \"country\": \"Canada\"}, {\"longitude\": -90.0516, \"latitude\": 35.149, \"country\": \"USA\"}, {\"longitude\": -122.2714, \"latitude\": 37.8045, \"country\": \"USA\"}, {\"longitude\": -119.7848, \"latitude\": 36.7394, \"country\": \"USA\"}, {\"longitude\": -104.8253, \"latitude\": 38.834, \"country\": \"USA\"}, {\"longitude\": -74.0132, \"latitude\": 45.7754, \"country\": \"Canada\"}, {\"longitude\": -79.3377, \"latitude\": 43.8564, \"country\": \"Canada\"}, {\"longitude\": -93.2655, \"latitude\": 44.9773, \"country\": \"USA\"}, {\"longitude\": -95.3677, \"latitude\": 29.7589, \"country\": \"USA\"}, {\"longitude\": -80.3123, \"latitude\": 43.3601, \"country\": \"Canada\"}, {\"longitude\": -79.1153, \"latitude\": 43.101, \"country\": \"Canada\"}, {\"longitude\": -79.7599, \"latitude\": 43.6858, \"country\": \"Canada\"}, {\"longitude\": -75.5192, \"latitude\": 44.7184, \"country\": \"Canada\"}, {\"longitude\": -68.6034, \"latitude\": 47.2527, \"country\": \"Canada\"}, {\"longitude\": -83.0353, \"latitude\": 42.3171, \"country\": \"Canada\"}, {\"longitude\": -73.7344, \"latitude\": 45.6056, \"country\": \"Canada\"}, {\"longitude\": -72.0968, \"latitude\": 45.0072, \"country\": \"Canada\"}, {\"longitude\": -67.5735, \"latitude\": 46.1503, \"country\": \"Canada\"}, {\"longitude\": -80.4944, \"latitude\": 43.4532, \"country\": \"Canada\"}, {\"longitude\": -79.1153, \"latitude\": 43.101, \"country\": \"Canada\"}, {\"longitude\": -110.679, \"latitude\": 50.043, \"country\": \"Canada\"}, {\"longitude\": -78.3199, \"latitude\": 44.3048, \"country\": \"Canada\"}, {\"longitude\": -79.2506, \"latitude\": 42.9931, \"country\": \"Canada\"}, {\"longitude\": -96.7969, \"latitude\": 32.7763, \"country\": \"USA\"}, {\"longitude\": -122.3295, \"latitude\": 49.0521, \"country\": \"Canada\"}, {\"longitude\": -123.078, \"latitude\": 48.9854, \"country\": \"USA\"}, {\"longitude\": -97.5171, \"latitude\": 35.473, \"country\": \"USA\"}, {\"longitude\": -104.9849, \"latitude\": 39.7392, \"country\": \"USA\"}, {\"longitude\": -94.5781, \"latitude\": 39.1001, \"country\": \"USA\"}, {\"longitude\": -122.9109, \"latitude\": 49.2068, \"country\": \"Canada\"}, {\"longitude\": -89.2598, \"latitude\": 48.4064, \"country\": \"Canada\"}, {\"longitude\": -82.4584, \"latitude\": 27.9478, \"country\": \"USA\"}, {\"longitude\": -71.1473, \"latitude\": 48.382, \"country\": \"Canada\"}, {\"longitude\": -71.1753, \"latitude\": 46.791, \"country\": \"Canada\"}, {\"longitude\": -73.6104, \"latitude\": 45.4972, \"country\": \"Canada\"}, {\"longitude\": -79.8828, \"latitude\": 43.5137, \"country\": \"Canada\"}, {\"longitude\": -118.2428, \"latitude\": 34.0537, \"country\": \"USA\"}, {\"longitude\": -118.1916, \"latitude\": 33.769, \"country\": \"USA\"}, {\"longitude\": -86.1584, \"latitude\": 39.7683, \"country\": \"USA\"}, {\"longitude\": -72.9406, \"latitude\": 45.6275, \"country\": \"Canada\"}, {\"longitude\": -75.6903, \"latitude\": 45.4211, \"country\": \"Canada\"}, {\"longitude\": -76.3019, \"latitude\": 44.211, \"country\": \"Canada\"}, {\"longitude\": -115.1485, \"latitude\": 36.1673, \"country\": \"USA\"}, {\"longitude\": -122.8491, \"latitude\": 49.1913, \"country\": \"Canada\"}, {\"longitude\": -67.4253, \"latitude\": 45.5672, \"country\": \"Canada\"}, {\"longitude\": -122.8491, \"latitude\": 49.1913, \"country\": \"Canada\"}, {\"longitude\": -76.3305, \"latitude\": 44.1255, \"country\": \"USA\"}, {\"longitude\": -74.7287, \"latitude\": 45.0184, \"country\": \"Canada\"}, {\"longitude\": -121.4944, \"latitude\": 38.5816, \"country\": \"USA\"}, {\"longitude\": -79.5656, \"latitude\": 43.6436, \"country\": \"Canada\"}, {\"longitude\": -66.9195, \"latitude\": 44.8938, \"country\": \"Canada\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "\n",
    "cities_viz = alt.Chart(cities_train_df).mark_circle(size=20, opacity=0.6).encode(\n",
    "    alt.X('longitude:Q', scale=alt.Scale(domain=[-140, -40])),\n",
    "    alt.Y('latitude:Q', scale=alt.Scale(domain=[20, 60])),\n",
    "    alt.Color('country:N', scale=alt.Scale(domain=['Canada', 'USA'],\n",
    "                                           range=['red', 'blue']))\n",
    ")\n",
    "cities_viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the housing training dataset we saw? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14305</th>\n",
       "      <td>3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2170</td>\n",
       "      <td>2738</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1550</td>\n",
       "      <td>620</td>\n",
       "      <td>1930</td>\n",
       "      <td>0</td>\n",
       "      <td>98109</td>\n",
       "      <td>47.6389</td>\n",
       "      <td>-122.349</td>\n",
       "      <td>1170</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19844</th>\n",
       "      <td>4</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3550</td>\n",
       "      <td>9400</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3550</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98059</td>\n",
       "      <td>47.4827</td>\n",
       "      <td>-122.131</td>\n",
       "      <td>3550</td>\n",
       "      <td>9421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>3</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1210</td>\n",
       "      <td>1173</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>210</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>98133</td>\n",
       "      <td>47.7114</td>\n",
       "      <td>-122.356</td>\n",
       "      <td>1650</td>\n",
       "      <td>1493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11926</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2370</td>\n",
       "      <td>7875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2370</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98065</td>\n",
       "      <td>47.5427</td>\n",
       "      <td>-121.863</td>\n",
       "      <td>2660</td>\n",
       "      <td>7752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13873</th>\n",
       "      <td>5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2250</td>\n",
       "      <td>8970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1500</td>\n",
       "      <td>750</td>\n",
       "      <td>1966</td>\n",
       "      <td>0</td>\n",
       "      <td>98034</td>\n",
       "      <td>47.7217</td>\n",
       "      <td>-122.188</td>\n",
       "      <td>1940</td>\n",
       "      <td>8710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15377</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3440</td>\n",
       "      <td>14554</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2170</td>\n",
       "      <td>1270</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>98155</td>\n",
       "      <td>47.7364</td>\n",
       "      <td>-122.286</td>\n",
       "      <td>3170</td>\n",
       "      <td>11810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21602</th>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1500</td>\n",
       "      <td>11968</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98010</td>\n",
       "      <td>47.3095</td>\n",
       "      <td>-122.002</td>\n",
       "      <td>1320</td>\n",
       "      <td>11303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17730</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1640</td>\n",
       "      <td>5200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1040</td>\n",
       "      <td>600</td>\n",
       "      <td>1937</td>\n",
       "      <td>0</td>\n",
       "      <td>98199</td>\n",
       "      <td>47.6426</td>\n",
       "      <td>-122.403</td>\n",
       "      <td>1780</td>\n",
       "      <td>5040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15725</th>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1560</td>\n",
       "      <td>1466</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1560</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6604</td>\n",
       "      <td>-122.352</td>\n",
       "      <td>1530</td>\n",
       "      <td>2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19966</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2300</td>\n",
       "      <td>3825</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2300</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>98042</td>\n",
       "      <td>47.3594</td>\n",
       "      <td>-122.082</td>\n",
       "      <td>2110</td>\n",
       "      <td>3825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17290 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
       "14305         3       2.75         2170      2738     1.5           0     0   \n",
       "19844         4       2.75         3550      9400     2.0           0     0   \n",
       "2686          3       3.25         1210      1173     2.0           0     0   \n",
       "11926         3       2.50         2370      7875     2.0           0     0   \n",
       "13873         5       1.75         2250      8970     1.0           0     0   \n",
       "...         ...        ...          ...       ...     ...         ...   ...   \n",
       "15377         4       2.50         3440     14554     2.0           1     4   \n",
       "21602         3       1.75         1500     11968     1.0           0     0   \n",
       "17730         2       1.00         1640      5200     1.0           0     0   \n",
       "15725         3       3.00         1560      1466     3.0           0     0   \n",
       "19966         4       2.50         2300      3825     2.0           0     0   \n",
       "\n",
       "       condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
       "14305          4      9        1550            620      1930             0   \n",
       "19844          3      9        3550              0      2014             0   \n",
       "2686           3      8        1000            210      2002             0   \n",
       "11926          3      9        2370              0      2003             0   \n",
       "13873          4      7        1500            750      1966             0   \n",
       "...          ...    ...         ...            ...       ...           ...   \n",
       "15377          3      8        2170           1270      2012             0   \n",
       "21602          3      6        1500              0      2014             0   \n",
       "17730          4      7        1040            600      1937             0   \n",
       "15725          3      8        1560              0      2006             0   \n",
       "19966          3      7        2300              0      2012             0   \n",
       "\n",
       "       zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "14305    98109  47.6389 -122.349           1170        1062  \n",
       "19844    98059  47.4827 -122.131           3550        9421  \n",
       "2686     98133  47.7114 -122.356           1650        1493  \n",
       "11926    98065  47.5427 -121.863           2660        7752  \n",
       "13873    98034  47.7217 -122.188           1940        8710  \n",
       "...        ...      ...      ...            ...         ...  \n",
       "15377    98155  47.7364 -122.286           3170       11810  \n",
       "21602    98010  47.3095 -122.002           1320       11303  \n",
       "17730    98199  47.6426 -122.403           1780        5040  \n",
       "15725    98103  47.6604 -122.352           1530        2975  \n",
       "19966    98042  47.3594 -122.082           2110        3825  \n",
       "\n",
       "[17290 rows x 18 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df = pd.read_csv(\"data/kc_house_data.csv\")\n",
    "house_df = house_df.drop(columns=[\"id\", \"date\"])\n",
    "\n",
    "X = house_df.drop(columns=[\"price\"])\n",
    "y = house_df[\"price\"]\n",
    "\n",
    "\n",
    "house_X_train, house_X_test, house_y_train, house_y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "house_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice a problem?!\n",
    "\n",
    "We can only visualize data when the dimensions <= 3. \n",
    "\n",
    "BUT, in ML, we usually deal with high-dimensional problems where examples are hard to visualize.\n",
    "High dimensional = 100s or 1000s of dimensions (roughly speaking, it depends on the specific problem at hands and the density of the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Vectors\n",
    "\n",
    "**Feature vector**: a vector composed of feature values associated with an example.\n",
    "\n",
    "\n",
    "An example feature vector from the cities dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-76.4813,  44.2307])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_train_df.drop(columns=[\"country\"]).iloc[0].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example feature vector from the housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.00000e+00,  2.75000e+00,  2.17000e+03,  2.73800e+03,\n",
       "        1.50000e+00,  0.00000e+00,  0.00000e+00,  4.00000e+00,\n",
       "        9.00000e+00,  1.55000e+03,  6.20000e+02,  1.93000e+03,\n",
       "        0.00000e+00,  9.81090e+04,  4.76389e+01, -1.22349e+02,\n",
       "        1.17000e+03,  1.06200e+03])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_X_train.iloc[0].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance\n",
    "\n",
    "We have our feature vectors, one for each observation, but how we calculate the similarity between these feature vectors? \n",
    "\n",
    "One way to calculate the similarity between two points in high-dimensional space is by calculating the distance between them. \n",
    "\n",
    "So, if the distance is higher, that means that the points are less similar and when the distance is smaller, that means that the points are more similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean distance\n",
    "\n",
    "There are different ways to calculate distance but we are going to focus on Euclidean distance. \n",
    "\n",
    "**Euclidean distance:** Euclidean distance is a measure of the true straight line distance between two points in Euclidean space. ([source](https://hlab.stanford.edu/brian/euclidean_distance_in.html))\n",
    "\n",
    "\n",
    "The Euclidean distance between vectors \n",
    "\n",
    "$$u = <u_1, u_2, \\dots, u_n>$$ and \n",
    "\n",
    "$$v = <v_1, v_2, \\dots, v_n>$$ is defined as: \n",
    "\n",
    "<br>\n",
    "\n",
    "$distance(u, v) = \\sqrt{\\sum_{i =1}^{n} (u_i - v_i)^2}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because that equation can look a bit intimidating, let's use it in an example, particularly our Canadian/US cities data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Euclidean distance \"by hand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-76.4813</td>\n",
       "      <td>44.2307</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-81.2496</td>\n",
       "      <td>42.9837</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-66.0580</td>\n",
       "      <td>45.2788</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-73.2533</td>\n",
       "      <td>45.3057</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-67.9245</td>\n",
       "      <td>47.1652</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-76.3305</td>\n",
       "      <td>44.1255</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-74.7287</td>\n",
       "      <td>45.0184</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-121.4944</td>\n",
       "      <td>38.5816</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>-79.5656</td>\n",
       "      <td>43.6436</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-66.9195</td>\n",
       "      <td>44.8938</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     longitude  latitude country\n",
       "160   -76.4813   44.2307  Canada\n",
       "127   -81.2496   42.9837  Canada\n",
       "169   -66.0580   45.2788  Canada\n",
       "188   -73.2533   45.3057  Canada\n",
       "187   -67.9245   47.1652  Canada\n",
       "..         ...       ...     ...\n",
       "17    -76.3305   44.1255     USA\n",
       "98    -74.7287   45.0184  Canada\n",
       "66   -121.4944   38.5816     USA\n",
       "126   -79.5656   43.6436  Canada\n",
       "109   -66.9195   44.8938  Canada\n",
       "\n",
       "[167 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take 2 points (two feature vectors) from the cities dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-66.9843</td>\n",
       "      <td>44.8607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-80.2632</td>\n",
       "      <td>43.1408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     longitude  latitude\n",
       "30    -66.9843   44.8607\n",
       "171   -80.2632   43.1408"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_cities = cities_df.sample(2, random_state=42).drop(columns=[\"country\"])\n",
    "two_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two sampled points are shown as black circles below.\n",
    "\n",
    "Our goal is to find how similar these two points are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-2f747c3788eb42aa8a07647c88c69432\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2f747c3788eb42aa8a07647c88c69432\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2f747c3788eb42aa8a07647c88c69432\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-66158384001fb6a73b6445c49f67d5ce\"}, \"mark\": {\"type\": \"circle\", \"opacity\": 0.6, \"size\": 20}, \"encoding\": {\"color\": {\"field\": \"country\", \"scale\": {\"domain\": [\"Canada\", \"USA\"], \"range\": [\"red\", \"blue\"]}, \"type\": \"nominal\"}, \"x\": {\"field\": \"longitude\", \"scale\": {\"domain\": [-140, -40]}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"latitude\", \"scale\": {\"domain\": [20, 60]}, \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-7c144ccbe61beb3e29b101c8ca59a046\"}, \"mark\": {\"type\": \"circle\", \"color\": \"black\", \"size\": 130}, \"encoding\": {\"x\": {\"field\": \"longitude\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"latitude\", \"type\": \"quantitative\"}}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-66158384001fb6a73b6445c49f67d5ce\": [{\"longitude\": -76.4813, \"latitude\": 44.2307, \"country\": \"Canada\"}, {\"longitude\": -81.2496, \"latitude\": 42.9837, \"country\": \"Canada\"}, {\"longitude\": -66.058, \"latitude\": 45.2788, \"country\": \"Canada\"}, {\"longitude\": -73.2533, \"latitude\": 45.3057, \"country\": \"Canada\"}, {\"longitude\": -67.9245, \"latitude\": 47.1652, \"country\": \"Canada\"}, {\"longitude\": -120.3394, \"latitude\": 50.6758, \"country\": \"Canada\"}, {\"longitude\": -106.651, \"latitude\": 35.0841, \"country\": \"USA\"}, {\"longitude\": -79.6902, \"latitude\": 44.3893, \"country\": \"Canada\"}, {\"longitude\": -84.3201, \"latitude\": 46.5239, \"country\": \"Canada\"}, {\"longitude\": -98.4951, \"latitude\": 29.4246, \"country\": \"USA\"}, {\"longitude\": -77.0366, \"latitude\": 38.895, \"country\": \"USA\"}, {\"longitude\": -93.3968, \"latitude\": 48.6114, \"country\": \"Canada\"}, {\"longitude\": -67.2799, \"latitude\": 45.2004, \"country\": \"Canada\"}, {\"longitude\": -122.8565, \"latitude\": 49.3144, \"country\": \"Canada\"}, {\"longitude\": -63.572, \"latitude\": 44.68, \"country\": \"Canada\"}, {\"longitude\": -68.3219, \"latitude\": 47.3556, \"country\": \"USA\"}, {\"longitude\": -97.1385, \"latitude\": 49.8955, \"country\": \"Canada\"}, {\"longitude\": -122.3295, \"latitude\": 49.0521, \"country\": \"Canada\"}, {\"longitude\": -87.6244, \"latitude\": 41.8756, \"country\": \"USA\"}, {\"longitude\": -68.5897, \"latitude\": 47.2587, \"country\": \"USA\"}, {\"longitude\": -73.4467, \"latitude\": 45.5172, \"country\": \"Canada\"}, {\"longitude\": -63.5859, \"latitude\": 44.6486, \"country\": \"Canada\"}, {\"longitude\": -97.7437, \"latitude\": 30.2711, \"country\": \"USA\"}, {\"longitude\": -79.0247, \"latitude\": 43.8504, \"country\": \"Canada\"}, {\"longitude\": -111.9639, \"latitude\": 49.0017, \"country\": \"Canada\"}, {\"longitude\": -129.9912, \"latitude\": 55.9383, \"country\": \"Canada\"}, {\"longitude\": -78.9186, \"latitude\": 42.9131, \"country\": \"Canada\"}, {\"longitude\": -71.7985, \"latitude\": 45.0126, \"country\": \"Canada\"}, {\"longitude\": -95.9929, \"latitude\": 36.1557, \"country\": \"USA\"}, {\"longitude\": -123.0833, \"latitude\": 49.0167, \"country\": \"Canada\"}, {\"longitude\": -94.5648, \"latitude\": 48.7227, \"country\": \"Canada\"}, {\"longitude\": -118.7148, \"latitude\": 50.4165, \"country\": \"Canada\"}, {\"longitude\": -97.2049, \"latitude\": 48.9988, \"country\": \"USA\"}, {\"longitude\": -122.7933, \"latitude\": 49.2843, \"country\": \"Canada\"}, {\"longitude\": -97.1056, \"latitude\": 32.7019, \"country\": \"USA\"}, {\"longitude\": -72.5565, \"latitude\": 46.3327, \"country\": \"Canada\"}, {\"longitude\": -75.1635, \"latitude\": 39.9527, \"country\": \"USA\"}, {\"longitude\": -110.9748, \"latitude\": 32.2229, \"country\": \"USA\"}, {\"longitude\": -67.2781, \"latitude\": 45.189, \"country\": \"USA\"}, {\"longitude\": -83.0466, \"latitude\": 42.3316, \"country\": \"USA\"}, {\"longitude\": -79.7599, \"latitude\": 43.6858, \"country\": \"Canada\"}, {\"longitude\": -84.3201, \"latitude\": 46.5239, \"country\": \"Canada\"}, {\"longitude\": -106.6608, \"latitude\": 52.1318, \"country\": \"Canada\"}, {\"longitude\": -83.0007, \"latitude\": 39.9623, \"country\": \"USA\"}, {\"longitude\": -75.7106, \"latitude\": 45.4284, \"country\": \"Canada\"}, {\"longitude\": -52.7151, \"latitude\": 47.5617, \"country\": \"Canada\"}, {\"longitude\": -113.508, \"latitude\": 53.5354, \"country\": \"Canada\"}, {\"longitude\": -76.6108, \"latitude\": 39.2909, \"country\": \"USA\"}, {\"longitude\": -97.5533, \"latitude\": 48.7531, \"country\": \"USA\"}, {\"longitude\": -66.9843, \"latitude\": 44.8607, \"country\": \"USA\"}, {\"longitude\": -113.8184, \"latitude\": 52.2698, \"country\": \"Canada\"}, {\"longitude\": -113.2966, \"latitude\": 53.5257, \"country\": \"Canada\"}, {\"longitude\": -79.4394, \"latitude\": 43.8801, \"country\": \"Canada\"}, {\"longitude\": -66.9905, \"latitude\": 44.9065, \"country\": \"USA\"}, {\"longitude\": -112.0741, \"latitude\": 33.4484, \"country\": \"USA\"}, {\"longitude\": -130.0437, \"latitude\": 55.9773, \"country\": \"USA\"}, {\"longitude\": -75.7887, \"latitude\": 45.3113, \"country\": \"Canada\"}, {\"longitude\": -80.8431, \"latitude\": 35.2272, \"country\": \"USA\"}, {\"longitude\": -79.6667, \"latitude\": 43.4474, \"country\": \"Canada\"}, {\"longitude\": -121.8906, \"latitude\": 37.3362, \"country\": \"USA\"}, {\"longitude\": -85.7039, \"latitude\": 38.2092, \"country\": \"USA\"}, {\"longitude\": -73.6515, \"latitude\": 45.7081, \"country\": \"Canada\"}, {\"longitude\": -122.4199, \"latitude\": 37.779, \"country\": \"USA\"}, {\"longitude\": -79.4109, \"latitude\": 43.7615, \"country\": \"Canada\"}, {\"longitude\": -67.9245, \"latitude\": 47.1652, \"country\": \"Canada\"}, {\"longitude\": -111.9626, \"latitude\": 48.9971, \"country\": \"USA\"}, {\"longitude\": -79.0359, \"latitude\": 43.1726, \"country\": \"USA\"}, {\"longitude\": -73.6875, \"latitude\": 45.5089, \"country\": \"Canada\"}, {\"longitude\": -111.8315, \"latitude\": 33.4151, \"country\": \"USA\"}, {\"longitude\": -114.0626, \"latitude\": 51.0534, \"country\": \"Canada\"}, {\"longitude\": -73.6289, \"latitude\": 45.468, \"country\": \"Canada\"}, {\"longitude\": -75.9774, \"latitude\": 36.853, \"country\": \"USA\"}, {\"longitude\": -79.3839, \"latitude\": 43.6535, \"country\": \"Canada\"}, {\"longitude\": -87.9225, \"latitude\": 43.035, \"country\": \"USA\"}, {\"longitude\": -72.7218, \"latitude\": 45.399, \"country\": \"Canada\"}, {\"longitude\": -117.1628, \"latitude\": 32.7174, \"country\": \"USA\"}, {\"longitude\": -67.4297, \"latitude\": 45.5634, \"country\": \"USA\"}, {\"longitude\": -83.0466, \"latitude\": 42.3316, \"country\": \"USA\"}, {\"longitude\": -123.1374, \"latitude\": 49.1632, \"country\": \"Canada\"}, {\"longitude\": -119.4983, \"latitude\": 49.8893, \"country\": \"Canada\"}, {\"longitude\": -79.8729, \"latitude\": 43.2561, \"country\": \"Canada\"}, {\"longitude\": -122.5997, \"latitude\": 49.2197, \"country\": \"Canada\"}, {\"longitude\": -80.2632, \"latitude\": 43.1408, \"country\": \"Canada\"}, {\"longitude\": -79.2441, \"latitude\": 43.158, \"country\": \"Canada\"}, {\"longitude\": -97.2089, \"latitude\": 49.0061, \"country\": \"Canada\"}, {\"longitude\": -94.6002, \"latitude\": 48.7124, \"country\": \"USA\"}, {\"longitude\": -102.5496, \"latitude\": 48.9959, \"country\": \"USA\"}, {\"longitude\": -83.0353, \"latitude\": 42.3171, \"country\": \"Canada\"}, {\"longitude\": -71.889, \"latitude\": 45.4033, \"country\": \"Canada\"}, {\"longitude\": -66.6458, \"latitude\": 45.9664, \"country\": \"Canada\"}, {\"longitude\": -71.0692, \"latitude\": 48.406, \"country\": \"Canada\"}, {\"longitude\": -84.3902, \"latitude\": 33.7491, \"country\": \"USA\"}, {\"longitude\": -122.7436, \"latitude\": 48.9881, \"country\": \"USA\"}, {\"longitude\": -102.548, \"latitude\": 49.0014, \"country\": \"Canada\"}, {\"longitude\": -104.6173, \"latitude\": 50.4488, \"country\": \"Canada\"}, {\"longitude\": -122.3301, \"latitude\": 47.6038, \"country\": \"USA\"}, {\"longitude\": -123.114, \"latitude\": 49.2609, \"country\": \"Canada\"}, {\"longitude\": -71.0583, \"latitude\": 42.3603, \"country\": \"USA\"}, {\"longitude\": -134.4197, \"latitude\": 58.3019, \"country\": \"USA\"}, {\"longitude\": -75.4864, \"latitude\": 44.6943, \"country\": \"USA\"}, {\"longitude\": -82.4405, \"latitude\": 42.9816, \"country\": \"USA\"}, {\"longitude\": -71.3998, \"latitude\": 46.8884, \"country\": \"Canada\"}, {\"longitude\": -122.6742, \"latitude\": 45.5202, \"country\": \"USA\"}, {\"longitude\": -67.9353, \"latitude\": 47.1575, \"country\": \"USA\"}, {\"longitude\": -69.265, \"latitude\": 47.5052, \"country\": \"Canada\"}, {\"longitude\": -97.3327, \"latitude\": 32.7532, \"country\": \"USA\"}, {\"longitude\": -123.365, \"latitude\": 48.4283, \"country\": \"Canada\"}, {\"longitude\": -68.3281, \"latitude\": 47.3644, \"country\": \"Canada\"}, {\"longitude\": -78.8784, \"latitude\": 42.8867, \"country\": \"USA\"}, {\"longitude\": -79.5268, \"latitude\": 43.7942, \"country\": \"Canada\"}, {\"longitude\": -79.6457, \"latitude\": 43.5903, \"country\": \"Canada\"}, {\"longitude\": -79.4608, \"latitude\": 46.3092, \"country\": \"Canada\"}, {\"longitude\": -95.9384, \"latitude\": 41.2587, \"country\": \"USA\"}, {\"longitude\": -79.0615, \"latitude\": 43.0844, \"country\": \"USA\"}, {\"longitude\": -79.7967, \"latitude\": 43.3249, \"country\": \"Canada\"}, {\"longitude\": -69.2275, \"latitude\": 47.4562, \"country\": \"USA\"}, {\"longitude\": -123.0833, \"latitude\": 49.0833, \"country\": \"Canada\"}, {\"longitude\": -90.0516, \"latitude\": 35.149, \"country\": \"USA\"}, {\"longitude\": -122.2714, \"latitude\": 37.8045, \"country\": \"USA\"}, {\"longitude\": -119.7848, \"latitude\": 36.7394, \"country\": \"USA\"}, {\"longitude\": -104.8253, \"latitude\": 38.834, \"country\": \"USA\"}, {\"longitude\": -74.0132, \"latitude\": 45.7754, \"country\": \"Canada\"}, {\"longitude\": -79.3377, \"latitude\": 43.8564, \"country\": \"Canada\"}, {\"longitude\": -93.2655, \"latitude\": 44.9773, \"country\": \"USA\"}, {\"longitude\": -95.3677, \"latitude\": 29.7589, \"country\": \"USA\"}, {\"longitude\": -80.3123, \"latitude\": 43.3601, \"country\": \"Canada\"}, {\"longitude\": -79.1153, \"latitude\": 43.101, \"country\": \"Canada\"}, {\"longitude\": -79.7599, \"latitude\": 43.6858, \"country\": \"Canada\"}, {\"longitude\": -75.5192, \"latitude\": 44.7184, \"country\": \"Canada\"}, {\"longitude\": -68.6034, \"latitude\": 47.2527, \"country\": \"Canada\"}, {\"longitude\": -83.0353, \"latitude\": 42.3171, \"country\": \"Canada\"}, {\"longitude\": -73.7344, \"latitude\": 45.6056, \"country\": \"Canada\"}, {\"longitude\": -72.0968, \"latitude\": 45.0072, \"country\": \"Canada\"}, {\"longitude\": -67.5735, \"latitude\": 46.1503, \"country\": \"Canada\"}, {\"longitude\": -80.4944, \"latitude\": 43.4532, \"country\": \"Canada\"}, {\"longitude\": -79.1153, \"latitude\": 43.101, \"country\": \"Canada\"}, {\"longitude\": -110.679, \"latitude\": 50.043, \"country\": \"Canada\"}, {\"longitude\": -78.3199, \"latitude\": 44.3048, \"country\": \"Canada\"}, {\"longitude\": -79.2506, \"latitude\": 42.9931, \"country\": \"Canada\"}, {\"longitude\": -96.7969, \"latitude\": 32.7763, \"country\": \"USA\"}, {\"longitude\": -122.3295, \"latitude\": 49.0521, \"country\": \"Canada\"}, {\"longitude\": -123.078, \"latitude\": 48.9854, \"country\": \"USA\"}, {\"longitude\": -97.5171, \"latitude\": 35.473, \"country\": \"USA\"}, {\"longitude\": -104.9849, \"latitude\": 39.7392, \"country\": \"USA\"}, {\"longitude\": -94.5781, \"latitude\": 39.1001, \"country\": \"USA\"}, {\"longitude\": -122.9109, \"latitude\": 49.2068, \"country\": \"Canada\"}, {\"longitude\": -89.2598, \"latitude\": 48.4064, \"country\": \"Canada\"}, {\"longitude\": -82.4584, \"latitude\": 27.9478, \"country\": \"USA\"}, {\"longitude\": -71.1473, \"latitude\": 48.382, \"country\": \"Canada\"}, {\"longitude\": -71.1753, \"latitude\": 46.791, \"country\": \"Canada\"}, {\"longitude\": -73.6104, \"latitude\": 45.4972, \"country\": \"Canada\"}, {\"longitude\": -79.8828, \"latitude\": 43.5137, \"country\": \"Canada\"}, {\"longitude\": -118.2428, \"latitude\": 34.0537, \"country\": \"USA\"}, {\"longitude\": -118.1916, \"latitude\": 33.769, \"country\": \"USA\"}, {\"longitude\": -86.1584, \"latitude\": 39.7683, \"country\": \"USA\"}, {\"longitude\": -72.9406, \"latitude\": 45.6275, \"country\": \"Canada\"}, {\"longitude\": -75.6903, \"latitude\": 45.4211, \"country\": \"Canada\"}, {\"longitude\": -76.3019, \"latitude\": 44.211, \"country\": \"Canada\"}, {\"longitude\": -115.1485, \"latitude\": 36.1673, \"country\": \"USA\"}, {\"longitude\": -122.8491, \"latitude\": 49.1913, \"country\": \"Canada\"}, {\"longitude\": -67.4253, \"latitude\": 45.5672, \"country\": \"Canada\"}, {\"longitude\": -122.8491, \"latitude\": 49.1913, \"country\": \"Canada\"}, {\"longitude\": -76.3305, \"latitude\": 44.1255, \"country\": \"USA\"}, {\"longitude\": -74.7287, \"latitude\": 45.0184, \"country\": \"Canada\"}, {\"longitude\": -121.4944, \"latitude\": 38.5816, \"country\": \"USA\"}, {\"longitude\": -79.5656, \"latitude\": 43.6436, \"country\": \"Canada\"}, {\"longitude\": -66.9195, \"latitude\": 44.8938, \"country\": \"Canada\"}], \"data-7c144ccbe61beb3e29b101c8ca59a046\": [{\"longitude\": -66.9843, \"latitude\": 44.8607}, {\"longitude\": -80.2632, \"latitude\": 43.1408}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_viz + alt.Chart(two_cities).mark_circle(size=130, color='black').encode(\n",
    "    alt.X('longitude'),\n",
    "    alt.Y('latitude')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we subtract these two cities. We are subtracting the city at index 0 from the city at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude   -13.2789\n",
       "latitude     -1.7199\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_cities.iloc[1] - two_cities.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we square the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude    176.329185\n",
       "latitude       2.958056\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(two_cities.iloc[1] - two_cities.iloc[0])**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we sum up the squared differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179.28724121999983"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((two_cities.iloc[1] - two_cities.iloc[0])**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then take the square root of the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.389818565611703"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To the power of 0.5 is the same as square root\n",
    "((two_cities.iloc[1] - two_cities.iloc[0])**2).sum()**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end with a value of 13.3898 which is the distance between the two cities in feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Euclidean distance  with `sklearn`\n",
    "\n",
    "That's more work than we really have time for and since `sklearn` knows we are very busy people, they have a function that does this for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , 13.38981857],\n",
       "       [13.38981857,  0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "\n",
    "euclidean_distances(two_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call this function on our two cities data, it outputs this matrix with four values.\n",
    "\n",
    "- Our first value is the distance between city 0 and itself. \n",
    "- Our second value is the distance between city 0 and city1. \n",
    "- Our third value is the distance between city 1and city 0.\n",
    "- Our fourth value is the distance between city 1 and itself.\n",
    "\n",
    "As we can see, the distances are symmetric. If we calculate the distance between city 0 and city1, it’s going to have the same value as if we calculated the distance between city 1 and city 0.\n",
    "\n",
    "This isn’t always the case if we use a different metric to calculate distances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Nearest Neighbour \n",
    "\n",
    "Now that we know how to calculate the distance between two points,\n",
    "we can use this metric as a definition for what \"most similar\" means in our cities data.\n",
    "In this case,\n",
    "we would say that it is the cities that have the shortest distance between them.\n",
    "These are often called the \"Nearest Neighbors\".\n",
    "\n",
    "Let's find the closest cities to City 0 from our `cities_train_df` dataframe. \n",
    "\n",
    "Using `euclidean_distances` on the entire dataset will calculate the distances from all the cities to all other cities in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  4.92866046, 10.47586257, ..., 45.36619339,\n",
       "         3.13968038,  9.58476504],\n",
       "       [ 4.92866046,  0.        , 15.36399019, ..., 40.48484175,\n",
       "         1.80868018, 14.45684087],\n",
       "       [10.47586257, 15.36399019,  0.        , ..., 55.83947468,\n",
       "        13.60621684,  0.94361393],\n",
       "       ...,\n",
       "       [45.36619339, 40.48484175, 55.83947468, ...,  0.        ,\n",
       "        42.23325838, 54.93872568],\n",
       "       [ 3.13968038,  1.80868018, 13.60621684, ..., 42.23325838,\n",
       "         0.        , 12.70774745],\n",
       "       [ 9.58476504, 14.45684087,  0.94361393, ..., 54.93872568,\n",
       "        12.70774745,  0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = euclidean_distances(cities_train_df[[\"latitude\", \"longitude\"]])\n",
    "dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is going to be of shape 167 by 167 as this was the number of examples in our training portion.\n",
    "\n",
    "Each row here gives us the distance of that particular city to all other cities in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 167)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.928660</td>\n",
       "      <td>10.475863</td>\n",
       "      <td>3.402295</td>\n",
       "      <td>9.046000</td>\n",
       "      <td>44.329135</td>\n",
       "      <td>31.525721</td>\n",
       "      <td>3.212817</td>\n",
       "      <td>8.167347</td>\n",
       "      <td>26.529757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180478</td>\n",
       "      <td>39.498997</td>\n",
       "      <td>46.632397</td>\n",
       "      <td>9.154090</td>\n",
       "      <td>46.632397</td>\n",
       "      <td>0.183869</td>\n",
       "      <td>1.921478</td>\n",
       "      <td>45.366193</td>\n",
       "      <td>3.139680</td>\n",
       "      <td>9.584765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.928660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.363990</td>\n",
       "      <td>8.326614</td>\n",
       "      <td>13.965788</td>\n",
       "      <td>39.839439</td>\n",
       "      <td>26.601406</td>\n",
       "      <td>2.099390</td>\n",
       "      <td>4.686255</td>\n",
       "      <td>21.937558</td>\n",
       "      <td>...</td>\n",
       "      <td>5.097647</td>\n",
       "      <td>34.577431</td>\n",
       "      <td>42.060108</td>\n",
       "      <td>14.063632</td>\n",
       "      <td>42.060108</td>\n",
       "      <td>5.049876</td>\n",
       "      <td>6.830969</td>\n",
       "      <td>40.484842</td>\n",
       "      <td>1.808680</td>\n",
       "      <td>14.456841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.475863</td>\n",
       "      <td>15.363990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.195350</td>\n",
       "      <td>2.653738</td>\n",
       "      <td>54.549042</td>\n",
       "      <td>41.853597</td>\n",
       "      <td>13.661189</td>\n",
       "      <td>18.304496</td>\n",
       "      <td>36.104309</td>\n",
       "      <td>...</td>\n",
       "      <td>10.299402</td>\n",
       "      <td>49.928916</td>\n",
       "      <td>56.925712</td>\n",
       "      <td>1.397385</td>\n",
       "      <td>56.925712</td>\n",
       "      <td>10.337038</td>\n",
       "      <td>8.674609</td>\n",
       "      <td>55.839475</td>\n",
       "      <td>13.606217</td>\n",
       "      <td>0.943614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.402295</td>\n",
       "      <td>8.326614</td>\n",
       "      <td>7.195350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.643921</td>\n",
       "      <td>47.391337</td>\n",
       "      <td>34.926888</td>\n",
       "      <td>6.501805</td>\n",
       "      <td>11.133646</td>\n",
       "      <td>29.822103</td>\n",
       "      <td>...</td>\n",
       "      <td>3.239187</td>\n",
       "      <td>42.880277</td>\n",
       "      <td>49.747776</td>\n",
       "      <td>5.833864</td>\n",
       "      <td>49.747776</td>\n",
       "      <td>3.295760</td>\n",
       "      <td>1.503112</td>\n",
       "      <td>48.707466</td>\n",
       "      <td>6.527458</td>\n",
       "      <td>6.347179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.046000</td>\n",
       "      <td>13.965788</td>\n",
       "      <td>2.653738</td>\n",
       "      <td>5.643921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.532333</td>\n",
       "      <td>40.567164</td>\n",
       "      <td>12.088727</td>\n",
       "      <td>16.408137</td>\n",
       "      <td>35.345303</td>\n",
       "      <td>...</td>\n",
       "      <td>8.883025</td>\n",
       "      <td>48.487730</td>\n",
       "      <td>54.961957</td>\n",
       "      <td>1.674158</td>\n",
       "      <td>54.961957</td>\n",
       "      <td>8.938714</td>\n",
       "      <td>7.134836</td>\n",
       "      <td>54.253225</td>\n",
       "      <td>12.162108</td>\n",
       "      <td>2.483804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.183869</td>\n",
       "      <td>5.049876</td>\n",
       "      <td>10.337038</td>\n",
       "      <td>3.295760</td>\n",
       "      <td>8.938714</td>\n",
       "      <td>44.493704</td>\n",
       "      <td>31.639843</td>\n",
       "      <td>3.370041</td>\n",
       "      <td>8.341824</td>\n",
       "      <td>26.596728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090157</td>\n",
       "      <td>39.625372</td>\n",
       "      <td>46.793616</td>\n",
       "      <td>9.021147</td>\n",
       "      <td>46.793616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.833858</td>\n",
       "      <td>45.502887</td>\n",
       "      <td>3.270795</td>\n",
       "      <td>9.442309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1.921478</td>\n",
       "      <td>6.830969</td>\n",
       "      <td>8.674609</td>\n",
       "      <td>1.503112</td>\n",
       "      <td>7.134836</td>\n",
       "      <td>45.960223</td>\n",
       "      <td>33.432373</td>\n",
       "      <td>5.001225</td>\n",
       "      <td>9.708835</td>\n",
       "      <td>28.425488</td>\n",
       "      <td>...</td>\n",
       "      <td>1.768291</td>\n",
       "      <td>41.377557</td>\n",
       "      <td>48.300994</td>\n",
       "      <td>7.323990</td>\n",
       "      <td>48.300994</td>\n",
       "      <td>1.833858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.206600</td>\n",
       "      <td>5.028487</td>\n",
       "      <td>7.810194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>45.366193</td>\n",
       "      <td>40.484842</td>\n",
       "      <td>55.839475</td>\n",
       "      <td>48.707466</td>\n",
       "      <td>54.253225</td>\n",
       "      <td>12.149226</td>\n",
       "      <td>15.249886</td>\n",
       "      <td>42.205693</td>\n",
       "      <td>38.013270</td>\n",
       "      <td>24.755170</td>\n",
       "      <td>...</td>\n",
       "      <td>45.541763</td>\n",
       "      <td>6.789646</td>\n",
       "      <td>10.695838</td>\n",
       "      <td>54.518494</td>\n",
       "      <td>10.695838</td>\n",
       "      <td>45.502887</td>\n",
       "      <td>47.206600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.233258</td>\n",
       "      <td>54.938726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>3.139680</td>\n",
       "      <td>1.808680</td>\n",
       "      <td>13.606217</td>\n",
       "      <td>6.527458</td>\n",
       "      <td>12.162108</td>\n",
       "      <td>41.375773</td>\n",
       "      <td>28.405702</td>\n",
       "      <td>0.756038</td>\n",
       "      <td>5.558903</td>\n",
       "      <td>23.675006</td>\n",
       "      <td>...</td>\n",
       "      <td>3.312655</td>\n",
       "      <td>36.359838</td>\n",
       "      <td>43.637580</td>\n",
       "      <td>12.291750</td>\n",
       "      <td>43.637580</td>\n",
       "      <td>3.270795</td>\n",
       "      <td>5.028487</td>\n",
       "      <td>42.233258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.707747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>9.584765</td>\n",
       "      <td>14.456841</td>\n",
       "      <td>0.943614</td>\n",
       "      <td>6.347179</td>\n",
       "      <td>2.483804</td>\n",
       "      <td>53.731902</td>\n",
       "      <td>40.924593</td>\n",
       "      <td>12.780661</td>\n",
       "      <td>17.476788</td>\n",
       "      <td>35.161267</td>\n",
       "      <td>...</td>\n",
       "      <td>9.407212</td>\n",
       "      <td>49.012123</td>\n",
       "      <td>56.094462</td>\n",
       "      <td>0.842200</td>\n",
       "      <td>56.094462</td>\n",
       "      <td>9.442309</td>\n",
       "      <td>7.810194</td>\n",
       "      <td>54.938726</td>\n",
       "      <td>12.707747</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "0     0.000000   4.928660  10.475863   3.402295   9.046000  44.329135   \n",
       "1     4.928660   0.000000  15.363990   8.326614  13.965788  39.839439   \n",
       "2    10.475863  15.363990   0.000000   7.195350   2.653738  54.549042   \n",
       "3     3.402295   8.326614   7.195350   0.000000   5.643921  47.391337   \n",
       "4     9.046000  13.965788   2.653738   5.643921   0.000000  52.532333   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "162   0.183869   5.049876  10.337038   3.295760   8.938714  44.493704   \n",
       "163   1.921478   6.830969   8.674609   1.503112   7.134836  45.960223   \n",
       "164  45.366193  40.484842  55.839475  48.707466  54.253225  12.149226   \n",
       "165   3.139680   1.808680  13.606217   6.527458  12.162108  41.375773   \n",
       "166   9.584765  14.456841   0.943614   6.347179   2.483804  53.731902   \n",
       "\n",
       "           6          7          8          9    ...        157        158  \\\n",
       "0    31.525721   3.212817   8.167347  26.529757  ...   0.180478  39.498997   \n",
       "1    26.601406   2.099390   4.686255  21.937558  ...   5.097647  34.577431   \n",
       "2    41.853597  13.661189  18.304496  36.104309  ...  10.299402  49.928916   \n",
       "3    34.926888   6.501805  11.133646  29.822103  ...   3.239187  42.880277   \n",
       "4    40.567164  12.088727  16.408137  35.345303  ...   8.883025  48.487730   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "162  31.639843   3.370041   8.341824  26.596728  ...   0.090157  39.625372   \n",
       "163  33.432373   5.001225   9.708835  28.425488  ...   1.768291  41.377557   \n",
       "164  15.249886  42.205693  38.013270  24.755170  ...  45.541763   6.789646   \n",
       "165  28.405702   0.756038   5.558903  23.675006  ...   3.312655  36.359838   \n",
       "166  40.924593  12.780661  17.476788  35.161267  ...   9.407212  49.012123   \n",
       "\n",
       "           159        160        161        162        163        164  \\\n",
       "0    46.632397   9.154090  46.632397   0.183869   1.921478  45.366193   \n",
       "1    42.060108  14.063632  42.060108   5.049876   6.830969  40.484842   \n",
       "2    56.925712   1.397385  56.925712  10.337038   8.674609  55.839475   \n",
       "3    49.747776   5.833864  49.747776   3.295760   1.503112  48.707466   \n",
       "4    54.961957   1.674158  54.961957   8.938714   7.134836  54.253225   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "162  46.793616   9.021147  46.793616   0.000000   1.833858  45.502887   \n",
       "163  48.300994   7.323990  48.300994   1.833858   0.000000  47.206600   \n",
       "164  10.695838  54.518494  10.695838  45.502887  47.206600   0.000000   \n",
       "165  43.637580  12.291750  43.637580   3.270795   5.028487  42.233258   \n",
       "166  56.094462   0.842200  56.094462   9.442309   7.810194  54.938726   \n",
       "\n",
       "           165        166  \n",
       "0     3.139680   9.584765  \n",
       "1     1.808680  14.456841  \n",
       "2    13.606217   0.943614  \n",
       "3     6.527458   6.347179  \n",
       "4    12.162108   2.483804  \n",
       "..         ...        ...  \n",
       "162   3.270795   9.442309  \n",
       "163   5.028487   7.810194  \n",
       "164  42.233258  54.938726  \n",
       "165   0.000000  12.707747  \n",
       "166  12.707747   0.000000  \n",
       "\n",
       "[167 rows x 167 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance of each city to itself is going to be zero.\n",
    "\n",
    "If we don’t replace the 0's on the diagonal with infinity, each city’s most similar city is going to be itself which is not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inf</td>\n",
       "      <td>4.928660</td>\n",
       "      <td>10.475863</td>\n",
       "      <td>3.402295</td>\n",
       "      <td>9.046000</td>\n",
       "      <td>44.329135</td>\n",
       "      <td>31.525721</td>\n",
       "      <td>3.212817</td>\n",
       "      <td>8.167347</td>\n",
       "      <td>26.529757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180478</td>\n",
       "      <td>39.498997</td>\n",
       "      <td>46.632397</td>\n",
       "      <td>9.154090</td>\n",
       "      <td>46.632397</td>\n",
       "      <td>0.183869</td>\n",
       "      <td>1.921478</td>\n",
       "      <td>45.366193</td>\n",
       "      <td>3.139680</td>\n",
       "      <td>9.584765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.928660</td>\n",
       "      <td>inf</td>\n",
       "      <td>15.363990</td>\n",
       "      <td>8.326614</td>\n",
       "      <td>13.965788</td>\n",
       "      <td>39.839439</td>\n",
       "      <td>26.601406</td>\n",
       "      <td>2.099390</td>\n",
       "      <td>4.686255</td>\n",
       "      <td>21.937558</td>\n",
       "      <td>...</td>\n",
       "      <td>5.097647</td>\n",
       "      <td>34.577431</td>\n",
       "      <td>42.060108</td>\n",
       "      <td>14.063632</td>\n",
       "      <td>42.060108</td>\n",
       "      <td>5.049876</td>\n",
       "      <td>6.830969</td>\n",
       "      <td>40.484842</td>\n",
       "      <td>1.808680</td>\n",
       "      <td>14.456841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.475863</td>\n",
       "      <td>15.363990</td>\n",
       "      <td>inf</td>\n",
       "      <td>7.195350</td>\n",
       "      <td>2.653738</td>\n",
       "      <td>54.549042</td>\n",
       "      <td>41.853597</td>\n",
       "      <td>13.661189</td>\n",
       "      <td>18.304496</td>\n",
       "      <td>36.104309</td>\n",
       "      <td>...</td>\n",
       "      <td>10.299402</td>\n",
       "      <td>49.928916</td>\n",
       "      <td>56.925712</td>\n",
       "      <td>1.397385</td>\n",
       "      <td>56.925712</td>\n",
       "      <td>10.337038</td>\n",
       "      <td>8.674609</td>\n",
       "      <td>55.839475</td>\n",
       "      <td>13.606217</td>\n",
       "      <td>0.943614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.402295</td>\n",
       "      <td>8.326614</td>\n",
       "      <td>7.195350</td>\n",
       "      <td>inf</td>\n",
       "      <td>5.643921</td>\n",
       "      <td>47.391337</td>\n",
       "      <td>34.926888</td>\n",
       "      <td>6.501805</td>\n",
       "      <td>11.133646</td>\n",
       "      <td>29.822103</td>\n",
       "      <td>...</td>\n",
       "      <td>3.239187</td>\n",
       "      <td>42.880277</td>\n",
       "      <td>49.747776</td>\n",
       "      <td>5.833864</td>\n",
       "      <td>49.747776</td>\n",
       "      <td>3.295760</td>\n",
       "      <td>1.503112</td>\n",
       "      <td>48.707466</td>\n",
       "      <td>6.527458</td>\n",
       "      <td>6.347179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.046000</td>\n",
       "      <td>13.965788</td>\n",
       "      <td>2.653738</td>\n",
       "      <td>5.643921</td>\n",
       "      <td>inf</td>\n",
       "      <td>52.532333</td>\n",
       "      <td>40.567164</td>\n",
       "      <td>12.088727</td>\n",
       "      <td>16.408137</td>\n",
       "      <td>35.345303</td>\n",
       "      <td>...</td>\n",
       "      <td>8.883025</td>\n",
       "      <td>48.487730</td>\n",
       "      <td>54.961957</td>\n",
       "      <td>1.674158</td>\n",
       "      <td>54.961957</td>\n",
       "      <td>8.938714</td>\n",
       "      <td>7.134836</td>\n",
       "      <td>54.253225</td>\n",
       "      <td>12.162108</td>\n",
       "      <td>2.483804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.183869</td>\n",
       "      <td>5.049876</td>\n",
       "      <td>10.337038</td>\n",
       "      <td>3.295760</td>\n",
       "      <td>8.938714</td>\n",
       "      <td>44.493704</td>\n",
       "      <td>31.639843</td>\n",
       "      <td>3.370041</td>\n",
       "      <td>8.341824</td>\n",
       "      <td>26.596728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090157</td>\n",
       "      <td>39.625372</td>\n",
       "      <td>46.793616</td>\n",
       "      <td>9.021147</td>\n",
       "      <td>46.793616</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.833858</td>\n",
       "      <td>45.502887</td>\n",
       "      <td>3.270795</td>\n",
       "      <td>9.442309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1.921478</td>\n",
       "      <td>6.830969</td>\n",
       "      <td>8.674609</td>\n",
       "      <td>1.503112</td>\n",
       "      <td>7.134836</td>\n",
       "      <td>45.960223</td>\n",
       "      <td>33.432373</td>\n",
       "      <td>5.001225</td>\n",
       "      <td>9.708835</td>\n",
       "      <td>28.425488</td>\n",
       "      <td>...</td>\n",
       "      <td>1.768291</td>\n",
       "      <td>41.377557</td>\n",
       "      <td>48.300994</td>\n",
       "      <td>7.323990</td>\n",
       "      <td>48.300994</td>\n",
       "      <td>1.833858</td>\n",
       "      <td>inf</td>\n",
       "      <td>47.206600</td>\n",
       "      <td>5.028487</td>\n",
       "      <td>7.810194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>45.366193</td>\n",
       "      <td>40.484842</td>\n",
       "      <td>55.839475</td>\n",
       "      <td>48.707466</td>\n",
       "      <td>54.253225</td>\n",
       "      <td>12.149226</td>\n",
       "      <td>15.249886</td>\n",
       "      <td>42.205693</td>\n",
       "      <td>38.013270</td>\n",
       "      <td>24.755170</td>\n",
       "      <td>...</td>\n",
       "      <td>45.541763</td>\n",
       "      <td>6.789646</td>\n",
       "      <td>10.695838</td>\n",
       "      <td>54.518494</td>\n",
       "      <td>10.695838</td>\n",
       "      <td>45.502887</td>\n",
       "      <td>47.206600</td>\n",
       "      <td>inf</td>\n",
       "      <td>42.233258</td>\n",
       "      <td>54.938726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>3.139680</td>\n",
       "      <td>1.808680</td>\n",
       "      <td>13.606217</td>\n",
       "      <td>6.527458</td>\n",
       "      <td>12.162108</td>\n",
       "      <td>41.375773</td>\n",
       "      <td>28.405702</td>\n",
       "      <td>0.756038</td>\n",
       "      <td>5.558903</td>\n",
       "      <td>23.675006</td>\n",
       "      <td>...</td>\n",
       "      <td>3.312655</td>\n",
       "      <td>36.359838</td>\n",
       "      <td>43.637580</td>\n",
       "      <td>12.291750</td>\n",
       "      <td>43.637580</td>\n",
       "      <td>3.270795</td>\n",
       "      <td>5.028487</td>\n",
       "      <td>42.233258</td>\n",
       "      <td>inf</td>\n",
       "      <td>12.707747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>9.584765</td>\n",
       "      <td>14.456841</td>\n",
       "      <td>0.943614</td>\n",
       "      <td>6.347179</td>\n",
       "      <td>2.483804</td>\n",
       "      <td>53.731902</td>\n",
       "      <td>40.924593</td>\n",
       "      <td>12.780661</td>\n",
       "      <td>17.476788</td>\n",
       "      <td>35.161267</td>\n",
       "      <td>...</td>\n",
       "      <td>9.407212</td>\n",
       "      <td>49.012123</td>\n",
       "      <td>56.094462</td>\n",
       "      <td>0.842200</td>\n",
       "      <td>56.094462</td>\n",
       "      <td>9.442309</td>\n",
       "      <td>7.810194</td>\n",
       "      <td>54.938726</td>\n",
       "      <td>12.707747</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "0          inf   4.928660  10.475863   3.402295   9.046000  44.329135   \n",
       "1     4.928660        inf  15.363990   8.326614  13.965788  39.839439   \n",
       "2    10.475863  15.363990        inf   7.195350   2.653738  54.549042   \n",
       "3     3.402295   8.326614   7.195350        inf   5.643921  47.391337   \n",
       "4     9.046000  13.965788   2.653738   5.643921        inf  52.532333   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "162   0.183869   5.049876  10.337038   3.295760   8.938714  44.493704   \n",
       "163   1.921478   6.830969   8.674609   1.503112   7.134836  45.960223   \n",
       "164  45.366193  40.484842  55.839475  48.707466  54.253225  12.149226   \n",
       "165   3.139680   1.808680  13.606217   6.527458  12.162108  41.375773   \n",
       "166   9.584765  14.456841   0.943614   6.347179   2.483804  53.731902   \n",
       "\n",
       "           6          7          8          9    ...        157        158  \\\n",
       "0    31.525721   3.212817   8.167347  26.529757  ...   0.180478  39.498997   \n",
       "1    26.601406   2.099390   4.686255  21.937558  ...   5.097647  34.577431   \n",
       "2    41.853597  13.661189  18.304496  36.104309  ...  10.299402  49.928916   \n",
       "3    34.926888   6.501805  11.133646  29.822103  ...   3.239187  42.880277   \n",
       "4    40.567164  12.088727  16.408137  35.345303  ...   8.883025  48.487730   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "162  31.639843   3.370041   8.341824  26.596728  ...   0.090157  39.625372   \n",
       "163  33.432373   5.001225   9.708835  28.425488  ...   1.768291  41.377557   \n",
       "164  15.249886  42.205693  38.013270  24.755170  ...  45.541763   6.789646   \n",
       "165  28.405702   0.756038   5.558903  23.675006  ...   3.312655  36.359838   \n",
       "166  40.924593  12.780661  17.476788  35.161267  ...   9.407212  49.012123   \n",
       "\n",
       "           159        160        161        162        163        164  \\\n",
       "0    46.632397   9.154090  46.632397   0.183869   1.921478  45.366193   \n",
       "1    42.060108  14.063632  42.060108   5.049876   6.830969  40.484842   \n",
       "2    56.925712   1.397385  56.925712  10.337038   8.674609  55.839475   \n",
       "3    49.747776   5.833864  49.747776   3.295760   1.503112  48.707466   \n",
       "4    54.961957   1.674158  54.961957   8.938714   7.134836  54.253225   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "162  46.793616   9.021147  46.793616        inf   1.833858  45.502887   \n",
       "163  48.300994   7.323990  48.300994   1.833858        inf  47.206600   \n",
       "164  10.695838  54.518494  10.695838  45.502887  47.206600        inf   \n",
       "165  43.637580  12.291750  43.637580   3.270795   5.028487  42.233258   \n",
       "166  56.094462   0.842200  56.094462   9.442309   7.810194  54.938726   \n",
       "\n",
       "           165        166  \n",
       "0     3.139680   9.584765  \n",
       "1     1.808680  14.456841  \n",
       "2    13.606217   0.943614  \n",
       "3     6.527458   6.347179  \n",
       "4    12.162108   2.483804  \n",
       "..         ...        ...  \n",
       "162   3.270795   9.442309  \n",
       "163   5.028487   7.810194  \n",
       "164  42.233258  54.938726  \n",
       "165        inf  12.707747  \n",
       "166  12.707747        inf  \n",
       "\n",
       "[167 rows x 167 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "np.fill_diagonal(dists, np.inf)\n",
    "pd.DataFrame(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the distance between city 0 and some other cities. \n",
    "\n",
    "We can look at city 0 with its respective `longitude` and `latitude` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-76.4813</td>\n",
       "      <td>44.2307</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     longitude  latitude country\n",
       "160   -76.4813   44.2307  Canada"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_train_df.iloc[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the distances from city 0 to the other cities in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([        inf,  4.92866046, 10.47586257,  3.40229467,  9.04600003,\n",
       "       44.32913545, 31.52572108,  3.21281701,  8.16734667, 26.52975665,\n",
       "        5.36451793, 17.47354208,  9.25235538, 46.65300827, 12.91711643,\n",
       "        8.73732272, 21.41984759, 46.10101237, 11.38925694,  8.45258153,\n",
       "        3.29603996, 12.90216965, 25.43541008,  2.57167487, 35.80191816,\n",
       "       54.77569987,  2.77064993,  4.74762925, 21.11653758, 46.84711517,\n",
       "       18.63306299, 42.68410294, 21.26505054, 46.58691036, 23.62784332,\n",
       "        4.45224202,  4.47636916, 36.52381145,  9.25295786,  6.83445279,\n",
       "        3.32357247,  8.16734667, 31.19662805,  7.79242035,  1.42424148,\n",
       "       23.99849627, 38.17792497,  4.94149717, 21.5518279 ,  9.51787313,\n",
       "       38.19275017, 37.97055885,  2.97880445,  9.51483002, 37.1901251 ,\n",
       "       54.83532899,  1.28350735, 10.0044146 ,  3.28029451, 45.92971431,\n",
       "       11.01430039,  3.19225293, 46.38943202,  2.96693525,  9.04600003,\n",
       "       35.80001702,  2.76505999,  3.07231406, 36.96774058, 38.19559327,\n",
       "        3.10919556,  7.39488827,  2.95943349, 11.50351059,  3.93684711,\n",
       "       42.2793155 ,  9.14918312,  6.83445279, 46.91610836, 43.38757936,\n",
       "        3.5288519 , 46.38746533,  3.93581626,  2.96373905, 21.27058643,\n",
       "       18.66494501, 26.50025275,  6.82764827,  4.7396424 ,  9.9874779 ,\n",
       "        6.83549241, 13.13067545, 46.50627115, 26.49966844, 28.81491391,\n",
       "       45.97271218, 46.90321547,  5.73649067, 59.62262041,  1.09761148,\n",
       "        6.08870392,  5.73454545, 46.21089504,  9.03328701,  7.92447701,\n",
       "       23.80155222, 47.07123507,  8.73468637,  2.74816746,  3.07662193,\n",
       "        3.22855068,  3.63284771, 19.68277227,  2.82337311,  3.43691007,\n",
       "        7.93860597, 46.85396601, 16.3288186 , 46.23882897, 43.94670281,\n",
       "       28.85319232,  2.91163454,  2.88081958, 16.80079704, 23.7934676 ,\n",
       "        3.9286773 ,  2.86603875,  3.32357247,  1.07865087,  8.4376414 ,\n",
       "        6.82764827,  3.0717763 ,  4.45272866,  9.11228649,  4.08772282,\n",
       "        2.86603875, 34.6881178 ,  1.8400926 ,  3.03326165, 23.32224009,\n",
       "       46.10101237, 46.83865522, 22.78600867, 28.85530775, 18.81002995,\n",
       "       46.69549579, 13.44345687, 17.34527477,  6.75905672,  5.89141512,\n",
       "        3.13784784,  3.47624672, 42.98365051, 43.00228242, 10.65641958,\n",
       "        3.80625889,  1.42924216,  0.18047839, 39.49899714, 46.63239678,\n",
       "        9.15409025, 46.63239678,  0.18386865,  1.92147809, 45.36619339,\n",
       "        3.13968038,  9.58476504])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that our goal is to find the closest example to city 0. \n",
    "\n",
    "We can find the closest city to city 0 by finding the city with the minimum distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(dists[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closest city in the training dataset is the city with index 157.\n",
    "\n",
    "This corresponds to index 96 from the original dataset before shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-76.3019</td>\n",
       "      <td>44.211</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    longitude  latitude country\n",
       "96   -76.3019    44.211  Canada"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_train_df.iloc[[157]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the `longitude` and `latitude` values for the city at index 157 (labelled 96), they look pretty close to those of city 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-76.4813</td>\n",
       "      <td>44.2307</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     longitude  latitude country\n",
       "160   -76.4813   44.2307  Canada"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_train_df.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18047839205805613"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists[0][157]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in this case, the closest city to city 0 is city 157 and the Euclidean distance between the two cities is 0.184. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest city to a query point\n",
    "\n",
    "We can also find the distances to a new \"test\" or \"query\" city:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.54996348],\n",
       "       [18.02706204],\n",
       "       [24.60912622],\n",
       "       [21.39718237],\n",
       "       [25.24111312],\n",
       "       [47.81750619],\n",
       "       [28.49499735],\n",
       "       [19.39177482],\n",
       "       [21.95316686],\n",
       "       [19.01698738]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_point = [[-80, 25]]\n",
    "\n",
    "\n",
    "dists = euclidean_distances(cities_train_df[[\"longitude\", \"latitude\"]], query_point)\n",
    "dists[:10]  # Only show the first few observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the city closest to the query point (-80, 25) using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.83839229])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists[np.argmin(dists)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the city at index 147 is the closest point to (-80, 25) with the Euclidean distance between the two equal to 3.838"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of doing this manually we can use Sklearn's `NearestNeighbors` function to get the closest example and the distance between the query point and the closest example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel/miniconda3/envs/bait/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[3.83839229]]), array([[147]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=1)\n",
    "nn.fit(cities_train_df[['longitude', 'latitude']]);\n",
    "nn.kneighbors([[-80, 25]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `kneighbors` to find the 5 nearest cities in the training split to one of the cities in the test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.03461517, 0.90722048, 0.90722048, 0.90970871, 0.90970871]]),\n",
       " array([[100,  77,  39,  87, 130]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_test_X = cities_test_df[['longitude', 'latitude']]\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=5)\n",
    "nn.fit(cities_train_df[['longitude', 'latitude']]);\n",
    "nn.kneighbors(cities_test_X.iloc[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the last line,\n",
    "we need to be careful and make sure that we pass in either a 2D numpy array\n",
    "or a dataframe as our input.\n",
    "This is why we use 2 sets of square brackets with our city above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice\n",
    "\n",
    "\n",
    "```             \n",
    "       seeds   shape  sweetness   water-content      weight    fruit_veg\n",
    "0      1        0        35          84               100        fruit\n",
    "1      0        0        23          75               120        fruit\n",
    "2      1        1        15          90              1360         veg\n",
    "3      1        1         7          96               600         veg\n",
    "4      0        0        37          80                 5        fruit\n",
    "5      0        0        45          78                40        fruit  \n",
    "6      1        0        27          83               450         veg\n",
    "7      1        1        18          73                 5         veg\n",
    "8      1        1        32          80                76         veg\n",
    "9      0        0        40          83                65        fruit\n",
    "```\n",
    "\n",
    "1\\. Giving the table above and that we are trying to predict if each example is either a fruit or a vegetable, what would be the dimension of feature vectors in this problem?\n",
    "\n",
    "\n",
    "2\\. Which of the following would be the feature vector for example 0. \n",
    "\n",
    "a) `array([1,  0, 1, 1, 0, 0, 1, 1, 1, 0])`    \n",
    "b) `array([fruit,  fruit, veg, veg, fruit, fruit, veg, veg, veg, fruit])`     \n",
    "c) `array([1, 0, 35, 84, 100])`    \n",
    "d) `array([1, 0, 35, 84, 100,  fruit])`     \n",
    "\n",
    "\n",
    "3\\. Given the following 2 feature vectors, what is the Euclidean distance between the following two feature vectors?\n",
    "\n",
    "```\n",
    "u = np.array([5, 0, 22, -11])\n",
    "v = np.array([-1, 0, 19, -9])\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**True or False**     \n",
    "\n",
    "4\\. Analogy-based models find examples from the test set that are most similar to the test example we are predicting.   \n",
    "5\\. Feature vectors can only be of length 3 since we cannot visualize past that.    \n",
    "6\\. Euclidean distance will always have a positive value.    \n",
    "7\\. When finding the nearest neighbour in a dataset using `kneighbors()` from the `sklearn` library, we must `fit`  the data first.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Solutions!\n",
    ":class: dropdown\n",
    "\n",
    "1. 5 dimensions.\n",
    "2. c) `array([1, 0, 35, 84, 100])`\n",
    "3. 7\n",
    "4. False   \n",
    "5. False\n",
    "6. True\n",
    "7. True\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$ -Nearest Neighbours ($k$-NNs) Classifier\n",
    "\n",
    "Now that we have learned how to find similar examples, can we use this idea in a predictive model?\n",
    "\n",
    "- Yes! The k Nearest Neighbors (kNN) algorithm\n",
    "- This is a fairly simple algorithm that is best understood by example\n",
    "\n",
    "\n",
    "<img src=\"imgs/scatter.png\"  width = \"30%\" alt=\"404 image\" />\n",
    "\n",
    "\n",
    "We have two features in our toy example; feature 1 and feature 2.\n",
    "\n",
    "We have two targets; 0 represented with  <font color=\"blue\">blue</font> points and 1 represented with  <font color=\"orange\">orange</font> points.\n",
    "\n",
    "We want to predict the point in gray."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on what we have been doing so far, we can find the closest example ($k$=1) to this gray point and use its class as the class for our grey point. \n",
    "\n",
    "In this particular case, we will predict orange as the class for our query point. \n",
    "\n",
    "<img src=\"imgs/scatter_k1.png\"  width = \"30%\" alt=\"404 image\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we consider more than one nearest example and let them vote on the target of the query example. \n",
    "\n",
    "Let's consider the nearest 3 neighbours and let them vote. \n",
    "\n",
    "<img src=\"imgs/scatter_k3.png\"  width = \"30%\" alt=\"404 image\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this with a smaller set of our data and `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_df = cities_train_df.sample(30, random_state=1223)\n",
    "small_X_train = small_train_df.drop(columns=[\"country\"])\n",
    "small_y_train = small_train_df[\"country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-122.7454</td>\n",
       "      <td>53.9129</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     longitude  latitude country\n",
       "195  -122.7454   53.9129  Canada"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_city = cities_test_df.sample(1, random_state=33)\n",
    "one_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-ec5f28b5d8084dad968e2d2c3fad60f3\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ec5f28b5d8084dad968e2d2c3fad60f3\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ec5f28b5d8084dad968e2d2c3fad60f3\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-c4c6612deb1589c1d2e3cbfa1b504ae9\"}, \"mark\": \"circle\", \"encoding\": {\"color\": {\"field\": \"country\", \"scale\": {\"domain\": [\"Canada\", \"USA\"], \"range\": [\"red\", \"blue\"]}, \"type\": \"nominal\"}, \"x\": {\"field\": \"longitude\", \"scale\": {\"domain\": [-140, -40]}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"latitude\", \"scale\": {\"domain\": [20, 60]}, \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-d0ae25a3f6b392271f284534b330ba9e\"}, \"mark\": {\"type\": \"point\", \"fill\": \"darkgreen\", \"opacity\": 1, \"shape\": \"triangle-up\", \"size\": 400}, \"encoding\": {\"x\": {\"field\": \"longitude\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"latitude\", \"type\": \"quantitative\"}}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-c4c6612deb1589c1d2e3cbfa1b504ae9\": [{\"longitude\": -79.4608, \"latitude\": 46.3092, \"country\": \"Canada\"}, {\"longitude\": -84.3902, \"latitude\": 33.7491, \"country\": \"USA\"}, {\"longitude\": -67.4253, \"latitude\": 45.5672, \"country\": \"Canada\"}, {\"longitude\": -97.7437, \"latitude\": 30.2711, \"country\": \"USA\"}, {\"longitude\": -97.1385, \"latitude\": 49.8955, \"country\": \"Canada\"}, {\"longitude\": -82.4584, \"latitude\": 27.9478, \"country\": \"USA\"}, {\"longitude\": -71.1473, \"latitude\": 48.382, \"country\": \"Canada\"}, {\"longitude\": -104.9849, \"latitude\": 39.7392, \"country\": \"USA\"}, {\"longitude\": -76.3305, \"latitude\": 44.1255, \"country\": \"USA\"}, {\"longitude\": -76.4813, \"latitude\": 44.2307, \"country\": \"Canada\"}, {\"longitude\": -111.8315, \"latitude\": 33.4151, \"country\": \"USA\"}, {\"longitude\": -115.1485, \"latitude\": 36.1673, \"country\": \"USA\"}, {\"longitude\": -102.5496, \"latitude\": 48.9959, \"country\": \"USA\"}, {\"longitude\": -68.5897, \"latitude\": 47.2587, \"country\": \"USA\"}, {\"longitude\": -71.0692, \"latitude\": 48.406, \"country\": \"Canada\"}, {\"longitude\": -66.9905, \"latitude\": 44.9065, \"country\": \"USA\"}, {\"longitude\": -122.8491, \"latitude\": 49.1913, \"country\": \"Canada\"}, {\"longitude\": -84.3201, \"latitude\": 46.5239, \"country\": \"Canada\"}, {\"longitude\": -79.1153, \"latitude\": 43.101, \"country\": \"Canada\"}, {\"longitude\": -122.4199, \"latitude\": 37.779, \"country\": \"USA\"}, {\"longitude\": -122.6742, \"latitude\": 45.5202, \"country\": \"USA\"}, {\"longitude\": -66.9843, \"latitude\": 44.8607, \"country\": \"USA\"}, {\"longitude\": -71.3998, \"latitude\": 46.8884, \"country\": \"Canada\"}, {\"longitude\": -95.9384, \"latitude\": 41.2587, \"country\": \"USA\"}, {\"longitude\": -98.4951, \"latitude\": 29.4246, \"country\": \"USA\"}, {\"longitude\": -82.4405, \"latitude\": 42.9816, \"country\": \"USA\"}, {\"longitude\": -79.2506, \"latitude\": 42.9931, \"country\": \"Canada\"}, {\"longitude\": -118.1916, \"latitude\": 33.769, \"country\": \"USA\"}, {\"longitude\": -86.1584, \"latitude\": 39.7683, \"country\": \"USA\"}, {\"longitude\": -75.9774, \"latitude\": 36.853, \"country\": \"USA\"}], \"data-d0ae25a3f6b392271f284534b330ba9e\": [{\"longitude\": -122.7454, \"latitude\": 53.9129, \"country\": \"Canada\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart_knn = alt.Chart(small_train_df).mark_circle().encode(\n",
    "    alt.X('longitude', scale=alt.Scale(domain=[-140, -40])),\n",
    "    alt.Y('latitude', scale=alt.Scale(domain=[20, 60])),\n",
    "    alt.Color('country', scale=alt.Scale(domain=['Canada', 'USA'], range=['red', 'blue'])))\n",
    "\n",
    "one_city_point = alt.Chart(one_city).mark_point(\n",
    "    shape='triangle-up', size=400, fill='darkgreen', opacity=1).encode(\n",
    "    alt.X('longitude'),\n",
    "    alt.Y('latitude')\n",
    ")\n",
    "\n",
    "chart_knn +  one_city_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the class for this green triangle city.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Canada'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "neigh_clf = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh_clf.fit(small_X_train, small_y_train)\n",
    "neigh_clf.predict(one_city.drop(columns=[\"country\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set `n_neighbors` equal to 1 to classify this triangle based on one neighbouring point. \n",
    "\n",
    "Our prediction here is Canada since the closest point to the green triangle is a city with the class “Canada”.\n",
    "\n",
    "Now, what if we consider the nearest 3 neighbours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USA'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh_clf.fit(small_X_train, small_y_train)\n",
    "neigh_clf.predict(one_city.drop(columns=[\"country\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we change our model to consider the nearest 3 neighbours, our prediction changes!\n",
    "\n",
    "It now predicts \"USA\" since the majority of the 3 nearest points are \"USA\" cities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our entire training dataset and calculate our training and validation scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_X_train = cities_train_df.drop(columns=['country'])\n",
    "cities_y_train = cities_train_df['country']\n",
    "cities_X_test = cities_test_df.drop(columns=['country'])\n",
    "cities_y_test = cities_test_df['country']\n",
    "\n",
    "\n",
    "kn1_model = KNeighborsClassifier(n_neighbors=1)\n",
    "scores = cross_validate(kn1_model, cities_X_train, cities_y_train, cv=10, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.002475    0.002093    0.823529          1.0\n",
       "1  0.001399    0.001869    0.705882          1.0\n",
       "2  0.001503    0.001856    0.647059          1.0\n",
       "3  0.001508    0.001797    0.941176          1.0\n",
       "4  0.001377    0.001621    0.823529          1.0\n",
       "5  0.001268    0.001399    0.588235          1.0\n",
       "6  0.001389    0.001456    0.647059          1.0\n",
       "7  0.001302    0.001423    0.812500          1.0\n",
       "8  0.001266    0.001498    0.937500          1.0\n",
       "9  0.001331    0.001545    0.750000          1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.001482\n",
       "score_time     0.001656\n",
       "test_score     0.767647\n",
       "train_score    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing K\n",
    "\n",
    "Ok, so we saw our validation and training scores for `n_neighbors` =1. What happens when we change that? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.606667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.629139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.622517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.629139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.001924    0.002541    0.705882     0.620000\n",
       "1  0.001278    0.002043    0.588235     0.620000\n",
       "2  0.001830    0.002455    0.588235     0.633333\n",
       "3  0.001358    0.001940    0.588235     0.606667\n",
       "4  0.001391    0.001709    0.588235     0.620000\n",
       "5  0.001365    0.001626    0.588235     0.633333\n",
       "6  0.001363    0.001619    0.647059     0.700000\n",
       "7  0.001348    0.001807    0.625000     0.629139\n",
       "8  0.001831    0.002362    0.687500     0.622517\n",
       "9  0.002112    0.002652    0.625000     0.629139"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn90_model = KNeighborsClassifier(n_neighbors=90)\n",
    "\n",
    "scores_df = pd.DataFrame(cross_validate(kn90_model, cities_X_train, cities_y_train, cv=10, return_train_score=True))\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.001580\n",
       "score_time     0.002075\n",
       "test_score     0.623162\n",
       "train_score    0.631413\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing this with the results of `n_neighbors=1` we see that we went from overfitting to underfitting.\n",
    "\n",
    "Let's look at the decision boundaries now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel/miniconda3/envs/bait/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/joel/miniconda3/envs/bait/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'n_neighbors = 90'}, xlabel='longitude', ylabel='latitude'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_classifier import plot_classifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "kn1_model.fit(cities_X_train, cities_y_train);\n",
    "plt.title(\"n_neighbors = 1\")\n",
    "plt.ylabel(\"latitude\")\n",
    "plt.xlabel(\"longitude\")\n",
    "plot_classifier(cities_X_train, cities_y_train, kn1_model, ax=plt.gca(), ticks=True)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"n_neighbors = 90\")\n",
    "kn90_model.fit(cities_X_train, cities_y_train);\n",
    "plt.ylabel(\"latitude\")\n",
    "plt.xlabel(\"longitude\")\n",
    "plot_classifier(cities_X_train, cities_y_train, kn90_model, ax=plt.gca(), ticks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot these two models with $k=1$ on the left and $k=90$ on the right. \n",
    "\n",
    "The left plot shows a much more complex model where it is much more specific and attempts to get every example correct. \n",
    "\n",
    "The plot on right is plotting a simpler model and we can see more training examples are being predicted incorrectly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to choose $K$ (`n_neighbors`)?\n",
    "\n",
    "So we saw the model was overfitting with $k$=1 and  when $k$=90, the model was underfitting.\n",
    "\n",
    "So, the question is how do we pick $k$?\n",
    "\n",
    "- Since $k$ is a hyperparameter (`n_neighbors` in `sklearn`), we can use hyperparameter optimization to choose $k$.\n",
    "\n",
    "Here we are looping over different values of $k$ and performing cross-validation on each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.767647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.841660</td>\n",
       "      <td>0.785662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.823051</td>\n",
       "      <td>0.811029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.807726</td>\n",
       "      <td>0.793382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>0.777810</td>\n",
       "      <td>0.756985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>0.765854</td>\n",
       "      <td>0.739338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31</td>\n",
       "      <td>0.758525</td>\n",
       "      <td>0.738971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36</td>\n",
       "      <td>0.738583</td>\n",
       "      <td>0.720221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41</td>\n",
       "      <td>0.725912</td>\n",
       "      <td>0.726471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46</td>\n",
       "      <td>0.733916</td>\n",
       "      <td>0.713971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_neighbors  mean_train_score  mean_cv_score\n",
       "0            1          1.000000       0.767647\n",
       "1            6          0.841660       0.785662\n",
       "2           11          0.823051       0.811029\n",
       "3           16          0.807726       0.793382\n",
       "4           21          0.777810       0.756985\n",
       "5           26          0.765854       0.739338\n",
       "6           31          0.758525       0.738971\n",
       "7           36          0.738583       0.720221\n",
       "8           41          0.725912       0.726471\n",
       "9           46          0.733916       0.713971"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict = {\"n_neighbors\": list(), \"mean_train_score\": list(), \"mean_cv_score\": list()}\n",
    "\n",
    "for k in range(1, 50, 5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_validate(knn, cities_X_train, cities_y_train, cv=10, return_train_score=True)\n",
    "    results_dict[\"n_neighbors\"].append(k)\n",
    "    results_dict[\"mean_cv_score\"].append(np.mean(scores[\"test_score\"]))\n",
    "    results_dict[\"mean_train_score\"].append(np.mean(scores[\"train_score\"]))\n",
    "\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-be0d2e4b98f542a5a5791e4fe3b65e63\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-be0d2e4b98f542a5a5791e4fe3b65e63\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-be0d2e4b98f542a5a5791e4fe3b65e63\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-0a30ebbeafb719cb7f4a23a7432da33a\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"field\": \"score_type\", \"type\": \"nominal\"}, \"x\": {\"field\": \"n_neighbors\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"accuracy\", \"scale\": {\"domain\": [0.67, 1.0]}, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Accuracies of n_neighbors for KNeighborsClassifier\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-0a30ebbeafb719cb7f4a23a7432da33a\": [{\"n_neighbors\": 1, \"score_type\": \"mean_train_score\", \"accuracy\": 1.0}, {\"n_neighbors\": 6, \"score_type\": \"mean_train_score\", \"accuracy\": 0.8416600441501103}, {\"n_neighbors\": 11, \"score_type\": \"mean_train_score\", \"accuracy\": 0.8230507726269316}, {\"n_neighbors\": 16, \"score_type\": \"mean_train_score\", \"accuracy\": 0.8077262693156733}, {\"n_neighbors\": 21, \"score_type\": \"mean_train_score\", \"accuracy\": 0.7778101545253863}, {\"n_neighbors\": 26, \"score_type\": \"mean_train_score\", \"accuracy\": 0.7658543046357617}, {\"n_neighbors\": 31, \"score_type\": \"mean_train_score\", \"accuracy\": 0.7585253863134657}, {\"n_neighbors\": 36, \"score_type\": \"mean_train_score\", \"accuracy\": 0.7385827814569536}, {\"n_neighbors\": 41, \"score_type\": \"mean_train_score\", \"accuracy\": 0.7259116997792494}, {\"n_neighbors\": 46, \"score_type\": \"mean_train_score\", \"accuracy\": 0.7339161147902871}, {\"n_neighbors\": 1, \"score_type\": \"mean_cv_score\", \"accuracy\": 0.7676470588235293}, {\"n_neighbors\": 6, \"score_type\": \"mean_cv_score\", \"accuracy\": 0.7856617647058823}, {\"n_neighbors\": 11, \"score_type\": \"mean_cv_score\", \"accuracy\": 0.8110294117647058}, {\"n_neighbors\": 16, \"score_type\": \"mean_cv_score\", \"accuracy\": 0.7933823529411764}, {\"n_neighbors\": 21, \"score_type\": \"mean_cv_score\", \"accuracy\": 0.7569852941176471}, {\"n_neighbors\": 26, \"score_type\": \"mean_cv_score\", \"accuracy\": 0.7393382352941177}, {\"n_neighbors\": 31, \"score_type\": \"mean_cv_score\", \"accuracy\": 0.7389705882352942}, {\"n_neighbors\": 36, \"score_type\": \"mean_cv_score\", \"accuracy\": 0.7202205882352942}, {\"n_neighbors\": 41, \"score_type\": \"mean_cv_score\", \"accuracy\": 0.7264705882352942}, {\"n_neighbors\": 46, \"score_type\": \"mean_cv_score\", \"accuracy\": 0.7139705882352942}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotting_source = results_df.melt(\n",
    "    id_vars='n_neighbors',\n",
    "    value_vars=['mean_train_score', 'mean_cv_score'],\n",
    "    var_name='score_type',\n",
    "    value_name='accuracy'\n",
    ")\n",
    "\n",
    "K_plot = alt.Chart(plotting_source, width=500, height=300).mark_line().encode(\n",
    "    alt.X('n_neighbors:Q'),\n",
    "    alt.Y('accuracy:Q', scale=alt.Scale(domain=[.67, 1.00])),\n",
    "    alt.Color('score_type:N')\n",
    ").properties(title=\"Accuracies of n_neighbors for KNeighborsClassifier\")\n",
    "\n",
    "K_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this graph with k on the x-axis and accuracy on the y-axis, we can see there is a sweet spot where the gap between the validation and training scores is the lowest and cross-validation score is the highest. Here it’s when `n_neighbors` is 11.\n",
    "\n",
    "How do I know it's 11? \n",
    "Here's how! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.823051</td>\n",
       "      <td>0.811029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.807726</td>\n",
       "      <td>0.793382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.841660</td>\n",
       "      <td>0.785662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.767647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>0.777810</td>\n",
       "      <td>0.756985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>0.765854</td>\n",
       "      <td>0.739338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31</td>\n",
       "      <td>0.758525</td>\n",
       "      <td>0.738971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41</td>\n",
       "      <td>0.725912</td>\n",
       "      <td>0.726471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36</td>\n",
       "      <td>0.738583</td>\n",
       "      <td>0.720221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46</td>\n",
       "      <td>0.733916</td>\n",
       "      <td>0.713971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_neighbors  mean_train_score  mean_cv_score\n",
       "2           11          0.823051       0.811029\n",
       "3           16          0.807726       0.793382\n",
       "1            6          0.841660       0.785662\n",
       "0            1          1.000000       0.767647\n",
       "4           21          0.777810       0.756985\n",
       "5           26          0.765854       0.739338\n",
       "6           31          0.758525       0.738971\n",
       "8           41          0.725912       0.726471\n",
       "7           36          0.738583       0.720221\n",
       "9           46          0.733916       0.713971"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(\"mean_cv_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.857\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(cities_X_train, cities_y_train);\n",
    "print(\"Test accuracy:\", round(knn.score(cities_X_test, cities_y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This testing accuracy even higher than the validation mean accuracy we had earlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curse of Dimensionality \n",
    "\n",
    "> $k$ -NN usually works well when the number of dimensions is small.\n",
    "\n",
    "In the previous module, we discussed one of the most important problems in machine learning which was overfitting.\n",
    "The second most important problem in machine learning is **the curse of dimensionality**.\n",
    "This refers to that datasets with many many features generally have a sparser distribution of observations within this feature space,\n",
    "since there are so many possible unique combinations of features.\n",
    "This makes it both harder to detect the same general patterns between observations in the data\n",
    "and easier to accidentally mistake \"noise\" (meaningless correlations) for general patterns.\n",
    "\n",
    "We will talk more later about what can be done to alleviate the curse of dimensionality,\n",
    "but for now it is enough to know that many supervised ML algorithms, including k-NN,\n",
    "can perform poorly when there are too high dimensionality in the data.\n",
    "With enough irrelevant features, the accidental similarity between features wipes out any meaningful similarity and $k$-NN is no better than random guessing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice \n",
    "\n",
    "Consider this toy dataset:\n",
    "\n",
    "$$ X = \\begin{bmatrix}5 & 2\\\\4 & 3\\\\  2 & 2\\\\ 10 & 10\\\\ 9 & -1\\\\ 9& 9\\end{bmatrix}, \\quad y = \\begin{bmatrix}A\\\\A\\\\B\\\\B\\\\B\\\\C\\end{bmatrix}.$$\n",
    "\n",
    "What would you predict for $x=\\begin{bmatrix} 0 & 0\\end{bmatrix}$:\n",
    "\n",
    "1\\. If $k=1$?    \n",
    "2\\. If $k=3$?     \n",
    "\n",
    "\n",
    "**True or False**       \n",
    "\n",
    "3\\. The classification of the closest neighbour to the test example always contributes the most to the prediction.    \n",
    "4\\. The `n_neighbors` hyperparameter must be less than the number of examples in the training set.     \n",
    "5\\. Similar to decision trees, $k$-NNs find a small set of good features.     \n",
    "6\\. With  $k$-NN, setting the hyperparameter  $k$  to larger values typically increases training score.      \n",
    "7\\. $k$-NN may perform poorly in high-dimensional space (say, d > 100)     \n",
    "8\\. Based on the graph below, what value of `n_neighbors` would you choose to train your model on?    \n",
    "\n",
    "<img src=\"imgs/Q18a.png\"  width = \"70%\" alt=\"404 image\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Solutions!\n",
    ":class: dropdown\n",
    "\n",
    "1. B\n",
    "2. A\n",
    "3. False\n",
    "4. True   \n",
    "5. False\n",
    "6. False \n",
    "7. True\n",
    "8. 12\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We've Learned Today<a id=\"9\"></a>\n",
    "\n",
    "- The concept of baseline models.\n",
    "- How to initiate a Dummy Classifier and Regressor.\n",
    "- How to measure Euclidean distance.\n",
    "- How the $k$NN algorithm works for classification.\n",
    "- How changing $k$ (`n_neighbors`) affects a model.\n",
    "- What the curse of dimensionality is.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bait]",
   "language": "python",
   "name": "conda-env-bait-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "402.125px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
