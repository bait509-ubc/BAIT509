{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice! \n",
    "\n",
    "Are the following supervised or unsupervised problems?\n",
    "\n",
    "1. Finding groups of similar properties in a real estate data set.\n",
    "\n",
    "> Unsupervised\n",
    "\n",
    "2. Predicting real estate prices based on house features like number of rooms, learning from past sales as examples.\n",
    "\n",
    "> Supervised\n",
    "\n",
    "3. Identifying groups of animals given features such as \"number of legs\", \"wings/no wings\", \"fur/no fur\", etc.\n",
    "\n",
    "> Unsupervised\n",
    "\n",
    "4. Detecting heart disease in patients based on different test results and history.\n",
    "\n",
    "> Supervised\n",
    "\n",
    "5. Grouping articles on different topics from different news sources (something like Google News app).\n",
    "\n",
    "> Unsupervised\n",
    "\n",
    "Are the following classification or regression problems?\n",
    "\n",
    "1. Predicting the price of a house based on features such as number of rooms and the year built.\n",
    "\n",
    "> Regression \n",
    "\n",
    "2. Predicting if a house will sell or not based on features like the price of the house, number of rooms, etc.\n",
    "\n",
    "> Classification \n",
    "\n",
    "3. Predicting your grade in BAIT 509 based on past grades.\n",
    "\n",
    "> Regression \n",
    "\n",
    "4. Predicting whether you should bicycle tomorrow or not based on the weather forecast.\n",
    "\n",
    "> Classification \n",
    "\n",
    "5. Predicting a cereal’s manufacturer given the nutritional information.\n",
    "\n",
    "> Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice! \n",
    "\n",
    "Using the data `candybars.csv` from the datafolder to aswer the following questions:\n",
    "\n",
    "1. How many features are there? \n",
    "\n",
    "> 8 \n",
    "\n",
    "2. How many observations are there? \n",
    "\n",
    "> 25 \n",
    "\n",
    "3. What would be a suitable target with this data?\n",
    "\n",
    "> Probably `availability` but we could use the other features as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer as either `fit`  or `predict`***\n",
    "1. Is called first (before the other one).\n",
    "\n",
    "> `fit`\n",
    "\n",
    "2. Only takes X as an argument.\n",
    "\n",
    "> `predict`\n",
    "\n",
    "3. In scikit-learn, we can ignore its output.In scikit-learn, we can ignore its output.\n",
    "\n",
    "> `fit`\n",
    "\n",
    "***Quick Questions***\n",
    "1. What is the top node in a decision tree called? \n",
    "\n",
    "> The root\n",
    "\n",
    "2. What Python structure/syntax are the nodes in a decision tree similar to? \n",
    "\n",
    "> If-else statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "candy_df = pd.read_csv('data/candybars.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min_sample_split = 2 accuracy= 0.84\n",
      "For min_sample_split = 5 accuracy= 0.68\n",
      "For min_sample_split = 10 accuracy= 0.64\n"
     ]
    }
   ],
   "source": [
    "# Define X and y\n",
    "X = candy_df.drop(columns=['availability'])\n",
    "y = candy_df['availability']\n",
    "\n",
    "# Creating a model\n",
    "for min_samples_split in [2, 5, 10]:\n",
    "    hyper_tree = DecisionTreeClassifier(random_state=1, min_samples_split=min_samples_split)\n",
    "    hyper_tree.fit(X,y)\n",
    "    print(\"For min_sample_split =\",min_samples_split, \"accuracy=\", hyper_tree.score(X, y).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. a) Which `min_samples_split` value would you choose to predict this data? <br>\n",
    "\n",
    "> It has the best accuracy with the lowest value of `min_sample_split`.\n",
    "   \n",
    "4. b) Would you choose the same `min_samples_split` value to predict new data?\n",
    "\n",
    ">  No and we will explain this next lecture. \n",
    "\n",
    "5. Do you think most of the computational effort for a decision tree takes place in the `.fit()` stage or `.predict()` stage?\n",
    "\n",
    ">  Most of the computational effort takes places in the .fit() stage, when we create the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice \n",
    "\n",
    "1. When is the most optimal time to split our data?\n",
    "\n",
    "> Before we visualize/explore it.\n",
    "\n",
    "2. Why do we split our data?\n",
    "\n",
    "> To help us assess how well our model generalizes.\n",
    "\n",
    "3. Fill in the table below:\n",
    "\n",
    "| datasets   | `.fit()` | `.score()` | `.predict()` |\n",
    "|------------|:--------:|:----------:|:------------:|\n",
    "| Train      |    ✔️     |   ✔️        |   ✔️          |\n",
    "| Validation |          |   ✔️        |     ✔️        |\n",
    "| Test       |          |    Once    |   Once       |\n",
    "| Deployment |          |            |      ✔️       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice \n",
    "\n",
    "1. We carry out cross-validation to avoid reusing the same validation set again and again. Let’s say you do 10-fold cross-validation on 1000 examples. For each fold, how many examples do you train on?\n",
    "\n",
    "> 900\n",
    "\n",
    "2. With 10-fold cross-validation, you split 1000 examples into 10-folds. For each fold, when you are done, you add up the accuracies from each fold and divide by what?\n",
    "\n",
    "> 10\n",
    "\n",
    "True/False:\n",
    "- 𝑘-fold cross-validation calls fit 𝑘 times and predict 𝑘 times.\n",
    "\n",
    "> True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice\n",
    "\n",
    "Overfitting or Underfitting:\n",
    "1. If our train accuracy is much higher than our test accuracy.\n",
    "\n",
    "> Overfitting\n",
    "\n",
    "2. If our train accuracy and our test accuracy are both low and relatively similar in value.\n",
    "\n",
    "> Underfitting\n",
    "\n",
    "3. If our model is using a Decision Tree Classifier for a classification problem with no limit on `max_depth`.\n",
    "\n",
    "> Likely overfitting\n",
    "\n",
    "\n",
    "True or False \n",
    "1. In supervised learning, the training score is always higher than the validation score.\n",
    "\n",
    "> False\n",
    "\n",
    "2. The fundamental tradeoff of ML states that as training score goes up, validation score goes down.\n",
    "\n",
    "> False\n",
    "\n",
    "3. More \"complicated\" models are more likely to overfit than \"simple\" ones.\n",
    "\n",
    "> True\n",
    "\n",
    "5. If our training score is extremely high, that means we're overfitting.\n",
    "\n",
    "> False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.002964\n",
       "score_time     0.001910\n",
       "test_score     0.832667\n",
       "train_score    0.957826\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bball_df = pd.read_csv('data/bball.csv')\n",
    "bball_df = bball_df[(bball_df['position'] =='G') | (bball_df['position'] =='F')]\n",
    "\n",
    "# Define X and y\n",
    "X = bball_df.loc[:, ['height', 'weight', 'salary']]\n",
    "y = bball_df['position']\n",
    "\n",
    "# 1. Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# 2. Create a model\n",
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# 3. Cross validate\n",
    "scores = cross_validate(model, X_train, y_train, cv=10, return_train_score=True)\n",
    "\n",
    "# 4. Covert scores into a dataframe\n",
    "scores_df = pd.DataFrame(scores)\n",
    "\n",
    "# 5. Calculate the mean value of each column\n",
    "mean_scores = scores_df.mean()\n",
    "mean_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Is your model overfitting or underfitting? \n",
    "\n",
    "> The training score is a little higher than the validation score and thus the model is overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice \n",
    "\n",
    "1. \n",
    "\n",
    "Below we have the output of `y_train.value_counts()`\n",
    "\n",
    "```\n",
    "Position\n",
    "Forward     13\n",
    "Defense      7\n",
    "Goalie       2\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "In this scenario, what would a `DummyClassifier(strategy='most_frequent')` model predict on the following observation: \n",
    "\n",
    "\n",
    "```\n",
    "   No.  Age  Height  Weight  Experience     Salary\n",
    "1   83   34     191     210          11  3200000.0\n",
    "```\n",
    "\n",
    "\n",
    ">  `Forward`\n",
    "\n",
    "\n",
    "2. \n",
    "\n",
    "When using a regression model, which of the following is not a possible return value from .score(X,y) ?\n",
    "    a) 0.0\n",
    "    b) 1.0\n",
    "    c) -0.1\n",
    "    d) 1.5\n",
    "    \n",
    "> 1.5    \n",
    "    \n",
    "3. \n",
    "\n",
    "Below are the values for `y` that were used to train  `DummyRegressor(strategy='mean')`:\n",
    "```\n",
    "Grade\n",
    "0     75\n",
    "1     80\n",
    "2     90\n",
    "3     95\n",
    "4     85\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "What value will the model predict for every example?\n",
    "\n",
    "> 85\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice\n",
    "\n",
    "\n",
    "```\n",
    "               \n",
    "       seeds   shape  sweetness   water-content      weight    fruit_veg\n",
    "0      1        0        35          84               100        fruit\n",
    "1      0        0        23          75               120        fruit\n",
    "2      1        1        15          90              1360         veg\n",
    "3      1        1         7          96               600         veg\n",
    "4      0        0        37          80                 5        fruit\n",
    "5      0        0        45          78                40        fruit  \n",
    "6      1        0        27          83               450         veg\n",
    "7      1        1        18          73                 5         veg\n",
    "8      1        1        32          80                76         veg\n",
    "9      0        0        40          83                65        fruit\n",
    "```\n",
    "\n",
    "1. Giving the table above and that we are trying to predict if each example is either a fruit or a vegetable, what would be the dimension of feature vectors in this problem?\n",
    "\n",
    "> 5 dimensions!\n",
    "\n",
    "2. Which of the following would be the feature vector for example 0. \n",
    "\n",
    "    a) `array([1,  0, 1, 1, 0, 0, 1, 1, 1, 0])`\n",
    "\n",
    "    b) `array([fruit,  fruit, veg, veg, fruit, fruit, veg, veg, veg, fruit])`\n",
    "\n",
    "    c) `array([1, 0, 35, 84, 100])`\n",
    "\n",
    "    d) `array([1, 0, 35, 84, 100,  fruit])`\n",
    "\n",
    "> c) `array([1, 0, 35, 84, 100])`\n",
    "\n",
    "3. Given the following 2 feature vectors, what is the Euclidean distance between the following two feature vectors?\n",
    "\n",
    "    ```\n",
    "    u = np.array([5, 0, 22, -11])\n",
    "    v = np.array([-1, 0, 19, -9])\n",
    "    ```\n",
    "\n",
    "> 7\n",
    "\n",
    "**True or False**     \n",
    "\n",
    "4. Analogy-based models find examples from the test set that are most similar to the test example we are predicting.\n",
    "\n",
    "> False\n",
    "\n",
    "5. Feature vectors can only be of length 3 since we cannot visualize past that.\n",
    "\n",
    "> False\n",
    "\n",
    "6. A dataset with 10 dimensions is considered low dimensional.\n",
    "\n",
    "> True\n",
    "\n",
    "7. Euclidean distance will always have a positive value.\n",
    "\n",
    "> True (0 and positive) \n",
    "8. When finding the nearest neighbour in a dataset using `kneighbors()` from the `sklearn` library, we must `fit`  the data first.\n",
    "\n",
    "> True\n",
    "\n",
    "9. Calculating the distances between an example and a query point takes twice as long as calculating the distances between two examples.\n",
    "\n",
    "> False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's practice \n",
    "\n",
    "Consider this toy dataset:\n",
    "\n",
    "$$ X = \\begin{bmatrix}5 & 2\\\\4 & 3\\\\  2 & 2\\\\ 10 & 10\\\\ 9 & -1\\\\ 9& 9\\end{bmatrix}, \\quad y = \\begin{bmatrix}0\\\\0\\\\1\\\\1\\\\1\\\\2\\end{bmatrix}.$$\n",
    "\n",
    "1. If $k=1$, what would you predict for $x=\\begin{bmatrix} 0\\\\0\\end{bmatrix}$?\n",
    "\n",
    "> 1\n",
    "\n",
    "2. If $k=3$, what would you predict for $x=\\begin{bmatrix} 0\\\\0\\end{bmatrix}$?\n",
    "\n",
    "> 0\n",
    "\n",
    "**True or False**    \n",
    "\n",
    "3. The classification of the closest neighbour to the test example always contributes the most to the prediction\n",
    "\n",
    "> False\n",
    "\n",
    "4. The `n_neighbors` hyperparameter must be less than the number of examples in the training set.\n",
    "\n",
    "> True\n",
    "\n",
    "5. Similar to decision trees, $k$-NNs find a small set of good features.\n",
    "\n",
    "> False\n",
    "\n",
    "6. With  $k$ -NN, setting the hyperparameter  $k$  to larger values typically increases training score.\n",
    "\n",
    "> False\n",
    "\n",
    "7. $k$-NN may perform poorly in high-dimensional space (say, d > 100)\n",
    "\n",
    "> True\n",
    "\n",
    "Consider this graph:\n",
    "\n",
    "<img src=\"imgs/Q18a.png\"  width = \"50%\" alt=\"404 image\" />\n",
    "\n",
    "   \n",
    "8. What value of `n_neighbors` would you choose to train your model on? \n",
    "\n",
    "> 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4 - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice\n",
    "\n",
    "$$ X = \\begin{bmatrix}5 & 2\\\\4 & 3\\\\  2 & 2\\\\ 10 & 10\\\\ 9 & -1\\\\ 9& 9\\end{bmatrix}, \\quad y = \\begin{bmatrix}0\\\\0\\\\1\\\\1\\\\1\\\\2\\end{bmatrix}.$$\n",
    "\n",
    "If $k=3$, what would you predict for $x=\\begin{bmatrix} 0\\\\0\\end{bmatrix}$ if we were doing regression rather than classification?\n",
    "\n",
    "> 1/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's practice \n",
    "\n",
    "\n",
    "**True or False** \n",
    "\n",
    "1.In Scikit Learn’s SVC classifier, large values of gamma tend to result in higher training scores but probably lower validation scores.   \n",
    "\n",
    "> True \n",
    "\n",
    "2.If we increase both `gamma` and `C`, we can't be certain if the model becomes more complex or less complex.\n",
    "\n",
    "> False\n",
    "\n",
    "**Coding practice**\n",
    "\n",
    "Below is some starter code that creates your feature table and target column from the data from the `bball.csv` dataset (in the data folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_df = pd.read_csv('data/bball.csv')\n",
    "bball_df = bball_df[(bball_df['position'] =='G') | (bball_df['position'] =='F')]\n",
    "\n",
    "# Define X and y\n",
    "X = bball_df.loc[:, ['height', 'weight', 'salary']]\n",
    "y = bball_df['position']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Split the dataset into 4 objects: `X_train`, `X_test`, `y_train`, `y_test`. Make the test set 0.2 (or the train set 0.8) and make sure to use `random_state=7`.\n",
    "2. Create an `SVM` model with `gamma` equal to 0.1 and `C` equal to 10.\n",
    "3. Cross-validate using cross_validate() on the objects X_train and y_train specifying the model and making sure to use 5 fold cross-validation and `return_train_score=True`.\n",
    "4. Calculate the mean training and cross-validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean training score is 0.996 and the mean validation score is 0.559\n"
     ]
    }
   ],
   "source": [
    "# 1. Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# 2. Create a model\n",
    "model = SVC(gamma=0.1, C=10)\n",
    "\n",
    "# 3. Cross-validate\n",
    "scores_df = pd.DataFrame(cross_validate(model,X_train,y_train, cv=5, return_train_score=True))\n",
    "\n",
    "# 4.  Calculate the mean training and cross-validation scores.\n",
    "print('The mean training score is', scores_df.mean()['train_score'].round(3), 'and the mean validation score is', scores_df.mean()['test_score'].round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! I wonder how this can be improved?! More on this in the next class :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4 - Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's practice \n",
    "\n",
    "1. Name a model that will still produce meaningful predictions with different scaled column values.\n",
    "\n",
    "> Decision Tree Classifier\n",
    "\n",
    "2. Complete the following statement: Preprocessing is done ____.  \n",
    "\n",
    "\n",
    "- To the model but before training\n",
    "- To the data before training the model\n",
    "- To the model after training\n",
    "- To the data after training the model\n",
    "\n",
    ">  To the data before training the model\n",
    "\n",
    "3. `StandardScaler` is a type of what?\n",
    "\n",
    "> Transformer\n",
    "\n",
    "4. What data splits does `StandardScaler` alter (Training, Testing, Validation, None, All)?\n",
    "\n",
    "> All\n",
    "\n",
    "**True or False**   \n",
    "\n",
    "5. Columns with lower magnitudes compared to columns with higher magnitudes are less important when making predictions.  \n",
    "\n",
    "> False\n",
    "\n",
    "6. A model less sensitive to the scale of the data makes it more robust.\n",
    "\n",
    "> True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice\n",
    "\n",
    "1. When/Why do we need to impute our data?\n",
    "\n",
    "> When we have missing data.\n",
    "\n",
    "2. If we have `NaN` values in our data, can we simply drop the column missing the data?\n",
    "\n",
    "> Yes, if the majority of the values are missing from the column\n",
    "\n",
    "\n",
    "3. Which scaling method will never produce negative values?\n",
    "\n",
    "> Normalization (`MinMaxScaler`)\n",
    "\n",
    "\n",
    "4. Which scaling method will never produce values greater than 1?\n",
    "\n",
    "> Normalization (`MinMaxScaler`)\n",
    "\n",
    "\n",
    "5. Which scaling method will produce values where the range depends on the values in the data?\n",
    "\n",
    "> Standardization (StandardScaler)\n",
    "\n",
    "\n",
    "\n",
    "**True or False**     \n",
    "6. `SimpleImputer` is a type of transformer.  \n",
    "\n",
    "> True\n",
    "\n",
    "7. Scaling is a form of transformation.   \n",
    "\n",
    "> True\n",
    "\n",
    "\n",
    "8. We can use `SimpleImputer` to impute values that are missing from numerical and categorical columns.    \n",
    "> True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which of the following steps cannot be used in a pipeline?\n",
    "    - Scaling\n",
    "    - Model building \n",
    "    - Imputation\n",
    "    - Data Splitting\n",
    "\n",
    "> Data Splitting\n",
    "\n",
    "\n",
    "2. Why can't we fit and transform the training and test data together?\n",
    "\n",
    "> It's violating the golden rule.\n",
    "\n",
    "\n",
    "**True or False**     \n",
    "3. We have to be careful of the order we put each transformation and model in a pipeline.   \n",
    "\n",
    "> True\n",
    "\n",
    "\n",
    "4. Pipelines will fit and transform on both the training and validation folds during cross-validation.\n",
    "\n",
    "> False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring in the basketball dataset again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the data\n",
    "bball_df = pd.read_csv('data/bball.csv')\n",
    "bball_df = bball_df[(bball_df['position'] =='G') | (bball_df['position'] =='F')]\n",
    "\n",
    "# Define X and y\n",
    "X = bball_df.loc[:, ['height', 'weight', 'salary']]\n",
    "y = bball_df['position']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline named `bb_pipe` that: \n",
    "1. Imputes using \"median\" as a strategy, \n",
    "2. scale using `StandardScaler` \n",
    "3. builds a `KNeighborsClassifier`.\n",
    "\n",
    "\n",
    "Next, do 5 fold cross-validation on the pipeline using `X_train` and `y_train` and save the results in an dataframe.\n",
    "Take the mean of each column and assess your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.009682\n",
       "score_time     0.006163\n",
       "test_score     0.881633\n",
       "train_score    0.915306\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a pipeline\n",
    "bb_pipe = Pipeline(\n",
    "            steps=[(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                   (\"scaler\", StandardScaler()),\n",
    "                   (\"knn\", KNeighborsClassifier())])\n",
    "\n",
    "# Do 5 fold cross-validation on the pipeline using `X_train` and `y_train` and save the results in an dataframe.\n",
    "cross_scores = pd.DataFrame(cross_validate(bb_pipe, X_train, y_train, return_train_score=True))\n",
    "\n",
    "# Transform cross_scores to a dataframe and take the mean of each column\n",
    "# Save the result in an object named mean_scores\n",
    "mean_scores = cross_scores.mean()\n",
    "mean_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice\n",
    "\n",
    "\n",
    "```\n",
    "           name    colour    location    seed   shape  sweetness   water-content  weight  popularity\n",
    "0         apple       red     canada    True   round     True          84         100      popular\n",
    "1        banana    yellow     mexico   False    long     True          75         120      popular\n",
    "2    cantaloupe    orange      spain    True   round     True          90        1360      neutral\n",
    "3  dragon-fruit   magenta      china    True   round    False          96         600      not popular\n",
    "4    elderberry    purple    austria   False   round     True          80           5      not popular\n",
    "5           fig    purple     turkey   False    oval    False          78          40      neutral\n",
    "6         guava     green     mexico    True    oval     True          83         450      neutral\n",
    "7   huckleberry      blue     canada    True   round     True          73           5      not popular\n",
    "8          kiwi     brown      china    True   round     True          80          76      popular\n",
    "9         lemon    yellow     mexico   False    oval    False          83          65      popular\n",
    "\n",
    "```\n",
    "\n",
    "1.  What would be the unique values given to the categories in the `popularity` column, if we transformed it with ordinal encoding?\n",
    "\n",
    "- `[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]`\n",
    "- `[0, 1, 2]` \n",
    "- `[1, 2, 3]`\n",
    "- `[0, 1, 2, 3]`\n",
    "\n",
    "> `[0, 1, 2]` \n",
    "\n",
    "2. Does it make sense to be doing ordinal transformations on the `colour` column?\n",
    "\n",
    "> No\n",
    "\n",
    "3. If we one hot encoded the `shape` column, what datatype would be the output after using `transform`?\n",
    "\n",
    "> NumPy array\n",
    "\n",
    "4. Which of the following outputs is the result of one-hot encoding the `shape` column?    \n",
    "\n",
    "a)    \n",
    "\n",
    "``` \n",
    "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 1],\n",
    "       [1, 0, 1, 1, 1, 0, 0, 1, 1, 0]])\n",
    "```\n",
    "\n",
    "b)    \n",
    "\n",
    "```\n",
    "array([[0, 0, 1],\n",
    "       [1, 0, 0],\n",
    "       [0, 0, 1],\n",
    "       [0, 0, 1],\n",
    "       [0, 0, 1],\n",
    "       [0, 1, 0],\n",
    "       [0, 1, 0],\n",
    "       [0, 0, 1],\n",
    "       [0, 0, 1],\n",
    "       [0, 1, 0]])\n",
    "```\n",
    "\n",
    "c)\n",
    "\n",
    "```\n",
    "array([[0, 1, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 1, 0, 0],\n",
    "       [0, 0, 0, 0, 1, 0],\n",
    "       [0, 0, 1, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0, 0],\n",
    "       [0, 0, 0, 0, 0, 1],\n",
    "       [0, 0, 0, 1, 0, 0],\n",
    "       [0, 1, 0, 0, 0, 0],\n",
    "       [0, 0, 1, 0, 0, 0],\n",
    "       [0, 0, 0, 1, 0, 0]])\n",
    "```\n",
    "\n",
    "d) \n",
    "\n",
    "```\n",
    "array([[0],\n",
    "       [5],\n",
    "       [0],\n",
    "       [3],\n",
    "       [0],\n",
    "       [0],\n",
    "       [3],\n",
    "       [0],\n",
    "       [5],\n",
    "       [3],\n",
    "       [1],\n",
    "       [4],\n",
    "       [3],\n",
    "       [2]])\n",
    "\n",
    "```\n",
    "\n",
    "> B\n",
    "\n",
    "5. On which column(s) would you use `OneHotEncoder(sparse=False, dtype=int, drop=\"if_binary\")`?\n",
    "\n",
    "> `seed`, `sweetness`\n",
    "\n",
    "\n",
    "**True or False?**    \n",
    "    \n",
    "6. Whenever we have categorical values, we should use ordinal encoding. \n",
    "\n",
    "> False\n",
    "\n",
    "7. If we include categorical values in our feature table, `sklearn` will throw an error.\n",
    "\n",
    "> True\n",
    "\n",
    "8. One-hot encoding a column with 5 unique categories will produce 5 new transformed columns.\n",
    "\n",
    "> True\n",
    "\n",
    "\n",
    "9. The values in the new transformed columns after one-hot encoding, are all possible integer or float values.\n",
    "\n",
    "> False\n",
    "\n",
    "10. It’s important to be mindful of the consequences of including certain features in your predictive model.\n",
    "\n",
    "> True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice \n",
    "\n",
    "\n",
    "Refer to the dataframe to answer the following question.\n",
    "```\n",
    "       colour   location    shape   water_content  weight\n",
    "0       red      canada      NaN         84          100\n",
    "1     yellow     mexico     long         75          120\n",
    "2     orange     spain       NaN         90          NaN\n",
    "3    magenta     china      round        NaN         600\n",
    "4     purple    austria      NaN         80          115\n",
    "5     purple    turkey      oval         78          340\n",
    "6     green     mexico      oval         83          NaN\n",
    "7      blue     canada      round        73          535\n",
    "8     brown     china        NaN         NaN        1743  \n",
    "9     yellow    mexico      oval         83          265\n",
    "```\n",
    "\n",
    "<br>\n",
    " \n",
    "1. How many categorical columns are there and how many numeric?\n",
    "\n",
    "> 3 categoric columns and 2 numeric columns\n",
    "\n",
    "2. What transformations are being done to both numeric and categorical columns?\n",
    "\n",
    "> Imputation\n",
    "\n",
    "\n",
    "Use the diagram below to answer the following questions.\n",
    "\n",
    "```\n",
    "Pipeline(\n",
    "    steps=[('columntransformer',\n",
    "               ColumnTransformer(\n",
    "                  transformers=[('pipeline-1',\n",
    "                                  Pipeline(\n",
    "                                    steps=[('simpleimputer',\n",
    "                                             SimpleImputer(strategy='median')),\n",
    "                                           ('standardscaler',\n",
    "                                             StandardScaler())]),\n",
    "                      ['water_content', 'weight', 'carbs']),\n",
    "                                ('pipeline-2',\n",
    "                                  Pipeline(\n",
    "                                    steps=[('simpleimputer',\n",
    "                                             SimpleImputer(fill_value='missing',\n",
    "                                                                strategy='constant')),\n",
    "                                           ('onehotencoder',\n",
    "                                             OneHotEncoder(handle_unknown='ignore'))]),\n",
    "                      ['colour', 'location', 'seed', 'shape', 'sweetness',\n",
    "                                                   'tropical'])])),\n",
    "         ('decisiontreeclassifier', DecisionTreeClassifier())])\n",
    "```\n",
    "\n",
    "3. How many columns are being transformed in `pipeline-1`?\n",
    "\n",
    "> 3\n",
    "\n",
    "4. Which pipeline is transforming the categorical columns?\n",
    "\n",
    "> pipeline-2\n",
    "\n",
    "5. What model is the pipeline fitting on?\n",
    "\n",
    "> DecisionTreeClassifier\n",
    "\n",
    "**True or False**     \n",
    "6. If there are missing values in both numeric and categorical columns, we can specify this in a single step in the main pipeline.   \n",
    "\n",
    "> False\n",
    "\n",
    "7. If we do not specify `remainder=\"passthrough\"` as an argument in `ColumnTransformer`, the columns not being transformed will be dropped.\n",
    "\n",
    "> True\n",
    "\n",
    "8. `Pipeline()` is the same as `make_pipeline()` but  `make_pipeline()` requires you to name the steps.\n",
    "\n",
    "> False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice\n",
    "\n",
    "1. \n",
    "What is the size of the vocabulary for the examples below?\n",
    "\n",
    "```\n",
    "X = [ \"Take me to the river\",\n",
    "    \"Drop me in the water\",\n",
    "    \"Push me in the river\",\n",
    "    \"dip me in the water\"]\n",
    "```\n",
    "\n",
    "> 10\n",
    "\n",
    "\n",
    "2. \n",
    "\n",
    "Which of the following is not a hyperparameter of `CountVectorizer()`?   \n",
    "- `binary`\n",
    "- `max_features` \n",
    "- `vocab`\n",
    "- `ngram_range`\n",
    "\n",
    ">  `vocab`\n",
    "\n",
    "3. What kind of representation do we use for our vocabulary? \n",
    "\n",
    "> Bag of Words \n",
    "\n",
    "**True or False**     \n",
    "\n",
    "4. As you increase the value for the `max_features` hyperparameter of `CountVectorizer`, the training score is likely to go up.\n",
    "\n",
    "> True \n",
    "\n",
    "5. If we encounter a word in the validation or the test split that's not available in the training data, we'll get an error.\n",
    "\n",
    "> False \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Practice \n",
    "\n",
    "We are going to bring in a new dataset for you to practice on. (Make sure you've downloaded it from the `data` folder from the `lectures` section in Canvas). \n",
    "\n",
    "This dataset contains a text column containing tweets associated with disaster keywords and a target column denoting whether a tweet is about a real disaster (1) or not (0). [[Source](Source)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3219    Buri handwoven bags : • Buri handbag - Php 280...\n",
       "3825    Energetic and Comedic Redhead Teen, just seen ...\n",
       "1544    A 63 year old man charged in connection with a...\n",
       "1050    Water levels in Venice drastically drop two mo...\n",
       "296     2 buildings on fire at seminole State College ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in the data\n",
    "tweets_df = pd.read_csv('data/balanced_tweets.csv').dropna(subset=['target'])\n",
    "\n",
    "# Split the dataset into the feature table `X` and the target value `y`\n",
    "X = tweets_df['text']\n",
    "y = tweets_df['target']\n",
    "\n",
    "# Split the dataset into X_train, X_test, y_train, y_test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=7)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make a pipeline with `CountVectorizer` as the first step and `SVC()` as the second.\n",
    "2. Perform 5 fold cross-validation using your pipeline and return the training score. \n",
    "3. Convert the results into a dataframe. \n",
    "4. What are the mean training and validation scores? \n",
    "5. Train your pipeline on the training set.\n",
    "6. Score the pipeline  on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean training score: 0.9821853538313572\n",
      "Mean Validation score: 0.8326422696721526\n",
      "Test score: 0.83451536643026\n"
     ]
    }
   ],
   "source": [
    "# 1. Make a pipeline with `CountVectorizer` as the first step and `SVC()` as the second\n",
    "pipe = make_pipeline(CountVectorizer(), SVC())\n",
    "\n",
    "# 2. Perform 5 fold cross-validation using your pipeline and return the training score\n",
    "cv_scores = cross_validate(pipe, X_train, y_train, return_train_score=True)\n",
    "\n",
    "# 3. Convert the results into a dataframe\n",
    "cv_scores_df = pd.DataFrame(cv_scores)\n",
    "\n",
    "# 4. What are the mean training and validation scores?\n",
    "print('Mean training score:', cv_scores_df.mean()['train_score'])\n",
    "print('Mean Validation score:', cv_scores_df.mean()['test_score'])\n",
    "\n",
    "# 5. Train your pipeline on the training set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# 6. Score the pipeline  on the test set\n",
    "tweet_test_score = pipe.score(X_test, y_test)\n",
    "print('Test score:', tweet_test_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
