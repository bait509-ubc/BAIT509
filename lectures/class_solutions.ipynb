{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice! \n",
    "\n",
    "Are the following supervised or unsupervised problems?\n",
    "\n",
    "1. Finding groups of similar properties in a real estate data set.\n",
    "\n",
    "> Unsupervised\n",
    "\n",
    "2. Predicting real estate prices based on house features like number of rooms, learning from past sales as examples.\n",
    "\n",
    "> Supervised\n",
    "\n",
    "3. Identifying groups of animals given features such as \"number of legs\", \"wings/no wings\", \"fur/no fur\", etc.\n",
    "\n",
    "> Unsupervised\n",
    "\n",
    "4. Detecting heart disease in patients based on different test results and history.\n",
    "\n",
    "> Supervised\n",
    "\n",
    "5. Grouping articles on different topics from different news sources (something like Google News app).\n",
    "\n",
    "> Unsupervised\n",
    "\n",
    "Are the following classification or regression problems?\n",
    "\n",
    "1. Predicting the price of a house based on features such as number of rooms and the year built.\n",
    "\n",
    "> Regression \n",
    "\n",
    "2. Predicting if a house will sell or not based on features like the price of the house, number of rooms, etc.\n",
    "\n",
    "> Classification \n",
    "\n",
    "3. Predicting your grade in BAIT 509 based on past grades.\n",
    "\n",
    "> Regression \n",
    "\n",
    "4. Predicting whether you should bicycle tomorrow or not based on the weather forecast.\n",
    "\n",
    "> Classification \n",
    "\n",
    "5. Predicting a cereal’s manufacturer given the nutritional information.\n",
    "\n",
    "> Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice! \n",
    "\n",
    "Using the data `candybars.csv` from the datafolder to aswer the following questions:\n",
    "\n",
    "1. How many features are there? \n",
    "\n",
    "> 8 \n",
    "\n",
    "2. How many observations are there? \n",
    "\n",
    "> 25 \n",
    "\n",
    "3. What would be a suitable target with this data?\n",
    "\n",
    "> Probably `availability` but we could use the other features as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer as either `fit`  or `predict`***\n",
    "1. Is called first (before the other one).\n",
    "\n",
    "> `fit`\n",
    "\n",
    "2. Only takes X as an argument.\n",
    "\n",
    "> `predict`\n",
    "\n",
    "3. In scikit-learn, we can ignore its output.In scikit-learn, we can ignore its output.\n",
    "\n",
    "> `fit`\n",
    "\n",
    "***Quick Questions***\n",
    "1. What is the top node in a decision tree called? \n",
    "\n",
    "> The root\n",
    "\n",
    "2. What Python structure/syntax are the nodes in a decision tree similar to? \n",
    "\n",
    "> If-else statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "candy_df = pd.read_csv('data/candybars.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For min_sample_split = 2 accuracy= 0.84\n",
      "For min_sample_split = 5 accuracy= 0.68\n",
      "For min_sample_split = 10 accuracy= 0.64\n"
     ]
    }
   ],
   "source": [
    "# Define X and y\n",
    "X = candy_df.drop(columns=['availability'])\n",
    "y = candy_df['availability']\n",
    "\n",
    "# Creating a model\n",
    "for min_samples_split in [2, 5, 10]:\n",
    "    hyper_tree = DecisionTreeClassifier(random_state=1, min_samples_split=min_samples_split)\n",
    "    hyper_tree.fit(X,y)\n",
    "    print(\"For min_sample_split =\",min_samples_split, \"accuracy=\", hyper_tree.score(X, y).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. a) Which `min_samples_split` value would you choose to predict this data? <br>\n",
    "\n",
    "> It has the best accuracy with the lowest value of `min_sample_split`.\n",
    "   \n",
    "4. b) Would you choose the same `min_samples_split` value to predict new data?\n",
    "\n",
    ">  No and we will explain this next lecture. \n",
    "\n",
    "5. Do you think most of the computational effort for a decision tree takes place in the `.fit()` stage or `.predict()` stage?\n",
    "\n",
    ">  Most of the computational effort takes places in the .fit() stage, when we create the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice \n",
    "\n",
    "1. When is the most optimal time to split our data?\n",
    "\n",
    "> Before we visualize/explore it.\n",
    "\n",
    "2. Why do we split our data?\n",
    "\n",
    "> To help us assess how well our model generalizes.\n",
    "\n",
    "3. Fill in the table below:\n",
    "\n",
    "| datasets   | `.fit()` | `.score()` | `.predict()` |\n",
    "|------------|:--------:|:----------:|:------------:|\n",
    "| Train      |    ✔️     |   ✔️        |   ✔️          |\n",
    "| Validation |          |   ✔️        |     ✔️        |\n",
    "| Test       |          |    Once    |   Once       |\n",
    "| Deployment |          |            |      ✔️       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice \n",
    "\n",
    "1. We carry out cross-validation to avoid reusing the same validation set again and again. Let’s say you do 10-fold cross-validation on 1000 examples. For each fold, how many examples do you train on?\n",
    "\n",
    "> 900\n",
    "\n",
    "2. With 10-fold cross-validation, you split 1000 examples into 10-folds. For each fold, when you are done, you add up the accuracies from each fold and divide by what?\n",
    "\n",
    "> 10\n",
    "\n",
    "True/False:\n",
    "- 𝑘-fold cross-validation calls fit 𝑘 times and predict 𝑘 times.\n",
    "\n",
    "> True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice\n",
    "\n",
    "Overfitting or Underfitting:\n",
    "1. If our train accuracy is much higher than our test accuracy.\n",
    "\n",
    "> Overfitting\n",
    "\n",
    "2. If our train accuracy and our test accuracy are both low and relatively similar in value.\n",
    "\n",
    "> Underfitting\n",
    "\n",
    "3. If our model is using a Decision Tree Classifier for a classification problem with no limit on `max_depth`.\n",
    "\n",
    "> Likely overfitting\n",
    "\n",
    "\n",
    "True or False \n",
    "1. In supervised learning, the training score is always higher than the validation score.\n",
    "\n",
    "> False\n",
    "\n",
    "2. The fundamental tradeoff of ML states that as training score goes up, validation score goes down.\n",
    "\n",
    "> False\n",
    "\n",
    "3. More \"complicated\" models are more likely to overfit than \"simple\" ones.\n",
    "\n",
    "> True\n",
    "\n",
    "5. If our training score is extremely high, that means we're overfitting.\n",
    "\n",
    "> False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.002964\n",
       "score_time     0.001910\n",
       "test_score     0.832667\n",
       "train_score    0.957826\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bball_df = pd.read_csv('data/bball.csv')\n",
    "bball_df = bball_df[(bball_df['position'] =='G') | (bball_df['position'] =='F')]\n",
    "\n",
    "# Define X and y\n",
    "X = bball_df.loc[:, ['height', 'weight', 'salary']]\n",
    "y = bball_df['position']\n",
    "\n",
    "# 1. Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# 2. Create a model\n",
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# 3. Cross validate\n",
    "scores = cross_validate(model, X_train, y_train, cv=10, return_train_score=True)\n",
    "\n",
    "# 4. Covert scores into a dataframe\n",
    "scores_df = pd.DataFrame(scores)\n",
    "\n",
    "# 5. Calculate the mean value of each column\n",
    "mean_scores = scores_df.mean()\n",
    "mean_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Is your model overfitting or underfitting? \n",
    "\n",
    "> The training score is a little higher than the validation score and thus the model is overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice \n",
    "\n",
    "1. \n",
    "\n",
    "Below we have the output of `y_train.value_counts()`\n",
    "\n",
    "```\n",
    "Position\n",
    "Forward     13\n",
    "Defense      7\n",
    "Goalie       2\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "In this scenario, what would a `DummyClassifier(strategy='most_frequent')` model predict on the following observation: \n",
    "\n",
    "\n",
    "```\n",
    "   No.  Age  Height  Weight  Experience     Salary\n",
    "1   83   34     191     210          11  3200000.0\n",
    "```\n",
    "\n",
    "\n",
    ">  `Forward`\n",
    "\n",
    "\n",
    "2. \n",
    "\n",
    "When using a regression model, which of the following is not a possible return value from .score(X,y) ?\n",
    "    a) 0.0\n",
    "    b) 1.0\n",
    "    c) -0.1\n",
    "    d) 1.5\n",
    "    \n",
    "> 1.5    \n",
    "    \n",
    "3. \n",
    "\n",
    "Below are the values for `y` that were used to train  `DummyRegressor(strategy='mean')`:\n",
    "```\n",
    "Grade\n",
    "0     75\n",
    "1     80\n",
    "2     90\n",
    "3     95\n",
    "4     85\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "What value will the model predict for every example?\n",
    "\n",
    "> 85\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice\n",
    "\n",
    "\n",
    "```\n",
    "               \n",
    "       seeds   shape  sweetness   water-content      weight    fruit_veg\n",
    "0      1        0        35          84               100        fruit\n",
    "1      0        0        23          75               120        fruit\n",
    "2      1        1        15          90              1360         veg\n",
    "3      1        1         7          96               600         veg\n",
    "4      0        0        37          80                 5        fruit\n",
    "5      0        0        45          78                40        fruit  \n",
    "6      1        0        27          83               450         veg\n",
    "7      1        1        18          73                 5         veg\n",
    "8      1        1        32          80                76         veg\n",
    "9      0        0        40          83                65        fruit\n",
    "```\n",
    "\n",
    "1. Giving the table above and that we are trying to predict if each example is either a fruit or a vegetable, what would be the dimension of feature vectors in this problem?\n",
    "\n",
    "> 5 dimensions!\n",
    "\n",
    "2. Which of the following would be the feature vector for example 0. \n",
    "\n",
    "    a) `array([1,  0, 1, 1, 0, 0, 1, 1, 1, 0])`\n",
    "\n",
    "    b) `array([fruit,  fruit, veg, veg, fruit, fruit, veg, veg, veg, fruit])`\n",
    "\n",
    "    c) `array([1, 0, 35, 84, 100])`\n",
    "\n",
    "    d) `array([1, 0, 35, 84, 100,  fruit])`\n",
    "\n",
    "> c) `array([1, 0, 35, 84, 100])`\n",
    "\n",
    "3. Given the following 2 feature vectors, what is the Euclidean distance between the following two feature vectors?\n",
    "\n",
    "    ```\n",
    "    u = np.array([5, 0, 22, -11])\n",
    "    v = np.array([-1, 0, 19, -9])\n",
    "    ```\n",
    "\n",
    "> 7\n",
    "\n",
    "**True or False**     \n",
    "\n",
    "4. Analogy-based models find examples from the test set that are most similar to the test example we are predicting.\n",
    "\n",
    "> False\n",
    "\n",
    "5. Feature vectors can only be of length 3 since we cannot visualize past that.\n",
    "\n",
    "> False\n",
    "\n",
    "6. A dataset with 10 dimensions is considered low dimensional.\n",
    "\n",
    "> True\n",
    "\n",
    "7. Euclidean distance will always have a positive value.\n",
    "\n",
    "> True (0 and positive) \n",
    "8. When finding the nearest neighbour in a dataset using `kneighbors()` from the `sklearn` library, we must `fit`  the data first.\n",
    "\n",
    "> True\n",
    "\n",
    "9. Calculating the distances between an example and a query point takes twice as long as calculating the distances between two examples.\n",
    "\n",
    "> False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's practice \n",
    "\n",
    "Consider this toy dataset:\n",
    "\n",
    "$$ X = \\begin{bmatrix}5 & 2\\\\4 & 3\\\\  2 & 2\\\\ 10 & 10\\\\ 9 & -1\\\\ 9& 9\\end{bmatrix}, \\quad y = \\begin{bmatrix}0\\\\0\\\\1\\\\1\\\\1\\\\2\\end{bmatrix}.$$\n",
    "\n",
    "1. If $k=1$, what would you predict for $x=\\begin{bmatrix} 0\\\\0\\end{bmatrix}$?\n",
    "\n",
    "> 1\n",
    "\n",
    "2. If $k=3$, what would you predict for $x=\\begin{bmatrix} 0\\\\0\\end{bmatrix}$?\n",
    "\n",
    "> 0\n",
    "\n",
    "**True or False**    \n",
    "\n",
    "3. The classification of the closest neighbour to the test example always contributes the most to the prediction\n",
    "\n",
    "> False\n",
    "\n",
    "4. The `n_neighbors` hyperparameter must be less than the number of examples in the training set.\n",
    "\n",
    "> True\n",
    "\n",
    "5. Similar to decision trees, $k$-NNs find a small set of good features.\n",
    "\n",
    "> False\n",
    "\n",
    "6. With  $k$ -NN, setting the hyperparameter  $k$  to larger values typically increases training score.\n",
    "\n",
    "> False\n",
    "\n",
    "7. $k$-NN may perform poorly in high-dimensional space (say, d > 100)\n",
    "\n",
    "> True\n",
    "\n",
    "Consider this graph:\n",
    "\n",
    "<img src=\"imgs/Q18a.png\"  width = \"50%\" alt=\"404 image\" />\n",
    "\n",
    "   \n",
    "8. What value of `n_neighbors` would you choose to train your model on? \n",
    "\n",
    "> 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 4 - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice\n",
    "\n",
    "$$ X = \\begin{bmatrix}5 & 2\\\\4 & 3\\\\  2 & 2\\\\ 10 & 10\\\\ 9 & -1\\\\ 9& 9\\end{bmatrix}, \\quad y = \\begin{bmatrix}0\\\\0\\\\1\\\\1\\\\1\\\\2\\end{bmatrix}.$$\n",
    "\n",
    "If $k=3$, what would you predict for $x=\\begin{bmatrix} 0\\\\0\\end{bmatrix}$ if we were doing regression rather than classification?\n",
    "\n",
    "> 1/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's practice \n",
    "\n",
    "\n",
    "**True or False** \n",
    "\n",
    "1.In Scikit Learn’s SVC classifier, large values of gamma tend to result in higher training scores but probably lower validation scores.   \n",
    "\n",
    "> True \n",
    "\n",
    "2.If we increase both `gamma` and `C`, we can't be certain if the model becomes more complex or less complex.\n",
    "\n",
    "> False\n",
    "\n",
    "**Coding practice**\n",
    "\n",
    "Below is some starter code that creates your feature table and target column from the data from the `bball.csv` dataset (in the data folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_df = pd.read_csv('data/bball.csv')\n",
    "bball_df = bball_df[(bball_df['position'] =='G') | (bball_df['position'] =='F')]\n",
    "\n",
    "# Define X and y\n",
    "X = bball_df.loc[:, ['height', 'weight', 'salary']]\n",
    "y = bball_df['position']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Split the dataset into 4 objects: `X_train`, `X_test`, `y_train`, `y_test`. Make the test set 0.2 (or the train set 0.8) and make sure to use `random_state=7`.\n",
    "2. Create an `SVM` model with `gamma` equal to 0.1 and `C` equal to 10.\n",
    "3. Cross-validate using cross_validate() on the objects X_train and y_train specifying the model and making sure to use 5 fold cross-validation and `return_train_score=True`.\n",
    "4. Calculate the mean training and cross-validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean training score is 0.996 and the mean validation score is 0.559\n"
     ]
    }
   ],
   "source": [
    "# 1. Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# 2. Create a model\n",
    "model = SVC(gamma=0.1, C=10)\n",
    "\n",
    "# 3. Cross-validate\n",
    "scores_df = pd.DataFrame(cross_validate(model,X_train,y_train, cv=5, return_train_score=True))\n",
    "\n",
    "# 4.  Calculate the mean training and cross-validation scores.\n",
    "print('The mean training score is', scores_df.mean()['train_score'].round(3), 'and the mean validation score is', scores_df.mean()['test_score'].round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! I wonder how this can be improved?! More on this in the next class :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 4 - Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's practice \n",
    "\n",
    "1. Name a model that will still produce meaningful predictions with different scaled column values.\n",
    "\n",
    "> Decision Tree Classifier\n",
    "\n",
    "2. Complete the following statement: Preprocessing is done ____.  \n",
    "\n",
    "\n",
    "- To the model but before training\n",
    "- To the data before training the model\n",
    "- To the model after training\n",
    "- To the data after training the model\n",
    "\n",
    ">  To the data before training the model\n",
    "\n",
    "3. `StandardScaler` is a type of what?\n",
    "\n",
    "> Transformer\n",
    "\n",
    "4. What data splits does `StandardScaler` alter (Training, Testing, Validation, None, All)?\n",
    "\n",
    "> All\n",
    "\n",
    "**True or False**   \n",
    "\n",
    "5. Columns with lower magnitudes compared to columns with higher magnitudes are less important when making predictions.  \n",
    "\n",
    "> False\n",
    "\n",
    "6. A model less sensitive to the scale of the data makes it more robust.\n",
    "\n",
    "> True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Practice\n",
    "\n",
    "1. When/Why do we need to impute our data?\n",
    "\n",
    "> When we have missing data.\n",
    "\n",
    "2. If we have `NaN` values in our data, can we simply drop the column missing the data?\n",
    "\n",
    "> Yes, if the majority of the values are missing from the column\n",
    "\n",
    "\n",
    "3. Which scaling method will never produce negative values?\n",
    "\n",
    "> Normalization (`MinMaxScaler`)\n",
    "\n",
    "\n",
    "4. Which scaling method will never produce values greater than 1?\n",
    "\n",
    "> Normalization (`MinMaxScaler`)\n",
    "\n",
    "\n",
    "5. Which scaling method will produce values where the range depends on the values in the data?\n",
    "\n",
    "> Standardization (StandardScaler)\n",
    "\n",
    "\n",
    "\n",
    "**True or False**     \n",
    "6. `SimpleImputer` is a type of transformer.  \n",
    "\n",
    "> True\n",
    "\n",
    "7. Scaling is a form of transformation.   \n",
    "\n",
    "> True\n",
    "\n",
    "\n",
    "8. We can use `SimpleImputer` to impute values that are missing from numerical and categorical columns.    \n",
    "> True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which of the following steps cannot be used in a pipeline?\n",
    "    - Scaling\n",
    "    - Model building \n",
    "    - Imputation\n",
    "    - Data Splitting\n",
    "\n",
    "> Data Splitting\n",
    "\n",
    "\n",
    "2. Why can't we fit and transform the training and test data together?\n",
    "\n",
    "> It's violating the golden rule.\n",
    "\n",
    "\n",
    "**True or False**     \n",
    "3. We have to be careful of the order we put each transformation and model in a pipeline.   \n",
    "\n",
    "> True\n",
    "\n",
    "\n",
    "4. Pipelines will fit and transform on both the training and validation folds during cross-validation.\n",
    "\n",
    "> False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring in the basketball dataset again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the data\n",
    "bball_df = pd.read_csv('data/bball.csv')\n",
    "bball_df = bball_df[(bball_df['position'] =='G') | (bball_df['position'] =='F')]\n",
    "\n",
    "# Define X and y\n",
    "X = bball_df.loc[:, ['height', 'weight', 'salary']]\n",
    "y = bball_df['position']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline named `bb_pipe` that: \n",
    "1. Imputes using \"median\" as a strategy, \n",
    "2. scale using `StandardScaler` \n",
    "3. builds a `KNeighborsClassifier`.\n",
    "\n",
    "\n",
    "Next, do 5 fold cross-validation on the pipeline using `X_train` and `y_train` and save the results in an dataframe.\n",
    "Take the mean of each column and assess your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.006609\n",
       "score_time     0.005555\n",
       "test_score     0.881633\n",
       "train_score    0.915306\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a pipeline\n",
    "bb_pipe = Pipeline(\n",
    "            steps=[(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                   (\"scaler\", StandardScaler()),\n",
    "                   (\"knn\", KNeighborsClassifier())])\n",
    "\n",
    "# Do 5 fold cross-validation on the pipeline using `X_train` and `y_train` and save the results in an dataframe.\n",
    "cross_scores = pd.DataFrame(cross_validate(bb_pipe, X_train, y_train, return_train_score=True))\n",
    "\n",
    "# Transform cross_scores to a dataframe and take the mean of each column\n",
    "# Save the result in an object named mean_scores\n",
    "mean_scores = cross_scores.mean()\n",
    "mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
